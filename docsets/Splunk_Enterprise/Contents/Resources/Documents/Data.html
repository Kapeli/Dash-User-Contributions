<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:og="http://ogp.me/ns#" xmlns:fb="http://ogp.me/ns/fb#" charset="utf-8"><head><meta charset="UTF-8"><title></title>
<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" type="text/css" href="css/main.css">
<link rel="stylesheet" href="css/style.css">
<style>
html,body {
margin: 0px;
padding: 10px;
width: 210mm;
max-width: 210mm;
overflow-x: hidden;
}
pre {
	width: 100%;
	overflow-x: hidden;
}
</style>
 <script src="js/prefixfree.min.js"></script>
 </head><body><h1>Introduction</h1><a name="whatsplunkcanmonitor"></a><div class="all-questions">
<h2> <a name="whatsplunkcanmonitor_what_splunk_enterprise_can_index"><span class="mw-headline" id="What_Splunk_Enterprise_can_index"> What Splunk Enterprise can index</span></a></h2>
<p>The first step in using Splunk Enterprise is to feed it data. Once Splunk Enterprise gets some data, it immediately indexes it and makes it available for searching. With its universal indexing ability, Splunk Enterprise transforms your data into a series of <b>events</b> that consist of searchable fields. You can massage the data before and after Splunk indexes it, but this is usually not necessary.  
</p><p>Basically, you point Splunk Enterprise at data and in moments, you can start searching the data, or use it to create charts, reports, alerts, and other interesting outputs.
</p>

<h3> <a name="whatsplunkcanmonitor_what_kind_of_data.3f"><span class="mw-headline" id="What_kind_of_data.3F"> What kind of data?</span></a></h3>
<p>Any data. In particular, any and all IT streaming, machine, and historical data. Stuff like Windows event logs, web server logs, live application logs, network feeds, system metrics, change monitoring, message queues, archive files, or anything else of interest. Any data. Really.
</p><p>Point Splunk Enterprise at a data source. Tell it a bit about the source. That source then becomes a data input. Splunk Enterprise begins to index the data stream, transforming it into a series of individual events. You can view and search those events right away. If the results aren't exactly what you want, you can tweak the indexing process until it is.
</p><p>The data can be on the same machine as the Splunk Enterprise <b>indexer</b> (<b>local data</b>), or it can be on another machine altogether (<b>remote data</b>). You can easily get remote data into Splunk Enterprise, either by using network feeds or by installing Splunk <b>forwarders</b> on the machines where the data originates. Forwarders are lightweight versions of Splunk that consume data and then forward it on to the main Splunk Enterprise instance for indexing and searching. For more information on local vs. remote data, see <a href="#whereismydata" class="external text">"Where is my data?"</a>.
</p><p>To make the job easier, Splunk offers lots of free <b>apps</b> and <b>add-ons</b>, with pre-configured inputs for things like Windows- or Linux-specific data sources, Cisco security data, Blue Coat data, and so on. Look in Splunkbase for an app or add-on that fits your needs.  Splunk also comes with dozens of recipes for data sources like web server logs, Java 2 Platform, Enterprise Edition (J2EE) logs, or Windows performance metrics. You can get to these from the <b>Add data</b> section of Splunk Web, described later. If the recipes and apps don't cover your needs, then you can use the general input configuration capabilities of Splunk Enterprise to specify your particular data source. These generic data sources are discussed <a href="#whatsplunkcanmonitor_types_of_data_sources" class="external text">here</a>.
</p>
<h3> <a name="whatsplunkcanmonitor_how_to_specify_data_inputs"><span class="mw-headline" id="How_to_specify_data_inputs">How to specify data inputs</span></a></h3>
<p>You add new types of data to Splunk Enterprise by specifying them. There are a number of ways you can specify a data input:
</p>
<ul><li> <b>Apps.</b> Splunk has a large and growing variety of apps and add-ons that offer preconfigured inputs for various types of data sources. Take advantage of Splunk apps and free yourself from having to configure the inputs yourself. For more information, see <a href="#usingapps" class="external text">"Use apps"</a>. 
</li></ul><ul><li> <b>Splunk Web.</b> You can configure most inputs using the <b>Splunk Web</b> data input pages. These provide a GUI-based approach to configuring inputs. You can access the <b>Add data</b> landing page from either Splunk Home or the <b>System</b> menu. See <a href="#configureyourinputs_use_splunk_web" class="external text">"Use Splunk Web"</a>.
</li></ul><ul><li> <b>The Splunk CLI.</b> You can use the CLI (command line interface) to configure most types of inputs. See <a href="#configureyourinputs_use_the_cli" class="external text">"Use the CLI"</a>.
</li></ul><ul><li> <b>The inputs.conf configuration file.</b> When you specify your inputs with Splunk Web or the CLI, the configurations get saved in a configuration file called inputs.conf. You can edit that file directly, if you prefer. To handle some advanced data input requirements, you might need to edit it. See <a href="#configureyourinputs_edit_inputsconf" class="external text">"Edit inputs.conf"</a>.
</li></ul><p>In addition, if you use forwarders to send data from outlying machines to a central indexer, you can specify some inputs during forwarder installation. See <a href="#usingforwardingagents" class="external text">"Use forwarders"</a>. 
</p><p>For more information on configuring inputs, see <a href="#configureyourinputs" class="external text">"Configure your inputs"</a>.
</p>
<h3> <a name="whatsplunkcanmonitor_types_of_data_sources"><span class="mw-headline" id="Types_of_data_sources"> Types of data sources </span></a></h3>
<p>As described earlier, Splunk provides tools to configure all sorts of data inputs, including many that are specific to particular application needs. Splunk also provides the tools to configure any arbitrary data input types. In general, you can categorize Splunk inputs as follows:
</p>
<ul><li>Files and directories
</li><li>Network events
</li><li>Windows sources
</li><li>Other sources
</li></ul><h4><font size="3"><b><i> <a name="whatsplunkcanmonitor_files_and_directories"><span class="mw-headline" id="Files_and_directories"> Files and directories </span></a></i></b></font></h4>
<p>A lot of the data you might be interested in comes directly from files and directories. For the most part, you can use the Splunk Enterprise <b>files and directories monitor</b> input processor to get data from files and directories.  
</p><p>To monitor files and directories, see <a href="#monitorfilesanddirectories" class="external text">"Get data from files and directories"</a>.
</p>
<h4><font size="3"><b><i> <a name="whatsplunkcanmonitor_network_events"><span class="mw-headline" id="Network_events"> Network events </span></a></i></b></font></h4>
<p>Splunk Enterprise can index data from any network port. For example, Splunk can index remote data from <code><font size="2">syslog-ng</font></code> or any other application that transmits via TCP. It can also index UDP data, but we recommend using TCP instead whenever possible, for enhanced reliability. 
</p><p>Splunk Enterprise can also receive and index SNMP events, alerts fired off by remote devices.
</p><p>To get data from network ports, see <a href="#monitornetworkports" class="external text">"Get data from TCP and UDP ports"</a>.
</p><p>To get SNMP data, see <a href="#sendsnmpeventstosplunk" class="external text">"Send SNMP events to Splunk"</a>.
</p>
<h4><font size="3"><b><i> <a name="whatsplunkcanmonitor_windows_sources"><span class="mw-headline" id="Windows_sources"> Windows sources </span></a></i></b></font></h4>
<p>The Windows version of Splunk Enterprise includes a wide range of Windows-specific inputs. It also provides pages in Splunk System for defining the Windows-specific input types listed below:  
</p>
<ul><li> <a href="#monitorwindowsdata" class="external text">Windows Event Log data</a>
</li><li> <a href="#monitorwindowsregistrydata" class="external text">Windows Registry data</a>
</li><li> <a href="#monitorwmidata" class="external text">WMI data</a>
</li><li> <a href="#auditactivedirectory" class="external text">Active Directory data</a>
</li><li> <a href="#real-timewindowsperformancemonitoring" class="external text">Performance monitoring data</a>
</li></ul><p><b>Important:</b> To index and search Windows data on a non-Windows instance of Splunk Enterprise, you must first use a Windows instance to gather the data. See <a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">"Considerations for deciding how to monitor remote Windows data"</a> for details.
</p><p>For a more detailed introduction to using Windows data in Splunk Enterprise, see <a href="#aboutwindowsdataandsplunk" class="external text">"About Windows data and Splunk Enterprise"</a>.
</p>
<h4><font size="3"><b><i> <a name="whatsplunkcanmonitor_other_sources"><span class="mw-headline" id="Other_sources">Other sources</span></a></i></b></font></h4>
<p>Splunk Enterprise also supports other kinds of data sources. For example:
</p>
<ul><li> <a href="#monitorfifoqueues" class="external text">First-in, first-out (FIFO) queues</a>
</li></ul><ul><li> <a href="#setupcustominputs" class="external text">Scripted inputs</a><br>Get data from APIs and other remote data interfaces and message queues.
</li></ul><ul><li> Modular inputs<br>Define a custom input capability to extend the Splunk Enterprise framework.
</li></ul><h3> <a name="whatsplunkcanmonitor_what_to_read_next"><span class="mw-headline" id="What_to_read_next">What to read next</span></a></h3>
<p>The topics that follow this one discuss issues to consider when specifying Splunk data:
</p>
<ul><li> <a href="#whereismydata" class="external text">"Where is my data?"</a>. A concise explanation of remote vs. local data, and why it matters.
</li><li> <a href="#usingforwardingagents" class="external text">"Use forwarders"</a>. How to use forwarders to simplify the remote collection of data.
</li><li> <a href="#usingapps" class="external text">"Use apps"</a>. How to use Splunk apps to get your data into Splunk Enterprise quickly.
</li><li> <a href="#howtogetgoing" class="external text">"Get started with getting data in"</a>. An overview of the process of getting and configuring data sources, with tips on best practices.
</li><li> <a href="#configureyourinputs" class="external text">"Configure your inputs"</a>. The ways you can configure data inputs in Splunk Enterprise.
</li><li> <a href="#aboutwindowsdataandsplunk" class="external text">"About Windows data and Splunk Enterprise"</a>. An introduction to getting Windows data into Splunk Enterprise.
</li><li> <a href="#whatsplunkdoeswithyourdata" class="external text">"How Splunk Enterprise handles your data)"</a>. What happens to your data once it enters Splunk Enterprise, and how you can configure Splunk to make the data even more useful.
</li></ul><a name="howtogetgoing"></a><h2> <a name="howtogetgoing_get_started_with_getting_data_in"><span class="mw-headline" id="Get_started_with_getting_data_in">Get started with getting data in</span></a></h2>
<p>To get started with getting data into Splunk Enterprise, point it at some data by <a href="#configureyourinputs" class="external text">configuring an input</a> from the <b>Add data</b> page. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>Alternatively, you can download and enable an <a href="#usingapps" class="external text">app</a>, such as one of the OS apps (Splunk App for Windows Infrastructure or Splunk App for Unix and Linux). 
</p><p>Once you have installed Splunk Enterprise and either configured the inputs or enabled an app, Splunk Enterprise immediately starts storing and processing the specified data. In a short time, you can go to either the Search app (reachable from Splunk Home, the starting page for Splunk Web) or the main app page and begin exploring the data that you have collected in detail.
</p>
<h3> <a name="howtogetgoing_add_new_inputs"><span class="mw-headline" id="Add_new_inputs"> Add new inputs </span></a></h3>
<p>Here is a recommended way to start out:
</p><p><b>1.</b> Understand your needs. Some of the questions you might ask yourself include: 
</p>
<ul><li>What kind of data do I want Splunk Enterprise to index? See "<a href="#whatsplunkcanmonitor" class="external text">What Splunk Enterprise can index</a>."
</li><li>Is there an app for that? See "<a href="#usingapps" class="external text">Use apps to get data in</a>" to find out.
</li><li>Where does the data reside? Is it local or remote? See "<a href="#whereismydata" class="external text">Where is my data?</a>."
</li><li>Should I use forwarders to access remote data? See "<a href="#usingforwardingagents" class="external text">Use forwarders to get data in</a>."
</li><li>What do I want to do with the indexed data? See ""What is Splunk knowledge?" in the Knowledge Manager manual.
</li></ul><p><b>2.</b> Create a test index and add just a few inputs. See "<a href="#testyourinputs_use_a_test_index" class="external text">Use a test index</a>." Try to keep the amount of test data to a minimum, as any data added to your test index counts against your maximum daily indexing volume for licensing purposes.
</p><p><b>3.</b> Preview and, if needed, modify how Splunk Enteprise indexes your data before committing the data to the test index.  Splunk Enterprise lets you preview incoming data from files that you monitor or upload. See <a href="#overviewofdatapreview" class="external text">"The "Set Sourcetype" page"</a> for details.
</p><p><b>4.</b> Run some searches on the test data:
</p>
<ul><li> Do you see the sort of data you were expecting? 
</li><li> Did the default configurations work well for your events? 
</li><li> Is data missing or mangled? 
</li><li> Are the results optimal? 
</li></ul><p><b>5.</b> If necessary, tweak your input and event processing configurations further until events look the way you want them to. To learn how to configure event processing, see <a href="#whatsplunkdoeswithyourdata" class="external text">"What Splunk Enterprise does with your data"</a> in this manual.
</p><p><b>6.</b> Delete the data from your test index and start over, if necessary. See "<a href="#testyourinputs_delete_indexed_data_and_start_over" class="external text">Delete indexed data and start over</a>" for information on how to do that.
</p><p><b>7.</b> When you are ready to index the data for real, point your inputs to the default "main" index, as described <a href="#testyourinputs_point_your_inputs_at_the_default_index" class="external text">here</a>.
</p><p>Repeat this approach when you have other inputs to add.
</p>
<h3> <a name="howtogetgoing_got_custom_data.3f"><span class="mw-headline" id="Got_custom_data.3F">Got custom data?</span></a></h3>
<p>Splunk Enterprise can index any time-series data, usually without the need for additional configuration. If you have logs from a custom application or device, you should let Splunk Enterprise attempt to process it with the default configuration first. If you don't get the results you want, you can tweak some things to make sure Splunk Enterprise indexes your events correctly.
</p><p>See "<a href="#overviewofeventprocessing" class="external text">Overview of event processing</a>" and "How Splunk Enterprise indexes data" before proceeding so you can make informed decisions about how to make Splunk Enterprise work with your data. Here are some issues to consider:
</p>
<ul><li> <a href="#indexmulti-lineevents" class="external text">Are your events multi-line?</a>
</li><li> <a href="#configurecharactersetencoding" class="external text">Is your data in an unusual character set?</a>
</li><li> <a href="#howsplunkextractstimestamps" class="external text">Is Splunk Enterprise unable to determine the timestamps correctly?</a>
</li></ul><a name="whereismydata"></a><h2> <a name="whereismydata_is_my_data_local_or_remote.3f"><span class="mw-headline" id="Is_my_data_local_or_remote.3F"> Is my data local or remote?</span></a></h2>
<p>When initially getting data into Splunk Enterprise, you might encounter some confusion as to what type of data is considered "local" and what type of data is considered "remote."  The distinction between local and remote is particularly important when you are navigating the new data input pages.
</p><p>The answer to this question depends on a number of criteria, including (but not limited to):
</p>
<ul><li> The operating system on which your Splunk Enterprise instance resides
</li><li> The types of data stores that are directly connected to your Splunk Enterprise instance
</li><li> Whether any authentication or other intermediate steps are needed to access the data store that contains the data you want to index
</li></ul><h3> <a name="whereismydata_local"><span class="mw-headline" id="Local">Local</span></a></h3>
<p>A <b>local</b> resource is a fixed resource that your Splunk Enterprise server has direct access to, meaning you are able to access it - and whatever is contained within it - without having to attach, connect, or perform any other intermediate action (such as authentication or mapping a network drive) in order to have that resource appear available to your system.  If your data is on such a resource, the data is considered "local."
</p><p>Some examples of local data include:
</p>
<ul><li> A hard disk or solid state drive installed in a desktop or laptop
</li><li> A RAM disk loaded at system start-up
</li></ul><h3> <a name="whereismydata_remote"><span class="mw-headline" id="Remote">Remote</span></a></h3>
<p>A <b>remote</b> resource is any resource where the above definition is not satisfied.  Network drives mapped from Windows systems, Active Directory schemas, and NFS or other network-based mounts on *nix systems are examples that qualify for this designation.  Data gathered from these resource endpoints is also considered "remote."
</p>
<h3> <a name="whereismydata_exceptions"><span class="mw-headline" id="Exceptions">Exceptions</span></a></h3>
<p>There are cases where resources that would normally be considered remote are actually not.  Here are some examples:
</p>
<ul><li> A machine has a volume permanently mounted over a high-bandwidth physical connection such as USB or FireWire.  Since the computer can mount the resource at boot time, it's treated as a local resource, even though the resource can theoretically be disconnected at a later time.
</li><li> A machine has a resource permanently mounted over a high-bandwidth network standard such as iSCSI, or to a Storage Area Network over fiber.  As the standard treats such volumes as local block devices, such a resource would be considered local.
</li></ul><a name="usingforwardingagents"></a><h2> <a name="usingforwardingagents_use_forwarders_to_get_data_in"><span class="mw-headline" id="Use_forwarders_to_get_data_in"> Use forwarders to get data in</span></a></h2>
<p><b>Forwarders</b> are lightweight Splunk instances whose purpose is to consume data and forward it on to Splunk Enterprise <b>indexers</b> for further processing. They require minimal resources and have little impact on performance, so they can usually reside on the machines where the data originates. 
</p><p>For example, if you have a number of Apache servers generating data that you want to search centrally, you can install a Splunk Enterprise indexer and then set up forwarders on the Apache machines. The forwarders take the Apache data and send it on to the indexer, which then consolidates, stores, and makes it available for searching. Because of their light footprint, the forwarders have minimum performance impact on the Apache servers.
</p><p>Similarly, you can install forwarders on your employees' Windows desktops. These can send logs and other data to a central Splunk Enterprise instance, where you can view the data as a whole to track malware or other issues.
</p>
<h3> <a name="usingforwardingagents_what_forwarders_do"><span class="mw-headline" id="What_forwarders_do"> What forwarders do </span></a></h3>
<p>You can use forwarders to get data from remote machines. They represent a much more robust solution than raw network feeds, with their capabilities for:
</p>
<ul><li> Tagging of metadata (source, sourcetype, and host)
</li><li> Configurable buffering 
</li><li> Data compression
</li><li> SSL security
</li><li> Use of any available network ports
</li><li> Running scripted inputs locally
</li></ul><p>Forwarders consume data in the same way as any other Splunk Enterprise instance. They can handle exactly the same types of data as an indexer. The difference is that they usually do not index the data themselves. Instead, they just get the data and send it on to a central indexer, which does the indexing and searching. A single indexer can process data coming from many forwarders. For detailed information on forwarders, see the <i>Fowarding Data</i> manual.
</p><p>In most Splunk Enterprise deployments, forwarders serve as the primary consumers of data. It's only in single-machine deployments that the indexer is likely to also be the main data consumer. In a large Splunk Enterprise deployment, you might have hundreds or even thousands of forwarders consuming data and forwarding it on to a group of indexers for consolidation.
</p>
<h3> <a name="usingforwardingagents_how_to_configure_forwarder_inputs"><span class="mw-headline" id="How_to_configure_forwarder_inputs">How to configure forwarder inputs</span></a></h3>
<p>As lightweight instances of Splunk Enterprise, forwarders have limited capabilities by design. For example, most forwarders do not include Splunk Web, so you do not have direct access to a UI for setting up the forwarder's data inputs. Here are the main ways that you can configure a forwarder's data inputs:
</p>
<ul><li> Specify inputs during initial deployment. For Windows forwarders, you can specify common inputs during the installation process itself. For *nix forwarders, you can specify inputs directly after installation.
</li><li> Use the CLI.
</li><li> Edit inputs.conf.
</li><li> Deploy an app containing the desired inputs. 
</li><li> Use Splunk Web on a full Splunk Enteprise test instance to configure the inputs and then distribute the resulting <code><font size="2">inputs.conf</font></code> file to the forwarder itself. 
</li></ul><h3> <a name="usingforwardingagents_for_more_information"><span class="mw-headline" id="For_more_information"> For more information </span></a></h3>
<p>For detailed information on forwarders, including use cases, typical topologies, and configurations, see "About forwarding and receiving" in the <i>Forwarding Data</i> manual.
</p><p>For details on forwarder deployment, including how to use the <b>deployment server</b> to simplify distribution of configuration files and apps to multiple forwarders, see "Universal forwarder deployment overview" in the <i>Forwarding Data</i> manual.
</p><p>For information on using forwarders for monitoring of remote Windows data, see <a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">"Considerations for deciding how to monitor remote Windows data"</a>.
</p>
<a name="usingapps"></a><h2> <a name="usingapps_use_apps_to_get_data_in"><span class="mw-headline" id="Use_apps_to_get_data_in"> Use apps to get data in</span></a></h2>
<p>Splunk offers a wide variety of <b>apps</b> and <b>add-ons</b> that extend the capability of Splunk Enterprise. Apps simplify the process of getting data into Splunk Enterprise. Instead of configuring inputs yourself for a particular environment or application, you can often find an app with the data inputs already configured. Download apps from Splunkbase. 
</p><p>Apps typically target specific data types and handle everything from configuring the inputs to generating useful views of the data. For example, the Splunk App for Windows Infrastructure provides data inputs, searches, reports, alerts, and dashboards for Windows server and desktop management. The Splunk App for Unix and Linux offers the same for Unix and Linux environments. There is a wide range of other apps that handle specific types of application data, such as: 
</p>
<ul><li> Splunk App for Blue Coat ProxySG
</li><li> Splunk App for F5
</li><li> Splunk App for Cisco Security
</li><li> Splunk App for Websphere Application Server 
</li></ul><p>Go to Splunkbase to browse through the large set of apps available for download. Check Splunkbase frequently, because new apps get added all the time. 
</p><p>If Splunk Web is behind a proxy server, you might have trouble accessing Splunkbase directly from within Splunk Enterprise. To solve this problem, see "Specify a proxy server" in the <i>Admin manual</i>.
</p><p>For more information on apps, see "What are apps and add-ons?" in the <i>Admin Manual</i>. In particular, ""Where to get more apps and add-ons" tells you how to download and install apps:. 
</p><p>For information on how to create your own apps, see the <i>Developing Views and Apps for Splunk Web</i> manual.
</p>
<a name="configureyourinputs"></a><h2> <a name="configureyourinputs_configure_your_inputs"><span class="mw-headline" id="Configure_your_inputs"> Configure your inputs</span></a></h2>
<p>To add a new type of data to Splunk Enterprise, configure a data input.  There are a number of ways to configure data inputs.
</p>
<ul><li> <b>Apps</b>. Splunk has a large variety of <b>apps</b> that offer preconfigured inputs for various types of data.  For information, see <a href="#usingapps" class="external text">"Use apps to get data in."</a>
</li></ul><ul><li> <b>Splunk Web</b>. You can configure most inputs using the <b>Splunk Web</b> data input pages. These provide a GUI-based approach to configuring inputs. You can access the Add Data landing page from Splunk Home. You can also use <b>System</b> to add new inputs or view and manage existing inputs. In addition, when you upload or monitor a file, Splunk Enterprise lets you <a href="#overviewofdatapreview" class="external text">preview the file</a> and make adjustments to how Splunk Enterprise plans to index it before the data is written to the index.
</li></ul><ul><li> <b>The Splunk Command-Line Interface (CLI).</b> Use the CLI to configure most types of inputs. 
</li></ul><ul><li> The <b>inputs.conf configuration file.</b> When you specify your inputs with Splunk Web or the CLI, Splunk Enterprise saves them in a <b>configuration file</b>, inputs.conf. You also can edit that file directly. To handle some advanced data input requirements, you might need to edit it. 
</li></ul><p>In addition, if you configure <b>forwarders</b> to send data from outlying machines to a central <b>indexer</b>, you can specify some inputs at installation time. See <a href="#usingforwardingagents" class="external text">"Use forwarders to get data in."</a> 
</p><p>This topic describes how to configure data inputs yourself, using Splunk Web, the CLI, or <code><font size="2">inputs.conf</font></code>.
</p>
<h3> <a name="configureyourinputs_use_splunk_web"><span class="mw-headline" id="Use_Splunk_Web"> Use Splunk Web </span></a></h3>
<p>You can add data inputs from Splunk Home or Splunk System.
</p>
<ul><li> From Splunk Home, select <b>Add Data</b>. This takes you to the Add Data page, with links to recipes for a variety of data input types.  See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</li></ul><ul><li> From anywhere in Splunk Web, select <b>System</b>, and then select <b>Data inputs</b> from the <b>Data</b> section of the <b>System</b> pop-up. This takes you to a page where you can view and manage your existing inputs, as well as add new ones.
</li></ul><p>The Add Data page has three options to get data in: <a href="#uploaddata" class="external text">Upload</a>, <a href="#monitordata" class="external text">Monitor</a>, and <a href="#forwarddata" class="external text">Forward.</a> Clicking one of the icons takes you to a page that lets you define the data you want to upload, monitor, or forward.
</p><p>For information on using Splunk Web to configure your inputs, look in the topics covering specific inputs later in this manual. For example, to learn how to use Splunk Web to configure network inputs, see "<a href="#monitornetworkports" class="external text">Get data from TCP and UDP ports</a>." 
</p><p>You can configure most inputs with Splunk Web. For a small number of input types, you must edit <code><font size="2">inputs.conf</font></code> directly. In addition, some advanced settings for other input types are available only through <code><font size="2">inputs.conf</font></code>.
</p><p>When you add an input through Splunk Web, Splunk Enterprise adds that input to a copy of <code><font size="2">inputs.conf</font></code> that belongs to the app you are currently in. This has consequences that you need to consider. For example, if you navigated to Splunk System directly from the Search page and then added an input there, Splunk Enterprise adds the input to <code><font size="2">$SPLUNK_HOME/etc/apps/search/local/inputs.conf</font></code>. Make sure you are in the app when you add your inputs. For information on how configuration files work, see "About configuration files."
</p>
<h3> <a name="configureyourinputs_use_the_cli"><span class="mw-headline" id="Use_the_CLI"> Use the CLI </span></a></h3>
<p>You can use the Splunk CLI to configure most inputs. Navigate to the <code><font size="2">$SPLUNK_HOME/bin/</font></code> directory and use the <code><font size="2">./splunk</font></code> command from the UNIX or Windows command prompt. For example, this command adds <code><font size="2">/var/log/</font></code> as a data input:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk add monitor /var/log/<br></font></code></div>
<p>If you get stuck, the Splunk CLI has built-in help. For the list of CLI commands, type:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk help commands<br></font></code></div>
<p>Individual commands have their own help pages as well. To see them, type: 
</p>
<div class="samplecode"><code><font size="2">./splunk help &lt;command&gt;<br></font></code></div>
<p>For information on how to use the CLI to configure a specific input, see the topic in this manual for that input. For example, to learn how to use the CLI to configure network inputs, see: <a href="#monitornetworkports_add_a_network_input_using_the_cli" class="external text">"Add a network input using the CLI."</a>
</p><p>For informaton on the CLI, see "About the CLI" and the topics that follow it in the <i>Admin Manual</i>.
</p>
<h3> <a name="configureyourinputs_edit_inputs.conf"><span class="mw-headline" id="Edit_inputs.conf"> Edit inputs.conf </span></a></h3>
<p>To add an input by directly editing inputs.conf, add a <b>stanza</b> for the input. You can add the stanza to the <code><font size="2">inputs.conf</font></code> file in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code>, or in your own custom application directory (in <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app name&gt;/local</font></code>). If you have not worked with the configuration files, see "About configuration files."
</p><p>Configure the data input by adding attribute/value pairs to its stanza. You can set multiple attributes in an input stanza. If you do not specify a value for an attribute, Splunk Enterprise uses the default value that is preset in <code><font size="2">$SPLUNK_HOME/etc/system/default/inputs.conf</font></code>. 
</p><p>Following is an example of adding a network input. This configuration directs Splunk Enterprise to listen on TCP port 9995 for raw data from any remote server. Splunk Enterprise uses the DNS name of the remote server to set the host of the data. It assigns the source type log4j and the source tcp:9995 to the data.
</p>
<div class="samplecode"><code><font size="2"><br>[tcp://:9995]<br>connection_host = dns<br>sourcetype = log4j<br>source = tcp:9995<br></font></code></div>
<p>For information on how to configure a specific input, see the topic in this manual for that input. For example, to learn how to configure file inputs, see <a href="#editinputs.conf" class="external text">Edit inputs.conf</a>.
</p><p>The topic for each data input describes the main attributes available for that input. However, refer to the <code><font size="2">inputs.conf</font></code> spec file, located inputs.conf, for the list of available attributes. The spec file contains descriptions of the attributes. There is also a file that contains several examples.
</p>
<h3> <a name="configureyourinputs_about_source_types"><span class="mw-headline" id="About_source_types"> About source types </span></a></h3>
<p>As part of the input process, Splunk Enterprise assigns a <b>source type</b> to the data. The source type identifies the format of the data. Splunk Enterprise uses the source type during indexing to format events correctly. It usually knows what source type to assign. For instance, syslog data gets a source type of "syslog". If you are not happy with the source type Splunk Enterprise assigns to a particular input, you can substitute a different source type -- either one of the predefined source types or one that you create yourself. You set the source type at the time you configure the input, using any of the configuration methods described in this topic.
</p><p>For information on source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter."</a> The topic <a href="#bypassautomaticsourcetypeassignment" class="external text">"Override automatic source type assignment"</a> describes source type assignment options.
</p><p>To learn how to set the source type on a per-event basis, see <a href="#advancedsourcetypeoverrides" class="external text">"Advanced source type overrides."</a>
</p>
<a name="whatsplunkdoeswithyourdata"></a><h2> <a name="whatsplunkdoeswithyourdata_how_splunk_enterprise_handles_your_data"><span class="mw-headline" id="How_Splunk_Enterprise_handles_your_data"> How Splunk Enterprise handles your data</span></a></h2>
<p>Splunk Enterprise consumes any sort of data and <b>indexes</b> it, transforming it into searchable knowledge in the form of <b>events</b>.  The data pipeline shows the main processes that act on the data during indexing. These processes constitute <b>event processing</b>. After the data is  processed into events, you can associate the events with <b>knowledge objects</b> to enhance their usefulness.
</p>
<h3> <a name="whatsplunkdoeswithyourdata_the_data_pipeline"><span class="mw-headline" id="The_data_pipeline"> The data pipeline</span></a></h3>
<p>After a chunk of data enters Splunk Enterprise, it moves through the data pipeline, which transforms the data into searchable events. This diagram shows the main steps in the data pipeline.
</p><p><img alt="Datapipeline1 60.png" src="images/5/5e/Datapipeline1_60.png" width="607" height="801"></p><p>For a description of the data pipeline, see "How data moves through Splunk Enterprise" in the <i>Distributed Deployment Manual</i>.
</p><p>Depending on the data and what sort of knowledge you need to extract from it, you can tweak one or more steps of event processing. 
</p>
<h3> <a name="whatsplunkdoeswithyourdata_event_processing"><span class="mw-headline" id="Event_processing"> Event processing </span></a></h3>
<p>Event processing occurs in two stages, parsing and indexing. All data that comes into Splunk Enterprise enters through the <b>parsing pipeline</b> as large chunks. During parsing, Splunk Enterprise breaks these chunks into events. It then hands off the events to the <b>indexing pipeline</b>, where final processing occurs. 
</p><p>During both parsing and indexing, Splunk Enterprise acts on the data, transforming it in various ways. Most of these processes are configurable, so you have the ability to adapt them to your needs. In the description that follows, each link takes you to a topic that discusses one of these processes, with information on ways you can configure it.
</p><p>While parsing, Splunk Enterprise performs a number of actions, including:
</p>
<ul><li> Extracting a set of <a href="#aboutdefaultfields" class="external text">default fields</a> for each event, including <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>.
</li><li> Configuring <a href="#configurecharactersetencoding" class="external text">character set encoding</a>.
</li><li> Identifying line termination using <a href="#indexmulti-lineevents" class="external text">line breaking</a> rules. While many events are short and only take up a line or two, others can be long. You can also modify line termination settings interactively, using the "Set Sourcetype" page in Splunk Web.
</li><li> Identifying <a href="#howsplunkextractstimestamps" class="external text">timestamps</a> or creating them if they don't exist. At the same time that it processes timestamps, Splunk Enterprise identifies event boundaries. You can also modify timestamp setings interactively, using the "Set sourcetype" page.
</li></ul><ul><li> Splunk Enterprise can be set up to mask sensitive event data (such as credit card or social security numbers) at this stage. It can also be configured to <a href="#assignmetadatatoeventsdynamically" class="external text">apply custom metadata</a> to incoming events.
</li></ul><p>In the indexing pipeline, Splunk Enterprise performs additional processing, including:
</p>
<ul><li> Breaking all events into <a href="#abouteventsegmentation" class="external text">segments</a> that can then be searched. You can determine the level of segmentation. The segmentation level affects indexing and searching speed, search capability, and efficiency of disk compression.
</li><li> Building the index data structures.
</li><li> Writing the raw data and index files to disk, where post-indexing compression occurs.
</li></ul><p>The distinction between parsing and indexing pipelines matters mainly for forwarders. Heavy forwarders can parse data locally and then forward the parsed data on to receiving indexers, where the final indexing occurs. With universal forwarders, on the other hand, the data gets forwarded after very minimal parsing. Most parsing then occurs on the receiving indexer.
</p>
<ul><li> For more information about events and what happens to them during the indexing process, see <a href="#overviewofeventprocessing" class="external text">Overview of event processing</a> in this manual.
</li></ul><h3> <a name="whatsplunkdoeswithyourdata_enhance_and_refine_events"><span class="mw-headline" id="Enhance_and_refine_events"> Enhance and refine events </span></a></h3>
<p>Once the data has been transformed into events, you can make the events even more useful by associating them with knowledge objects, such as event types, field extractions, and reports. For information about managing Splunk knowledge, read the <i>Knowledge Manager</i> manual, starting with "What is Splunk knowledge?".
</p>
<h1>How to get data into Splunk Enterprise</h1><a name="howdoyouwanttoadddata"></a><h2> <a name="howdoyouwanttoadddata_how_do_you_want_to_add_data.3f"><span class="mw-headline" id="How_do_you_want_to_add_data.3F"> How do you want to add data?</span></a></h2>
<p>Adding data is now easier than ever in Splunk Enterprise. Once you log in with a user with appropriate permissions, accessing the new process is one click away. This topic walks you through the "add data" process.
</p><p>For a tutorial on how to get data into Splunk, see the Search Tutorial.
</p><p><b>Note:</b> This page is not available if:
</p>
<ul><li> This instance has been configured as part of a <b>search head cluster</b>. See "About search head clustering" in the Distributed Search manual.
</li><li> This instance runs Splunk Cloud.
</li></ul><h3> <a name="howdoyouwanttoadddata_the_.22add_data.22_page"><span class="mw-headline" id="The_.22Add_Data.22_page">The "Add Data" page</span></a></h3>
<p>Once you log into Splunk Enterprise, it presents the updated Home page:
</p><p><img alt="62 Home.png" src="images/a/a9/62_Home.png" width="700" height="208"></p><p>To add data, click the green "Add Data" button on the center-left of the page (to the right of the list of apps.) Splunk Enterprise then loads the "Add Data" page.
</p><p>You can also access the "Add Data" page by clicking the "Settings" menu in the system bar. When the menu drops down, the "Add Data" button is on the left side.
</p><p><img alt="62 AddData.png" src="images/7/7e/62_AddData.png" width="700" height="337"></p><p>This page presents you with three options for getting data into your Splunk Enterprise instance: <b>Upload</b>, <b>Monitor</b>, and <b>Forward</b>.
</p>
<h3> <a name="howdoyouwanttoadddata_upload"><span class="mw-headline" id="Upload">Upload</span></a></h3>
<p>The "Upload" option lets you upload a file or archive of files into Splunk Enterprise for indexing. When you click the "Upload" button, Splunk Enterprise takes you to a page that starts the upload process. See "<a href="#uploaddata" class="external text">Upload data</a>."
</p>
<h3> <a name="howdoyouwanttoadddata_monitor"><span class="mw-headline" id="Monitor">Monitor</span></a></h3>
<p>The "Monitor" option lets you monitor one or more files, directories, network streams, scripts, Event Logs (on Windows hosts only), performance metrics, or any other type of machine data that the Splunk Enterprise instance has access to. When you click the "Monitor" button, Splunk Enterprise takes you to a page that starts the monitoring process. See "<a href="#monitordata" class="external text">Monitor data</a>."
</p>
<h3> <a name="howdoyouwanttoadddata_forward"><span class="mw-headline" id="Forward">Forward</span></a></h3>
<p>The "Forward" option lets you receive data from <b>forwarders</b> into this Splunk Enterprise instance. When you click on the "Forward" button, Splunk Enterprise takes you to a page that starts the data collection process from forwarders. See "<a href="#forwarddata" class="external text">Forward data</a>."
</p><p><b>Note:</b> This option requires additional configuration before use. Use it in a single-instance environment only. If you have multiple Splunk Enterprise instances that index data, see "About forwarding and receiving data" in the Forwarding Data manual.
</p>
<a name="uploaddata"></a><h2> <a name="uploaddata_upload_data"><span class="mw-headline" id="Upload_data"> Upload data</span></a></h2>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> This feature does not work in Internet Explorer version 9.
</th></tr><tr><td valign="center" align="left"> While Internet Explorer version 9 is a supported browser for Splunk Web, due to issues with compatibility, the "Upload Data" feature does not work in this version.
<p>To access this feature in IE, use version 10 or later.
</p>
</td></tr></table><p>This topic explains the page that Splunk Enterprise loads when you select the "Upload" button on the "Add data" page.
</p>
<h3> <a name="uploaddata_the_.22upload.22_page"><span class="mw-headline" id="The_.22Upload.22_page">The "Upload" page</span></a></h3>
<p>When you access the "Upload" page, Splunk Enterprise presents you with the following:
</p><p><img alt="62 SelectSource Upload.png" src="images/c/c0/62_SelectSource_Upload.png" width="700" height="506"></p><p>This page lets you upload data to Splunk Enterprise using one of the following methods:
</p>
<ul><li> Drag the file you want Splunk Enterprise to index directly from your desktop and drop it into the "Drop your data file here" area on the page.
</li></ul><p>or
</p>
<ul><li> In the upper left corner of the screen, click the "Select File" button to bring up a dialog box where you can select the file that you want Splunk Enterprise to index.
</li></ul><p>Splunk Enterprise then loads the file and processes it, depending on what type of file it is. Once it has completed loading, you can then click the green <b>Next</b> button on the upper right to proceed to the next step in the "Add data" process.
</p>
<a name="monitordata"></a><h2> <a name="monitordata_monitor_data"><span class="mw-headline" id="Monitor_data"> Monitor data</span></a></h2>
<p>This topic explains the page that Splunk Enterprise loads when you select the "Monitor" button on the "Add data" page.
</p>
<h3> <a name="monitordata_the_.22monitor.22_page"><span class="mw-headline" id="The_.22Monitor.22_page">The "Monitor" page</span></a></h3>
<p>When you access the "Monitor" page, Splunk Enterprise presents you with the following:
</p><p><img alt="62 SelectSource Monitor.png" src="images/b/b6/62_SelectSource_Monitor.png" width="700" height="231"></p><p>This page lets you choose the type of data that Splunk Enterprise should monitor. Splunk Enterprise lists the default inputs first. It then lists forwarded inputs below the default inputs. Finally,it shows any modular inputs you have installed on the instance.
</p><p>To monitor data, perform the following steps:
</p><p><b>1.</b> Select a source from the left side of the screen by clicking it once.
</p>
<dl><dd>Splunk Enterprise updates the rest of the page with controls that are specific to the source you selected. For example, if you select "Files &amp; Directories", the page updates with a field to enter a file or directory name and specify how Splunk Enterprise should monitor the file or directory.
</dd></dl><p><b>Note:</b> Splunk Enterprise shows only sources that it has the capability of monitoring. Refer to the <a href="#whatsplunkcanmonitor_types_of_data_sources" class="external text">list of data sources</a> for specifics. If you do not see the data source that you want to monitor, consider the following reasons:
</p>
<ul><li> Some data sources are available only on certain operating systems. For example, all Windows data sources are not available on a Splunk Enterprise instance that runs on *nix (and vice versa).
</li><li> The user you logged into Splunk Enterprise with might not have permissions to add data or see the data source.
</li></ul><p><b>2.</b> Follow the on-screen prompts to complete the selection of the source object that you want Splunk Enterprise to monitor.
</p><p><b>3.</b> Click the green <b>Next</b> button on the upper right to proceed to the next step in the "Add data" process.
</p>
<a name="forwarddata"></a><h2> <a name="forwarddata_forward_data"><span class="mw-headline" id="Forward_data"> Forward data</span></a></h2>
<p>This topic explains the "Select Forwarders" page that Splunk Enterprise loads when you click the "Forward" button on the "Add data" page.
</p><p><b>Important:</b> Only use this page if you have a single instance of Splunk Enterprise acting as an indexer and deployment server. If you have multiple servers that perform indexing, see "About deployment server and forwarder management" in the Updating Splunk Enterprise Instances manual.
</p>
<h3> <a name="forwarddata_the_.22select_forwarders.22_page"><span class="mw-headline" id="The_.22Select_Forwarders.22_page">The "Select Forwarders" page</span></a></h3>
<p>When you access the "Forward" page, Splunk Enterprise presents you with the following:
</p><p><img alt="62 SelectSource Forward.png" src="images/4/44/62_SelectSource_Forward.png" width="700" height="487"></p><p>The page lets you define <b>server classes</b> and add forwarders to those classes in order to receive data from them.
</p><p>This page only displays forwarders that you have already configured to forward data and act as deployment clients to this instance. If you have not configured any forwarders, the page warns you of this. 
</p><p>For a forwarder to appear in the list, the following must happen:
</p>
<ul><li> You must configure the forwarder as a <b>deployment client</b>. This means that a deployment server can manage the configurations for the forwarder. See "Configure deployment clients" in the Updating Splunk Enterprise Instances manual. 
</li><li> The forwarder must make a successful connection to the deployment server.
</li></ul><p>Once you see the forwarder in the list, you can configure it to add data:
</p><p><b>1.</b> In <b>Select Server Class</b>, click one of the options shown:
</p>
<ul><li> <b>New</b> If you have not defined any server classes, you want to create a new server class for any reason, or if an existing server class does not match the group of forwarders that you want to configure an input for.
</li><li> <b>Existing</b> if you want to use an existing server class.
</li></ul><p><b>2.</b> In the <b>Available host(s)</b> pane, choose the forwarders that you want this instance to receive data from. The forwarders move from the <b>Available host(s)</b> pane to the <b>Selected host(s)</b> pane. You can add all of the hosts by clicking the <b>add all</b> link, or remove all hosts by selecting the <b>remove all</b> link.
</p><p><b>Important:</b> Hosts you add to a server class must contain hosts of a certain platform. You cannot, for example, put Windows and *nix hosts in the same server class.
</p><p><b>3a.</b> If you chose <b>New</b> in "Select server class", enter a unique name for the server class that you will remember.
</p><p><b>3b.</b> If you chose <b>Existing</b>, select the server class you want from the drop-down list.
</p><p><b>4.</b> Click the green <b>Next</b> button on the upper right to proceed to the next step in the "Add data" process.
</p><p>Splunk Enterprise loads the "Select Source" page and shows source types that are valid for the forwarders that you have selected.
</p><p><b>5.</b> Select the data sources that you want the forwarders to send data to this instance. See "<a href="#monitordata" class="external text">Monitor data</a>."
</p><p><b>6.</b> Click the green <b>Next</b> button to proceed to the next step in the <b>Add data</b> process.
</p>
<a name="overviewofdatapreview"></a><h2> <a name="overviewofdatapreview_the_.22set_sourcetype.22_page"><span class="mw-headline" id="The_.22Set_Sourcetype.22_page"> The "Set Sourcetype" page</span></a></h2>
<p>The "Set Sourcetype" page lets you improve <b>event processing</b> by previewing how Splunk Enterprise indexes your data. You can use this page to make sure that Splunk Enterprise indexes your data exactly as you want it to appear. 
</p>
<h3> <a name="overviewofdatapreview_how_does_it_work.3f"><span class="mw-headline" id="How_does_it_work.3F">How does it work?</span></a></h3>
<p>The Set Sourcetype page appears after you use the "<a href="#uploaddata" class="external text">Upload</a>" or "<a href="#monitordata" class="external text">Monitor</a>" pages to specify a single file as a source of data. 
</p><p>It does not appear when:
</p>
<ul><li> You forward data from another Splunk instance such as a heavy or universal forwarder.
</li><li> You specify a network input as a data source.
</li><li> You specify a directory as a data source. 
</li></ul><p>In those cases, the "<a href="#modifyinputsettings" class="external text">Modify input settings</a>" page appears instead. With some advance planning, you can use this page for those input types as well. See <a href="#prepareyourdata" class="external text">"Prepare your data"</a>.
</p><p>On the "Set Sourcetypes" page, you can easily make adjustments to how Splunk Enterprise eventually indexes your data. You can adjust and improve the indexing process interactively so that when Splunk Enterprise later performs the actual indexing, your <b>event data</b> ends up stored in the exact format you want.
</p>
<h3> <a name="overviewofdatapreview_use_the_.22set_sourcetypes.22_page"><span class="mw-headline" id="Use_the_.22Set_Sourcetypes.22_page">Use the "Set Sourcetypes" page</span></a></h3>
<p>When this page loads, Splunk Enterprise chooses a source type based on the data you specified. You can accept that recommended source type or change it.
</p><p>Here is an example of the "Set Sourcetype" page:
</p><p><img alt="62 datapreview.png" src="images/1/13/62_datapreview.png" width="700" height="236"></p>
<h4><font size="3"><b><i> <a name="overviewofdatapreview_view_or_change_the_recommended_source_type"><span class="mw-headline" id="View_or_change_the_recommended_source_type">View or change the recommended source type</span></a></i></b></font></h4>
<p>You can view how Splunk Enterprise plans to break the data in your file into events. If the proposed indexing does not suit your needs, you can choose a different source type or create a new one by clicking the <b>Sourcetype: New Sourcetype</b> button. See "<a href="#accessdatapreview" class="external text">View and set source types for event data</a>."
</p>
<h4><font size="3"><b><i> <a name="overviewofdatapreview_view_event_summary"><span class="mw-headline" id="View_event_summary">View event summary</span></a></i></b></font></h4>
<p>You can see a summary of the events within the data sample that Splunk Enterprise collected by clicking the "View Event Summary" link on the right side of the page. This summary shows the following information:
</p>
<ul><li> The size of the sample data, in bytes, that Splunk Enterprise gathered.
</li><li> The number of events that were present in the sample.
</li><li> The chart that represents the distribution of the events over time. Splunk Enterprise uses date stamps within the file to determine how to display this chart.
</li><li> A breakdown of the number of lines each event in the sample took up.
</li></ul><p><img alt="62 datapreview eventsummary.png" src="images/e/ee/62_datapreview_eventsummary.png" width="400" height="396"></p>
<h4><font size="3"><b><i> <a name="overviewofdatapreview_adjust_time_stamps_and_event_breaks"><span class="mw-headline" id="Adjust_time_stamps_and_event_breaks">Adjust time stamps and event breaks</span></a></i></b></font></h4>
<p>You can adjust how Splunk Enterprise processes timestamps and event breaks. Once the results suit you, you can save your changes as a new <b>source type</b>, which you can then apply to the actual data. See <a href="#datapreviewandsourcetypes" class="external text">"Assign the right source type to your data"</a> for details.
</p>
<h4><font size="3"><b><i> <a name="overviewofdatapreview_delimited_settings"><span class="mw-headline" id="Delimited_settings">Delimited settings</span></a></i></b></font></h4>
<p>When you select a structured data file, such as a comma-separated values (CSV), tab-separated values (TSV), or similar file, the "Delimited settings" bar appears. This window lets you adjust settings related to how Splunk Enterprise parses these structured data files. You can adjust:
</p>
<ul><li> The field delimiter - the character that Splunk Enterprise uses to separate the data into fields.
</li><li> The quote character - the character that Splunk Enterprise uses to determine when something is within quotes.
</li><li> The file preamble - a regular expression that tells Splunk Enterprise to ignore preamble lines within the structure data file.
</li><li> Field names - how Splunk Enterprise determines field names: automatically, by line number, custom entry, or regular expression.
</li></ul><p><img alt="62 datapreview delimitedsettings.png" src="images/7/7f/62_datapreview_delimitedsettings.png" width="400" height="320"></p>
<a name="datapreviewandsourcetypes"></a><h2> <a name="datapreviewandsourcetypes_assign_the_right_source_type_to_your_data"><span class="mw-headline" id="Assign_the_right_source_type_to_your_data">Assign the right source type to your data</span></a></h2>
<p>This topic discusses how the "Set sourcetype" page helps you correlate the proper source type to data that you index into Splunk Enterprise.
</p><p>The purpose of the "Set sourcetype" page is to help you apply the right <b>source type</b> to your incoming data. The source type is one of the <b>default fields</b> that Splunk Enterprise assigns to all incoming data. The source type determines how Splunk Enterprise formats your data during indexing. By assigning the correct source type to your data, the indexed version of the data (the <b>event data</b>) will look the way you want it to, with proper <b>timestamps</b> and <b>event</b> breaks. 
</p><p>Splunk Enterprise comes with a large number of predefined source types. When consuming data, in most cases, Splunk Enterprise attempts to automatically assign the correct source type to your data and process the data appropriately. If you have specialized data, you might need to manually select a different predefined source type to the data. In other cases, you might need to create a new source type with customized event processing settings. 
</p><p>The "Set sourcetype" page helps you assign the right source type to your data by showing you the results of applying any predefined source type to the data. It also allows you to modify the settings for a source type interactively, until you achieve the desired results. At that point, you can save the modifications as a new source type.
</p><p>The "Set sourcetype" page lets you:
</p>
<ul><li> See what your data will look like without any changes, using the default event processing configuration that Splunk Enterprise automatically applies.
</li><li> Apply a different source type to see whether that offers better results.
</li><li> Modify settings for timestamps and event breaks to improve the quality of the indexed data and save the modifications as a new source type.
</li><li> Create a new source type from scratch.
</li></ul><p>The page saves any new source types to a <code><font size="2">props.conf</font></code> file, which you can later distribute across the indexers in your deployment, so that the source types are available globally. See <a href="#datapreviewanddistributeddeployment" class="external text">"Data preview and distributed Splunk Enterprise"</a> for details.
</p><p>For detailed information on source types, see "<a href="#whysourcetypesmatter" class="external text">Why source types matter</a>" in this manual. In addition, several topics in the "Configure event processing", "Configure timestamps", and "Configure source types" chapters provide advanced information on source type processing.
</p>
<a name="prepareyourdata"></a><h2> <a name="prepareyourdata_prepare_your_data_for_previewing"><span class="mw-headline" id="Prepare_your_data_for_previewing"> Prepare your data for previewing</span></a></h2>
<p>This topic discusses how to prepare your data to be viewed in the Splunk Enterprise "Set sourcetype" page.
</p><p>The "<a href="#overviewofdatapreview" class="external text">Set Sourcetype</a>" page works on single files only, and can only access files that are on the Splunk Enterprise instance or have been uploaded there. Although it doesn't directly process network data or directories of files, you can easily get around those limitations.
</p>
<h3> <a name="prepareyourdata_preview_network_data"><span class="mw-headline" id="Preview_network_data">Preview network data</span></a></h3>
<p>You can direct some sample network data into a file, which you can then either upload or add as a file monitoring input.  There are a number of external tools that can do this; a typical one in the *nix world is <code><font size="2">netcat</font></code>. For example, if you're listening to UDP data on port 514, you can use <code><font size="2">netcat</font></code> to direct some of your network data into a file:
</p>
<div class="samplecode"><code><font size="2"><br>nc -lu 514 &gt; sample_network_data<br></font></code></div>
<p>It is best practice to run the command inside a shell script that has logic to kill <code><font size="2">netcat</font></code> once the file reaches a size of 2MB. By default, data preview reads only the first 2MB of data from a file.
</p><p>After you've created the "sample_network_data" file, you can add it like a normal input (either by uploading it or adding it as a file input.) Splunk Enterprise brings up the "Set sourcetypes" page as part of the input definition process. Once you have previewed the file and made any necessary changes to its event processing, you can apply any newly created source type directly to the file.
</p>
<h3> <a name="prepareyourdata_preview_directories_of_files"><span class="mw-headline" id="Preview_directories_of_files">Preview directories of files</span></a></h3>
<p>If all the files in a directory are similar in content, then you can preview a single file and feel fairly confident that the results will be valid for all files in the directory.  However, if you have directories with files of heterogeneous data, you should preview a set of files that represents the full range of data in the directory. This means that you should preview each type of file separately, as specifying any wildcard causes Splunk Enterprise to disable the "Set Sourcetype" page.)
</p>
<h3> <a name="prepareyourdata_file_size_limit"><span class="mw-headline" id="File_size_limit">File size limit</span></a></h3>
<p>Splunk Enterprise reads and displays the first 2MB of data from a file in the "Set Sourcetypes" page. In most cases, this should provide a sufficient sampling of your data. If you need to sample a larger quantity of data, you can change the <code><font size="2">max_preview_bytes</font></code> attribute in limits.conf. Alternatively, you can edit the file to reduce large amounts of similar data, so that the remaining 2MB of data contains a representation of all the types of data in the original file.
</p>
<a name="accessdatapreview"></a><h2> <a name="accessdatapreview_view_and_set_source_types_for_event_data"><span class="mw-headline" id="View_and_set_source_types_for_event_data"> View and set source types for event data</span></a></h2>
<p>This topic describes how to preview incoming data and set or create the source type for that data in Splunk Enterprise.
</p><p>You access the feature automatically when you create a file input in Splunk Web. When you start to add a new input from the <b>Files &amp; Directories</b> page for a single file in Splunk Web, or upload a file, as described <a href="#usesplunkweb" class="external text">here</a>, Splunk Web presents the "Set sourcetypes" page. 
</p><p>At that point, you can see how Splunk Enterprise will index your data. Then, you can either modify that and define a new source type, choose an existing source type, or accept the recommend source type and continue directly to the input settings page.
</p>
<h3> <a name="accessdatapreview_review_and_set_source_types"><span class="mw-headline" id="Review_and_set_source_types">Review and set source types</span></a></h3>
<p>After you choose the file you want to monitor in the <b>Files &amp; Directories</b> Add Data panel or upload a file from the <b>Upload</b> page, Splunk Web presents the "Set Sourcetypes" page.
</p><p>The page has three sections. The top section provides instructions on how to use the page. The bottom left section has controls which let you select and define a new source type, including setting event break, timestamp, and other options. The bottom right section - the "data preview pane" - provides a window into how Splunk Enterprise sees the data currently. The actions you take in the lower left section reflect immediately in the lower right section.
</p><p>At any time, you can return to the previous page and select a new file to preview by clicking the white "&lt;" button in the top section.
</p><p><b>1a.</b> First, look at how Splunk Enterprise displays the data currently. How it displays here is how it will be indexed. Review event breaks and time stamps. 
</p><p><b>1b.</b> You can use the Event Summary pop-up dialog to show the number of lines that Splunk Enterprise counted when parsing the file. A lower number of lines counted in the file than you expect can indicate the need to customize event breaking.
</p><p><b>2a.</b> If the data appears the way you want, then proceed to Step 3a.
</p><p><b>2b.</b> If the data does not appear the way you want, proceed to "Choose an existing source type" later in this topic to change source type parameters until it does.
</p><p><b>3a.</b> If you agree with the existing source type that Splunk Enterprise selected, click the green "Next" button in the top section to proceed to the <b>Input Settings</b> page. The data preview process is now complete.
</p><p><b>3b.</b> If you do not agree with the existing source type that Splunk Enterprise selects, Splunk Enterprise does not choose a source type, or you want to define a new source type, then you can do one of the following:
</p>
<ul><li> <b>Choose an existing source type.</b> Splunk Enterprise indexes your data with this source type going forward. <b>Caution:</b> Choosing a different source type might change how Splunk Enterprise displays - and indexes - your data.
</li><li> <b>Save a new source type.</b> In rare cases, Splunk Enterprise parses the data correctly but doesn't provide an existing source type to use. In this case, you can save the source type and apply it to similar files in the future.
</li></ul><p><b>4.</b> Once you have chosen or saved a source type, click on the green "Next" button in the top section to proceed to the <b>Input Settings</b> page. The data preview process is now complete.
</p>
<h3> <a name="accessdatapreview_choose_an_existing_source_type"><span class="mw-headline" id="Choose_an_existing_source_type">Choose an existing source type</span></a></h3>
<p>If Splunk Enterprise doesn't display the data the way you want initially, first see if there is an existing source type that works.
</p><p>If you try to choose an existing source type and do not find success, then proceed to "Define a new source type" later in this topic for additional options to make your data display the way you like.
</p><p><img alt="62 setsourcetype existing.png" src="images/f/f1/62_setsourcetype_existing.png" width="700" height="571"></p><p><b>1.</b> Click the <b>Sourcetype: System Defaults</b> button.
</p><p>Splunk Enterprise displays a list of source type categories. Under each category is a list of source types within that category.
</p><p><b>2.</b> Mouse over the category that best represents your data. As you do, the source types under that category pop up in a menu to the right.
</p><p><b>3.</b> Select the source type that you feel best represents your data. Splunk Enterprise updates the data preview pane to show how the data looks under the new source type.
</p><p><b>Note:</b> You might need to scroll to see all source types in a category.
</p><p><b>4.</b> Review your data again, as described in "Review and set source types" earlier in this topic.
</p>
<h3> <a name="accessdatapreview_define_a_new_source_type"><span class="mw-headline" id="Define_a_new_source_type">Define a new source type</span></a></h3>
<p>If Splunk Enterprise does not show the data in the way you want even after choosing an existing source type, then define a new source type and configure event breaks, time stamp recognition, and other parameters until Splunk Enterprise displays the data to your liking.
</p><p>To modify these parameters and define the source type, proceed to "<a href="#modifyeventprocessing" class="external text">Modify event processing</a>" in this manual.
</p>
<a name="modifyeventprocessing"></a><h2> <a name="modifyeventprocessing_modify_event_processing"><span class="mw-headline" id="Modify_event_processing"> Modify event processing</span></a></h2>
<p>If you're not satisfied with how Splunk Enterprise initially processes your data, as described in <a href="#accessdatapreview" class="external text">"View and set source types for event data"</a>, you can use data preview to change the event processing settings and save the improved settings as a new source type. Here are the main steps:
</p><p><b>1.</b> View the event data, as described in <a href="#accessdatapreview" class="external text">"View and set source types for event data"</a>.
</p><p><b>2.</b> Modify the event processing settings. 
</p><p><b>3.</b> Review the effect of your changes and iterate until you are satisfied.
</p><p><b>4.</b> Save the modified settings as a new source type.
</p><p>You can then apply the new source type to any of your inputs.
</p>
<h3> <a name="modifyeventprocessing_modify_the_event_processing_settings"><span class="mw-headline" id="Modify_the_event_processing_settings">Modify the event processing settings </span></a></h3>
<p>Splunk Enterprise is ready to create a new source type by default. The "Sourcetype: System Defaults" drop-down in the "Set sourcetypes" page indicates this. To create the new source type, set the event-breaking and time stamp parameters as shown later in this topic, then save the source type.
</p><p><br><img alt="62 datapreview adjustevents.png" src="images/8/83/62_datapreview_adjustevents.png" width="700" height="221"></p><p>On the left side of the "Set Sourcetypes" page, there are collapsible tabs and links for the three types of adjustments that you can perform:
</p>
<ul><li> <b>Event Breaks.</b> Adjust the way that Splunk Enterprise breaks the data into events.
</li><li> <b>Timestamps.</b> Adjust the way Splunk Enterprise determines event timestamps.
</li><li> <b>Advanced mode.</b> Edit <code><font size="2">props.conf</font></code> directly.
</li></ul><h4><font size="3"><b><i> <a name="modifyeventprocessing_event_breaks"><span class="mw-headline" id="Event_breaks">Event breaks</span></a></i></b></font></h4>
<p><img alt="62 datapreview eventbreaks.png" src="images/8/82/62_datapreview_eventbreaks.png" width="640" height="260"></p><p>To modify event break parameters, click on the <b>Event Breaks</b> bar to expand it. The bar opens to display the following buttons:
</p>
<ul><li> <b>Auto</b> - Splunk Enterprise performs event breaking based on where it finds timestamps in the data.
</li><li> <b>Every line</b> - Splunk Enterprise considers every line a single event.
</li><li> <b>Regex...</b> - Click on this button to specify a regular expression that Splunk Enterprise uses to break data into events.
</li></ul><p>For detailed information on event linebreaking, see <a href="#indexmulti-lineevents" class="external text">"Configure event linebreaking"</a>.
</p><p>For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test your regular expression by using it in a search with the rex search command. Splunk Enterprise also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<h4><font size="3"><b><i> <a name="modifyeventprocessing_timestamps"><span class="mw-headline" id="Timestamps">Timestamps</span></a></i></b></font></h4>
<p><img alt="62 datapreview timestamps.png" src="images/d/d5/62_datapreview_timestamps.png" width="640" height="793"></p><p>To modify time stamp recognition parameters click the <b>Timestamps</b> bar to expand it. The bar opens to reveal these options:
</p><p>For <b>Extraction</b>, you can choose one of these options:
</p>
<ul><li> <b>Auto</b> - Splunk Enterprise automatically locates the timestamp.
</li><li> <b>Current Time</b> - Splunk Enterprise uses the current time on the local instance.
</li><li> <b>Advanced</b> - Splunk provides additional advanced parameters to adjust.
</li></ul><p>The "Advanced" parameters are:
</p>
<ul><li> <b>Timezone</b> - Select the time zone that you want to use for the events.
</li><li> <b>Timestamp format</b> - Type in a string that represents the <a href="#configuretimestamprecognition" class="external text">time stamp format</a> you expect Splunk Enterprise to use when searching for time stamps within the data. 
</li><li> <b>Timestamp prefix</b> - Enter a regular expression that represents the characters that appear before a time stamp.
</li><li> <b>Lookahead</b> - Enter the number of characters that Splunk Enterprise should look into the event (or, for the regular expression that you specified in "Timestamp prefix") for the time stamp.
</li></ul><p><b>Important:</b> If you specify a timestamp format in the "Timestamp format" field and the timestamp is not located at the very start of each event, you must also specify a prefix in the <b>Timestamp prefix</b> field. Otherwise, Splunk Enterprise will not be able to process the formatting instructions, and every event will contain a warning about the inability to use <code><font size="2">strptime</font></code>. (It's possible that you will still end up with a valid timestamp, based on how Splunk attempts to recover from the problem.)
</p><p>For detailed information on configuring timestamps, see the topics in the chapter <a href="#howsplunkextractstimestamps" class="external text">"Configure timestamps"</a>.
</p>
<h4><font size="3"><b><i> <a name="modifyeventprocessing_advanced"><span class="mw-headline" id="Advanced">Advanced</span></a></i></b></font></h4>
<p>To modify advanced parameters, click the <b>Advanced</b> bar to expand it. The bar opens to reveal options that let you specify source type properties by directly editing the underlying <code><font size="2">props.conf</font></code> file.
</p><p>Here, you can add or change source type properties, by specifying attribute/value pairs. See props.conf for details on how to set these properties.
</p><p>This box shows the current, complete set of properties for the source type you're editing, including:
</p>
<ul><li> any settings generated by changes made in the <b>Event Breaks</b> or <b>Timestamps</b> tabs (after you click the <b>Apply</b> button).
</li><li> any pre-existing settings for a source type that was either auto-detected or manually selected when you first fed the file to Data Preview.
</li><li> any settings you apply from the <b>Additional settings</b> text box (after you click the <b>Apply settings</b> button).
</li></ul><p><img alt="62 datapreview advmode.png" src="images/1/13/62_datapreview_advmode.png" width="640" height="364"></p><p>For information on how to set source type properties, see props.conf in the Configuration file reference. Also, you can refer to these topics on <a href="#howsplunkextractstimestamps" class="external text">timestamp configuration</a> and <a href="#indexmulti-lineevents" class="external text">event linebreaking</a>.
</p>
<h4><font size="3"><b><i> <a name="modifyeventprocessing_how_splunk_enterprise_combines_settings"><span class="mw-headline" id="How_Splunk_Enterprise_combines_settings">How Splunk Enterprise combines settings </span></a></i></b></font></h4>
<p>The settings you make in <b>Advanced mode</b> always take precedence. For example, if you alter a timestamp setting using the <b>Timestamps</b> tab and also make a conflicting timestamp change in <b>Advanced mode</b> - no matter whether before or after - the <b>Advanced mode</b> change wins. 
</p><p>Starting with highest precedence, here is how Splunk Enterprise combines any adjustments with the underlying default settings:
</p>
<ul><li> Advanced mode changes
</li><li> Event Breaks/Timestamps changes
</li><li> Settings for the underlying source type, if any
</li><li> Default system settings for all source types
</li></ul><p>Also, if you return to the Event Breaks or Timestamps tabs after making changes in <b>Advanced mode</b>, the changes will not be visible from those tabs.
</p>
<h3> <a name="modifyeventprocessing_review_your_changes"><span class="mw-headline" id="Review_your_changes">Review your changes</span></a></h3>
<p>When you're ready to view the effect of your changes, select <b>Apply settings</b>. Splunk Web refreshes the screen, so you can review the effect of your changes on the data.  
</p><p>If you want to make further changes, you can now do so, using any of the three adjustment methods available.  Once again, select <b>Apply changes</b> to view the effect of the changes on your data.
</p>
<h3> <a name="modifyeventprocessing_save_modifications_as_a_new_source_type"><span class="mw-headline" id="Save_modifications_as_a_new_source_type">Save modifications as a new source type</span></a></h3>
<p>To save the changes as a new source type, click the green "Save As" button next to the "Sourcetype" button. Splunk Web displays a dialog box where you can name your new source type, choose the category in which it should be shown in the "Sourcetype" button dialog, and the application context it should use.
</p><p><img alt="62 datapreview savesourcetype.png" src="images/9/96/62_datapreview_savesourcetype.png" width="640" height="416"></p><p><b>1.</b> Enter the <b>Name</b> of the new source type.
</p><p><b>2.</b> Enter the <b>Description</b> of what the source type is.
</p><p><b>3.</b> Choose the <b>Category</b> in which the source type should appear when you select the "Sourcetype" button.
</p><p><b>4.</b> Choose the <b>App</b> for which the new source type should be used.
</p><p><b>5.</b> Click the green <b>Save</b> button to save the source type and return to the "Set Sourcetypes" page.
</p><p>At this point you can:
</p>
<ul><li> Click the green <b>Next</b> button to apply the source type to your data and proceed to the <b>Input settings</b> page.
</li><li> Click the white "&lt;" button to go back and choose a new file to upload or monitor.
</li><li> Click the <b>Add data</b> text to return to the beginning of the Add Data wizard.
</li></ul><a name="datapreviewanddistributeddeployment"></a><h2> <a name="datapreviewanddistributeddeployment_data_preview_and_distributed_splunk_enterprise"><span class="mw-headline" id="Data_preview_and_distributed_Splunk_Enterprise"> Data preview and distributed Splunk Enterprise</span></a></h2>
<p>You can use data preview to create new source types, which you can then assign to inputs from specific files/directories or from tcp/udp.  Data preview saves any new source type to a <code><font size="2">props.conf</font></code> configuration file on the Splunk Enterprise instance you're running it on. If you want to use the source type on other Splunk Enterprise instances, you can distribute the file as needed.
</p><p>There are two steps to using a new source type in a distributed environment, where you have <b>forwarders</b> consuming data and then forwarding the data to indexers:
</p><p><b>1.</b> Distribute the <code><font size="2">props.conf</font></code> file containing the source type definition to any indexers that will be indexing data with the source type.
</p><p><b>2.</b> You can then use the new source type when you define an input on forwarders sending data to those indexers.
</p><p>When a forwarder sends data tagged with the new source type to an indexer, the indexer will be able to correctly process it into events.
</p><p>This topic first describes the configuration file that data preview creates. It then explains how to distribute the file to the indexers in your deployment. Finally, it tells you how to specify the new source type when defining an input on a forwarder.
</p><p>For detailed information on distributed Splunk Enterprise, read the Distributed Deployment Manual.
</p>
<h3> <a name="datapreviewanddistributeddeployment_the_data_preview_props.conf_file"><span class="mw-headline" id="The_data_preview_props.conf_file"> The data preview props.conf file </span></a></h3>
<p>When you create a new source type in the "Set Sourcetype" page, Splunk Enterprise saves the source type definition as a stanza in a props.conf file in the app that you selected when you saved the source type. For example, if you deleted the "Search and Reporting" app, the file will reside in <code><font size="2">$SPLUNK_HOME/etc/apps/search/local/props.conf</font></code>. The only exception is the "System" app: If you choose that app when saving the source type, the file will reside in <code><font size="2">$SPLUNK_HOME/etc/system/local.</font></code>.
</p><p>The first time you use data preview to create a source type, Splunk Enterprise generates a new <code><font size="2">props.conf</font></code> file in the directory for the app that you chose when saving the source type. If you later create additional source types, Splunk saves the additional source types to the same <code><font size="2">props.conf</font></code> file.
</p><p><b>Note:</b> A Splunk Enterprise instance might have multiple versions of some configuration files, spread across several directories. At run-time, Splunk Enterprise combines the contents of configuration files according to a set of rules. For background on how configuration files work, read "About configuration files" and "Configuration file precedence".
</p>
<h3> <a name="datapreviewanddistributeddeployment_distribute_props.conf_to_other_indexers"><span class="mw-headline" id="Distribute_props.conf_to_other_indexers"> Distribute props.conf to other indexers </span></a></h3>
<p>After you create new source types, you can distribute the data preview  <code><font size="2">props.conf</font></code> file to another Splunk Enterprise instance. That instance will then be able to index any incoming data that's been tagged with the new source type(s).
</p><p>Generally, you will want to put the configuration file in its own app directory on the target Splunk Enterprise instance; for example, <code><font size="2">$SPLUNK_HOME/etc/apps/splunk_datapreview/local/</font></code>. 
</p><p>To distribute configuration files to other Splunk instances, you can use Splunk's <b>deployment server</b> or another distribution tool of your choice. To learn how to use the deployment server, read the Updating Splunk Instances manual.
</p><p><b>Note:</b> Splunk Enterprise uses the source type definitions in <code><font size="2">props.conf</font></code> to parse incoming data into events. For this reason, you can only distribute the file to a Splunk Enterprise instance that performs <b>parsing</b>; that is, either an indexer or a <b>heavy forwarder</b>.
</p>
<h3> <a name="datapreviewanddistributeddeployment_specify_the_new_source_type_in_forwarder_inputs"><span class="mw-headline" id="Specify_the_new_source_type_in_forwarder_inputs"> Specify the new source type in forwarder inputs</span></a></h3>
<p>Since forwarders (with the exception of the heavy forwarder) do not contain Splunk Web, you usually configure their inputs through the 
<code><font size="2">inputs.conf</font></code> configuration file. When you specify an input in that file, you can also specify the input's source type. For detailed information on <code><font size="2">inputs.conf</font></code>, read the section on <code><font size="2">inputs.conf</font></code> in the Configuration file reference.
</p><p>To tag a forwarder input with a new source type, you just add the source type to the input stanza in <code><font size="2">inputs.conf</font></code>. For example:
</p>
<code><font size="2"><br>[tcp://:9995]<br>sourcetype = new_network_type<br></font></code>
<p>You must make sure that all of the forwarder's receiving indexers have copies of the data preview <code><font size="2">props.conf</font></code> file containing the source type definition for "new_network_type". When the forwarder sends data to the indexers, they will then be able to identify the new source type and correctly format the data. The procedure for distributing <code><font size="2">props.conf</font></code> is described earlier in this topic, in the section "Distribute props.conf to other indexers". 
</p>
<h3> <a name="datapreviewanddistributeddeployment_data_preview_and_search_head_pooling"><span class="mw-headline" id="Data_preview_and_search_head_pooling"> Data preview and search head pooling</span></a></h3>
<p>If you use the  <b>search head pooling</b> feature of <b>distributed search</b>, you need to follow some guidelines to ensure that data preview appears in Splunk Web. This is because Splunk Enterprise implements data preview as a built-in app. For more information, read "Artifacts and incorrectly displayed items in Splunk Web after upgrade" in the Distributed Search Manual.
</p>
<a name="modifyinputsettings"></a><h2> <a name="modifyinputsettings_modify_input_settings"><span class="mw-headline" id="Modify_input_settings"> Modify input settings</span></a></h2>
<p>This topic discusses the "Input Settings" page Splunk Enterprise presents after you configure the data source in the "Set Sourcetypes" page.
</p><p>After you select the source (or set your source type when uploading or monitoring a single file), Splunk Enterprise presents the following page:
</p><p><img alt="62 datapreview inputsettings.png" src="images/8/8a/62_datapreview_inputsettings.png" width="700" height="392"></p><p>The page lets you specify additional parameters for your data input, such as its source type, its application context, its host value, and the index where data from the input should be stored.
</p><p>The input settings available are as follows:
</p>
<h3> <a name="modifyinputsettings_source_type"><span class="mw-headline" id="Source_type">Source type</span></a></h3>
<p>The "Sourcetype" setting lets you specify what source type Splunk Enterprise should apply to your data. It appears when:
</p>
<ul><li> You specify a data source that is not a single file.
</li><li> You specify a directory as a data source.
</li><li> You specify a network input as a data source.
</li><li> You specify a data source that has been forwarded from another Splunk Enterprise instance.
</li></ul><p>If your data source does not meet these criteria, then the "Sourcetype" setting does not appear.
</p><p>To specify a source type, click one of the three buttons:
</p>
<ul><li> <b>Automatic</b>: Tells Splunk Enterprise to apply the default source type to the data.
</li><li> <b>Select</b>: Tells Splunk Enterprise to apply the source type you specify to the data. When you click "Select," a drop-down appears that lists all available source types on the machine, arranged by category. First, choose the category that best represents the source type you want, then choose the source type from the list.
</li><li> <b>Manual</b>: Tells Splunk Enterprise to use the source type that you enter in the field that appears below.
</li></ul><p><b>Note:</b> There is no facility to create a source type on this page. If you want to create a source type so that it appears in the "Select" list, either:
</p>
<ul><li> Choose a single file to <a href="#uploaddata" class="external text">upload</a> or <a href="#monitordata" class="external text">monitor</a> and create the source type using the "<a href="#overviewofdatapreview" class="external text">Set Sourcetypes</a>" page, or
</li><li> <a href="#createsourcetypes" class="external text">Create the source type</a> by editing the <code><font size="2">props.conf</font></code> file. Read the props.conf spec file for a list of valid attributes. 
</li></ul><h3> <a name="modifyinputsettings_app_context"><span class="mw-headline" id="App_context">App context</span></a></h3>
<p>The <b>Application Context</b> setting tells Splunk Enterprise the context in which the input should collect data. Application contexts improve manageability of input and source type definitions. Splunk Enterprise loads all app contexts based on precedence rules. See "Configuration file precedence" in the Admin manual.
</p><p>Select the application context you want this input to operate within by clicking the drop-down and selecting the application context you want from the list.
</p>
<h3> <a name="modifyinputsettings_host_value"><span class="mw-headline" id="Host_value">Host value</span></a></h3>
<p>Splunk Enterprise tags each event that it indexes with a host value. You can configure what Splunk Enterprise tags events with by specifying how it should do so:
</p>
<ul><li> <b>Constant value</b>: Tells Splunk Enterprise to use the value you specify in the "Host Field Value" field. Splunk Enterprise tags each event with this value for the "Host" field, and you can later search on this host field with the same value.
</li></ul><ul><li> <b>Regular expression on path</b>: Use this setting to configure Splunk Enterprise to extract the host value from the path of the file that contains the data. Enter the valid regular expression in the <b>Regular expression</b> field below. Splunk Enterprise then uses this regular expression to extract the host name from the path. See "<a href="#abouthosts" class="external text">About hosts</a>."
</li></ul><ul><li> <b>Segment in path</b>: Use this setting to tell Splunk Enterprise to determine the host value from a segment within the source input path name. Enter the segment number in the <b>Segment number</b> field below.
</li></ul><p>For example, if the source input has a pathname <code><font size="2">/var/server/&lt;hostname&gt;</font></code>, and you wanted Splunk Enterprise to set the host field based on <code><font size="2">hostname</font></code>, you would select "Segment in path" and enter <code><font size="2">3</font></code> as the segment number, since <code><font size="2">&lt;hostname&gt;</font></code> is the third segment in the path <code><font size="2">/var/log/hostname</font></code>.
</p>
<h3> <a name="modifyinputsettings_index"><span class="mw-headline" id="Index">Index</span></a></h3>
<p>The "Index" setting tells Splunk Enterprise which index that it should store the events for this input. To use the default index, leave the drop-down button set to "Default". To choose another index, click the drop-down button and select the index you want the data to go to by clicking the selection in the list. If the index you want to send the data to is not in the list, and you have the permissions, you can create a new index by clicking the <b>Create a new index</b> button.
</p><p>Once you have made your selections, you can proceed to the final step of the "Add Data" process by clicking the green <b>Next</b> button.
</p>
<h1>Get data from files and directories</h1><a name="monitorfilesanddirectories"></a><h2> <a name="monitorfilesanddirectories_monitor_files_and_directories"><span class="mw-headline" id="Monitor_files_and_directories"> Monitor files and directories</span></a></h2>
<p>Splunk Enterprise has three file input processors: <b>monitor</b>, <b>MonitorNoHandle</b>, and <b>upload</b>. 
</p><p>You can use <b>monitor</b> to add nearly all your data sources from files and directories. However, you might want to use upload to add one-time inputs, such as an archive of historical data.
</p><p>On Windows systems, you can use <b>MonitorNoHandle</b> to monitor files which the system rotates automatically.  <b>MonitorNoHandle</b> works only on Windows systems. 
</p><p>You can add inputs to monitor or upload using any of these methods:
</p>
<ul><li> <a href="#usesplunkweb" class="external text">Splunk Web</a>
</li><li> <a href="#monitorfilesanddirectoriesusingthecli" class="external text">The CLI</a> 
</li><li> <a href="#editinputs.conf" class="external text">inputs.conf</a>
</li></ul><p>You can add inputs to <b>MonitorNoHandle</b> using either the CLI or inputs.conf.
</p><p>You can use the "Set Sourcetype" page to see how Splunk Enterprise will index data from a file. See  "<a href="#overviewofdatapreview" class="external text">The "Set Sourcetype" page</a>" for details.
</p>
<h3> <a name="monitorfilesanddirectories_how_monitor_works_in_splunk_enterprise"><span class="mw-headline" id="How_monitor_works_in_Splunk_Enterprise"> How monitor works in Splunk Enterprise </span></a></h3>
<p>Specify a path to a file or directory and the Splunk Enterprise monitor processor consumes any new data written to that file or directory. This is how you can monitor live application logs such as those coming from Java 2 Platform Enterprise Edition (J2EE) or .NET applications, Web access logs, and so on. Splunk Enterprise continues to monitor and index the file or directory as new data appears. You can also specify a mounted or shared directory, including network file systems, so long as Splunk Enterprise can read from the directory. If the specified directory contains subdirectories, Splunk Enterprise recursively examines them for new files. 
</p><p>Splunk Enterprise checks for the file or directory specified in a monitor configuration on start and restart. If the file or directory is not present on start, Splunk Enterprise continues to check for it every 24 hours from the time of the last restart. Splunk Enterprise also scans subdirectories of monitored directories continuously. To add new inputs without restarting Splunk Enterprise, use Splunk Web or the CLI.  If you want Splunk Enterprise to find potential new inputs automatically, use the <b>crawl</b> CLI command.
</p><p>When using monitor, note the following:
</p>
<ul><li> On most file systems, files can be read even as they are being written to. However, Windows file systems can prevent files from being read while they are being written to, and some Windows programs might use these modes. If you need to read files while they are being written to, you can use the <code><font size="2">MonitorNoHandle</font></code> input.
</li><li> Files or directories can be included or excluded via <b>whitelists</b> and <b>blacklists</b>.
</li><li> Upon restart, Splunk Enterprise continues processing files where it left off.
</li><li> Splunk Enterprise decompresses archive files before it indexes them. It can handle these common archive file types: <code><font size="2">tar, gz, bz2, tar.gz, tgz, tbz, tbz2, zip</font></code>, and <code><font size="2">z</font></code>.
</li><li> If you add new data to an existing archive file, Splunk Enterprise will re-index the entire file, not just the new data in the file. This can result in duplication of events.
</li><li> Splunk Enterprise detects log file rotation and does not process renamed files it has already indexed (with the exception of .tar and .gz archives; for more information see <a href="#howlogfilerotationishandled" class="external text">"Log file rotation"</a> in this manual).
</li><li> The entire <code><font size="2">dir/filename</font></code> path must not exceed 1024 characters.
</li><li> Disabling or deleting a file-based input using the command line or System does not stop the input's files from being indexed. Rather, it stops files from being checked again, but all the initial content will be indexed. To stop all in-process data, you must restart the Splunk Enterprise server.
</li><li> Splunk Enterprise does not index files with a <code><font size="2">.splunk</font></code> filename extension. This is because Splunk Enterprise expects files with that extension to be metadata information files. If you need to index files with a <code><font size="2">.splunk</font></code> extension, use the <code><font size="2">add oneshot</font></code> CLI command.
</li></ul><p>Monitor inputs may overlap. So long as the stanza names are different, Splunk Enterprise treats them as independent stanzas and files matching the most specific stanza will be treated in accordance with its settings.
</p>
<h3> <a name="monitorfilesanddirectories_why_use_upload_or_batch.3f"><span class="mw-headline" id="Why_use_upload_or_batch.3F"> Why use upload or batch? </span></a></h3>
<p>To index a static file once, select <b>Upload</b> in Splunk Web. Splunk Enterprise will only monitor the file once. 
</p><p>You can also use the CLI <code><font size="2">add oneshot</font></code> or <code><font size="2">spool</font></code> commands for the same purpose. See "<a href="#monitorfilesanddirectoriesusingthecli" class="external text">Use the CLI</a>" for details.
</p><p>Use the <code><font size="2">batch</font></code> input type in <code><font size="2">inputs.conf</font></code> to load files once and destructively. By default, the Splunk batch processor is located in <code><font size="2">$SPLUNK_HOME/var/spool/splunk</font></code>. If you move a file into this directory, Splunk indexes it and then deletes it. 
</p><p><b>Note:</b> For best practices on loading file archives, see "How to index different sized archives" on the Community Wiki.
</p>
<h3> <a name="monitorfilesanddirectories_why_use_monitornohandle.3f"><span class="mw-headline" id="Why_use_MonitorNoHandle.3F"> Why use MonitorNoHandle? </span></a></h3>
<p>This Windows-only input allows you to read files on Windows systems as Windows writes to them. It does this by using a kernel-mode filter driver to capture raw data as it gets written to the file. Use this input stanza on files which get locked open for writing. You can use this input stanza on a file which the system locks open for writing, such as the Windows DNS server log file.
</p><p><b>Note:</b> You can only monitor single files with <code><font size="2">MonitorNoHandle</font></code>. You can not monitor directories. If a file you choose to monitor already exists, Splunk does not index its current contents, only new information that comes into the file as it gets written to.
</p>
<a name="usesplunkweb"></a><h2> <a name="usesplunkweb_use_splunk_web"><span class="mw-headline" id="Use_Splunk_Web"> Use Splunk Web</span></a></h2>
<p>You can use Splunk Web to add inputs from files and directories or any other input that the Splunk Enterprise instance is capable of monitoring.
</p>
<h4><font size="3"><b><i> <a name="usesplunkweb_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></i></b></font></h4>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Upload</b> to upload a file, <b>Monitor</b> to monitor a file, or <b>Forward</b> to forward a file.
</p><p><b>Note:</b> Forwarding a file requires additional setup. See "Set up forwarding and receiving" in the Forwarding Data manual.
</p>
<h4><font size="3"><b><i> <a name="usesplunkweb_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></i></b></font></h4>
<p><b>1.</b> To add a file or directory input, click <b>Files &amp; Directories.</b>
</p><p><b>2.</b> In the <b>File or Directory</b> field, specify the full path to the file or directory.
</p><p>To monitor a shared network drive, enter the following: <code><font size="2">&lt;myhost&gt;/&lt;mypath&gt;</font></code> (or <code><font size="2">\\&lt;myhost&gt;\&lt;mypath&gt;</font></code> on Windows). Make sure Splunk Enterprise has read access to the mounted drive, as well as to the files you wish to monitor. 
</p><p><b>3.</b> Choose how you want Splunk Enterprise to monitor the file:
</p>
<ul><li> <b>Continuously Monitor</b>. Sets up an ongoing input. Splunk Enterprise monitors the file continuously for new data. Read the next section for advanced options specific to this choice.
</li><li> <b>Index Once</b>. Copies a file on the server into Splunk Enterprise.
</li></ul><p><b>4.</b> Click the green <b>Next</b> button. 
</p>
<ul><li> If you specified a directory in the "File or Directory" field, Splunk Enterprise refreshes the screen to show fields for "whitelist" and "blacklist". These fields let you specify regular expressions that Splunk Enterprise then uses to match files for inclusion (in the case of a whitelist) or exclusion (in the case of a blacklist). See "<a href="#whitelistorblacklistspecificincomingdata" class="external text">Whitelist or blacklist specific incoming data</a>."
</li></ul><ul><li> Otherwise, Splunk Enterprise lets you preview the data.
</li></ul><h4><font size="3"><b><i> <a name="usesplunkweb_c._preview_your_data_and_set_its_source_type"><span class="mw-headline" id="C._Preview_your_data_and_set_its_source_type"> C. Preview your data and set its source type </span></a></i></b></font></h4>
<p>When you add a new file input, Splunk Enterprise lets you set the <b>source type</b> of your data and preview how it will look once it has been indexed. This lets you ensure that the data has been formatted properly and make any necessary adjustments. 
</p>
<ul><li> See "<a href="#overviewofdatapreview" class="external text">The 'Set Sourcetypes' page</a>" to learn about the page.
</li><li> See "<a href="#accessdatapreview" class="external text">View and set source types for event data</a>" to learn how to use the page.
</li></ul><p>If you choose to skip data preview, Splunk Web takes you to the <b>Input Settings</b> page.
</p><p><b>Note:</b> Splunk Enterprise cannot show a preview of directories or archived files.
</p>
<h4><font size="3"><b><i> <a name="usesplunkweb_d._specify_input_settings"><span class="mw-headline" id="D._Specify_input_settings"> D. Specify input settings </span></a></i></b></font></h4>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in "<a href="#abouthosts" class="external text">About hosts</a>".
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to for this input. Leave the value as "default", unless you have defined multiple indexes and want to use one of those instead. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h4><font size="3"><b><i> <a name="usesplunkweb_e._review_your_choices"><span class="mw-headline" id="E._Review_your_choices"> E. Review your choices </span></a></i></b></font></h4>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the gray <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified file or directory.
</p>
<a name="monitorfilesanddirectoriesusingthecli"></a><h2> <a name="monitorfilesanddirectoriesusingthecli_use_the_cli"><span class="mw-headline" id="Use_the_CLI"> Use the CLI</span></a></h2>
<p>Monitor files and directories via the Splunk Enterprise Command Line Interface (CLI). To use the CLI, navigate to the <code><font size="2">$SPLUNK_HOME/bin/</font></code> directory from a command prompt or shell, and use the <code><font size="2">splunk</font></code> command in that directory. 
</p><p>If you get stuck, the CLI has built-in help.  Access the main CLI help by typing <code><font size="2">splunk help</font></code>. Individual commands have their own help pages as well -- type <code><font size="2">splunk help &lt;command&gt;</font></code>.
</p>
<h3> <a name="monitorfilesanddirectoriesusingthecli_cli_commands_for_input_configuration"><span class="mw-headline" id="CLI_commands_for_input_configuration"> CLI commands for input configuration </span></a></h3>
<p>The following commands are available for input configuration via the CLI:
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Command
</th><th bgcolor="#C0C0C0">Command syntax
</th><th bgcolor="#C0C0C0">Action
</th></tr><tr><td valign="center" align="left"><b>add monitor</b>
</td><td valign="center" align="left"><code><font size="2">add monitor &lt;source&gt; [-parameter value] ...</font></code>
</td><td valign="center" align="left">Monitor inputs from <code><font size="2">&lt;source&gt;</font></code>.
</td></tr><tr><td valign="center" align="left"><b>edit monitor</b>
</td><td valign="center" align="left"><code><font size="2">edit monitor &lt;source&gt; [-parameter value] ...</font></code>
</td><td valign="center" align="left">Edit a previously added monitor input for <code><font size="2">&lt;source&gt;</font></code>.
</td></tr><tr><td valign="center" align="left"><b>remove monitor</b>
</td><td valign="center" align="left"><code><font size="2">remove monitor &lt;source&gt;</font></code>
</td><td valign="center" align="left">Remove a previously added monitor input for <code><font size="2">&lt;source&gt;</font></code>.
</td></tr><tr><td valign="center" align="left"><b>list monitor</b>
</td><td valign="center" align="left"><code><font size="2">list monitor</font></code>
</td><td valign="center" align="left">List the currently configured monitor inputs.
</td></tr><tr><td valign="center" align="left"><b>add oneshot</b>
</td><td valign="center" align="left"><code><font size="2">add oneshot &lt;source&gt; [-parameter value] ...</font></code>
</td><td valign="center" align="left">Copy the file &lt;source&gt; directly into Splunk. This uploads the file once, but Splunk Enterprise does not continue to monitor it.
<p><b>Note:</b>
</p>
<ul><li> The <code><font size="2">oneshot</font></code> command cannot be used against a remote Splunk Enterprise instance. 
</li><li> The command does not support the use of either recursive folders or wildcards as a source. When using this command, specify the exact source path of the file you wish to monitor.
</li></ul></td></tr><tr><td valign="center" align="left"><b>spool</b>
</td><td valign="center" align="left"><code><font size="2">spool &lt;source&gt;</font></code>
</td><td valign="center" align="left">Copy the file &lt;source&gt; into Splunk Enterprise via the sinkhole directory. This command is similar to <b>add oneshot</b>, except that the file gets spooled from the sinkhole directory, rather than added immediately.
</td></tr></table><p>Change the configuration of each data input type by setting additional parameters. Parameters are set via the syntax: <code><font size="2">-parameter value</font></code>. 
</p><p><b>Note:</b> You can only set one <code><font size="2">-hostname</font></code>, <code><font size="2">-hostregex</font></code> or <code><font size="2">-hostsegmentnum</font></code> per command.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Parameter
</th><th bgcolor="#C0C0C0">Required?
</th><th bgcolor="#C0C0C0">Description
</th></tr><tr><td valign="center" align="left"><code><font size="2">&lt;source&gt;</font></code>
</td><td valign="center" align="left">Yes
</td><td valign="center" align="left">Path to the file or directory to monitor/upload for new input.
<p><b>Note:</b> Unlike the other parameters, the syntax for this parameter is just the value itself  and is not preceded by a parameter flag: "<code><font size="2">&lt;source&gt;</font></code>", not "<code><font size="2">-source &lt;source&gt;</font></code>".
</p>
</td></tr><tr><td valign="center" align="left"><code><font size="2">sourcetype</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a sourcetype field value for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">index</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify the destination index for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">hostname</font></code> <b>or</b> <code><font size="2">host</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a host name to set as the host field value for events from the input source.
<p><b>Note:</b> These are functionally equivalent.
</p>
</td></tr><tr><td valign="center" align="left"><code><font size="2">hostregex</font></code> <b>or</b> <code><font size="2">host_regex</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a regular expression to use to extract the host field value from the source key.
<p><b>Note:</b> These are functionally equivalent.
</p>
</td></tr><tr><td valign="center" align="left"><code><font size="2">hostsegmentnum</font></code> <b>or</b> <code><font size="2">host_segment</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">An integer, which determines what "/" separated segment of the path to set as the host field value. If set to 3, for example, the third segment of the path is used.
<p><b>Note:</b> These are functionally equivalent.
</p>
</td></tr><tr><td valign="center" align="left"><code><font size="2">rename-source</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a value for the "source" field to be applied to data from this file.
</td></tr><tr><td valign="center" align="left"><code><font size="2">follow-only</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Set to "true" or "false". Default is "false".
<p>When set to "true", Splunk Enterprise reads from the end of the source (like the "tail -f" Unix command).
</p><p><b>Note:</b> This parameter is not available for <code><font size="2">add oneshot</font></code>.
</p>
</td></tr></table><h3> <a name="monitorfilesanddirectoriesusingthecli_example_1:_monitor_files_in_a_directory"><span class="mw-headline" id="Example_1:_Monitor_files_in_a_directory"> Example 1: Monitor files in a directory </span></a></h3>
<p>The following example shows how to monitor files in <code><font size="2">/var/log/</font></code>. 
</p><p>Add <code><font size="2">/var/log/</font></code> as a data input:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk add monitor /var/log/ <br></font></code></div>
<h3> <a name="monitorfilesanddirectoriesusingthecli_example_2:_monitor_windowsupdate.log"><span class="mw-headline" id="Example_2:_Monitor_windowsupdate.log">  Example 2: Monitor windowsupdate.log </span></a></h3>
<p>The following example shows how to monitor the Windows Update log file (where Windows logs automatic updates), sending the data to an index called "newindex".
</p><p>Add <code><font size="2">C:\Windows\windowsupdate.log</font></code> as a data input:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk add monitor C:\Windows\windowsupdate.log -index newindex<br></font></code></div>
<h3> <a name="monitorfilesanddirectoriesusingthecli_example_3:_monitor_iis_logging"><span class="mw-headline" id="Example_3:_Monitor_IIS_logging">  Example 3: Monitor IIS logging </span></a></h3>
<p>This example shows how to monitor the default location for Windows IIS logging.
</p><p>Add <code><font size="2">C:\windows\system32\LogFiles\W3SVC </font></code> as a data input:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk add monitor c:\windows\system32\LogFiles\W3SVC <br></font></code></div>
<h3> <a name="monitorfilesanddirectoriesusingthecli_example_4:_upload_a_file"><span class="mw-headline" id="Example_4:_Upload_a_file">  Example 4: Upload a file </span></a></h3>
<p>This example shows how to upload a file into Splunk. Unlike the previous examples, Splunk Enterprise only consumes the file once; it does not continuously monitor it.
</p><p>Upload <code><font size="2">/var/log/applog</font></code> directly into Splunk Enterprise with the <code><font size="2">add oneshot</font></code> command:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk add oneshot /var/log/applog<br></font></code></div>
<p>You can also upload a file via the sinkhole directory with the <code><font size="2">spool</font></code> command:
</p>
<div class="samplecode"><code><font size="2"><br>./splunk spool /var/log/applog<br></font></code></div>
<p>The result is the same with either command.
</p>
<a name="editinputs.conf"></a><h2> <a name="editinputs.conf_edit_inputs.conf"><span class="mw-headline" id="Edit_inputs.conf"> Edit inputs.conf</span></a></h2>
<p>To add an input to Splunk Enterprise, add a <b>stanza</b> to inputs.conf in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code>, or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  If you have not worked with Splunk's configuration files before, read "About configuration files" before you begin.
</p><p>You can set multiple attributes in an input stanza. If you do not specify a value for an attribute, Splunk Enterprise uses the default, as defined in <code><font size="2">$SPLUNK_HOME/etc/system/default/inputs.conf</font></code>.
</p><p><b>Note:</b> To ensure that new events are indexed when you copy over an existing file with new contents, set the <code><font size="2">CHECK_METHOD = modtime</font></code> attribute in props.conf for the source. This checks the modification time of the file and re-indexes it when it changes. Be aware that the entire file will be re-indexed, which can result in duplicate events.
</p>
<h3> <a name="editinputs.conf_configuration_settings"><span class="mw-headline" id="Configuration_settings"> Configuration settings </span></a></h3>
<p>There are separate stanza types for monitor and batch. See <a href="#monitorfilesanddirectories" class="external text">"Monitor files and directories"</a> for detailed information about monitor and batch.
</p><p>The following are attributes that you can use in both <code><font size="2">monitor</font></code> and <code><font size="2">batch</font></code> input stanzas. See the sections that follow for attributes that are specific to each type of input.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">host = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the host key/field to a static value for this stanza.
</li><li> Sets the host key's initial value. The key is used during parsing/indexing, in particular to set the host field. It is also the host field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'host::'.
</li></ul></td><td valign="top" align="left"> <code><font size="2">the IP address or fully-qualified domain name of the host where the data originated.</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Set the index where events from this input will be stored.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'index::'.
</li><li> For more information about the index field, see "How indexing works" in the Managing Indexers and Clusters manual.
</li></ul></td><td valign="top" align="left"> <code><font size="2">main</font></code> or whatever you set the default index to
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the sourcetype key/field for events from this input.
</li><li> Explicitly declares the source type for this data, as opposed to allowing Splunk Enterprise to determine it automatically. This is important both for searchability and for applying the relevant formatting for this type of data during parsing and indexing.
</li><li> Sets the sourcetype key's initial value. Splunk Enterprise uses the key during parsing/indexing, in particular to set the source type field during indexing. It is also the source type field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'sourcetype::'.
</li><li> For more information about source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a>, in this manual.
</li></ul></td><td valign="top" align="left"> Splunk Enterprise picks a source type based on various aspects of the data. There is no hard-coded default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">queue = parsingQueue | indexQueue</font></code>
</td><td valign="top" align="left">
<ul><li> Specifies where the input processor should deposit the events that it reads.
</li><li> Set to "parsingQueue" to apply <code><font size="2">props.conf</font></code> and other parsing rules to your data.
</li><li> Set to "indexQueue" to send your data directly into the index.
</li></ul></td><td valign="top" align="left"> parsingQueue
</td></tr><tr><td valign="top" align="left"> <code><font size="2">_TCP_ROUTING = &lt;tcpout_group_name&gt;,&lt;tcpout_group_name&gt;,...</font></code>
</td><td valign="top" align="left">
<ul><li> Specifies a comma-separated list of tcpout group names.
</li><li> Using this attribute, you can selectively forward your data to specific indexer(s) by specifying the tcpout group(s) that the forwarder should use when forwarding your data.
</li><li> You define the tcpout group names in <code><font size="2">outputs.conf</font></code> in <code><font size="2">[tcpout:&lt;tcpout_group_name&gt;]</font></code> stanzas.
</li><li> This setting defaults to the groups present in 'defaultGroup' in <code><font size="2">[tcpout]</font></code> stanza in outputs.conf.
</li></ul></td><td valign="top" align="left"> the groups present in 'defaultGroup' in <code><font size="2">[tcpout]</font></code> stanza in outputs.conf
</td></tr><tr><td valign="top" align="left"> <code><font size="2">host_regex = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> If specified, the regex extracts host from the filename of each input. 
</li><li> Specifically, the first group of the regex is used as the host. 
</li></ul></td><td valign="top" align="left"> the default "<code><font size="2">host =</font></code>" attribute, if the regex fails to match
</td></tr><tr><td valign="top" align="left"> <code><font size="2">host_segment = &lt;integer&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> If specified, a segment of the path is set as host, using <code><font size="2">&lt;integer&gt;</font></code> to determine which segment. For example, if <code><font size="2">host_segment = 2</font></code>, host is set to the second segment of the path. Path segments are separated by the '/' character. 
</li></ul></td><td valign="top" align="left"> the default "<code><font size="2">host =</font></code>" attribute, if the value is not an integer, or is less than 1
</td></tr></table><h3> <a name="editinputs.conf_monitor_syntax_and_examples"><span class="mw-headline" id="Monitor_syntax_and_examples"> Monitor syntax and examples </span></a></h3>
<p>Monitor input stanzas direct Splunk Enterprise to watch all files in the <code><font size="2">&lt;path&gt;</font></code> (or just <code><font size="2">&lt;path&gt;</font></code> itself if it represents a single file). You must specify the input type and then the path, so put three slashes in your path if you're starting at the root directory.  
</p><p>You can use wildcards for the path. For more information, read "<a href="#specifyinputpathswithwildcards" class="external text">Specify input paths with wildcards</a>" in this manual.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://&lt;path&gt;]<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>The following are additional attributes you can use when defining monitor input stanzas:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> source = &lt;string&gt;
</td><td valign="top" align="left">
<ul><li> Sets the source key/field for events from this input.
</li><li> <b>Note:</b> Overriding the source key is generally not recommended. Typically, the input layer will provide a more accurate string to aid in problem analysis and investigation, accurately recording the file from which the data was retreived.  Consider use of source types, tagging, and search wildcards before overriding this value.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'source::'.
</li></ul></td><td valign="top" align="left"> the input file path
</td></tr><tr><td valign="top" align="left"> <code><font size="2">crcSalt = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Use this setting to force Splunk Enterprise to consume files that have matching CRCs (cyclic redundancy checks). (Splunk only performs CRC checks against the first few lines of a file. This behavior prevents Splunk from indexing the same file twice, even though you may have renamed it -- as, for example, with rolling log files. However, because the CRC is based on only the first few lines of the file, it is possible for legitimately different files to have matching CRCs, particularly if they have identical headers.)
</li><li> If set, <code><font size="2">string</font></code> is added to the CRC. 
</li><li> If set to <code><font size="2">&lt;SOURCE&gt;</font></code>, the full source path is added to the CRC. This ensures that each file being monitored has a unique CRC. 
</li><li> Be cautious about using this attribute with rolling log files. It could lead to the log file being re-indexed after it has rolled.
</li><li> <b>Note:</b> This setting is case sensitive.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">ignoreOlderThan = &lt;time window&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Causes the monitored input to stop checking files for updates if their modification time (modtime) has passed the <code><font size="2">&lt;time window&gt;</font></code> threshold. This improves the speed of file tracking operations when monitoring directory hierarchies with large numbers of historical files (for example, when active log files are co-located with old files that are no longer being written to).
</li><li> <b>Note:</b> A file whose modtime falls outside <code><font size="2">&lt;time window&gt;</font></code> when monitored for the first time will not get indexed.
</li><li> Value must be: <code><font size="2">&lt;number&gt;&lt;unit&gt;</font></code>. For example, "7d" indicates one week.  Valid units are "d" (days), "h" (hours), "m" (minutes), and "s" (seconds).
</li></ul></td><td valign="top" align="left"> 0 (disabled)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">followTail = 0|1</font></code>
</td><td valign="top" align="left">
<ul><li> If set to 1, monitoring begins at the end of the file (like *nix <code><font size="2">tail -f</font></code>).
</li><li> This only applies to files the first time they are picked up.
</li><li> After that, Splunk Enterprise keeps track of the file using its internal file position records.
</li></ul></td><td valign="top" align="left"> 0
</td></tr><tr><td valign="top" align="left"> <code><font size="2">whitelist = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> If set, Splunk Enterprise only monitors files whose names match the specified regex.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">blacklist = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> If set, Splunk Enterprise does NOT monitor files whose names match the specified regex.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">alwaysOpenFile = 0 | 1</font></code>
</td><td valign="top" align="left">
<ul><li> If set to 1, Splunk Enterprise opens a file to check if it has already been indexed.
</li><li> Only useful for files that don't update modtime.
</li><li> Should only be used for monitoring files on Windows, and mostly for IIS logs.
</li><li> <b>Important:</b> This flag should only be used as a last resort, as it increases load and slows down indexing.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">recursive = true|false</font></code>
</td><td valign="top" align="left">
<ul><li> If set to <code><font size="2">false</font></code>, Splunk Enterprise will not go into subdirectories found within a monitored directory.
</li></ul></td><td valign="top" align="left"> true
</td></tr><tr><td valign="top" align="left"> <code><font size="2">time_before_close = &lt;integer&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Modtime delta required before Splunk Enterprise can close a file on EOF.
</li><li> Tells the system not to close files that have been updated in past <code><font size="2">&lt;integer&gt;</font></code> seconds.
</li></ul></td><td valign="top" align="left"> 3
</td></tr><tr><td valign="top" align="left"> <code><font size="2">followSymlink = true|false</font></code>
</td><td valign="top" align="left">
<ul><li> If <code><font size="2">false</font></code>, Splunk Enterprise will ignore symbolic links found within a monitored directory.
</li></ul></td><td valign="top" align="left"> true
</td></tr></table><p><b>Example 1.</b> To load anything in <code><font size="2">/apache/foo/logs</font></code> or <code><font size="2">/apache/bar/logs</font></code>, etc.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/.../logs]<br></font></code></div>
<p><b>Example 2.</b> To load anything in <code><font size="2">/apache/</font></code> that ends in <code><font size="2">.log</font></code>.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/*.log]<br></font></code></div>
<h3> <a name="editinputs.conf_monitornohandle_syntax_and_examples"><span class="mw-headline" id="MonitorNoHandle_syntax_and_examples"> MonitorNoHandle syntax and examples </span></a></h3>
<p>On Windows systems only, use the MonitorNoHandle stanza to monitor files without using Windows file handles. This allows you to read special log files like Windows's DNS server log files.
</p><p>You must specify a valid path to a file when you use MonitorNoHandle. You cannot specify a directory. If you specify a file that already exists, Splunk Enterprise does not index the existing data in the file. It only indexes new data that the system writes to the file.
</p><p>You can only configure <code><font size="2">monitorNoHandle</font></code> using inputs.conf or the CLI. you cannot configure it in Splunk Web.
</p>
<div class="samplecode"><code><font size="2"><br>[MonitorNoHandle://&lt;path&gt;]<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<h3> <a name="editinputs.conf_batch_syntax_and_examples"><span class="mw-headline" id="Batch_syntax_and_examples"> Batch syntax and examples </span></a></h3>
<p>Use batch to set up a one time, destructive input of data from a source. For continuous, non-destructive inputs, use <b>monitor</b>. Remember, after the batch input is indexed, Splunk <b>deletes</b> the file. 
</p>
<div class="samplecode"><code><font size="2"><br>[batch://&lt;path&gt;]<br>move_policy = sinkhole<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p><b>Important:</b> When defining batch inputs, you must include the attribute, <code><font size="2">move_policy = sinkhole</font></code>. This loads the file destructively. Do not use the batch input type for files you do not want to delete after indexing.
</p><p><b>Example:</b> This example batch loads all files from the directory <code><font size="2">system/flight815/</font></code>, but does not recurse through any subdirectories under it:
</p>
<div class="samplecode"><code><font size="2"><br>[batch://system/flight815/*]<br>move_policy = sinkhole<br></font></code></div>

<a name="specifyinputpathswithwildcards"></a><h2> <a name="specifyinputpathswithwildcards_specify_input_paths_with_wildcards"><span class="mw-headline" id="Specify_input_paths_with_wildcards"> Specify input paths with wildcards</span></a></h2>
<p>This topic discusses how to specify wildcards in a path in <code><font size="2">inputs.conf</font></code>. It is only relevant when using <code><font size="2">inputs.conf</font></code> to specify inputs, as described in "<a href="#editinputs.conf" class="external text">Edit inputs.conf</a>" in this manual.
</p><p><b>Important</b>: Input path specifications in <code><font size="2">inputs.conf</font></code> don't use regular expressions (regexes) but rather Splunk-defined wildcards.
</p>
<h3> <a name="specifyinputpathswithwildcards_wildcard_overview"><span class="mw-headline" id="Wildcard_overview">Wildcard overview</span></a></h3>
<p>A wildcard is a character that you can substitute for one or more unspecified characters when searching text or selecting multiple files or directories. In Splunk Enterprise, you can use wildcards to specify your input path for monitored input.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Wildcard
</th><th bgcolor="#C0C0C0">Description
</th><th bgcolor="#C0C0C0">Regex equivalent
</th><th bgcolor="#C0C0C0">Example(s)
</th></tr><tr><td valign="center" align="left"><code><font size="2">...</font></code>
</td><td valign="center" align="left">The ellipsis wildcard recurses through directories and any number of levels of subdirectories to find matches.
<p>Note: if the wildcard is followed by any folder separator (//var/log/.../file) it will not match the first folder level, only sub folders.
</p>
</td><td valign="center" align="left"><code><font size="2">.*</font></code>
</td><td valign="center" align="left"><code><font size="2">/foo/.../bar.log</font></code> matches the files <code><font size="2">/foo/1/bar.log</font></code>, <code><font size="2">/foo/2/bar.log</font></code>, <code><font size="2">/foo/1/2/bar.log</font></code>, etc.
<p>And will not match <code><font size="2">/foo/bar.log</font></code>, or  <code><font size="2">/foo/3/notbar.log</font></code>
</p><p><b>Note:</b> Because a single ellipse recurses through all directories and subdirectories, <code><font size="2">/foo/.../bar.log</font></code> matches the same as <code><font size="2">/foo/.../.../bar.log</font></code>.
</p>
</td></tr><tr><td valign="center" align="left"><code><font size="2">*</font></code>
</td><td valign="center" align="left">The asterisk wildcard matches anything in that specific directory path segment.
<p>Unlike "<code><font size="2">...</font></code>", "<code><font size="2">*</font></code>" doesn't recurse through any subdirectories.
</p>
</td><td valign="center" align="left"><code><font size="2">[^/]*</font></code>
</td><td valign="center" align="left"><code><font size="2">/foo/*/bar</font></code> matches the files <code><font size="2">/foo/bar</font></code>, <code><font size="2">/foo/1/bar</font></code>, <code><font size="2">/foo/2/bar</font></code>, etc.  However, it does not match <code><font size="2">/foo/1/2/bar</font></code>.
<p><code><font size="2">/foo/m*r/bar</font></code> matches <code><font size="2">/foo/mr/bar</font></code>, <code><font size="2">/foo/mir/bar</font></code>, <code><font size="2">/foo/moor/bar</font></code>, etc.  
</p><p><code><font size="2">/foo/*.log</font></code> matches all files with the <code><font size="2">.log</font></code> extension, such as <code><font size="2">/foo/bar.log</font></code>. It does not match <code><font size="2">/foo/bar.txt</font></code> or <code><font size="2">/foo/bar/test.log</font></code>.
</p>
</td></tr></table><p><b>Note:</b> A single dot (<code><font size="2">.</font></code>) is not a wildcard, and is the regex equivalent of <code><font size="2">\.</font></code>. 
</p><p>For more specific matches, combine  the <code><font size="2">...</font></code> and <code><font size="2">*</font></code> wildcards. For example, <code><font size="2">/foo/.../bar/*</font></code> matches any file in the <code><font size="2">/bar</font></code> directory within the specified path.
</p>
<h4><font size="3"><b><i> <a name="specifyinputpathswithwildcards_wildcards_and_regular_expression_metacharacters"><span class="mw-headline" id="Wildcards_and_regular_expression_metacharacters">Wildcards and regular expression metacharacters</span></a></i></b></font></h4>
<p>When determining the set of files or directories to monitor, Splunk Enterprise splits elements of a monitoring stanza into <b>segments</b> - defined as text between directory separator characters ("<code><font size="2">/</font></code>" or "<code><font size="2">\</font></code>") in the stanza definition. If you specify a monitor stanza that contains segments with both wildcards and regex metacharacters (such as <code><font size="2">(, ), [, ]</font></code>, and <code><font size="2">|</font></code>), those characters behave differently depending on where the wild card is in the stanza.
</p><p>If a monitoring stanza contains a segment with regex metacharacters <b>before</b> a segment with wildcards, Splunk Enterprise treats the metacharacters literally, as if you wanted to monitor files or directories with those characters in the files' or directories' names. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://var/log/log(a|b).log]<br></font></code></div>
<p>monitors the <code><font size="2">/var/log/log(a|b).log</font></code> file. Splunk Enterprise does not treat the <code><font size="2">(a|b)</font></code> as a regular expression because there are no wildcards present.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://var/log()/log*.log]<br></font></code></div>
<p>monitors all files in the <code><font size="2">/var/log()/</font></code> directory that begin with <code><font size="2">log</font></code> and have the extension <code><font size="2">.log</font></code>. Splunk Enterprise does not treat the <code><font size="2">()</font></code> as a regular expression because the regex is in the segment <b>before</b> the wildcard.
</p><p>If the regex metacharacters occur <b>within</b> or <b>after</b> a segment that contains a wildcard, Splunk Enterprise treats the metacharacters as a regex and matches files to monitor accordingly.  For example:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://var/log()/log(a|b)*.log]<br></font></code></div>
<p>monitors all files in the <code><font size="2">/var/log()/</font></code> directory that begin with either <code><font size="2">loga</font></code> or <code><font size="2">logb</font></code> and have the extension <code><font size="2">.log</font></code>. Splunk does not treat the first set of <code><font size="2">()</font></code> as a regex because the wild card is in the following segment. The second set of <code><font size="2">()</font></code> gets treated as a regex because it is in the same segment as the wildcard '<code><font size="2">*</font></code>'.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://var/.../log(a|b).log]<br></font></code></div>
<p>monitors all files in <i>any</i> subdirectory of the <code><font size="2">/var/</font></code> directory named <code><font size="2">loga.log</font></code> and <code><font size="2">logb.log</font></code>. Splunk treats <code><font size="2">(a|b)</font></code> as a regex because of the wildcard '<code><font size="2">...</font></code>' in the previous stanza segment.
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://var/.../log[A-Z0-9]*.log]<br></font></code></div>
<p>monitors all files in any subdirectory of the <code><font size="2">/var/</font></code> directory that:
</p>
<ul><li> begin with <code><font size="2">log</font></code>, then
</li><li> contain a single capital letter (from A-Z) or number (from 0-9), then
</li><li> contain any other characters, then
</li><li> end in <code><font size="2">.log</font></code>. 
</li></ul><p>Splunk Enterprise treats <code><font size="2">[A-Z0-9]*</font></code> as a regex because of the wildcard '<code><font size="2">...</font></code>' in the previous stanza segment.
</p>
<h3> <a name="specifyinputpathswithwildcards_input_examples"><span class="mw-headline" id="Input_examples"> Input examples </span></a></h3>
<p>To monitor <code><font size="2">/apache/foo/logs</font></code>, <code><font size="2">/apache/bar/logs</font></code>, <code><font size="2">/apache/bar/1/logs</font></code>, etc.:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/.../logs/*]<br></font></code></div>
<p>To monitor <code><font size="2">/apache/foo/logs</font></code>, <code><font size="2">/apache/bar/logs</font></code>, etc., but not <code><font size="2">/apache/bar/1/logs</font></code> or <code><font size="2">/apache/bar/2/logs</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/*/logs]<br></font></code></div>
<p>To monitor any file directly under <code><font size="2">/apache/</font></code> that ends in <code><font size="2">.log</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/*.log]<br></font></code></div>
<p>To monitor any file under <code><font size="2">/apache/</font></code> (under any level of subdirectory) that ends in <code><font size="2">.log</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///apache/.../*.log]<br></font></code></div>
<p>The "..." followed by a folder separator will imply that the wildcard level folder will be excluded.
</p>
<div class="samplecode"><code><font size="2">[monitor:///var/log/.../*.log]</font></code></div>
<p>the tailing logic will become <code><font size="2"> '^\/var\/log/.*/[^/]*\.log$' </font></code>
</p><p>Therefore, <code><font size="2">/var/log/subfolder/test.log </font></code> will match, but <code><font size="2">/var/log/test.log </font></code> will not match and be excluded. To monitor all files in all folders use:
</p>
<div class="samplecode"><code><font size="2">[monitor:///var/log/]
<p>whitelist=\.log$
</p><p>recurse=true
</p>
 #true by default</font></code></div>
<h3> <a name="specifyinputpathswithwildcards_wildcards_and_whitelisting"><span class="mw-headline" id="Wildcards_and_whitelisting"> Wildcards and whitelisting </span></a></h3>
<p><b>Important:</b> Splunk Enterprise defines whitelists and blacklists with standard Perl-compatible Regular Expression (PCRE) syntax, unlike the file input path syntax described in the previous sections.
</p><p>When you specify wildcards in a file input path, Splunk Enterprise creates an implicit <code><font size="2">whitelist</font></code> for that stanza. The longest wildcard-free path becomes the monitor stanza, and Splunk Enterprise translates the wildcards into regular expressions, as listed in the table above.
</p><p>Additionally, Splunk Enterprise anchors the converted expression to the right end of the file path, so that the entire path must be matched.
</p><p>For example, if you specify
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///foo/bar*.log]<br></font></code></div>
<p>Splunk Enterprise translates this into
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///foo/]<br>whitelist = bar[^/]*\.log$<br></font></code></div>
<p>On Windows, if you specify
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://C:\Windows\foo\bar*.log]<br></font></code></div>
<p>Splunk Enterprise translates it into
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://C:\Windows\foo\]<br>whitelist = bar[^/]*\.log$<br></font></code></div>
<p><b>Note:</b> In Windows, <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code> rules do not support regexes that include backslashes; you must use two backslashes <code><font size="2">\\</font></code> to escape wildcards.
</p><p>For more information on using whitelists with file inputs, see <a href="#whitelistorblacklistspecificincomingdata" class="external text">"Whitelist or blacklist specific incoming data"</a>.
</p>
<a name="whitelistorblacklistspecificincomingdata"></a><h2> <a name="whitelistorblacklistspecificincomingdata_whitelist-_or_blacklist-specific_incoming_data"><span class="mw-headline" id="Whitelist-_or_blacklist-specific_incoming_data"> Whitelist- or blacklist-specific incoming data</span></a></h2>
<p>Use <b>whitelist</b> and <b>blacklist</b> rules to explicitly tell Splunk Enterprise which files to consume when <b>monitoring</b> directories. You can also apply these settings to <code><font size="2">batch</font></code> inputs. When you define a <b>whitelist</b>, Splunk Enterprise indexes <b>only</b> the files in that list. When you define a <b>blacklist</b>, Splunk Enterprise ignores the files in that list and consumes everything else. You define whitelists and blacklists in the input stanza in <code><font size="2">inputs.conf</font></code>.
</p><p>You don't have to define both a whitelist and a blacklist in a stanza; they are independent settings. If you do define both and a file matches both, Splunk Enterprise does not index that file as <code><font size="2">blacklist</font></code> overrides <code><font size="2">whitelist</font></code>.
</p><p>Whitelist and blacklist rules use regular expression (regex) syntax to define the match on the file name/path. They must be contained within a configuration stanza, for example <code><font size="2">[monitor://&lt;path&gt;]</font></code>. Splunk Enterprise ignores whitelists and blacklists outside of stanzas.
</p><p>To learn more about how to build regular expressions, visit the Regular-expressions.info (http://regular-expressions.info) website.
</p><p><b>Important:</b> Define whitelist and blacklist entries with exact regex syntax. <b>The "..." wildcard used for input paths (described <a href="#specifyinputpathswithwildcards" class="external text">here</a>) is not supported.</b>
</p>
<h3> <a name="whitelistorblacklistspecificincomingdata_route_and_filter_data_instead_of_whitelisting_and_blacklisting"><span class="mw-headline" id="Route_and_filter_data_instead_of_whitelisting_and_blacklisting"> Route and filter data instead of whitelisting and blacklisting</span></a></h3>
<p>Instead of whitelisting or blacklisting your data inputs, you can filter specific events and send them to different queues or indexes. Read more about routing and filtering data. You can also use <a href="#findmorethingstomonitorwithcrawl" class="external text">the crawl feature</a> to predefine files you want Splunk to index or not index automatically when they get added to your file system. 
</p>
<h3> <a name="whitelistorblacklistspecificincomingdata_whitelist_.28allow.29_files"><span class="mw-headline" id="Whitelist_.28allow.29_files"> Whitelist (allow) files </span></a></h3>
<p>To define the files you want Splunk Enterprise to exclusively index, add the following line to your <code><font size="2">monitor</font></code> stanza in the <code><font size="2">/local/inputs.conf</font></code> file <b>for the app this input was defined in</b>: 
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = &lt;your_custom regex&gt;<br></font></code></div>
<p>For example, if you want Splunk Enterprise to monitor only files with the <code><font size="2">.log</font></code> extension:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs]<br>&nbsp;&nbsp;&nbsp;&nbsp;whitelist = \.log$<br></font></code></div>
<p>You can whitelist multiple files in one line, using the "|" (OR) operator. For example, to whitelist filenames that contain <code><font size="2">query.log OR my.log</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = query\.log$|my\.log$<br></font></code></div>
<p>Or, to whitelist exact matches:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = /query\.log$|/my\.log$<br></font></code></div>
<p><b>Note:</b> The "$" anchors the regex to the end of the line. There is no space before or after the "|" operator.
</p><p>For information on how whitelists interact with wildcards in input paths, see <a href="#specifyinputpathswithwildcards_wildcards_and_whitelisting" class="external text">"Wildcards and whitelisting"</a>.
</p>
<h3> <a name="whitelistorblacklistspecificincomingdata_blacklist_.28ignore.29_files"><span class="mw-headline" id="Blacklist_.28ignore.29_files"> Blacklist (ignore) files </span></a></h3>
<p>To define the files you want Splunk Enterprise to exclude from indexing, add the following line to your <code><font size="2">monitor</font></code> stanza in the <code><font size="2">/local/inputs.conf</font></code> file <b>for the app this input was defined in</b>:
</p>
<div class="samplecode"><code><font size="2"><br>blacklist = &lt;your_custom regex&gt;<br></font></code></div>
<p><b>Important:</b> If you create a <code><font size="2">blacklist</font></code> line for each file you want to ignore, Splunk activates only the last filter.
</p><p>If you want Splunk Enterprise to ignore and not monitor only files with the <code><font size="2">.txt</font></code> extension:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs]<br>&nbsp;&nbsp;&nbsp;&nbsp;blacklist = \.(txt)$<br></font></code></div>
<p>If you want Splunk Enterprise to ignore and not monitor all files with either the <code><font size="2">.txt</font></code> extension <code><font size="2">OR</font></code> the <code><font size="2">.gz</font></code> extension (note that you use the "|" for this):
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs]<br>&nbsp;&nbsp;&nbsp;&nbsp;blacklist = \.(txt|gz)$<br></font></code></div>
<p>If you want Splunk Enterprise to ignore entire directories beneath a monitor input refer to this example:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs]<br>&nbsp;&nbsp;&nbsp;&nbsp;blacklist = (archive|historical|\.bak$)<br></font></code></div>
<p>The above example tells Splunk Enterprise to ignore all files under /mnt/logs/ within the archive or historical directories and all files ending in *.bak.
</p><p>If you want Splunk Enterprise to ignore files whose names contain a specific string you could do something like this:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs]<br>&nbsp;&nbsp;&nbsp;blacklist = 2009022[8|9]file\.txt$<br></font></code></div>
<p>The above example ignores the <code><font size="2">webserver20090228file.txt</font></code> and <code><font size="2">webserver20090229file.txt</font></code> files under <code><font size="2">/mnt/logs/</font></code>.
</p>
<a name="howlogfilerotationishandled"></a><h2> <a name="howlogfilerotationishandled_how_splunk_enterprise_handles_log_file_rotation"><span class="mw-headline" id="How_Splunk_Enterprise_handles_log_file_rotation"> How Splunk Enterprise handles log file rotation </span></a></h2>
<p>Splunk Enterprise recognizes when a file that it is monitoring (such as <code><font size="2">/var/log/messages</font></code>) has been rolled by the operating system (<code><font size="2">/var/log/messages1</font></code>) and will not read the rolled file a second time.
</p>
<h3> <a name="howlogfilerotationishandled_how_to_work_with_log_rotation_into_compressed_files"><span class="mw-headline" id="How_to_work_with_log_rotation_into_compressed_files"> How to work with log rotation into compressed files </span></a></h3>
<p>Splunk Enterprise does not identify compressed files produced by the <code><font size="2">logrotate</font></code> command (such as <code><font size="2">bz2</font></code> or <code><font size="2">gz</font></code>) as being the same as the uncompressed originals. This can lead to a duplication of data if Splunk then monitors those files.
</p><p>To avoid this problem, you can choose from two approaches: 
</p>
<ul><li> Configure logrotate to move those files into a directory that Splunk Enterprise does not monitor.
</li></ul><ul><li> Set <b>blacklist</b> rules for archive file types to prevent Splunk Enterprise from reading those files as new log files. For example: 
</li></ul><div class="samplecode"><code><font size="2"><br>[monitor:///var/log]<br>blacklist = \.(gz|bz2|z|zip)$ </font></code></div>
<p>Splunk Enterprise recognizes the following archive filetypes: <code><font size="2">tar, gz, bz2, tar.gz, tgz, tbz, tbz2, zip</font></code>, and <code><font size="2">z</font></code>.
</p><p>For more information on how to set blacklist rules see "<a href="#whitelistorblacklistspecificincomingdata" class="external text">Whitelist or blacklist specific incoming data</a>" in this manual.
</p><p><b>Note:</b> if you add new data to an existing compressed archive such as a <code><font size="2">.gz</font></code> file, Splunk Enterprise re-indexes the entire file, not just the new data in the file. This can result in duplication of events.
</p>
<h3> <a name="howlogfilerotationishandled_how_splunk_enterprise_recognizes_log_rotation"><span class="mw-headline" id="How_Splunk_Enterprise_recognizes_log_rotation"> How Splunk Enterprise recognizes log rotation </span></a></h3>
<p>The monitoring processor picks up new files and reads the first 256 bytes of the file. The processor then hashes this data into a begin and end cyclic redundancy check (CRC), which functions as a fingerprint representing the file content. Splunk Enterprise uses this CRC to look up an entry in a database that contains all the beginning CRCs of files Splunk  Enterprise has seen before. If successful, the lookup returns a few values, but the important ones are a <b>seekAddress</b>, meaning the number of bytes into the known file that Splunk Enterprise has already read, and a seekCRC which is a fingerprint of the data at that location.
</p><p>Using the results of this lookup, Splunk Enterprise can attempt to categorize the file.
</p><p>There are three possible outcomes of a CRC check:
</p><p><b>1.</b> There is no matching record for the CRC from the file beginning in the database. This indicates a new file. Splunk Enterprise picks it up and consume its data from the start of the file. Splunk Enterprise updates the database with the new CRCs and Seek Addresses as it consumes the file.
</p><p><b>2.</b>  There is a matching record for the CRC from the file beginning in the database, the content at the Seek Address location matches the stored CRC for that location in the file, and the size of the file is larger than the Seek Address that Splunk Enterprise stored. This means that while Splunk Enterprise has seen the file before, there has been data added to it since it was last read. Splunk Enterprise opens the file, seeks to Seek Address--the end of the file when Splunk last finished with it--and starts reading from there. In this way, Splunk will only read the new data and not anything it has read before.
</p><p><b>3.</b> There is a matching record for the CRC from the file beginning in the database, but the content at the Seek Address location does not match the stored CRC at that location in the file. This means that Splunk Enterprise has previously read some file with the same initial data, but either some of the material that it read has since been modified in place, or it is in fact a wholly different file which simply begins with the same content. Since the Splunk database for content tracking is keyed to the beginning CRC, it has no way to track progress independently for the two different data streams, and further configuration is required.
</p><p><b>Important:</b> Since the CRC start check runs against only the first 256 bytes of the file by default, it is possible for non-duplicate files to have duplicate start CRCs, particularly if the files are ones with identical headers. To handle such situations you can:
</p>
<ul><li> Use the <code><font size="2">initCrcLength</font></code> attribute in <code><font size="2">inputs.conf</font></code> to increase the number of characters used for the CRC calculation, and make it longer than your static header.
</li><li> Use the <code><font size="2">crcSalt</font></code> attribute when configuring the file in <code><font size="2">inputs.conf</font></code>, as described in "<a href="#editinputs.conf" class="external text">Edit inputs.conf</a>" in this manual. The <code><font size="2">crcSalt</font></code> attribute, when set to <code><font size="2">&lt;SOURCE&gt;</font></code>, ensures that each file has a unique CRC. The effect of this setting is that Splunk Enterprise assumes that each path name contains unique content. 
</li></ul><p><b>Important:</b> You do <b>not</b> want to use <code><font size="2">crcSalt = &lt;SOURCE&gt;</font></code> with rolling log files, or any other scenario in which logfiles get renamed or moved to another monitored location. Doing so prevents Splunk Enterprise from recognizing log files across the roll or rename, which  causes Splunk to re-index the data.
</p>
<h1>Get network events</h1><a name="monitornetworkports"></a><h2> <a name="monitornetworkports_get_data_from_tcp_and_udp_ports"><span class="mw-headline" id="Get_data_from_TCP_and_UDP_ports"> Get data from TCP and UDP ports</span></a></h2>
<p>You can configure Splunk Enterprise to accept an input on any TCP or UDP port. Splunk Enterprise consumes any data sent on these ports. Use this method to capture data from network services such as syslog (default port is UDP 514). You can also set up the netcat service and bind it to a port.
</p><p>TCP is the network protocol that underlies the Splunk Enterprise data distribution and is the recommended method for sending data from any remote machine to your Splunk Enterprise server. Splunk Enterprise can index remote data from syslog-ng or any other application that transmits via TCP. 
</p><p>Splunk Enterprise supports monitoring over UDP, but recommends using TCP instead whenever possible. UDP is generally undesirable as a transport because, among other reasons, it doesn't guarantee delivery.
</p><p>Refer to "Working with UDP connections" on the Splunk Community Wiki for recommendations if you must use UDP.
</p>
<h3> <a name="monitornetworkports_add_a_network_input_using_splunk_web"><span class="mw-headline" id="Add_a_network_input_using_Splunk_Web"> Add a network input using Splunk Web </span></a></h3>
<p>To add inputs from network ports using Splunk Web, follow the "<a href="#syslogtcp" class="external text">Syslog - TCP/UDP</a>" recipe in this manual.
</p>
<h3> <a name="monitornetworkports_add_a_network_input_using_the_cli"><span class="mw-headline" id="Add_a_network_input_using_the_CLI"> Add a network input using the CLI </span></a></h3>
<p>To access the Splunk Enterprise CLI, navigate to the <code><font size="2">$SPLUNK_HOME/bin/</font></code> directory and use the <code><font size="2">./splunk</font></code> command. 
</p><p>If you get stuck, the CLI has built-in help.  Access the main CLI help by typing <code><font size="2">splunk help</font></code>. Individual commands have their own help pages as well; type <code><font size="2">splunk help &lt;command&gt;</font></code>.
</p><p>The following CLI commands are available for network input configuration:
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Command
</th><th bgcolor="#C0C0C0">Command syntax
</th><th bgcolor="#C0C0C0">Action
</th></tr><tr><td valign="center" align="left"><b>add</b>
</td><td valign="center" align="left"><code><font size="2">add tcp|udp &lt;port&gt; [-parameter value] ...</font></code>
</td><td valign="center" align="left">Add inputs from <code><font size="2">&lt;port&gt;</font></code>.
</td></tr><tr><td valign="center" align="left"><b>edit</b>
</td><td valign="center" align="left"><code><font size="2">edit tcp|udp &lt;port&gt; [-parameter value] ...</font></code>
</td><td valign="center" align="left">Edit a previously added input for <code><font size="2">&lt;port&gt;</font></code>.
</td></tr><tr><td valign="center" align="left"><b>remove</b>
</td><td valign="center" align="left"><code><font size="2">remove tcp|udp &lt;port&gt;</font></code>
</td><td valign="center" align="left">Remove a previously added data input.
</td></tr><tr><td valign="center" align="left"><b>list</b>
</td><td valign="center" align="left"><code><font size="2">list tcp|udp [&lt;port&gt;]</font></code>
</td><td valign="center" align="left">List the currently configured monitor.
</td></tr></table><p>The <code><font size="2">&lt;port&gt;</font></code> is the port number on which to listen for data. The user you run Splunk as must have access to this port. 
</p><p>You can modify the configuration of each input by setting any of these additional parameters: 
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Parameter
</th><th bgcolor="#C0C0C0">Required?
</th><th bgcolor="#C0C0C0">Description
</th></tr><tr><td valign="center" align="left"><code><font size="2">sourcetype</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a sourcetype field value for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">index</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify the destination index for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">hostname</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a host name to set as the host field value for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">remotehost</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify an IP address to exclusively accept data from.
</td></tr><tr><td valign="center" align="left"><code><font size="2">resolvehost</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Set True of False (T | F). Default is False.  Set True to use DNS to set the host field value for events from the input source.
</td></tr><tr><td valign="center" align="left"><code><font size="2">restrictToHost</font></code>
</td><td valign="center" align="left">No
</td><td valign="center" align="left">Specify a host name or IP address that this input should accept connections from only.
</td></tr></table><h4><font size="3"><b><i> <a name="monitornetworkports_examples"><span class="mw-headline" id="Examples"> Examples </span></a></i></b></font></h4>
<ul><li> Configure a UDP input to watch port 514 and set the source type to "syslog":
</li></ul><div class="samplecode"><code><font size="2"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;./splunk add udp 514 -sourcetype syslog<br></font></code></div>
<ul><li> Set the UDP input's host value via DNS.  Use <code><font size="2">auth</font></code> with your username and password:
</li></ul><div class="samplecode"><code><font size="2"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;./splunk edit udp 514 -resolvehost true -auth admin:changeme<br></font></code></div>
<p>Check the Best Practices Wiki for information about the best practices for using UDP when configuring Syslog input.
</p>
<h3> <a name="monitornetworkports_change_restricted_hosts_on_a_tcp_network_input"><span class="mw-headline" id="Change_restricted_hosts_on_a_TCP_network_input"> Change restricted hosts on a TCP network input</span></a></h3>
<p>If, when creating a TCP input, you decide to only accept connections from a specific host, once you save that input, you can neither change nor remove that host later, either from Splunk Web or the CLI.
</p><p>To change or remove the restricted host of a port, you must first delete the input that contains the old restricted host. Then, you must add a new input that either contains the new restricted host, or has no restriction.
</p>
<h3> <a name="monitornetworkports_add_a_network_input_using_inputs.conf"><span class="mw-headline" id="Add_a_network_input_using_inputs.conf"> Add a network input using inputs.conf </span></a></h3>
<p>To add an input, add a stanza for it to inputs.conf in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code>, or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  If you have not worked with Splunk's configuration files before, read "About configuration files" in the Admin manual before you begin.
</p><p>You can set any number of attributes and values following an input type.  If you do not specify a value for one or more attributes, Splunk uses the defaults that are preset in <code><font size="2">$SPLUNK_HOME/etc/system/default/</font></code> (noted below).
</p>
<h4><font size="3"><b><i> <a name="monitornetworkports_tcp"><span class="mw-headline" id="TCP"> TCP </span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[tcp://&lt;remote server&gt;:&lt;port&gt;]<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>This type of input stanza tells Splunk Enterprise to listen to &lt;remote server&gt; on &lt;port&gt;. If <code><font size="2">&lt;remote server&gt;</font></code> is blank, Splunk listens to all connections on the specified port.
</p><p><b>Note:</b> The user you run Splunk Enterprise as must have access to the listening port. On a *nix system, you must run as root to access a port under 1024.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">host = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the host key/field to a static value for this stanza.
</li><li> Sets the host key's initial value. The key is used during parsing/indexing, in particular to set the host field. It is also the host field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'host::'.
</li></ul></td><td valign="top" align="left"> <code><font size="2">the IP address or fully-qualified domain name of the host where the data originated.</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Set the index where events from this input will be stored.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'index::'.
</li><li> For more information about the index field, see "How indexing works" in the Managing Indexers and Clusters manual.
</li></ul></td><td valign="top" align="left"> <code><font size="2">main</font></code> or whatever you set the default index to
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the sourcetype key/field for events from this input.
</li><li> Explicitly declares the source type for this data, as opposed to allowing Splunk Enterprise to determine it automatically. This is important both for searchability and for applying the relevant formatting for this type of data during parsing and indexing.
</li><li> Sets the sourcetype key's initial value. Splunk Enterprise uses the key during parsing/indexing, in particular to set the source type field during indexing. It is also the source type field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'sourcetype::'.
</li><li> For more information about source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a>, in this manual.
</li></ul></td><td valign="top" align="left"> Splunk Enterprise picks a source type based on various aspects of the data. There is no hard-coded default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">source = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the source key/field for events from this input.
</li><li> <b>Note:</b> Overriding the source key is generally not recommended. Typically, the input layer will provide a more accurate string to aid in problem analysis and investigation, accurately recording the file from which the data was retreived.  Consider use of source types, tagging, and search wildcards before overriding this value.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'source::'.
</li></ul></td><td valign="top" align="left"> The input file path
</td></tr><tr><td valign="top" align="left"> <code><font size="2">queue = parsingQueue | indexQueue</font></code>
</td><td valign="top" align="left">
<ul><li> Specifies where the input processor should deposit the events that it reads.
</li><li> Set to "parsingQueue" to apply <code><font size="2">props.conf</font></code> and other parsing rules to your data.
</li><li> Set to "indexQueue" to send your data directly into the index.
</li></ul></td><td valign="top" align="left"> parsingQueue
</td></tr><tr><td valign="top" align="left"> <code><font size="2">connection_host = ip | dns | none</font></code>
</td><td valign="top" align="left">
<ul><li> "ip" sets the host to the IP address of the remote server. 
</li><li> "dns" sets the host to the DNS entry of the remote server.
</li><li> "none" leaves the host as specified.
</li></ul></td><td valign="top" align="left"> ip
</td></tr></table><h4><font size="3"><b><i> <a name="monitornetworkports_tcp_over_ssl"><span class="mw-headline" id="TCP_over_SSL"> TCP over SSL</span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[tcp-ssl:&lt;port&gt;]<br></font></code></div>
<p>Use this stanza type if you are receiving encrypted, unparsed data from a forwarder or third-party system. Set <code><font size="2">&lt;port&gt;</font></code> to the port on which the forwarder or third-party system is sending unparsed, encrypted data.
</p>
<h4><font size="3"><b><i> <a name="monitornetworkports_udp"><span class="mw-headline" id="UDP"> UDP </span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[udp://&lt;remote server&gt;:&lt;port&gt;]<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>This type of input stanza is similar to the TCP type, except that it listens on a UDP port.
</p><p>Note:
</p>
<ul><li> If <code><font size="2">&lt;remote server&gt;</font></code> is specified, the specified port will only accept data from that server.
</li><li> If <code><font size="2">&lt;remote server&gt;</font></code> is empty - <code><font size="2">[udp://&lt;port&gt;]</font></code> - the port will accept data sent from any server.
</li></ul><table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">host = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the host key/field to a static value for this stanza.
</li><li> Sets the host key's initial value. The key is used during parsing/indexing, in particular to set the host field. It is also the host field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'host::'.
</li></ul></td><td valign="top" align="left"> <code><font size="2">the IP address or fully-qualified domain name of the host where the data originated.</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Set the index where events from this input will be stored.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'index::'.
</li><li> For more information about the index field, see "How indexing works" in the Managing Indexers and Clusters manual.
</li></ul></td><td valign="top" align="left"> <code><font size="2">main</font></code> or whatever you set the default index to
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the sourcetype key/field for events from this input.
</li><li> Explicitly declares the source type for this data, as opposed to allowing Splunk Enterprise to determine it automatically. This is important both for searchability and for applying the relevant formatting for this type of data during parsing and indexing.
</li><li> Sets the sourcetype key's initial value. Splunk Enterprise uses the key during parsing/indexing, in particular to set the source type field during indexing. It is also the source type field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'sourcetype::'.
</li><li> For more information about source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a>, in this manual.
</li></ul></td><td valign="top" align="left"> Splunk Enterprise picks a source type based on various aspects of the data. There is no hard-coded default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">source = &lt;string&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Sets the source key/field for events from this input.
</li><li> <b>Note:</b> Overriding the source key is generally not recommended. Typically, the input layer will provide a more accurate string to aid in problem analysis and investigation, accurately recording the file from which the data was retreived.  Consider use of source types, tagging, and search wildcards before overriding this value.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'source::'.
</li></ul></td><td valign="top" align="left"> The input file path
</td></tr><tr><td valign="top" align="left"> <code><font size="2">queue = parsingQueue | indexQueue</font></code>
</td><td valign="top" align="left">
<ul><li> Specifies where the input processor should deposit the events that it reads.
</li><li> Set to "parsingQueue" to apply <code><font size="2">props.conf</font></code> and other parsing rules to your data.
</li><li> Set to "indexQueue" to send your data directly into the index.
</li></ul></td><td valign="top" align="left"> parsingQueue
</td></tr><tr><td valign="top" align="left"> <code><font size="2">_rcvbuf = &lt;integer&gt;</font></code>
</td><td valign="top" align="left">
<ul><li> Specify the receive buffer for the UDP port, in bytes.  
</li><li> If the value is 0 or negative, Splunk Enterprise ignores the value. 
</li></ul></td><td valign="top" align="left"> 1,572,864 - <b>however</b>, if the default value is too large for an OS, Splunk Enterprise halves the value from this default continuously until the buffer size is at an acceptable level.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">no_priority_stripping = true | false</font></code>
</td><td valign="top" align="left">
<ul><li> Setting for receiving syslog data. 
</li><li> If you set this attribute to true, Splunk Enterprise does NOT strip the &lt;priority&gt; syslog field from received events. 
</li><li> Depending on how this attribute is set, Splunk Enterprise sets event timestamps differently:
<ul><li> When set to true, Splunk Enterprise honors the timestamp as it comes from the source.
</li><li> When set to false, Splunk Enterprise assigns events the local time. 
</li></ul></li></ul></td><td valign="top" align="left"> false (Splunk Enterprise strips &lt;priority&gt;.)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">no_appending_timestamp = true | false</font></code>
</td><td valign="top" align="left">
<ul><li> If you set this attribute to true, Splunk Enterprise does NOT append a timestamp and host to received events.
</li><li> <b>Note:</b> Do NOT include this attribute if you want to append timestamp and host to received events.
</li></ul></td><td valign="top" align="left"> false
</td></tr></table><h3> <a name="monitornetworkports_udp_packets_and_line_merging"><span class="mw-headline" id="UDP_packets_and_line_merging"> UDP packets and line merging </span></a></h3>
<p>You might expect that Splunk Enterprise indexes each UDP packet as an independent event. However, this is not the case. Splunk Enterprise performs event merging on the datastream, and merges events together if they don't have a clear timestamp.
</p><p>In the case of single-line events, you can avoid this problem by editing the underlying source type in <code><font size="2">props.conf</font></code> and setting the <code><font size="2">SHOULD_LINEMERGE</font></code> attribute to <code><font size="2">false</font></code>. Doing so keeps Splunk Enterprise from merging packets together.
</p>
<h3> <a name="monitornetworkports_answers"><span class="mw-headline" id="Answers"> Answers </span></a></h3>
<p>Have questions? Visit Splunk Answers and see what and answers the Splunk community has about questions UDP inputs, TCP inputs, and inputs in general,
</p>
<a name="sendsnmpeventstosplunk"></a><h2> <a name="sendsnmpeventstosplunk_send_snmp_events_to_splunk_enterprise"><span class="mw-headline" id="Send_SNMP_events_to_Splunk_Enterprise"> Send SNMP events to Splunk Enterprise</span></a></h2>
<p>Simple Network Management Protocol (SNMP) traps are alerts that remote devices send out. This topic describes how to receive and index SNMP traps at the Splunk Enterprise indexer. 
</p><p><b>Note:</b> The procedures shown in this topic (for both *nix and Windows) are examples only. You can accomplish the task of sending SNMP traps to Splunk Enterprise in a number of ways. For example, instead of using Net-SNMP, you can use other tools, such as Snare or SNMPGate, to write SNMP traps to file storage for monitoring by Splunk Enterprise.
</p><p>For information on how to use Splunk Enterprise as a monitoring tool to send SNMP alerts to other systems, such as a Network Management System console, see "Send SNMP traps to other systems" in the <i>Alerting</i> manual.
</p>
<h3> <a name="sendsnmpeventstosplunk_how_to_index_snmp_traps"><span class="mw-headline" id="How_to_index_SNMP_traps">How to index SNMP traps</span></a></h3>
<p>The most effective way to index SNMP traps is to first write them to a file on the Splunk Enterprise server. Then, configure Splunk Enterprise to monitor the file.
</p><p>There are three steps:
</p><p><b>1.</b> Configure the remote devices to send their traps directly to the Splunk server's IP address. The default port for SNMP traps is <code><font size="2">udp:162</font></code>. 
</p><p><b>2.</b> Write the SNMP traps to a file on the Splunk server, as described later in this topic.
</p><p><b>3.</b> Configure Splunk Enterprise to monitor the file, as described in <a href="#monitorfilesanddirectories" class="external text">"Monitor files and directories"</a>.
</p><p><b>Note:</b> This topic does not cover SNMP polling, which is a way to query remote devices.
</p>
<h3> <a name="sendsnmpeventstosplunk_write_snmp_traps_to_a_file_on_the_splunk_server"><span class="mw-headline" id="Write_SNMP_traps_to_a_file_on_the_Splunk_server">Write SNMP traps to a file on the Splunk server</span></a></h3>
<p>For information about available SNMP software, visit the SNMP portal (http://www.snmplink.org) website.
</p>
<h4><font size="3"><b><i> <a name="sendsnmpeventstosplunk_for_.2anix"><span class="mw-headline" id="For_.2Anix">For *nix</span></a></i></b></font></h4>
<p>On *nix, you can use the Net-SNMP project <code><font size="2">snmptrapd</font></code> binary to write SNMP traps to a file. 
</p><p>Before installing <code><font size="2">snmptrapd</font></code> on your system, see the local documentation for the version of <code><font size="2">snmptrapd</font></code> that comes with your distribution of *nix. See also the manual page for <code><font size="2">snmptrapd</font></code>.
</p><p>The simplest configuration is: 
</p>
<div class="samplecode"><code><font size="2"><br># snmptrapd -Lf /var/log/snmp-traps<br></font></code></div>
<p><b>Note:</b> Versions 5.3 and later of <code><font size="2">snmptrapd</font></code> apply access control checks to all incoming notifications instead of accepting and logging them automatically (even if no explicit configuration was provided). If you run <code><font size="2">snmptrapd</font></code> without suitable access control settings, then it does not process those traps. You can avoid this by specifying:
</p>
<div class="samplecode"><code><font size="2"><br># snmptrapd -Lf /var/log/snmp-traps --disableAuthorization=yes<br></font></code></div>
<p>To see the version of <code><font size="2">snmptrapd</font></code>, run <code><font size="2">snmptrapd --version</font></code> from the command prompt.
</p>
<h4><font size="3"><b><i> <a name="sendsnmpeventstosplunk_troubleshoot_problems_with_snmp"><span class="mw-headline" id="Troubleshoot_problems_with_SNMP">Troubleshoot problems with SNMP</span></a></i></b></font></h4>
<p>If you experience problems sending SNMP traps to Splunk Enterprise, consider that:
</p>
<ul><li> UDP port 162 is a privileged network port. If you need to use this port, then you must run <code><font size="2">snmptrapd</font></code> as root.
</li><li> You can use the <code><font size="2">-f</font></code> flag to keep <code><font size="2">snmptrapd</font></code> in the foreground while testing.
</li><li> You can use the <code><font size="2">-Lo</font></code> flags instead of <code><font size="2">-Lf</font></code> to log to standard output.
</li><li> You can use the <code><font size="2">snmptrapd</font></code> command to generate an example trap, as in: 
</li></ul><div class="samplecode">
<p><code><font size="2"># snmptrap -v2c -c public localhost 1 1</font></code>
</p>
</div>
<h4><font size="3"><b><i> <a name="sendsnmpeventstosplunk_for_windows"><span class="mw-headline" id="For_Windows">For Windows</span></a></i></b></font></h4>
<p>To log SNMP traps to a file on Windows:
</p><p><b>1.</b> Download and install the latest version of <code><font size="2">NET-SNMP</font></code> for Windows from the NET-SNMP website.
</p><p><b>Note:</b> The OpenSSL library must not be installed on the system because it conflicts with NET-SNMP.
</p><p><b>2.</b> Register <code><font size="2">snmptrapd</font></code> as a service using the script included in the <code><font size="2">NET-SNMP</font></code> install.
</p><p><b>3.</b> Edit <code><font size="2">C:\usr\etc\snmp\snmptrapd.conf</font></code>:
</p>
<div class="samplecode">
<code><font size="2"><br>snmpTrapdAddr [System IP]:162<br>authCommunity log [community string]<br></font></code>
</div>
<p><b>4.</b> The default log location is <code><font size="2">C:\usr\log\snmptrapd.log</font></code>
</p>
<h3> <a name="sendsnmpeventstosplunk_use_management_information_bases_.28mibs.29"><span class="mw-headline" id="Use_Management_Information_Bases_.28MIBs.29">Use Management Information Bases (MIBs)</span></a></h3>
<p><i>Management Information Bases</i> (MIBs) provide a map between numeric object IDs (OIDs) reported by the SNMP trap and a textual human readable form. Though <code><font size="2">snmptrapd</font></code> can work without any MIB files at all, it won't display the results in exactly the same way. 
</p><p>The vendor of the device you receive SNMP traps from can provide a specific MIB. For example, all Cisco device MIBs can be located using the online Cisco SNMP Object Navigator.
</p><p>There are two steps required to add a new MIB file:
</p><p><b>1.</b> Download and copy the MIB file into the MIB search directory. On the *nix version of Net-SNMP, the default location is <code><font size="2">/usr/local/share/snmp/mibs</font></code>. You can set a different directory by providing the <code><font size="2">-m</font></code> argument to <code><font size="2">snmptrapd</font></code>.
</p><p><b>2.</b> Instruct <code><font size="2">snmptrapd</font></code> to load the MIB(s) by passing a colon-separated list to the <code><font size="2">-m</font></code> argument.
</p><p><b>Note:</b> 
</p>
<ul><li> If you add a leading '+' character for the parameters in the <code><font size="2">-m</font></code> argument, <code><font size="2">snmptrapd</font></code> loads the MIB in addition to the default list, instead of overwriting the list.
</li><li> The special keyword <code><font size="2">ALL</font></code> tells <code><font size="2">snmptrapd</font></code> to load all MIB modules in the MIB directory.
</li></ul><p>For example, to load all MIB modules in the MIB directory:
</p>
<div class="samplecode"><code><font size="2"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;snmptrapd -m +ALL<br></font></code></div>

<h1>Get Windows data</h1><a name="aboutwindowsdataandsplunk"></a><h2> <a name="aboutwindowsdataandsplunk_about_windows_data_and_splunk_enterprise"><span class="mw-headline" id="About_Windows_data_and_Splunk_Enterprise">About Windows data and Splunk Enterprise</span></a></h2>
<p>Splunk Enterprise can index many different kinds of Windows data. This data can be pretty much anything: a log file, a directory full of files, an Event Log channel, the Registry, or Active Directory. 
</p><p>You have several specialized inputs to monitor Windows data.
</p>
<ul><li> <b>Windows Event Logs.</b> Splunk Enterprise can <a href="#monitorwindowsdata" class="external text">monitor events</a> generated by the Windows Event Log service on any available event log channel on the machine.  You can collect events on the local machine or remotely by using either a universal forwarder or Windows Management Instrumentation (WMI).
</li></ul><ul><li> <b>Performance monitoring.</b> You can <a href="#real-timewindowsperformancemonitoring" class="external text">collect performance data</a> on Windows machines with Splunk Enterprise and then alert or report on that data. Any performance counter that is available in Performance Monitor is also available to Splunk Enterprise. You can monitor performance locally or remotely through a universal forwarder or WMI.
</li></ul><ul><li> <b>Remote monitoring over WMI.</b> Splunk Enterprise can <a href="#monitorwmidata" class="external text">use WMI</a> to access event log and performance data on remote machines.
</li></ul><ul><li> <b>Registry monitoring.</b> You can <a href="#monitorwindowsregistrydata" class="external text">monitor changes to the local Windows Registry</a> using the Registry monitoring capability. You can use a universal forwarder to gather Registry data from remote machines.
</li></ul><ul><li> <b>Active Directory monitoring.</b> Splunk Enterprise can audit any <a href="#auditactivedirectory" class="external text">changes to the Active Directory</a> including changes to user, group, machine, and group policy objects. You can forward Active Directory data to another Splunk Enterprise server.
</li></ul><p>These specialized inputs are available only on Windows installations of Splunk Enterprise. You also have available the standard set of Splunk Enterprise inputs, such as files and directories, the network monitoring inputs, and scripted inputs.
</p>
<h3> <a name="aboutwindowsdataandsplunk_the_splunk_app_for_windows_infrastructure"><span class="mw-headline" id="The_Splunk_App_for_Windows_Infrastructure"> The Splunk App for Windows Infrastructure</span></a></h3>
<p>The Splunk App for Windows Infrastructure provides data inputs, searches, reports, alerts, and dashboards for Windows server and desktop management. You can monitor, manage, and troubleshoot Windows operating systems from one place.  The app includes inputs for CPU, disk I/O, memory, event logs, configurations, and user data, plus a web-based setup UI for indexing Windows event logs.
</p>
<h3> <a name="aboutwindowsdataandsplunk_initial_considerations_for_deploying_splunk_enterprise_on_windows"><span class="mw-headline" id="Initial_considerations_for_deploying_Splunk_Enterprise_on_Windows"> Initial considerations for deploying Splunk Enterprise on Windows </span></a></h3>
<p>When you install and deploy Splunk Enterprise on Windows, consider the following points.
</p>
<ul><li> <b>Authentication.</b> To perform any operations on remote Windows machines in your network, Splunk Enterprise must run as a user with credentials to access those machines. Best practice entails making these credentials available before deploying. See <a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">"Considerations for deciding how to monitor remote Windows data."</a>
</li></ul><ul><li> <b>Disk bandwidth.</b> Splunk Enterprise indexers require lots of disk I/O bandwidth, particularly when indexing large amounts of data. Make sure that you configure any installed antivirus software to avoid monitoring Splunk Enterprise directories or processes, because such scans significantly reduce performance.
</li></ul><ul><li> <b>Shared servers.</b> Before you install Splunk Enterprise on a server that runs other services, see "Introduction to capacity planning for Splunk Enterprise" in the <i>Capacity Planning</i> manual. This is important if you install Splunk Enterprise on a domain controller or on a computer running memory-intensive services such as Exchange, SQL Server, or a virtual host server.
</li></ul><p>The most efficient way to gather data from any Windows server is to <a href="#usingforwardingagents" class="external text">install universal forwarders</a> on the machines from which you want to gather data. Universal forwarders have a small footprint and use limited resources. In some cases, such as Registry monitoring, you must use a forwarder, because you cannot collect Registry data remotely.
</p>
<a name="howtogetwindowsdataintosplunk"></a><h2> <a name="howtogetwindowsdataintosplunk_how_to_get_windows_data_into_splunk_enterprise"><span class="mw-headline" id="How_to_get_Windows_data_into_Splunk_Enterprise"> How to get Windows data into Splunk Enterprise</span></a></h2>
<p>Splunk Enterprise lets you collect many different kinds of Windows data.
</p><p>When you download and install Splunk Enterprise on a Windows machine, you can collect the following Windows statistics:
</p>
<ul><li> <a href="#monitorwindowsdata" class="external text">Windows Event Logs</a>
</li><li> <a href="#monitorfilesystemchangesonwindows" class="external text">File system changes</a>
</li><li> <a href="#auditactivedirectory" class="external text">Active Directory</a>
</li><li> <a href="#monitorwmidata" class="external text">data over the Windows Management Instrumentation (WMI) infrastructure</a>
</li><li> <a href="#monitorwindowsregistrydata" class="external text">Registry data</a>
</li><li> <a href="#real-timewindowsperformancemonitoring" class="external text">Performance metrics</a>
</li><li> <a href="#monitorwindowshostinformation" class="external text">Host information</a>
</li><li> <a href="#monitorwindowsprinterinformation" class="external text">Print information</a>
</li><li> <a href="#monitorwindowsnetworkinformation" class="external text">Network information</a>
</li></ul><p>You can collect all of these types of data only on Windows machines. Other operating systems cannot collect Windows data locally. However, you can forward Windows data from Windows systems to Splunk Enterprise instances that run on systems other than Windows.
</p>
<h3> <a name="howtogetwindowsdataintosplunk_use_splunk_web_to_collect_windows_data"><span class="mw-headline" id="Use_Splunk_Web_to_collect_Windows_data">Use Splunk Web to collect Windows data</span></a></h3>
<p>Nearly all Windows inputs let you collect Windows data by using the Splunk Web interface. The  exception is the <code><font size="2">MonitorNoHandle</font></code> input, which you must set up by using a configuration file.
</p><p><b>1.</b> Log into your Splunk Enterprise instance.
</p><p><b>2.</b> Click <b>Settings,</b> and in the pop-up window that appears, click <b>Data inputs</b>. The <b>Data inputs</b> page appears.
</p><p><b>3.</b> Find the input that you want to add in the list of available inputs by clicking <b>Add new</b> in the Actions column for the input.
</p><p><b>Note:</b> If the Splunk Enterprise system that you are logged into is not on Windows, no Windows inputs appear.
</p><p><b>4.</b> Follow the instructions in the subsequent pages for the input type you select. 
</p><p>See the pages above for specific instructions.
</p><p><b>5.</b> Click <b>Save.</b>
</p><p>Splunk Enterprise begins collecting the data immediately in most cases.
</p>
<h3> <a name="howtogetwindowsdataintosplunk_use_configuration_files_to_collect_windows_data"><span class="mw-headline" id="Use_configuration_files_to_collect_Windows_data">Use configuration files to collect Windows data</span></a></h3>
<p>In cases where you cannot use Splunk Web to create and enable data inputs, such as when you use a Splunk universal forwarder to collect the data, you must use configuration files. Using configuration files offers more control and configurability than Splunk Web does in many cases. Some inputs can only be configured using configuration files.
</p><p><b>Note:</b> The universal forwarder installer on Windows offers the ability to configure some - but not all - of the Windows inputs at installation time.
</p><p>To configure inputs using configuration files:
</p><p><b>1.</b> From a command prompt or PowerShell window, go to the <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code> directory.
</p><p><b>2.</b> Make a copy of <code><font size="2">inputs.conf</font></code> in this directory and move it to the <code><font size="2">%SPLUNK_HOME%\etc\system\local</font></code> directory.
</p><p><b>Note:</b> You only need to perform this step once, or if you want to overwrite <code><font size="2">inputs.conf</font></code> in the <code><font size="2">local</font></code> directory.
</p><p><b>3.</b> Use Notepad or another editor to open the <code><font size="2">inputs.conf</font></code> file in the <code><font size="2">local</font></code> directory for editing.
</p><p><b>4.</b> Add your inputs to the <code><font size="2">inputs.conf</font></code> file by defining stanzas, or change existing stanzas to meet your needs. Refer to the pages above for specific instructions for each input type.
</p><p><b>5.</b> Save the file and close it.
</p><p><b>6.</b> Restart Splunk Enterprise. The software reloads the configuration files and begins collecting data based on the new configuration.
</p><p><b>Note:</b> This is a basic guide to configuring inputs with configuration files. For more information, read "About configuration files" in the Admin manual.
</p>
<a name="considerationsfordecidinghowtomonitorwindowsdata"></a><h2> <a name="considerationsfordecidinghowtomonitorwindowsdata_considerations_for_deciding_how_to_monitor_remote_windows_data"><span class="mw-headline" id="Considerations_for_deciding_how_to_monitor_remote_Windows_data">Considerations for deciding how to monitor remote Windows data</span></a></h2>
<p>This topic discusses the considerations you must take when using Splunk Enterprise to gather remote Windows data.
</p>
<h3> <a name="considerationsfordecidinghowtomonitorwindowsdata_remote_windows_data_overview"><span class="mw-headline" id="Remote_Windows_data_overview"> Remote Windows data overview </span></a></h3>
<p>Splunk Enterprise collects remote Windows data for indexing in one of two ways:
</p>
<ul><li> from Splunk forwarders
</li><li> via Windows Management Instrumentation (WMI)
</li></ul><h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_use_a_forwarder"><span class="mw-headline" id="Use_a_forwarder"> Use a forwarder </span></a></i></b></font></h4>
<p>Splunk Enterprise can collect remote Windows data remotely with a forwarder. There are several types of forwarders: light, heavy and universal. See "About forwarding and receiving data" in the Forwarding Data Manual.
</p><p>Splunk Enterprise recommends using a universal forwarder to gather remote Windows data whenever possible. These are the advantages of using a universal forwarder:
</p>
<ul><li> The universal forwarder uses minimal network and disk resources on the installed machines.
</li><li> You can install a universal forwarder as a non-privileged user, whereas you require administrative access for WMI.
</li><li> If you install the universal forwarder as the Local System user, then it has administrative access to the machine and requires no authentication to get data from there, as WMI does.
</li><li> It scales well in large environments and is easy to deploy. You can deploy it manually, with either a Microsoft deployment tool like System Center Configuration Manager (SCCM) or Systems Management Server (SMS), or a third party distribution solution such as BigFix/Tivoli.
</li></ul><p>Once you install a universal forwarder, it gathers information locally and sends it to a central Splunk Enterprise indexer. You tell the forwarder what data to gather either during the installation process or later, by distributing configuration updates manually or with a <b>deployment server</b>. You can also install add-ons into the universal forwarder.
</p><p>There are some drawbacks to using the universal forwarder, depending on your network configuration and layout. See "Forwarders versus remote collection through WMI" later in this topic.
</p>
<h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_use_wmi"><span class="mw-headline" id="Use_WMI"> Use WMI </span></a></i></b></font></h4>
<p>The Windows Management Instrumentation (WMI) framework allows Splunk Enterprise to collect virtually any kind of data from remote Windows machines. In this configuration, Splunk Enterprise runs as a user that you specify at installation (or later on, in the Services control panel).
</p><p>This configuration:
</p>
<ul><li> gives Splunk Enterprise as much access to the network as the specified account has for remote access
</li><li> lets indexers collect data from remote Windows machines across the enterprise and place that data into a central repository
</li><li> is ideal for small to medium-sized networks with at least one indexer in each network segment
</li></ul><p>There are some caveats to this method of collection, however. See "<a href="#considerationsfordecidinghowtomonitorwindowsdata_forwarders_versus_wmi" class="external text">Forwarders versus WMI</a>" later in this topic.
</p><p><b>Note:</b> While Active Directory (AD) monitoring does not use WMI, it has the same authentication considerations as data inputs that do use it. For more information on how Splunk Enterprise monitors AD, see "<a href="#auditactivedirectory" class="external text">Monitor Active Directory</a>" in this manual.
</p>
<h3> <a name="considerationsfordecidinghowtomonitorwindowsdata_considerations_for_getting_data_over_wmi"><span class="mw-headline" id="Considerations_for_getting_data_over_WMI">Considerations for getting data over WMI</span></a></h3>
<p>When collecting remote Windows data over WMI, you must consider the following:
</p>
<h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_authentication_for_remote_windows_data"><span class="mw-headline" id="Authentication_for_remote_Windows_data">Authentication for remote Windows data</span></a></i></b></font></h4>
<p>Windows requires authentication for remote operations. Failure to understand how Splunk Enterprise interacts with Windows over the network can lead to suboptimal search results, or none at all. This section provides guidelines on security for collecting remote Windows data.
</p><p>When you install Splunk Enterprise, you can specify that it run as the Local System user, or another user. This choice has ramifications for both installation and data collection.
</p><p>The user you tell Splunk Enterprise to run as determines the type and amount of data it can retrieve from remote machines. To get the data you want, you must provide an appropriate level of permission to this user.
</p><p>The easiest way is to make the user that Splunk Enterprise runs as a member of the Administrators (or Domain Admins) group. This is a security risk and in some organizations, you might not be able to. Splunk does not recommend this practice.
</p><p>In most cases, you should configure the Splunk Enterprise user account with "least-permissive" access to the data sources you want to collect. This entails:
</p>
<ul><li> adding the user to various domain security groups.
</li><li> making changes to the access control lists of various AD objects, depending on the data sources you need to access. 
</li></ul><p>If your AD domain security policy enforces password changes regularly, you must also:
</p>
<ul><li> make sure that either the Splunk Enterprise user password never expires, or that you manually change the password before it expires, as defined by the password policy.
</li><li> restart Splunk services that run as that account on all servers in your network, once you change the password.
</li></ul><p><b>Note:</b> On recent versions of Windows Server, you can use managed service accounts (MSAs) to address issues with password expiry. See "Managed service accounts on Windows Server 2008 and Windows 7" in the Installation Manual.
</p><p>You should also assign the Splunk Enterprise account the "Deny log on locally" user rights assignment in Local Security Policy to prevent the user from logging in interactively to workstations. It does not need to do so to collect Windows data.
</p><p>While this method takes more time to complete, it gives you more control, and is more secure than handing out domain administrator access.
</p><p>Individual Getting Data In topics in this manual that deal with remote access to Windows machines contain additional information and recommendations on how to configure the user Splunk Enterprise runs as for least-permissive access.  Review the <b>Security and remote access considerations</b> section on those pages.
</p>
<h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_network_and_i.2fo_usage_considerations"><span class="mw-headline" id="Network_and_I.2FO_usage_considerations">Network and I/O usage considerations</span></a></i></b></font></h4>
<p>Network bandwidth usage should be monitored closely, especially in networks with slow or thin WAN links. For this reason alone, universal forwarders are a better choice for large remote collection operations.
</p><p>Disk bandwidth is a concern as well. Anti-virus scanner drivers and drivers that intermediate between Splunk Enterprise and the operating system should always be configured to ignore the Splunk Enterprise directory and processes, regardless of the type of installation.
</p>
<h3> <a name="considerationsfordecidinghowtomonitorwindowsdata_splunk_forwarders_versus_wmi"><span class="mw-headline" id="Splunk_forwarders_versus_WMI">Splunk forwarders versus WMI </span></a></h3>
<p>Use a universal forwarder to get data in from a remote Windows host. A universal forwarder offers the most types of data sources, provides more detailed data (for example, in performance monitoring metrics), minimizes network overhead, and reduces operational risk and complexity. It is also more scalable than WMI in many cases.
</p><p>In circumstances where you either want or have to collect data remotely (such as when corporate or security policy restricts code installation, or there are performance or interoperability concerns,) you can use the native WMI interface to collect event logs and performance data.
</p><p>These are the main areas of tradeoff between WMI and forwarders:
</p>
<ul><li> Performance
</li><li> Deployment
</li><li> Management
</li></ul><h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_performance"><span class="mw-headline" id="Performance"> Performance </span></a></i></b></font></h4>
<p>With respect to performance, a forwarder is a better choice when:
</p>
<ul><li> You collect local event logs or flat files. A forwarder requires less CPU and performs basic pre-compression of the data in an effort to reduce network overhead. 
</li><li> You want to collect data from a machine without having to worry about authentication. When you install a forwarder as the Local System user, it has administrative access to the machine, allowing you to collect any data from it.
</li><li> You want to collect data from busy hosts such as AD domain controllers or machines that consistently experience periods of high utilization, such as Exchange, SQL Server/Oracle, VMWare, Hyper-V, or SharePoint servers. This is because WMI might have problems keeping up with the amount of data these services generate. WMI polling is best-effort by design, and Splunk Enterprise also throttles WMI calls to prevent unintentional denial-of-service attacks.
</li><li> You are concerned about CPU and network utilization. Forwarders use as little of these resources as possible, while WMI uses more CPU and network resources to transfer data.
</li><li> You are concerned about scalability. Universal forwarders scale very well. Heavy forwarders do not scale as well as universal forwarders, but both types of forwarder scale considerably better than WMI.
</li></ul><p>WMI is a better choice when:
</p>
<ul><li> You are concerned about memory usage on a system with high memory utilization. Because forwarders have more polling options available, and reside on the local machine while collecting data, they use more memory than WMI does.
</li></ul><h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_deployment"><span class="mw-headline" id="Deployment">Deployment</span></a></i></b></font></h4>
<p>A forwarder is a better choice for deployment when:
</p>
<ul><li> You have control of the base build of the OS, as is the case when you create system images.
</li><li> You have many data sources to collect, particularly if the data collected requires transformation of any kind.
</li></ul><p><b>Note:</b> Except for a few cases, you cannot use a universal forwarder to process data before it reaches the indexer. If you need to make any changes to your data before it is indexed, you must use a heavy forwarder.
</p><p>WMI is a better choice when:
</p>
<ul><li> You don't have control of the base OS build, or you don't have domain administrator access, or local administrator privileges on the machines from which you want to get data.
</li><li> You want or need only a limited set of data from a large number of hosts (for example, CPU data for usage billing).
</li></ul><p>A common deployment scenario is to first test using remote polling, then add successful or useful data inputs to your forwarder's configuration later, or at mass deployment time. 
</p>
<h4><font size="3"><b><i> <a name="considerationsfordecidinghowtomonitorwindowsdata_management"><span class="mw-headline" id="Management">Management</span></a></i></b></font></h4>
<p>Both mechanisms offer logging and alerting to let you know if a host is coming on or offline or is no longer connected. However, to prevent an unintentional denial of service attack, the WMI polling service in Splunk Enterprise begins to poll less frequently over time if it cannot contact a host for a period of time, and will eventually stop polling unreachable hosts altogether. As a result, Splunk does not advise remote polling over WMI for machines that are frequently offline, such as laptops or dynamically provisioned virtual machines.
</p><p>The following table offers a list of data sources and indicates which data collection type(s) are appropriate for each data source. 
</p>
<table cellpadding="5" cellspacing="0" border="1"><caption> <b>Data sources and collection methods</b>
</caption><tr><th bgcolor="#C0C0C0"> Data source
</th><th bgcolor="#C0C0C0"> Local forwarder
</th><th bgcolor="#C0C0C0"> WMI
</th></tr><tr><td valign="center" align="left"> Event logs
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> Yes*
</td></tr><tr><td valign="center" align="left"> Performance
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> Yes
</td></tr><tr><td valign="center" align="left"> Registry
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> No
</td></tr><tr><td valign="center" align="left"> Active Directory
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> No
</td></tr><tr><td valign="center" align="left"> Log files
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> Yes**
</td></tr><tr><td valign="center" align="left"> Crawl
</td><td valign="center" align="left"> Yes
</td><td valign="center" align="left"> No
</td></tr></table><p><i>*   For remote event log collection, you </i>must<i> know the name of the event log you want to collect. On local forwarders, you have the option to collect all logs, regardless of name</i>.
</p><p><i>** Splunk Enterprise supports remote log file collection using the "\\SERVERNAME\SHARE" syntax; however, you must use CIFS (Common Internet File System, or Server Message Block) as your application layer file access protocol, and Splunk Enterprise must have at least read access to both the share and the underlying file system</i>.
</p>
<h3> <a name="considerationsfordecidinghowtomonitorwindowsdata_search_windows_data_on_a_non-windows_instance_of_splunk_enterprise"><span class="mw-headline" id="Search_Windows_data_on_a_non-Windows_instance_of_Splunk_Enterprise">Search Windows data on a non-Windows instance of Splunk Enterprise</span></a></h3>
<p>You can index and search your Windows data on a non-Windows instance of Splunk, but you must first use a Windows instance of Splunk Enterprise to gather the Windows data. You can do this by installing a Splunk forwarder onto the Windows computer and configuring it to forward Windows data to the non-Windows instance of Splunk Enterprise.
</p><p>There are two ways to proceed:
</p>
<ul><li> Set up forwarders locally on each Windows machine from which you want data. These forwarders can send the Windows data to the non-Windows receiving instance of Splunk.
</li><li> Set up a forwarder on a separate Windows machine. The forwarder can use WMI to collect data from all the Windows machines in the environment and then forward the combined data to a non-Windows receiving instance of Splunk. 
</li></ul><p>You must explicitly configure the non-Windows Splunk Enterprise instance to handle the Windows data. See  "Searching data received from a forwarder running on a different operating system" in the Forwarding Data Manual.
</p><p>For information on setting up forwarders, see "Set up forwarding and receiving" also in the Forwarding Data Manual.
</p>
<a name="auditactivedirectory"></a><h2> <a name="auditactivedirectory_monitor_active_directory"><span class="mw-headline" id="Monitor_Active_Directory"> Monitor Active Directory</span></a></h2>
<p>Active Directory (AD) is an integral part of any Windows network. The Active Directory database (known as the NT Directory Service (NTDS) database) is the central repository for user, computer, network, device and security objects in an AD domain or forest. When you make a change to Active Directory, such as adding or deleting a user, member server or domain controller, those changes are recordable. Splunk Enterprise lets you alert and monitor those changes in real time.
</p><p>You can configure AD monitoring to watch changes to your Active Directory forest, and collect user and machine metadata. You can use this feature combined with dynamic list lookups to decorate or modify events with any information available in AD. 
</p><p>Once you've configured Splunk to monitor your Active Directory, it takes a baseline snapshot of the AD schema. It uses this snapshot to establish a starting point against which to monitor. This process might take a little time before it completes.
</p><p>The AD monitoring input runs as a separate process called <code><font size="2">splunk-admon.exe</font></code>. It runs once for every Active Directory monitoring input defined in Splunk.
</p>
<h3> <a name="auditactivedirectory_why_monitor_active_directory.3f"><span class="mw-headline" id="Why_monitor_Active_Directory.3F">Why monitor Active Directory?</span></a></h3>
<p>If you are charged with maintaining the integrity, security and health of your Active Directory, then you are concerned with what is happening with it day to day. Splunk Enterprise allows you to see what has changed in your AD, who or what made the changes, and when they were made. 
</p><p>You can transform this data into reports for corporate security compliance or forensics. You can also use the data retrieved for intrusion alerts for immediate response. Additionally, you can create health reports with the data indexed for future AD infrastructure planning activities, such as assignment of operations master roles, AD replicas, and global catalogs across domain controllers (DCs).
</p>
<h3> <a name="auditactivedirectory_what_do_you_need_to_monitor_active_directory.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_Active_Directory.3F">What do you need to monitor Active Directory?</span></a></h3>
<p>The following table lists the explicit permissions needed to monitor an Active Directory schema.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor an Active Directory schema
</td><td valign="top" align="left"> * Splunk must run on Windows<br>* Splunk must run as a domain user<br>* The user Splunk runs as must have read access to all AD objects that you want to monitor
</td></tr></table><h3> <a name="auditactivedirectory_considerations_for_monitoring_active_directory"><span class="mw-headline" id="Considerations_for_monitoring_Active_Directory">Considerations for monitoring Active Directory</span></a></h3>
<p>To get the best results out of monitoring AD with Splunk Enterprise, be aware of the following:
</p>
<ul><li> This feature is only available with Splunk Enterprise on Windows. You won't be able to monitor AD changes from a *nix version of Splunk (though you can forward AD data gathered from a Windows version of Splunk to a *nix indexer).
</li><li> The AD monitoring process can run under a full Splunk instance or within any kind of forwarder.
</li><li> The machine that monitors changes to AD must belong to the domain or forest you want to monitor.
</li><li> The user Splunk runs as must be part of the domain too. This is because the permissions that the user has determine what parts of AD Splunk can monitor.
</li></ul><p>For additional information on deciding how to monitor Windows data remotely, see "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" in this manual. For information on deciding which user Splunk should run as at installation time, review "Choose the user Splunk should run as" in the Installation Manual.
</p>
<h3> <a name="auditactivedirectory_configure_active_directory_monitoring"><span class="mw-headline" id="Configure_Active_Directory_monitoring"> Configure Active Directory monitoring </span></a></h3>
<p>You can configure AD monitoring either in Splunk Web or by editing configuration files. More options, such as the ability to configure monitors for multiple DCs, are available when using configuration files.
</p>
<h4><font size="3"><b><i> <a name="auditactivedirectory_configure_ad_monitoring_with_splunk_web"><span class="mw-headline" id="Configure_AD_monitoring_with_Splunk_Web">Configure AD monitoring with Splunk Web</span></a></i></b></font></h4>
<p>To configure Active Directory monitoring, follow the "<a href="#windowsactivedirectory" class="external text">Windows Active Directory</a>" recipe in this manual.
</p>
<h4><font size="3"><b><i> <a name="auditactivedirectory_configure_ad_monitoring_with_configuration_files"><span class="mw-headline" id="Configure_AD_monitoring_with_configuration_files">Configure AD monitoring with configuration files</span></a></i></b></font></h4>
<p>The inputs.conf configuration file controls Active Directory monitoring configurations. Edit copies of <code><font size="2">inputs.conf</font></code> in the <code><font size="2">%SPLUNK_HOME%\etc\system\local</font></code> directory. If you edit them in the default directory, Splunk overwrites any changes you make when you upgrade. For more information about configuration file precedence, see "Configuration file precedence" in this manual. 
</p><p><b>1.</b> Make a copy of <code><font size="2">%SPLUNK_HOME%\etc\system\default\inputs.conf</font></code> and put it in <code><font size="2">%SPLUNK_HOME%\etc\system\local\inputs.conf</font></code>.
</p><p><b>2.</b> Edit inputs.conf to add the appropriate AD monitoring stanzas and settings. 
</p><p><b>Note:</b> By default, when you enable AD monitoring inputs, Splunk gathers AD change data from the first domain controller that it can attach to. If that is acceptable, no further configuration is necessary. 
</p>
<h5> <a name="auditactivedirectory_inputs.conf_settings"><span class="mw-headline" id="inputs.conf_settings">inputs.conf settings</span></a></h5>
<p><code><font size="2">inputs.conf</font></code> contains one stanza for each AD monitoring input, with a header like the following:
</p><p><code><font size="2">[admon://&lt;name of stanza&gt;]</font></code> 
</p><p>In each stanza, you can specify:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="20%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">targetDc</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> The unique name of the domain controller you want Splunk to use for AD monitoring.
<p>Specify a unique name for this attribute if:
</p>
<ul><li> You have a very large AD and you only want to monitor information in a particular Organizational Unit (OU), subdomain, etc. 
</li><li> You have a specific (read-only) domain controller that can be used for monitoring purposes in a high security environment.
</li><li> You have multiple domains or forests in with transitive trusts established, and want to target a different tree than the one where the server that runs Splunk resides. 
</li><li> You want to configure multiple AD monitoring inputs to target multiple domain controllers. For example, to monitor AD replication across a distributed environment.
</li></ul><p><b>Note:</b> If you want to target multiple DCs, add another <code><font size="2">[admon://&lt;uniquename&gt;targetDc]</font></code> stanza for a target in that tree. 
</p>
</td><td valign="top" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">startingNode</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> A fully qualified Lightweight Directory Access Protocol (LDAP) name (for example:  <code><font size="2">"LDAP://OU=Computers,DC=ad,DC=splunk,DC=com"</font></code>) that specifies where in the AD tree that Splunk should begin its indexing. Splunk starts there and enumerates down to sub-containers, depending on the configuration of the <code><font size="2">monitorSubtree</font></code> attribute.
<p><b>Note:</b> The value of <code><font size="2">startingNode</font></code> must be within the scope of the DC you are targeting in order for Splunk to successfully get AD data.
</p>
</td><td valign="top" align="left"> The highest root domain in the tree that Splunk can access
</td></tr><tr><td valign="top" align="left"> <code><font size="2">monitorSubtree</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> How much of the target AD container to index.  A value of 0 tells Splunk to index only the target container, and not traverse into subcontainers within that container. A value of 1 tells Splunk to enumerate all sub-containers and domains that it has access to.
</td><td valign="top" align="left"> 1 (monitor all domains that Splunk has access to)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">baseline</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not the input enumerates all existing available AD objects when it first runs. A value of 0 tells Splunk not to set a baseline, and a value of 1 tells Splunk to set a baseline.
</td><td valign="top" align="left"> 1 (set the baseline.)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> The index to route AD monitoring data to.
</td><td valign="top" align="left"> the 'default' index.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not the Splunk should run the input. A value of 0 tells Splunk that the input is enabled, and a value of 1 tells Splunk that the input is disabled.
</td><td valign="top" align="left"> 0 (enabled).
</td></tr></table><h3> <a name="auditactivedirectory_example_ad_monitoring_configurations"><span class="mw-headline" id="Example_AD_monitoring_configurations">Example AD monitoring configurations</span></a></h3>
<p>The following are examples of how to use <code><font size="2">inputs.conf</font></code> to monitor desired portions of your AD network.
</p><p>To index data from the top of the AD directory:
</p>
<div class="samplecode"><code><font size="2"><br>#Gather all AD data that this server can see<br><br>[admon://NearestDC]<br>targetDc =<br>startingNode =<br></font></code></div>
<p>To use a DC that is at a higher root level than an OU you want to target for monitoring:
</p>
<div class="samplecode"><code><font size="2"><br># Use the pri01.eng.ad.splunk.com domain controller to get all AD metadata for<br># the Computers OU in this forest. We want schema data for the entire AD tree, not<br># just this node.<br><br>[admon://DefaultTargetDc]<br>targetDc = pri01.eng.ad.splunk.com<br>startingNode = OU=Computers,DC=eng,DC=ad,DC=splunk,DC=com<br></font></code></div>
<p>To monitor multiple domain controllers:
</p>
<div class="samplecode"><code><font size="2"><br># Get change data from two domain controllers (pri01 and pri02) in the same AD tree.<br># Index both and compare/contrast to ensure AD replication is occurring properly.<br><br>[admon://DefaultTargetDc]<br>targetDc = pri01.eng.ad.splunk.com<br>startingNode = OU=Computers,DC=eng,DC=ad,DC=splunk,DC=com<br><br>[admon://SecondTargetDc]<br>targetDc = pri02.eng.ad.splunk.com<br>startingNode = OU=Computers,DC=eng,DC=ad,DC=splunk,DC=com<br></font></code></div>
<h3> <a name="auditactivedirectory_sample_ad_monitoring_output"><span class="mw-headline" id="Sample_AD_monitoring_output">Sample AD monitoring output</span></a></h3>
<p>When the Splunk AD monitoring utility runs, it gathers AD change events. Each change event is indexed as an event in Splunk. You can view these events as they come into Splunk in the Search app. 
</p><p>There are several types of AD change events that Splunk can index. Examples of these events are detailed below. Some of the content of these events has been obscured/altered for publication purposes. 
</p>
<h4><font size="3"><b><i> <a name="auditactivedirectory_update_event"><span class="mw-headline" id="Update_event">Update event</span></a></i></b></font></h4>
<p>When an AD object is changed in any way, Splunk generates this type of event. Splunk logs this change as type <code><font size="2">admonEventType=Update</font></code>.
</p>
<div class="samplecode"><code><font size="2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>2/1/10<br>3:17:18.009 PM &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>02/01/2010 15:17:18.0099<br>dcName=stuff.splunk.com<br>admonEventType=Update<br>Names:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectCategory=CN=Computer,CN=Schema,CN=Configuration<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name=stuff2<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;displayName=stuff2<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;distinguishedName=CN=stuff2,CN=Computers<br>Object Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sAMAccountType=805306369<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sAMAccountName=stuff2<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logonCount=4216<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accountExpires=9223372036854775807<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectSid=S-1-5-21-3436176729-1841096389-3700143990-1190<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;primaryGroupID=515<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pwdLastSet=06:30:13 pm, Sat 11/27/2010<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lastLogon=06:19:43 am, Sun 11/28/2010<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lastLogoff=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;badPasswordTime=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;countryCode=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;codePage=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;badPwdCount=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;userAccountControl=4096<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectGUID=blah<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenChanged=01:02.11 am, Thu 01/28/2010<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenCreated=05:29.50 pm, Tue 11/25/2008<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectClass=top|person|organizationalPerson|user|computer<br>Event Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uSNChanged=2921916<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uSNCreated=1679623<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instanceType=4<br>Additional Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;isCriticalSystemObject=FALSE<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;servicePrincipalName=TERMSRV/stuff2|TERMSRV blah<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dNSHostName=stuff2.splunk.com<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;operatingSystemServicePack=Service Pack 2<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;operatingSystemVersion=6.0 (6002)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;operatingSystem=Windows Vista? Ultimate<br>localPolicyFlags=0<br>&nbsp;<br></font></code></div>
<h4><font size="3"><b><i> <a name="auditactivedirectory_delete_event"><span class="mw-headline" id="Delete_event">Delete event</span></a></i></b></font></h4>
<p>Splunk generates this event type when an AD object has been marked for deletion. The event type is similar to <code><font size="2">admonEventType=Update</font></code>, except that it contains the <code><font size="2">isDeleted=True</font></code> key/value pair at the end of the event.
</p>
<div class="samplecode"><code><font size="2"><br>2/1/10<br>3:11:16.095 PM &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;<br>02/01/2010 15:11:16.0954<br>dcName=stuff.splunk.com<br>admonEventType=Update<br>Names:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name=SplunkTest<br>DEL:blah<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;distinguishedName=OU=SplunkTest\0ADEL:blah,CN=Deleted Objects<br>DEL:blah<br>Object Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectGUID=blah<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenChanged=11:31.13 pm, Thu 01/28/2010<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenCreated=11:27.12 pm, Thu 01/28/2010<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectClass=top|organizationalUnit<br>Event Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uSNChanged=2922895<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uSNCreated=2922846<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instanceType=4<br>Additional Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dSCorePropagationData=20100128233113.0Z|20100128233113.0Z|20100128233113.0Z|16010108151056.0Z<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lastKnownParent=stuff<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''isDeleted=TRUE'''<br>&nbsp;<br></font></code></div>
<h4><font size="3"><b><i> <a name="auditactivedirectory_sync_event"><span class="mw-headline" id="Sync_event">Sync event</span></a></i></b></font></h4>
<p>When AD monitoring inputs are configured, Splunk tries to capture a baseline of AD metadata when it is started. Splunk generates event type <code><font size="2">admonEventType=Sync</font></code>, which represents the instance of one AD object and all its field values. Splunk tries to capture all of the objects from the last recorded Update Sequence Number (USN).
</p><p><b>Note:</b> When you restart either Splunk or the <code><font size="2">splunk-admon.exe</font></code> process, Splunk will log an extra 'sync' event.  This is normal.
</p>
<div class="samplecode"><code><font size="2"><br>2/1/10<br>3:11:09.074 PM &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;<br>02/01/2010 15:11:09.0748<br>dcName=ftw.ad.splunk.com<br>admonEventType=Sync<br>Names:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name=NTDS Settings<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;distinguishedName=CN=NTDS Settings,CN=stuff,CN=Servers,CN=Default-First-Site-Name,CN=Sites,CN=Configuration<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cn=NTDS Settings<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectCategory=CN=NTDS-DSA,CN=Schema,CN=Configuration,DC=ad,DC=splunk,DC=com<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fullPath=LDAP://stuff.splunk.com/&lt;GUID=bla bla bla&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CN=NTDS Settings<br>Object Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenCreated=10:15.04 pm, Tue 02/12/2008<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whenChanged=10:23.00 pm, Tue 02/12/2008<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectGUID=bla bla bla<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objectClass=top|applicationSettings|nTDSDSA<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classPath=nTDSDSA<br>Event Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instanceType=4<br>Additional Details:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;systemFlags=33554432<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;showInAdvancedViewOnly=TRUE<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serverReferenceBL=CN=stuff,CN=Domain System Volume (SYSVOL share),CN=File Replication Service,CN=System<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;options=1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;msDS-hasMasterNCs=DC=ForestDnsZones|DC=DomainDnsZones|CN=Schema,CN=Configuration|CN=Configuration<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;msDS-HasInstantiatedNCs=<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;msDS-HasDomainNCs=blah<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;msDS-Behavior-Version=2<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;invocationId=bla bla bla<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hasMasterNCs=CN=Schema,CN=Configuration|CN=Configuration<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dSCorePropagationData=<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dMDLocation=CN=Schema,CN=Configuration<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nTSecurityDescriptor=NT AUTHORITY\Authenticated Users<br>SchemaName=LDAP://stuff.splunk.com/schema/nTDSDSA &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br></font></code></div>
<h4><font size="3"><b><i> <a name="auditactivedirectory_schema_event"><span class="mw-headline" id="Schema_event">Schema event</span></a></i></b></font></h4>
<p>When Splunk is started after configured for AD monitoring, it generates a schema type event: <code><font size="2">admonEventType=schema</font></code>. This event shows the definitions of every object in the Active Directory structure. The available, required and optional fields are listed for each AD object. Failure to see all of these fields can indicate a problem with Active Directory.
</p>
<div class="samplecode"><code><font size="2"><br>02/01/2010 15:11:16.0518<br>dcName=LDAP://stuff.splunk.com/<br>admonEventType=schema<br>className=msExchProtocolCfgSMTPIPAddress<br>classCN=ms-Exch-Protocol-Cfg-SMTP-IP-Address<br>instanceType=MandatoryProperties<br>nTSecurityDescriptor=MandatoryProperties<br>objectCategory=MandatoryProperties<br>objectClass=MandatoryProperties<br>adminDescription=OptionalProperties<br>adminDisplayName=OptionalProperties<br>allowedAttributes=OptionalProperties<br>allowedAttributesEffective=OptionalProperties<br>allowedChildClasses=OptionalProperties<br>allowedChildClassesEffective=OptionalProperties<br>bridgeheadServerListBL=OptionalProperties<br>canonicalName=OptionalProperties<br>cn=OptionalProperties<br>createTimeStamp=OptionalProperties<br>description=OptionalProperties<br>directReports=OptionalProperties<br>displayName=OptionalProperties<br>displayNamePrintable=OptionalProperties<br>distinguishedName=OptionalProperties<br>dSASignature=OptionalProperties<br>dSCorePropagationData=OptionalProperties<br>extensionName=OptionalProperties<br>flags=OptionalProperties<br>fromEntry=OptionalProperties<br>frsComputerReferenceBL=OptionalProperties<br>fRSMemberReferenceBL=OptionalProperties<br>fSMORoleOwner=OptionalProperties<br>heuristics=OptionalProperties<br>isCriticalSystemObject=OptionalProperties<br>isDeleted=OptionalProperties<br>isPrivilegeHolder=OptionalProperties<br>lastKnownParent=OptionalProperties<br>legacyExchangeDN=OptionalProperties<br>managedObjects=OptionalProperties<br>masteredBy=OptionalProperties<br>memberOf=OptionalProperties<br>modifyTimeStamp=OptionalProperties<br>mS-DS-ConsistencyChildCount=OptionalProperties<br>mS-DS-ConsistencyGuid=OptionalProperties<br>msCOM-PartitionSetLink=OptionalProperties<br>msCOM-UserLink=OptionalProperties<br>msDFSR-ComputerReferenceBL=OptionalProperties<br>msDFSR-MemberReferenceBL=OptionalProperties<br>msDS-Approx-Immed-Subordinates=OptionalProperties<br>msDs-masteredBy=OptionalProperties<br>msDS-MembersForAzRoleBL=OptionalProperties<br>msDS-NCReplCursors=OptionalProperties<br>msDS-NCReplInboundNeighbors=OptionalProperties<br>msDS-NCReplOutboundNeighbors=OptionalProperties<br>msDS-NonMembersBL=OptionalProperties<br>msDS-ObjectReferenceBL=OptionalProperties<br>msDS-OperationsForAzRoleBL=OptionalProperties<br>msDS-OperationsForAzTaskBL=OptionalProperties<br>msDS-ReplAttributeMetaData=OptionalProperties<br>msDS-ReplValueMetaData=OptionalProperties<br>msDS-TasksForAzRoleBL=OptionalProperties<br>msDS-TasksForAzTaskBL=OptionalProperties<br>msExchADCGlobalNames=OptionalProperties<br>msExchALObjectVersion=OptionalProperties<br>msExchHideFromAddressLists=OptionalProperties<br>msExchInconsistentState=OptionalProperties<br>msExchIPAddress=OptionalProperties<br>msExchTurfList=OptionalProperties<br>msExchUnmergedAttsPt=OptionalProperties<br>msExchVersion=OptionalProperties<br>msSFU30PosixMemberOf=OptionalProperties<br>name=OptionalProperties<br>netbootSCPBL=OptionalProperties<br>nonSecurityMemberBL=OptionalProperties<br>objectGUID=OptionalProperties<br>objectVersion=OptionalProperties<br>otherWellKnownObjects=OptionalProperties<br>ownerBL=OptionalProperties<br>partialAttributeDeletionList=OptionalProperties<br>partialAttributeSet=OptionalProperties<br>possibleInferiors=OptionalProperties<br>proxiedObjectName=OptionalProperties<br>proxyAddresses=OptionalProperties<br>queryPolicyBL=OptionalProperties<br>replicatedObjectVersion=OptionalProperties<br>replicationSignature=OptionalProperties<br>replPropertyMetaData=OptionalProperties<br>replUpToDateVector=OptionalProperties<br>repsFrom=OptionalProperties<br>repsTo=OptionalProperties<br>revision=OptionalProperties<br>sDRightsEffective=OptionalProperties<br>serverReferenceBL=OptionalProperties<br>showInAddressBook=OptionalProperties<br>showInAdvancedViewOnly=OptionalProperties<br>siteObjectBL=OptionalProperties<br>structuralObjectClass=OptionalProperties<br>subRefs=OptionalProperties<br>subSchemaSubEntry=OptionalProperties<br>systemFlags=OptionalProperties<br>unmergedAtts=OptionalProperties<br>url=OptionalProperties<br>uSNChanged=OptionalProperties<br>uSNCreated=OptionalProperties<br>uSNDSALastObjRemoved=OptionalProperties<br>USNIntersite=OptionalProperties<br>uSNLastObjRem=OptionalProperties<br>uSNSource=OptionalProperties<br>wbemPath=OptionalProperties<br>wellKnownObjects=OptionalProperties<br>whenChanged=OptionalProperties<br>whenCreated=OptionalProperties<br>wWWHomePage=OptionalProperties<br></font></code></div>
<h3> <a name="auditactivedirectory_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around monitoring AD with Splunk.
</p>
<a name="monitorwindowsdata"></a><h2> <a name="monitorwindowsdata_monitor_windows_event_log_data"><span class="mw-headline" id="Monitor_Windows_event_log_data"> Monitor Windows event log data</span></a></h2>
<p>Windows generates log data during the course of its operation. The Windows Event Log service handles nearly all of this communication. It gathers log data published by installed applications, services and system processes and places them into event log channels - intermediate locations that eventually get written to an event log file. Programs such as Microsoft's Event Viewer subscribe to these log channels to display events that have occurred on the system. 
</p><p>Splunk Enterprise also supports the monitoring of Windows event log channels. It can monitor event log channels and files stored on the local machine, and it can collect logs from remote machines.
</p><p>The event log monitor runs as an input processor within the <code><font size="2">splunkd</font></code> service. It runs once for every event log input defined in Splunk Enterprise.  
</p>
<h3> <a name="monitorwindowsdata_why_monitor_event_logs.3f"><span class="mw-headline" id="Why_monitor_event_logs.3F"> Why monitor event logs?</span></a></h3>
<p>Windows event logs are the core metric of Windows server operations - if there's a problem with your Windows system, the Event Log service likely knows about it. Splunk Enterprise's indexing, searching and reporting capabilities make your logs accessible.
</p>
<h3> <a name="monitorwindowsdata_what_do_you_need_to_monitor_event_logs.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_event_logs.3F"> What do you need to monitor event logs?</span></a></h3>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor local event logs
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as the Local System user to read all local event logs
</td></tr><tr><td valign="top" align="left"> Monitor remote event logs
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>AND<br>* Splunk Enterprise must run on a universal forwarder that is installed on the server you wish to collect event logs from<br>OR<br>* Splunk Enterprise must run as a domain or remote user with read access to Windows Management Instrumentation (WMI) on the target server<br>* The user Splunk Enterprise runs as must have read access to the desired event logs
</td></tr></table><h3> <a name="monitorwindowsdata_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enterprise collects event log data from remote machines using either WMI or a forwarder. Splunk recommends using a universal forwarder to send event log data from remote machines to an indexer. Review "Introducing the universal forwarder" in the Forwarding Data Manual for information about how to install, configure and use the forwarder to collect event log data.
</p><p>If you choose to install forwarders on your remote machines to collect event log data, then you can install the forwarder as the Local System user on these machines. The Local System user has access to all data on the local machine, but not on remote machines.
</p><p>If you want Splunk Enterprise to use WMI to get event log data from remote machines, then you must ensure that your network and Splunk instances are properly configured. You cannot install Splunk as the Local System user, and the user you install with determines the event logs Splunk sees. Review "<a href="#monitorwmidata_security_and_remote_access_considerations" class="external text">Security and remote access considerations</a>" in the "<a href="#monitorwmidata" class="external text">Monitor WMI-based data</a>" topic in this manual for additional information on the requirements you must satisfy in order for Splunk to collect remote data properly using WMI.
</p><p>By default, Windows restricts access to some event logs depending on which version of Windows you run. In particular, the Security event logs by default can only be read by members of the local Administrators or global Domain Admins groups.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_collect_event_logs_from_a_remote_windows_machine"><span class="mw-headline" id="Collect_event_logs_from_a_remote_Windows_machine"> Collect event logs from a remote Windows machine </span></a></i></b></font></h4>
<p>If you want Splunk Enterprise to collect event logs from a remote machine, you have two choices:
</p>
<ul><li> Collect the logs remotely using WMI. You use this option when you select "Remote event log collections" in Splunk Web.
</li><li> Install a <b>universal forwarder</b> on the machine from which you want to collect logs.
</li></ul><p>If you choose to collect event logs using WMI, you must install Splunk Enterprise with an Active Directory domain user. Refer to "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" for additional information on collecting data from remote Windows machines. If the selected domain user is not a member of the Administrators or Domain Admins groups, then you must configure event log security to give the domain user access to the event logs.
</p><p>To change event log security for access to the event logs from remote machines, you must:
</p>
<ul><li> Have administrator access to the server from which you are collecting event logs.
</li><li> Understand how the Security Description Definition Language (SDDL) (external link) works, and how to assign permissions with it.
</li></ul><p>For instructions on how to configure event log security permissions on Windows XP and Windows Server 2003/2003 R2, review this Microsoft Knowledge Base article. If you're running Windows Vista, Windows 7 or Windows Server 2008/2008 R2, use the <code><font size="2">wevtutil</font></code> utility to set event log security.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_anomalous_host_names_visible_in_event_logs_on_some_systems"><span class="mw-headline" id="Anomalous_host_names_visible_in_event_logs_on_some_systems">Anomalous host names visible in event logs on some systems</span></a></i></b></font></h4>
<p>On Windows Vista and Server 2008 systems, you might see some event logs with randomly-generated host names. This is the result of those systems logging events before the user has named the system, during the OS installation process.
</p><p>This anomaly only occurs when collecting logs from the above-mentioned versions of Windows remotely over WMI.
</p>
<h3> <a name="monitorwindowsdata_use_splunk_web_to_configure_event_log_monitoring"><span class="mw-headline" id="Use_Splunk_Web_to_configure_event_log_monitoring"> Use Splunk Web to configure event log monitoring </span></a></h3>
<p>To collect Windows event log data from the local machine, follow the "<a href="#windowseventlogslocal" class="external text">Windows event logs - local</a>" recipe in this manual.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_configure_remote_event_log_monitoring"><span class="mw-headline" id="Configure_remote_event_log_monitoring">Configure remote event log monitoring</span></a></i></b></font></h4>
<p>The process for configuring remote event log monitoring is nearly identical to the process for monitoring local event logs.
</p><p>To collect Windows event log data from a remote Windows machine, follow the "<a href="#windowseventlogsremote" class="external text">Windows event logs - remote</a>" recipe in this manual.
</p>
<h3> <a name="monitorwindowsdata_use_inputs.conf_to_configure_event_log_monitoring"><span class="mw-headline" id="Use_inputs.conf_to_configure_event_log_monitoring">Use inputs.conf to configure event log monitoring</span></a></h3>
<p>You can edit <code><font size="2">inputs.conf</font></code> to configure event log monitoring. For more information on configuring data inputs with <code><font size="2">inputs.conf</font></code>, read "<a href="#configureyourinputs_edit_inputs.conf" class="external text">Configure your inputs</a>" in this manual.
</p><p><b>Note:</b> You can always review the defaults for a configuration file by looking at the examples in <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code> or at the spec file in the Admin Manual.
</p>
<ul><li> For more information on how to edit configuration files, see "About configuration files" in the Admin Manual.
</li></ul><p>To enable event log inputs by editing <code><font size="2">inputs.conf</font></code>:
</p><p><b>1.</b> Copy inputs.conf from <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code>  to  <code><font size="2">etc\system\local</font></code> .
</p><p><b>2.</b> Use Explorer or the <code><font size="2">ATTRIB</font></code> command to remove the file's "Read Only" flag.
</p><p><b>3.</b> Open the file and edit it to enable Windows event log inputs.
</p><p><b>4.</b> Restart Splunk.
</p><p>The next section describes the available configuration values for event log monitoring.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_event_log_monitor_configuration_values"><span class="mw-headline" id="Event_log_monitor_configuration_values"> Event log monitor configuration values</span></a></i></b></font></h4>
<p>Windows event log (*.evt) files are in binary format. They can't be monitored like a normal text file. The <code><font size="2">splunkd</font></code> service monitors these binary files by using the appropriate APIs to read and index the data within the files.
</p><p>Splunk uses the following stanzas in <code><font size="2">inputs.conf</font></code> to monitor the default Windows event logs:
</p>
<div class="samplecode"><code><font size="2"><br># Windows platform specific input processor.<br>[WinEventLog://Application]<br>disabled = 0 <br>[WinEventLog://Security]<br>disabled = 0 <br>[WinEventLog://System]<br>disabled = 0 <br></font></code></div>
<p>You can also configure Splunk Enterprise to monitor non-default Windows event logs. Before you can do this, you must import them to the Windows Event Viewer. Once the logs are imported, you can add them to your local copy of <code><font size="2">inputs.conf</font></code>, as follows:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://DNS Server]<br>disabled = 0<br>[WinEventLog://Directory Service]<br>disabled = 0<br>[WinEventLog://File Replication Service]<br>disabled = 0<br></font></code></div>
<p>Note:  Use the log properties' "Full Name:" to index.  For example, to monitor Task Scheduler in Microsoft&gt; Windows &gt; TaskScheduler &gt;Operational, right click on Operational and select properties.  Use the "Full Name" to append to WinEventLog:// stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Microsoft-Windows-TaskScheduler/Operational]<br>disabled = 0<br></font></code></div>
<p>To disable indexing for an event log, add <code><font size="2">disabled = 1</font></code> below its listing in the stanza in <code><font size="2">%SPLUNK_HOME%\etc\system\local\inputs.conf</font></code>.
</p><p>Splunk Enterprise uses the following attributes in inputs.conf to monitor Event Log files:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">start_from</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how it should read events chronologically. 
</li><li> Acceptable values are <code><font size="2">oldest</font></code> (meaning that Splunk should read logs from the oldest to the newest) and <code><font size="2">newest</font></code> (meaning that Splunk should read logs from the newest to the oldest. 
</li><li> If you set the attribute to <code><font size="2">newest</font></code>, Splunk reads logs from the most recent to the oldest, then stops.
</li></ul><p><b>Note:</b> You cannot set this attribute to <code><font size="2">newest</font></code> while also setting the <code><font size="2">current_only</font></code> attribute to <code><font size="2">1</font></code> as this does not make sense. Splunk ignores this combination.
</p>
</td><td valign="top" align="left"> <code><font size="2">oldest</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">current_only</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how it should index events after it starts. 
</li><li> Acceptable values are 1 (where the input only acquires events that arrive after the input starts for the first time, like 'tail -f' on *nix systems) or 0 (where the input first gets all existing events in the log and then continues to monitor incoming events in real time)
</li></ul><p><b>Note:</b> You cannot set this attribute to <code><font size="2">1</font></code> while also setting the <code><font size="2">start_from</font></code> attribute to <code><font size="2">newest</font></code> as this does not make sense. Splunk ignores this combination.
</p>
</td><td valign="top" align="left"> 0
</td></tr><tr><td valign="top" align="left"> <code><font size="2">checkpointInterval</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how frequently, in seconds, that the Windows Event Log input should save a checkpoint. 
</li><li> Checkpoints store the eventID of acquired events. 
</li><li> This allows Splunk to continue monitoring at the correct event after a shutdown or outage.
</li></ul></td><td valign="top" align="left"> 5
</td></tr><tr><td valign="top" align="left"> <code><font size="2">evt_resolve_ad_obj</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how it should interact with Active Directory while indexing Windows Event Log events.
</li><li> Valid values are 1 (which tells Splunk to resolve Active Directory objects like Globally Unique IDentifier (GUID) and Security IDentifier (SID) objects to their canonical names for a specific Windows event log channel) and 0 (which tells Splunk not to attempt any resolution.)
</li><li> When you set this value to 1, you can optionally specify the Domain Controller name and/or DNS name of the domain to bind to, which Splunk will then use to resolve the AD objects.
</li><li> If you do not set this value, Splunk attempts to resolve the AD objects.
</li></ul></td><td valign="top" align="left"> 1
</td></tr><tr><td valign="top" align="left"> <code><font size="2">evt_dc_name</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise which Active Directory domain controller it should bind to in order to resolve AD objects.
</li><li> This name can be the NetBIOS name of the domain controller or the fully-qualified DNS name of the domain controller. 
</li><li> Either name type can, optionally, be preceded by two backslash characters.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">evt_dns_name</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise the fully-qualified DNS name of the domain it should bind to in order to resolve AD objects.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">suppress_text</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk whether or not to include the message text that comes with a security event. 
</li><li> A value of 1 suppresses the message text, and a value of 0 preserves the text.
</li></ul></td><td valign="top" align="left"> 0
</td></tr><tr><td valign="top" align="left"> <code><font size="2">whitelist</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk to index events that match the text string specified. 
</li><li> This attribute is optional.
</li><li> You can specify one of two formats:
<ul><li> One or more Event Log event codes or event IDs.
</li><li> One or more sets of keys and regular expressions. See "Create advanced filters with <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code>" later in this topic for details.
</li></ul></li><li> You cannot mix formats in a single entry.
</li><li> You also cannot mix formats in the same stanza.
</li><li> Splunk Enterprise processes whitelists first, then blacklists.
</li><li> If no whitelist is present, Splunk Enterprise indexes all events.
</li></ul><p>When using the Event Code/ID format:
</p>
<ul><li> For multiple codes/IDs, separate the list with commas.
</li><li> For ranges, use hyphens (for example "0-1000,5000-1000").
</li></ul><p>When using the advanced filtering format:
</p>
<ul><li> For advanced filtering, use '=' between the key and the regular expression that represents your filter (for example "whitelist = EventCode=%^1([8-9])$%"
</li><li> You can have multiple key/regular expression sets in a single advanced filtering entry. Splunk Enterprise logically conjuncts the sets. This means that the entry is valid only if all of the sets in the entry are true.
</li><li> You can specify up to 10 whitelists per stanza by adding a number to the end of the <code><font size="2">whitelist</font></code> attribute, for example <code><font size="2">whitelist1...whitelist9</font></code>.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">blacklist</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk <b>not</b> to index events that match the text string specified. 
</li><li> This attribute is optional.
</li><li> You can specify one of two formats:
<ul><li> One or more Event Log event codes or event IDs.
</li><li> One or more sets of keys and regular expressions. See "Create advanced filters with <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code>" later in this topic for details.
</li></ul></li><li> You cannot mix formats in a single entry.
</li><li> You also cannot mix formats in the same stanza.
</li><li> Splunk Enterprise processes whitelists first, then processes any blacklists.
</li><li> If no blacklist is present, Splunk Enterprise indexes all events.
</li></ul><p>When using the Event Log code/ID format:
</p>
<ul><li> For multiple codes/IDs, separate the list with commas.
</li><li> For ranges, use hyphens (for example "0-1000,5000-1000").
</li></ul><p>When using the advanced filtering format:
</p>
<ul><li> For advanced filtering, use '=' between the key and the regular expression that represents your filter (for example "blacklist = EventCode=%^1([8-9])$%"
</li><li> You can have multiple key/regular expression sets in a single advanced filtering entry. Splunk Enterprise logically conjuncts the sets. This means that the entry is valid only if all of the sets in the entry are true.
</li><li> You can specify up to 10 blacklists per stanza by adding a number to the end of the <code><font size="2">blacklist</font></code> attribute, for example <code><font size="2">blacklist1...blacklist9</font></code>.
</li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">renderXml</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise to render event data as XML supplied by the Windows Event Log subsystem.
</li><li> This attribute is optional.
</li><li> A value of '1' or 'true' tells Splunk Enterprise to render the events as XML.
</li><li> A value of '0' or 'false' tells Splunk Enterprise to render the events as plain text.
</li></ul></td><td valign="top" align="left"> 0 (false)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise the index that this input should send the data to.
</li></ul></td><td valign="top" align="left"> the default index
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise whether or not the input should run. 
</li><li> Valid values are 0 (meaning that the input should run) and 1 (meaning that the input should <b>not</b> run.
</li></ul></td><td valign="top" align="left"> 0
</td></tr></table><h4><font size="3"><b><i> <a name="monitorwindowsdata_use_the_security_event_log_to_monitor_changes_to_files"><span class="mw-headline" id="Use_the_Security_event_log_to_monitor_changes_to_files">Use the Security event log to monitor changes to files</span></a></i></b></font></h4>
<p>You can monitor changes to files on your system by enabling security auditing on a set of files and/or directories and then monitoring the Security event log channel for change events. The event log monitoring input includes three attributes which you can use in <code><font size="2">inputs.conf</font></code>. Here's an example:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>checkpointInterval = 5<br># only index events with these event IDs.<br>whitelist = 0-2000,3001-10000<br># exclude these event IDs from being indexed.<br>blacklist = 2001-3000<br></font></code></div>
<p>To enable security auditing for a set of files or directories, read "Auditing Security Events How To" (http://technet.microsoft.com/en-us/library/cc727935%28v=ws.10%29.aspx) on MS Technet.
</p><p>You can also use the <code><font size="2">suppress_text</font></code> attribute to include or exclude the message text that comes with a security event:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>checkpointInterval = 5<br># suppress message text, we only want the event number.<br>suppress_text = 1<br># only index events with these event IDs.<br>whitelist = 0-2000,2001-10000<br># exclude these event IDs from being indexed.<br>blacklist = 2001-3000<br></font></code></div>
<p>By default, <code><font size="2">suppress_text</font></code> defaults to 0 (false).
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_create_advanced_filters_with_.27whitelist.27_and_.27blacklist.27"><span class="mw-headline" id="Create_advanced_filters_with_.27whitelist.27_and_.27blacklist.27">Create advanced filters with 'whitelist' and 'blacklist'</span></a></i></b></font></h4>
<p>You can perform advanced filtering of incoming events with the <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code> attributes in addition to filtering based solely on event codes. To do this, specify the key/regular expression format in the attribute:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = key=&lt;regular expression&gt; [key=&lt;regular expression] ...<br></font></code></div>
<p>In this format, <code><font size="2">key</font></code> is a valid entry from the following list:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Key
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="top" align="left"> $TimeGenerated
</td><td valign="top" align="left"> The time that the computer generated the event. Splunk Enterprise only generates the time string as the event.
</td></tr><tr><td valign="top" align="left"> $Timestamp
</td><td valign="top" align="left"> The time that the event was received and recorded by the Event Log service. Splunk Enterprise only generates the time string as the event.
</td></tr><tr><td valign="top" align="left"> Category
</td><td valign="top" align="left"> The category number for a specific event source.
</td></tr><tr><td valign="top" align="left"> CategoryString
</td><td valign="top" align="left"> A string translation of the category. The translation depends on the event source.
</td></tr><tr><td valign="top" align="left"> ComputerName
</td><td valign="top" align="left"> The name of the computer that generated the event.
</td></tr><tr><td valign="top" align="left"> EventCode
</td><td valign="top" align="left"> The event ID number for an event. Corresponds to "Event ID" in Event Viewer.
</td></tr><tr><td valign="top" align="left"> EventType
</td><td valign="top" align="left"> A numeric value that represents one of the the five types of events that can be logged ("Error", "Warning", "Information", "Success Audit", and "Failure Audit".) Available only on server machines running Windows Server 2003 and earlier or clients running Windows XP and earlier. See "Win32_NTLogEvent class (Windows)" (http://msdn.microsoft.com/en-us/library/aa394226(v=vs.85).aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> Keywords
</td><td valign="top" align="left"> An element used to classify different types of events within an event log channel. The Security Event Log channel has this element, for example.
</td></tr><tr><td valign="top" align="left"> LogName
</td><td valign="top" align="left"> The name of the Event Log channel that received the event. Corresponds to "Log Name" in Event Viewer.
</td></tr><tr><td valign="top" align="left"> Message
</td><td valign="top" align="left"> The text of the message in the event.
</td></tr><tr><td valign="top" align="left"> OpCode
</td><td valign="center" align="left"> The severity level of the event ("OpCode" in Event Viewer.)
</td></tr><tr><td valign="top" align="left"> RecordNumber
</td><td valign="top" align="left"> The Windows Event Log record number. Each event on a Windows server gets a record number. This number starts at 0 with the first event generated on the system, and increases with each new event generated, until it reached a maximum of 4294967295. It then rolls back over to 0.
</td></tr><tr><td valign="top" align="left"> Sid
</td><td valign="top" align="left"> The Security Identifier (SID) of the principal (such as a user, group, computer, or other entity) that was associated with or generated the event.  See "Win32_UserAccount class (http://msdn.microsoft.com/en-us/library/windows/desktop/aa394507%28v=vs.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> SidType
</td><td valign="top" align="left"> A numeric value that represents the type of SID that was associated with the event. See "Win32_UserAccount class" (http://msdn.microsoft.com/en-us/library/windows/desktop/aa394507%28v=vs.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> SourceName
</td><td valign="top" align="left"> The source of the entity that generated the event ("Source" in Event Viewer)
</td></tr><tr><td valign="top" align="left"> TaskCategory
</td><td valign="top" align="left"> The task category of the event. Event sources allow you to define categories so that you can filter them with Event Viewer (using the "Task Category" field. See Event Categories (Windows) (http://msdn.microsoft.com/en-us/library/aa363649%28VS.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> Type
</td><td valign="top" align="left"> A numeric value that represents one of the the five types of events that can be logged ("Error", "Warning", "Information", "Success Audit", and "Failure Audit".) Only available on server machines that run Windows Server 2008 or later, or clients that run Windows Vista or later. See "Win32_NTLogEvent class (Windows)" (http://msdn.microsoft.com/en-us/library/aa394226(v=vs.85).aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> User
</td><td valign="top" align="left"> The user associated with the event. Correlates to "User" in Event Viewer.
</td></tr></table><p>and <code><font size="2">&lt;regular expression&gt;</font></code> is any valid regular expression that represents the filters that you want to include (when used with the <code><font size="2">whitelist</font></code> attribute) or exclude (when used with the <code><font size="2">blacklist</font></code> attribute).
</p><p>To learn more about regular expressions and how to use them, visit the Regularexpressions.info (http://www.regular-expressions.info) website.
</p><p>You can specify more than one key/regular expression set on a single entry line. When you do this, Splunk Enterprise logically conjuncts the sets. This means that only events which satisfy all of the sets on the line will be valid for inclusion or exclusion. For example, this entry:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$" Message="^Error"<br></font></code></div>
<p>tells Splunk Enterprise to include events that have an <code><font size="2">EventCode</font></code> ranging from 10 to 15 and contain a <code><font size="2">Message</font></code> that begins with the word <code><font size="2">Error</font></code>.
</p><p>You can specify up to 10 separate whitelist or blacklist entries in each stanza. To do so, add a number at the end of the <code><font size="2">whitelist</font></code> or <code><font size="2">blacklist</font></code> entry on a separate line:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = key=&lt;regular expression&gt;<br>whitelist1 = key=&lt;regular expression&gt; key2=&lt;regular expression 2&gt;<br>whitelist2 = key=&lt;regular expression&gt;<br></font></code></div>
<p><b>Note:</b> You cannot specify an entry that has more than one key/regular expression set that references the same key. If, for example, you specify:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$" EventCode="^2([0-5])$"<br></font></code></div>
<p>Splunk Enterprise ignores the first set and only attempts to include events that match the second set. In this case, only events that contain an <code><font size="2">EventCode</font></code> between 20 and 25 match. Events that contain an <code><font size="2">EventCode</font></code> between 10 and 15 do not match. Only the last set in the entry ever matches.
</p><p>To resolve this problem, specify two separate entries in the stanza:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$"<br>whitelist1 = EventCode="^2([0-5])$"<br></font></code></div>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_resolve_active_directory_objects_in_event_log_files"><span class="mw-headline" id="Resolve_Active_Directory_objects_in_event_log_files">Resolve Active Directory objects in event log files</span></a></i></b></font></h4>
<p>If you want to specify whether or not Active Directory objects like globally unique identifiers (GUIDs) and security identifiers (SIDs) are resolved for a given Windows event log channel, you can use the <code><font size="2">evt_resolve_ad_obj</font></code> attribute (1=enabled, 0=disabled) for that channel's stanza in your local copy of <code><font size="2">inputs.conf</font></code>. <b>The <code><font size="2">evt_resolve_ad_obj</font></code> attribute is on by default for the Security channel.</b>
</p><p>For example:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>checkpointInterval = 5<br></font></code></div>
<p>To specify a domain controller for the domain that Splunk should bind to in order to resolve AD objects, use the <code><font size="2">evt_dc_name</font></code> attribute. 
</p><p>The string specified in the <code><font size="2">evt_dc_name</font></code> attribute can represent either the domain controller's NetBIOS name, or its fully-qualified domain name (FQDN). Either name type can, optionally, be preceded by two backslash characters.
</p><p>The following examples are correctly formatted domain controller names:
</p>
<ul><li> <code><font size="2">FTW-DC-01</font></code>
</li><li> <code><font size="2">\\FTW-DC-01</font></code>
</li><li> <code><font size="2">FTW-DC-01.splunk.com</font></code>
</li><li> <code><font size="2">\\FTW-DC-01.splunk.com</font></code>
</li></ul><p>To specify the FQDN of the domain to bind to, use the <code><font size="2">evt_dns_name</font></code> attribute.
</p><p>For example:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>evt_dc_name = ftw-dc-01.splunk.com<br>evt_dns_name = splunk.com<br>checkpointInterval = 5<br></font></code></div>
<h5> <a name="monitorwindowsdata_constraints"><span class="mw-headline" id="Constraints">Constraints</span></a></h5>
<p>There are some things you must understand when using the <code><font size="2">evt_dc_resolve_obj</font></code> attribute:
</p>
<ul><li> When you specify this attribute, Splunk first attempts to resolve SIDs and GUIDs using the domain controller (DC) specified in the <code><font size="2">evt_dc_name</font></code> attribute first. If it cannot resolve SIDs using this DC, it attempts to bind to the default DC to perform the translation.
</li><li> If Splunk cannot contact a DC to translate SIDs, it then attempts to use the local machine for translation.
</li><li> If none of these methods works, then Splunk prints the SID as it was captured in the event.
</li><li> Splunk cannot translate SIDs that are not in the format <code><font size="2">S-1-N-NN-NNNNNNNNNN-NNNNNNNNNN-NNNNNNNNNN-NNNN</font></code>.
</li><li> If you discover that Splunk is not translating SIDs properly, review <code><font size="2">splunkd.log</font></code> for clues on what the problem might be.
</li></ul><h4><font size="3"><b><i> <a name="monitorwindowsdata_specify_whether_to_index_starting_at_earliest_or_most_recent_event"><span class="mw-headline" id="Specify_whether_to_index_starting_at_earliest_or_most_recent_event">Specify whether to index starting at earliest or most recent event</span></a></i></b></font></h4>
<p>Use the <code><font size="2">start_from</font></code> attribute to specify whether Splunk Enterprise indexes events starting at the earliest event or the most recent.  By default, Splunk starts with the oldest data and indexes forward. You can change this by setting this attribute to <code><font size="2">newest</font></code>, telling Splunk to start with the newest data, and index backward. We don't recommend changing this setting, as Splunk stops indexing after it has indexed the backlog using this method.
</p><p>Use the <code><font size="2">current_only</font></code> attribute to specify whether or not you want Splunk to index all preexisting events in a given log channel. When set to 1, Splunk indexes only new events that appear from the moment Splunk was started. When set to 0, Splunk indexes all events.
</p><p>For example: 
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://Application]<br>disabled = 0<br>start_from = oldest<br>current_only = 1<br></font></code></div>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_display_events_in_xml"><span class="mw-headline" id="Display_events_in_XML">Display events in XML</span></a></i></b></font></h4>
<p>To have Splunk Enterprise generate events in XML, use the <code><font size="2">renderXml</font></code> attribute:
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog://System]<br>&nbsp;disabled = 0<br>&nbsp;renderXml = 1<br>&nbsp;evt_resolve_ad_obj = 1<br>&nbsp;evt_dns_name = \"SV5DC02\"<br></font></code></div>
<p>This input stanza generates events like the following:
</p>
<div class="samplecode"><code><font size="2"> <br>&nbsp;&lt;Event xmlns='http://schemas.microsoft.com/win/2004/08/events/event'&gt;<br>&nbsp;&nbsp;&nbsp;&lt;System&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Provider Name='Service Control Manager' Guid='{555908d1-a6d7-4695-8e1e-26931d2012f4}' EventSourceName='Service Control Manager'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;EventID Qualifiers='16384'&gt;7036&lt;/EventID&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Version&gt;0&lt;/Version&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Level&gt;4&lt;/Level&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Task&gt;0&lt;/Task&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Opcode&gt;0&lt;/Opcode&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Keywords&gt;0x8080000000000000&lt;/Keywords&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;TimeCreated SystemTime='2014-04-24T18:38:37.868683300Z'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;EventRecordID&gt;412598&lt;/EventRecordID&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Correlation/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Execution ProcessID='192' ThreadID='210980'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Channel&gt;System&lt;/Channel&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Computer&gt;SplunkDoc.splunk-docs.local&lt;/Computer&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Security/&gt;<br>&nbsp;&nbsp;&nbsp;&lt;/System&gt;<br>&nbsp;&nbsp;&nbsp;&lt;EventData&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='param1'&gt;Application Experience&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='param2'&gt;stopped&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Binary&gt;410065004C006F006F006B00750070005300760063002F0031000000&lt;/Binary&gt;<br>&nbsp;&nbsp;&nbsp;&lt;/EventData&gt;<br>&nbsp;&lt;/Event&gt;<br></font></code></div>
<p><b>Note:</b> When you instruct Splunk Enterprise to render events in XML, event keys within the XML event render in English regardless of the machine's system locale. Compare the following events generated on a French version of Windows Server:
</p><p><b>Standard event:</b>
</p>
<div class="samplecode"><code><font size="2"><br>04/29/2014 02:50:23 PM<br>LogName=Security<br>SourceName=Microsoft Windows security auditing.<br>EventCode=4672<br>EventType=0<br>Type=Information<br>ComputerName=sacreblue<br>TaskCategory=Ouverture de session sp&Atilde;&copy;ciale<br>OpCode=Informations<br>RecordNumber=2746<br>Keywords=Succ&Atilde;&uml;s de l&acirc;&#128;&#153;audit<br>Message=Privil&Atilde;&uml;ges sp&Atilde;&copy;ciaux attribu&Atilde;&copy;s &Atilde;&nbsp; la nouvelle ouverture de session.<br>&nbsp;<br>Sujet&nbsp;:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ID de s&Atilde;&copy;curit&Atilde;&copy;&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AUTORITE NT\Syst&Atilde;&uml;me<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nom du compte&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Syst&Atilde;&uml;me<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Domaine du compte&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AUTORITE NT<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ID d&acirc;&#128;&#153;ouverture de session&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0x3e7<br>&nbsp;<br>Privil&Atilde;&uml;ges&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeAssignPrimaryTokenPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeTcbPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeSecurityPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeTakeOwnershipPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeLoadDriverPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeBackupPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeRestorePrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeDebugPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeAuditPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeSystemEnvironmentPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeImpersonatePrivilege<br></font></code></div>
<p><b>XML event:</b>
</p>
<div class="samplecode"><code><font size="2"><br>&lt;Event xmlns='http://schemas.microsoft.com/win/2004/08/events/event'&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;System&gt;&lt;Provider Name='Microsoft-Windows-Security-Auditing' Guid='{54849625-5478-4994-A5BA-3E3B0328C30D}'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;EventID&gt;4672&lt;/EventID&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Version&gt;0&lt;/Version&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Level&gt;0&lt;/Level&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Task&gt;12548&lt;/Task&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Opcode&gt;0&lt;/Opcode&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Keywords&gt;0x8020000000000000&lt;/Keywords&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;TimeCreated SystemTime='2014-04-29T22:15:03.280843700Z'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;EventRecordID&gt;2756&lt;/EventRecordID&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Correlation/&gt;&lt;Execution ProcessID='540' ThreadID='372'/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Channel&gt;Security&lt;/Channel&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Computer&gt;sacreblue&lt;/Computer&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Security/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/System&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;EventData&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='SubjectUserSid'&gt;AUTORITE NT\Syst&Atilde;&uml;me&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='SubjectUserName'&gt;Syst&Atilde;&uml;me&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='SubjectDomainName'&gt;AUTORITE NT&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='SubjectLogonId'&gt;0x3e7&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Data Name='PrivilegeList'&gt;SeAssignPrimaryTokenPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeTcbPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeSecurityPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeTakeOwnershipPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeLoadDriverPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeBackupPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeRestorePrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeDebugPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeAuditPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeSystemEnvironmentPrivilege<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SeImpersonatePrivilege&lt;/Data&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/EventData&gt;<br>&lt;/Event&gt;<br></font></code></div>
<p>The <code><font size="2">Data Name</font></code> keys in the XML event render in English despite rendering in the system's native language in the standard event.
</p>
<h3> <a name="monitorwindowsdata_use_the_cli_to_configure_event_log_monitoring"><span class="mw-headline" id="Use_the_CLI_to_configure_event_log_monitoring">Use the CLI to configure event log monitoring</span></a></h3>
<p>You can use the CLI to configure local event log monitoring. Before using the CLI, you must create stanza entries in <code><font size="2">inputs.conf</font></code> first. See "<a href="#monitorwindowsdata_use_inputs.conf_to_configure_event_log_monitoring" class="external text">Use inputs.conf to configure event log monitoring</a>."
</p><p><b>Note:</b> The CLI is not available for remote Event Log collections. 
</p><p>To list all configured Event Log channels on the local machine:
</p>
<div class="samplecode"><code><font size="2"><br>&gt; splunk list eventlog<br></font></code></div>
<p>You can also list a specific channel by specifying its name:
</p>
<div class="samplecode"><code><font size="2"><br>&gt; splunk list eventlog &lt;ChannelName&gt;<br></font></code></div>
<p>To enable an Event Log channel:
</p>
<div class="samplecode"><code><font size="2"><br>&gt; splunk enable eventlog &lt;ChannelName&gt;<br></font></code></div>
<p>To disable a channel:
</p>
<div class="samplecode"><code><font size="2"><br>&gt; splunk disable eventlog &lt;ChannelName&gt;<br></font></code></div>
<h3> <a name="monitorwindowsdata_index_exported_event_log_.28.evt_or_.evtx.29_files"><span class="mw-headline" id="Index_exported_event_log_.28.evt_or_.evtx.29_files">Index exported event log (.evt or .evtx) files </span></a></h3>
<p>To index exported Windows event log files, use the <a href="#monitorfilesanddirectories" class="external text">instructions for monitoring files and directories</a> to monitor the directory that contains the exported files. 
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsdata_constraints_2"><span class="mw-headline" id="Constraints_2">Constraints</span></a></i></b></font></h4>
<ul><li> As a result of API and log channel processing constraints on Windows XP and Server 2003 systems, imported .evt files from those systems do not contain the "Message" field. This means that the contents of the "Message" field do not appear in your Splunk index.
</li><li> Splunk running on Windows XP and Windows Server 2003/2003 R2 cannot index .evtx files exported from systems running Windows Vista and later or Windows Server 2008/2008 R2 and later.
</li><li> Splunk running on Windows Vista and later and Server 2008/2008 R2 and later can index both .evt and .evtx files.
</li><li> If your .evt or .evtx file is not from a standard event log channel, you must make sure that any dynamic link library (DLL) files required by that channel are present on the computer on which you are indexing. 
</li><li> Splunk indexes an .evt or .evtx file in the primary locale/language of the computer that collects the file. 
</li></ul><p><b>Caution:</b> Do not attempt to monitor a .evt or .evtx file that is currently being written to; Windows does not allow read access to these files. Use the event log monitoring feature instead.
</p><p><b>Note:</b> When producing .evt or .evtx files on one system, and monitoring them on another, it's possible that not all of the fields in each event expand as they would on the system producing the events. This is caused by variations in DLL versions, availability and APIs. Differences in OS version, language, Service Pack level and installed third party DLLs, etc. can also have this effect.
</p>
<h3> <a name="monitorwindowsdata_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around Windows event logs.
</p>
<a name="monitorfilesystemchangesonwindows"></a><h2> <a name="monitorfilesystemchangesonwindows_monitor_file_system_changes_on_windows"><span class="mw-headline" id="Monitor_file_system_changes_on_Windows"> Monitor file system changes on Windows</span></a></h2>
<p>Splunk Enterprise supports the monitoring of Windows file system changes through the Security Event Log channel. To enable monitoring of changes to files and directories, you first enable security auditing for the file(s) and folders you want to monitor for changes, then use the event log monitor to monitor the Security event log channel.
</p><p>This procedure of monitoring file system changes replaces the deprecated file system change monitor input.
</p>
<h3> <a name="monitorfilesystemchangesonwindows_what_do_you_need_to_monitor_file_system_changes.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_file_system_changes.3F"> What do you need to monitor file system changes?</span></a></h3>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor file system changes
</td><td valign="top" align="left">
<ul><li> Splunk Enterprise must run on Windows AND
</li><li> Splunk Enterprise must run as the Local System user OR as a domain user with specific security policy rights to read the Security event log AND
</li><li> You must enable security auditing for the file(s) or director(ies) you want Splunk Enterprise to monitor changes to 
</li></ul></td></tr></table><h3> <a name="monitorfilesystemchangesonwindows_use_the_security_event_log_to_monitor_changes_to_files"><span class="mw-headline" id="Use_the_Security_event_log_to_monitor_changes_to_files">Use the Security event log to monitor changes to files</span></a></h3>
<p>You can monitor changes to files on your system by enabling security auditing on a set of files and/or directories and then monitoring the Security event log channel for change events. The event log monitoring input includes three attributes which you can use in <code><font size="2">inputs.conf</font></code>: 
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">whitelist</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise to index events that match the text string specified. 
</li><li> This attribute is optional.
</li><li> You can specify one of two formats:
<ul><li> One or more Event Log event codes or event IDs.
</li><li> One or more sets of keys and regular expressions. See "Create advanced filters with <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code>" later in this topic for details.
</li></ul></li><li> You cannot mix formats in a single entry.
</li><li> You also cannot mix formats in the same stanza.
</li><li> Splunk Enterprise processes whitelists first, then blacklists.
</li><li> If no whitelist is present, Splunk Enterprise indexes all events.
</li></ul><p>When using the Event Code/ID format:
</p>
<ul><li> For multiple codes/IDs, separate the list with commas.
</li><li> For ranges, use hyphens (for example "0-1000,5000-1000").
</li></ul><p>When using the advanced filtering format:
</p>
<ul><li> For advanced filtering, use '=' between the key and the regular expression that represents your filter (for example "whitelist = EventCode=%^1([8-9])$%"
</li><li> You can have multiple key/regular expression sets in a single advanced filtering entry. Splunk Enterprise logically conjuncts the sets. This means that the entry is valid only if all of the sets in the entry are true.
</li><li> You can specify up to 10 whitelists per stanza by adding a number to the end of the <code><font size="2">whitelist</font></code> attribute, for example <code><font size="2">whitelist1...whitelist9</font></code>.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">blacklist</font></code>
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise <b>not</b> to index events that match the text string specified. 
</li><li> This attribute is optional.
</li><li> You can specify one of two formats:
<ul><li> One or more Event Log event codes or event IDs.
</li><li> One or more sets of keys and regular expressions. See "Create advanced filters with <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code>" later in this topic for details.
</li></ul></li><li> You cannot mix formats in a single entry.
</li><li> You also cannot mix formats in the same stanza.
</li><li> Splunk Enterprise processes whitelists first, then processes any blacklists.
</li><li> If no blacklist is present, Splunk Enterprise indexes all events.
</li></ul><p>When using the Event Log code/ID format:
</p>
<ul><li> For multiple codes/IDs, separate the list with commas.
</li><li> For ranges, use hyphens (for example "0-1000,5000-1000").
</li></ul><p>When using the advanced filtering format:
</p>
<ul><li> For advanced filtering, use '=' between the key and the regular expression that represents your filter (for example "blacklist = EventCode=%^1([8-9])$%"
</li><li> You can have multiple key/regular expression sets in a single advanced filtering entry. Splunk Enterprise logically conjuncts the sets. This means that the entry is valid only if all of the sets in the entry are true.
</li><li> You can specify up to 10 blacklists per stanza by adding a number to the end of the <code><font size="2">blacklist</font></code> attribute, for example <code><font size="2">blacklist1...blacklist9</font></code>.
</li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">suppress_text</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise whether or not to include the message text that comes with a security event. A value of 1 suppresses the message text, and a value of 0 preserves the text.
</td><td valign="top" align="left"> 0
</td></tr></table><p><b>Note:</b> You can use these attributes outside of the context of the Security event log and file system changes. Also, this list of attributes is only a subset of the available attributes for inputs.conf. For additional attributes, read "<b><a href="#monitorwindowsdata" class="external text">Monitor Windows event log data</a></b>" in this manual.
</p>
<h4><font size="3"><b><i> <a name="monitorfilesystemchangesonwindows_create_advanced_filters_with_whitelist_and_blacklist"><span class="mw-headline" id="Create_advanced_filters_with_whitelist_and_blacklist">Create advanced filters with <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code></span></a></i></b></font></h4>
<p>You can perform advanced filtering of incoming events with the <code><font size="2">whitelist</font></code> and <code><font size="2">blacklist</font></code> attributes in addition to filtering based solely on event codes. To do this, specify the key/regular expression format in the attribute:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = key=&lt;regular expression&gt; [key=&lt;regular expression] ...<br></font></code></div>
<p>In this format, <code><font size="2">key</font></code> is a valid entry from the following list:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Key
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="top" align="left"> $TimeGenerated
</td><td valign="top" align="left"> The time that the computer generated the event. Splunk Enterprise only generates the time string as the event.
</td></tr><tr><td valign="top" align="left"> $Timestamp
</td><td valign="top" align="left"> The time that the event was received and recorded by the Event Log service. Splunk Enterprise only generates the time string as the event.
</td></tr><tr><td valign="top" align="left"> Category
</td><td valign="top" align="left"> The category number for a specific event source.
</td></tr><tr><td valign="top" align="left"> CategoryString
</td><td valign="top" align="left"> A string translation of the category. The translation depends on the event source.
</td></tr><tr><td valign="top" align="left"> ComputerName
</td><td valign="top" align="left"> The name of the computer that generated the event.
</td></tr><tr><td valign="top" align="left"> EventCode
</td><td valign="top" align="left"> The event ID number for an event. Corresponds to "Event ID" in Event Viewer.
</td></tr><tr><td valign="top" align="left"> EventType
</td><td valign="top" align="left"> A numeric value that represents one of the the five types of events that can be logged ("Error", "Warning", "Information", "Success Audit", and "Failure Audit".) Available only on server machines running Windows Server 2003 and earlier or clients running Windows XP and earlier. See "Win32_NTLogEvent class (Windows)" (http://msdn.microsoft.com/en-us/library/aa394226(v=vs.85).aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> Keywords
</td><td valign="top" align="left"> An element used to classify different types of events within an event log channel. The Security Event Log channel has this element, for example.
</td></tr><tr><td valign="top" align="left"> LogName
</td><td valign="top" align="left"> The name of the Event Log channel that received the event. Corresponds to "Log Name" in Event Viewer.
</td></tr><tr><td valign="top" align="left"> Message
</td><td valign="top" align="left"> The text of the message in the event.
</td></tr><tr><td valign="top" align="left"> OpCode
</td><td valign="center" align="left"> The severity level of the event ("OpCode" in Event Viewer.)
</td></tr><tr><td valign="top" align="left"> RecordNumber
</td><td valign="top" align="left"> The Windows Event Log record number. Each event on a Windows server gets a record number. This number starts at 0 with the first event generated on the system, and increases with each new event generated, until it reached a maximum of 4294967295. It then rolls back over to 0.
</td></tr><tr><td valign="top" align="left"> Sid
</td><td valign="top" align="left"> The Security Identifier (SID) of the principal (such as a user, group, computer, or other entity) that was associated with or generated the event.  See "Win32_UserAccount class (http://msdn.microsoft.com/en-us/library/windows/desktop/aa394507%28v=vs.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> SidType
</td><td valign="top" align="left"> A numeric value that represents the type of SID that was associated with the event. See "Win32_UserAccount class" (http://msdn.microsoft.com/en-us/library/windows/desktop/aa394507%28v=vs.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> SourceName
</td><td valign="top" align="left"> The source of the entity that generated the event ("Source" in Event Viewer)
</td></tr><tr><td valign="top" align="left"> TaskCategory
</td><td valign="top" align="left"> The task category of the event. Event sources allow you to define categories so that you can filter them with Event Viewer (using the "Task Category" field. See Event Categories (Windows) (http://msdn.microsoft.com/en-us/library/aa363649%28VS.85%29.aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> Type
</td><td valign="top" align="left"> A numeric value that represents one of the the five types of events that can be logged ("Error", "Warning", "Information", "Success Audit", and "Failure Audit".) Only available on server machines that run Windows Server 2008 or later, or clients that run Windows Vista or later. See "Win32_NTLogEvent class (Windows)" (http://msdn.microsoft.com/en-us/library/aa394226(v=vs.85).aspx) on MSDN.
</td></tr><tr><td valign="top" align="left"> User
</td><td valign="top" align="left"> The user associated with the event. Correlates to "User" in Event Viewer.
</td></tr></table><p>and <code><font size="2">&lt;regular expression&gt;</font></code> is any valid regular expression that represents the filters that you want to include (when used with the <code><font size="2">whitelist</font></code> attribute) or exclude (when used with the <code><font size="2">blacklist</font></code> attribute).
</p><p>To learn more about regular expressions and how to use them, visit the Regularexpressions.info (http://www.regular-expressions.info) website.
</p><p>You can specify more than one regular expression on a single entry line. When you do this, Splunk Enterprise logically conjuncts the expressions. This means that only events which satisfy all of the entries on the line will be valid for inclusion or exclusion. For example, this entry:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$" Message="^Error"<br></font></code></div>
<p>tells Splunk Enterprise to include events that have an <code><font size="2">EventCode</font></code> ranging from 10 to 15 and contain a <code><font size="2">Message</font></code> that begins with the word <code><font size="2">Error</font></code>.
</p><p>You can specify up to 10 separate whitelist or blacklist entries in each stanza. To do so, add a number at the end of the <code><font size="2">whitelist</font></code> or <code><font size="2">blacklist</font></code> entry on a separate line:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = key=&lt;regular expression&gt;<br>whitelist1 = key=&lt;regular expression&gt; key2=&lt;regular expression 2&gt;<br>whitelist2 = key=&lt;regular expression&gt;<br></font></code></div>
<p><b>Note:</b> You cannot specify an entry that has more than one expression that references the same key. If, for example, you specify:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$" EventCode="^2([0-5])$"<br></font></code></div>
<p>Splunk Enterprise ignores the first expression and only attempts to include events that match the second expression. In this case, only events that contain an <code><font size="2">EventCode</font></code> between 20 and 25 match. Events that contain an <code><font size="2">EventCode</font></code> between 10 and 15 do not match. Only the last expression in the entry ever matches.
</p><p>To resolve this problem, specify two separate entries in the stanza:
</p>
<div class="samplecode"><code><font size="2"><br>whitelist = EventCode="^1([0-5])$"<br>whitelist1 = EventCode="^2([0-5])$"<br></font></code></div>
<h3> <a name="monitorfilesystemchangesonwindows_monitor_file_system_changes"><span class="mw-headline" id="Monitor_file_system_changes">Monitor file system changes</span></a></h3>
<p>To monitor file system changes for a set of files or directories:
</p><p><b>1.</b> Follow the instructions at "Auditing Security Events How To" (http://technet.microsoft.com/en-us/library/cc727935%28v=ws.10%29.aspx) on MS Technet to enable security auditing.
</p><p><b>Important:</b> You must have administrator privileges to perform this task.
</p><p><b>2.</b> Configure the Splunk Enterprise event log monitor input to monitor the Security event log channel.
</p><p><b>Note:</b> For specific instructions on how to configure the Event Long monitor input, read "<b><a href="#monitorwindowsdata" class="external text">Monitor Windows event log data</a></b>" in this manual.
</p>
<h3> <a name="monitorfilesystemchangesonwindows_examples"><span class="mw-headline" id="Examples">Examples</span></a></h3>
<p>Following are <code><font size="2">inputs.conf</font></code> stanzas which show examples of how to monitor file system changes.
</p><p>This stanza collects security events with event ID codes 0 to 2000 and 3001-10000.
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog:Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>checkpointInterval = 5<br># only index events with these event IDs.<br>whitelist = 0-2000,2001-10000<br># exclude these event IDs from being indexed.<br>blacklist = 2001-3000<br></font></code></div>
<p>This stanza collects security events with event ID codes 0 to 2000 and 3001-10000. It also suppresses the message text that comes in the event ID.
</p>
<div class="samplecode"><code><font size="2"><br>[WinEventLog:Security]<br>disabled = 0<br>start_from = oldest<br>current_only = 0<br>evt_resolve_ad_obj = 1<br>checkpointInterval = 5<br># suppress message text, we only want the event number.<br>suppress_text = 1<br># only index events with these event IDs.<br>whitelist = 0-2000,2001-10000<br># exclude these event IDs from being indexed.<br>blacklist = 2001-3000<br></font></code></div>

<a name="monitorwmidata"></a><h2> <a name="monitorwmidata_monitor_wmi-based_data"><span class="mw-headline" id="Monitor_WMI-based_data"> Monitor WMI-based data</span></a></h2>
<p>Splunk Enterprise supports the use of Windows Management Instrumentation (WMI) providers for agentless access to Windows performance and event log data on remote machines. This means you can pull event logs from all the Windows machines in your environment without having to install anything on those machines. 
</p><p><b>Important:</b> If possible, use a universal forwarder rather than WMI to collect data from remote machines. The resource load of WMI can exceed that of a Splunk universal forwarder in many cases. In particular, use a forwarder if you collect multiple event logs or performance counters from each host, or from very busy hosts like domain controllers. See "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" in this manual.
</p><p>WMI-based data inputs can connect to multiple WMI providers. The nput runs as a separate process called <code><font size="2">splunk-wmi.exe</font></code>. It is a <b>scripted input</b>.
</p>
<h3> <a name="monitorwmidata_what_do_you_need_to_monitor_wmi-based_data.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_WMI-based_data.3F">What do you need to monitor WMI-based data?</span></a></h3>
<p>Here are the basic minimum requirements to monitor WMI-based data. You might need additional permissions based on the logs or performance counters you want to monitor.
</p><p>For additional details on what's required to monitor WMI-based data, see "Security and remote access considerations" later in this topic.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor remote event logs over WMI
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as a domain user with at least read access to WMI<br>* Splunk Enterprise must run as a domain user with appropriate access to the desired event logs
</td></tr><tr><td valign="top" align="left"> Monitor remote performance monitor counters over WMI
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as a domain user with at least read access to WMI<br>* Splunk Enterprise must run as a domain user with appropriate access to the Performance Data Helper libraries
</td></tr></table><h3> <a name="monitorwmidata_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enterprise and your Windows network must be correctly configured for WMI data access. Review the following prerequisites before attempting to use Splunk Enterprise to get WMI data.
</p><p>Before Splunk Enterprise can get WMI-based data:
</p>
<ul><li> It must be installed with a user that has permissions to perform remote network connections.
</li><li> The user Splunk Enterprise runs as must be a member of an Active Directory (AD) domain or forest and must have appropriate privileges to query WMI providers.
</li><li> The Splunk user must also be a member of the local Administrators group on the computer that runs Splunk Enterprise. 
</li><li> The computer that runs Splunk Enterprise must be able to connect to the remote machine and must have permissions to get the desired data from the remote machine once it has connected.
</li><li> Both the Splunk Enterprise instance and the target machines must be part of the same AD domain or forest.
</li></ul><p>The Splunk user does not need to be a member of the Domain Admins group (and for security reasons, should not be). However, you must have domain administrator privileges in order to configure access for the Splunk user. If you don't have domain administrator access, find someone who can either configure Splunk user access or give domain administrator rights to you.
</p><p><b>Note:</b> If you install Splunk Enterprise as the Local System user, remote authentication over WMI does not work. The Local System user has no access to other machines on the network. It is not possible to grant privileges to a machine's Local System account for access to another machine.
</p><p>You can give the Splunk user access to WMI providers by doing one of the following:
</p>
<ul><li> Adding it to the local Administrators group on each member server you want to poll (not recommended for security reasons).
</li><li> Adding it to the Domain Admins global group (not recommended for security reasons).
</li><li> Assigning least-permissive rights as detailed below (recommended).
</li></ul><h4><font size="3"><b><i> <a name="monitorwmidata_important_notice_regarding_group_memberships_and_resource_access_control_lists_.28acls.29"><span class="mw-headline" id="Important_notice_regarding_group_memberships_and_resource_access_control_lists_.28ACLs.29"> Important notice regarding group memberships and resource access control lists (ACLs) </span></a></i></b></font></h4>
<p>To maintain security integrity, place Splunk users into a domain global group and assign permissions on Windows machines and resource ACLs to that group, instead of assigning permissions directly to the user. Assigning permissions directly to users is a security risk, and can cause problems during security audits or future changes.
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_configure_wmi_for_least_permissive_access"><span class="mw-headline" id="Configure_WMI_for_least_permissive_access"> Configure WMI for least permissive access </span></a></i></b></font></h4>
<p>If the user you've configured Splunk Enterprise to run as is not a domain administrator, you must configure WMI to provide access to this user. Grant only least-permissive access to all Windows resources, including WMI. In order to grant this type of access, follow this checklist. For additional information and step-by-step instructions, see "Prepare your Windows network for a Splunk Enterprise installation" in the Installation manual.
</p><p>You must grant to the user Splunk Enterprise runs as several levels of access in order for Splunk Enterprise to collect data over WMI using the least-permissive method:
</p><p><b>1. Local Security Policy Permissions.</b>  The Splunk user needs the following Local Security Policy user rights assignments defined on each machine you poll for WMI-based data:
</p>
<ul><li> <b>Access this Computer from the Network</b>
</li><li> <b>Act as part of the operating system</b>
</li><li> <b>Log on as a batch job</b>
</li><li> <b>Log on as a service</b>
</li><li> <b>Profile System Performance</b> 
</li><li> <b>Replace a process level token</b>
</li></ul><p><b>Note:</b> To deploy these user rights assignments domain-wide, use the <b>Domain Security Policy</b> (<code><font size="2">dompol.msc</font></code>) Microsoft Management Console (MMC) snap-in. Once deployed, those rights assignments will be inherited by any member servers on the network during the next AD replication cycle. You must restart Splunk Enterprise instances on those machines for the changes to take effect. 
</p><p>To extend this access to domain controllers specifically, assign the rights using the <b>Domain Controller Security Policy</b> (<code><font size="2">dcpol.msc</font></code>) snap-in.
</p><p><b>2. Distributed Component Object Model (DCOM) configuration and permissions.</b> DCOM must be enabled on every machine you want to monitor. In addition, the Splunk Enterprise user must be assigned permissions to access DCOM. There are many methods available to do this, but the best is to nest the "Distributed COM Users" domain global group into the "Distributed COM Users" local group on each machine you want to monitor, then add the Splunk Enterprise user to the "Distributed COM Users" domain global group. See "Securing a Remote WMI Connection" (http://msdn.microsoft.com/en-us/library/aa393266(VS.85).aspx) on MSDN for advanced options to give the Splunk Enterprise user access to DCOM.
</p><p><b>3. Performance Monitor configuration and permissions.</b> The Splunk Enterprise user must be a member of the "Performance Log Users" local group in order for Splunk Enterprise to access remote performance objects over WMI.  The best way to do this is to nest the "Performance Log Users" domain global group into the "Performance Log Users" local group on each member server and then assign the user to the global group.
</p><p><b>4. WMI namespace security.</b> The WMI namespace that Splunk Enterprise accesses (most commonly <code><font size="2">Root\CIMV2</font></code>) must have the proper permissions set. These permissions must be set on each server in your enterprise, as there is no global WMI security. Use the WMI Security MMC snap-in (<code><font size="2">wmimgmt.msc</font></code>) to enable the following permissions on the WMI tree for each host at the <b>Root</b> namespace for the Splunk user: 
</p>
<ul><li> <b>Execute Methods</b>
</li><li> <b>Enable Account</b>
</li><li> <b>Remote Enable</b>
</li><li> <b>Read Security</b>
</li></ul><p>These rights must be assigned to the Root namespace and all subnamespaces below it. See "HOW TO: Set WMI Namespace Security in Windows Server 2003" (http://support.microsoft.com/kb/325353) in the Microsoft Knowledgebase.
</p><p><b>Important:</b> There is no standard facility for deploying WMI security settings remotely to multiple machines at once using Group Policy. However, "Set WMI namespace security via GPO" (http://blogs.msdn.com/spatdsg/archive/2007/11/21/set-wmi-namespace-security-via-gpo-script.aspx) on MSDN Blogs offers instructions on how to create a startup script that you can place inside a Group Policy Object (GPO), which sets the namespace security once the GPO applies to the desired hosts.  You can then deploy this GPO domain-wide or to one or more Organizational Units (OUs).
</p><p><b>5. Firewall configuration.</b> If you have a firewall enabled, you must configure it to allow access for WMI. If you use the Windows Firewall included with recent versions of Windows, the exceptions list explicitly includes WMI. You must set this exception for both the originating and the target machines. See "Connecting to WMI Remotely Starting with Vista" (http://msdn.microsoft.com/en-us/library/aa822854(VS.85).aspx) on MSDN for more details.
</p><p><b>6. User access control (UAC) configuration.</b> If you run Windows Vista, Windows 7, Windows 8.1, or the Windows Server 2003, 2008, or 2012 families, UAC affects how Windows assigns permissions. See "User Account Control and WMI" (http://msdn.microsoft.com/en-us/library/aa826699(v=vs.85).aspx) on MSDN.
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_test_access_to_wmi_providers"><span class="mw-headline" id="Test_access_to_WMI_providers"> Test access to WMI providers </span></a></i></b></font></h4>
<p>Once you have configured WMI and set up the Splunk user for access to your domain, test access to the remote machine.
</p><p><b>Important:</b> This procedure includes steps to temporarily change the Splunk Enterprise data store directory (the location <code><font size="2">SPLUNK_DB</font></code> points to). You must do this before testing access to WMI. Failure to do so can result in missing WMI events. This is because the splunk-wmi.exe process updates the WMI checkpoint file every time it runs.
</p><p>To test access to WMI providers:
</p><p><b>1.</b> Log into the machine Splunk Enterprise runs on as the Splunk user.
</p><p><b>Note:</b> If attempting to log into a domain controller, you might have to change your domain controller security policy to assign the "Allow log on locally" policy for the designated user.
</p><p><b>2.</b> Open a command prompt window (click <b>Start -&gt; Run</b> and type <code><font size="2">cmd</font></code>).
</p><p><b>3.</b> Go to the <code><font size="2">bin</font></code> subdirectory under your Splunk Enterprise installation (for example, <code><font size="2">cd c:\Program Files\Splunk\bin</font></code>).
</p><p><b>4.</b> Determine where Splunk Enterprise currently stores its data by running:
</p>
<div class="samplecode"><code><font size="2">&gt; splunk show datastore-dir </font></code></div>
<p><b>Note:</b> You must authenticate into your Splunk Enterprise instance in order to do this. Once you have, note where Splunk Enterprise stores its data. You'll need to remember it for later.
</p><p><b>5.</b> Run the following command to change where Splunk Enterprise stores its data temporarily:
</p>
<div class="samplecode"><code><font size="2">&gt; splunk set datastore-dir&nbsp;%TEMP%</font></code></div>
<p><b>Note:</b> This example sets the data store directory to the current directory specified in the TEMP environment variable. If you want to set it to a different directory, you can do so, but the directory must already exist.
</p><p><b>6.</b> Restart Splunk Enterprise:
</p>
<div class="samplecode"><code><font size="2">&gt; splunk restart</font></code></div>
<p><b>Note:</b> It might take a while for Splunk Enterprise to restart. This is because it's creating a new data store where you specified in Step 5.
</p><p><b>7.</b> Once Splunk Enterprise has restarted, test access to WMI providers, replacing <code><font size="2">&lt;server&gt;</font></code> with the name of the remote server: 
</p>
<div class="samplecode"><code><font size="2">&gt; splunk cmd splunk-wmi -wql "select * from win32_service" -namespace \\&lt;server&gt;\root\cimv2</font></code></div>
<p><b>8.</b> If you see data streaming back and no error messages, then Splunk Enterprise was able to connect to the WMI provider and query successfully.
</p><p><b>9.</b> If there is an error, a message with a reason on what caused the error appears. Look for the <code><font size="2">error="&lt;msg&gt;"</font></code> string in the output for clues on how to correct the problem.
</p><p>After testing WMI access, be sure to point Splunk Enterprise back to the correct database directory by running the following command, and then restarting Splunk Enterprise:
</p>
<div class="samplecode"><code><font size="2">&gt; splunk set datastore-dir &lt;directory shown from Step 4&gt; </font></code></div>
<h3> <a name="monitorwmidata_configure_wmi-based_inputs"><span class="mw-headline" id="Configure_WMI-based_inputs"> Configure WMI-based inputs </span></a></h3>
<p>All remote data collection in Splunk Enterprise on Windows happens through either WMI providers or a forwarder. See "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" in this manual.
</p><p>You can configure WMI-based inputs either in Splunk Web or by editing configuration files. More options are available when using configuration files. 
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_configure_wmi-based_inputs_with_splunk_web"><span class="mw-headline" id="Configure_WMI-based_inputs_with_Splunk_Web">Configure WMI-based inputs with Splunk Web</span></a></i></b></font></h4>
<p>To add WMI-based inputs, consult one of the appropriate topics in this manual:
</p>
<ul><li> <a href="#real-timewindowsperformancemonitoring_configure_remote_windows_performance_monitoring_with_splunk_web" class="external text">Configure remote Windows performance monitoring with Splunk Web</a>
</li></ul><ul><li> <a href="#monitorwindowsdata_configure_remote_event_log_monitoring" class="external text">Configure remote Windows event log monitoring</a>
</li></ul><h4><font size="3"><b><i> <a name="monitorwmidata_configure_wmi-based_inputs_with_configuration_files"><span class="mw-headline" id="Configure_WMI-based_inputs_with_configuration_files">Configure WMI-based inputs with configuration files</span></a></i></b></font></h4>
<p>wmi.conf handles remote data collection configurations. Review this file to see the default values for WMI-based inputs. If you want to make changes to the default values, edit a copy of <code><font size="2">wmi.conf</font></code> in <code><font size="2">%SPLUNK_HOME%\etc\system\local\</font></code>. Only set values for the attributes you want to change for a given type of data input. See "About configuration files" in the Admin Manual.
</p><p><code><font size="2">wmi.conf</font></code> contains several stanzas:
</p>
<ul><li> The <code><font size="2">[settings]</font></code> stanza, which specifies global WMI parameters.
</li><li> One or more input-specific stanzas, which define how to connect to WMI providers to get data from the remote machine.
</li></ul><p><b>Global settings</b>
</p><p>The <code><font size="2">[settings]</font></code> stanza specifies global WMI parameters. The entire stanza and every parameter within it are optional. If the stanza is not present, Splunk Enterprise assumes system defaults. 
</p><p>When Splunk Enterprise cannot connect to a defined WMI provider, it generates an error in splunkd.log:
</p>
<div class="samplecode"><code><font size="2">
<p>05-12-2011 02:39:40.632 -0700 ERROR ExecProcessor - message from ""C:\Program Files\Splunk\bin\splunk-wmi.exe"" WMI - Unable to connect to WMI namespace "\\w2k3m1\root\cimv2" (attempt to connect took 42.06 seconds) (error="The RPC server is unavailable." HRESULT=800706BA)
</p>
</font></code></div>
<p>The following attributes control how Splunk Enterprise reconnects to a given WMI provider when an error occurs:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default value
</th></tr><tr><td valign="top" align="left"> <code><font size="2">initial_backoff</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise how long, in seconds, to wait the first time after an error occurs before trying to reconnect to the WMI provider. If connection errors continue to occur, Splunk Enterprise doubles the wait time until it reaches the value specified in <code><font size="2">max_backoff</font></code>.
</td><td valign="top" align="left"> 5
</td></tr><tr><td valign="top" align="left"> <code><font size="2">max_backoff</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise the maximum amount of time, in seconds, that it should wait between connection attempts, before invoking <code><font size="2">max_retries_at_max_backoff</font></code>.
</td><td valign="top" align="left"> 20
</td></tr><tr><td valign="top" align="left"> <code><font size="2">max_retries_at_max_backoff</font></code>
</td><td valign="top" align="left"> If the wait time between connection attempts reaches <code><font size="2">max_backoff</font></code>, tells Splunk Enterprise to try to reconnect to the provider this many times, every <code><font size="2">max_backoff</font></code> seconds. If Splunk Enterprise continues to encounter errors after it has made these attempts, it will give up, and won't attempt to connect to the problem provider again until you restart Splunk Enterprise. However, it will continue to log errors such as the example shown above.
</td><td valign="top" align="left"> 2
</td></tr><tr><td valign="top" align="left"> <code><font size="2">checkpoint_sync_interval</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise how long, in seconds, to wait for state data (event log checkpoint) to be written to disk.
</td><td valign="top" align="left"> 2
</td></tr></table><p><b>Input-specific settings</b>
</p><p>Input-specific stanzas tell Splunk Enterprise how to connect to WMI providers. They are defined by one of two attributes that specify the type of data Splunk Enterprise should gather. The stanza name can be anything, but usually begins with <code><font size="2">WMI:</font></code>, for example:
</p>
<div class="samplecode"><code><font size="2">[WMI:AppAndSys]</font></code></div>
<p>When you configure WMI-based inputs in Splunk Web, Splunk Enterprise uses this naming convention for input-specific stanza headers.
</p><p>You can specify one of two types of data inputs in an input-specific stanza: 
</p>
<ul><li> <b>Event log.</b> The <code><font size="2">event_log_file</font></code> attribute tells Splunk Enterprise to expect event log data from the sources defined in the stanza.
</li><li> <b>Windows Query Language (WQL).</b> The <code><font size="2">wql</font></code> attribute tells Splunk Enterprise to expect data from a WMI provider. When using this attribute, you must also specify a valid WQL statement. This attribute must be used when collecting performance data.
</li></ul><p><b>Caution:</b> Do not define both of these attributes in one stanza. Use only one or the other. Otherwise, the input defined by the stanza will not run.
</p><p>The common parameters for both types of inputs are:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default value
</th></tr><tr><td valign="top" align="left"> <code><font size="2">server</font></code>
</td><td valign="top" align="left"> A comma-separated list of servers from which to get data. If this parameter is missing, Splunk Enterprise assumes that you want to connect to the local machine.
</td><td valign="top" align="left"> The local server
</td></tr><tr><td valign="top" align="left"> <code><font size="2">interval</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise how often, in seconds, to poll for new data. If this attribute is not present and defined, the input that the stanza defines will not run.
</td><td valign="top" align="left"> N / A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise whether this input is enabled or disabled. Set this parameter to 1 to disable the input, and 0 to enable it.
</td><td valign="top" align="left"> 0 (enabled)
</td></tr></table><p>The event log-specific parameters are:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default value
</th></tr><tr><td valign="top" align="left"> <code><font size="2">event_log_file</font></code>
</td><td valign="top" align="left"> A comma-separated list of event log channels to monitor.
</td><td valign="top" align="left"> N / A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">current_only</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise whether or not to collect events that occur only when it is running. If events are generated when Splunk Enterprise is stopped, it will not attempt to index those events when it is started again. Set to 1 to have Splunk Enterprise collect events that occur only when it is running, and 0 to have Splunk Enterprise collect all events.
</td><td valign="top" align="left"> 0 (gather all events)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disable_hostname_normalization</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise not to normalize the host name that is retrieved from a WMI event. By default, Splunk Enterprise normalizes host names - it produces a single name for the host by identifying various equivalent host names for the local system. Set this parameter to 1 to disable host name normalization in events, and 0 to normalize host names in events.
</td><td valign="top" align="left"> 0 (normalize host names for WMI events)
</td></tr></table><p>The WQL-specific parameters are:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default value
</th></tr><tr><td valign="top" align="left"> <code><font size="2">wql</font></code>
</td><td valign="top" align="left"> A valid WQL statement.
</td><td valign="top" align="left"> N / A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">namespace</font></code>
</td><td valign="top" align="left"> (Optional) Specifies the path to the WMI provider. The local machine must be able to connect to the remote machine using delegated authentication. If you don't specify a path to a remote machine, Splunk Enterprise connects to the default local namespace (<code><font size="2">\Root\CIMV2</font></code>). This default namespace is where most of the providers you are likely to query reside. Microsoft provides a list of namespaces for Windows XP and later versions of Windows (http://msdn.microsoft.com/en-us/library/aa394084(VS.85).aspx).
</td><td valign="top" align="left"> <code><font size="2">\\&lt;local server&gt;\Root\CIMV2</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">current_only</font></code>
</td><td valign="top" align="left"> Tells Splunk Enterprise whether or not an event notification query is expected. See "WQL query types: event notification versus standard" below for additional information. Set this attribute to 1 to tell Splunk Enterprise to expect an event notification query, and 0 to expect a standard query.
</td><td valign="top" align="left"> 0 (expect a standard query)
</td></tr></table><h4><font size="3"><b><i> <a name="monitorwmidata_wql_query_types:_event_notification_versus_standard"><span class="mw-headline" id="WQL_query_types:_event_notification_versus_standard">WQL query types: event notification versus standard</span></a></i></b></font></h4>
<p>The <code><font size="2">current_only</font></code> attribute in WQL stanzas determines the type of query the stanza expects to use to collect WMI-based data. When you set the attribute to 1, the stanza expects event notification data. Event notification data is data that alerts you of an incoming event. To get event notification data, you must use an event notification query.
</p><p>For example, if you want to find out when a remote server spawns processes, you must use an event notification query. Standard queries have no facilities for notifying you when an event has occurred, and can only return results on information that already exists.
</p><p>Conversely, if you want to know what already-running processes on your system begin with the word "splunk", you must use a standard query. Event notification queries cannot tell you about static, pre-existing information.
</p><p>Event notification queries require that the WQL statement defined for the stanza be structurally and syntactically correct. Improperly formatted WQL will cause the input defined by the stanza to not run. Review the wmi.conf configuration file reference for specific details and examples.
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_wql_query_stanzas_do_not_update_the_wmi_checkpoint_file"><span class="mw-headline" id="WQL_query_stanzas_do_not_update_the_WMI_checkpoint_file">WQL query stanzas do not update the WMI checkpoint file</span></a></i></b></font></h4>
<p>When you use a WQL query stanza to gather data through WMI, Splunk Enterprise does not update the WMI checkpoint file - the file that determines if WMI data has already been indexed. This is by design - a WQL query of any type returns dynamic data and thus a context for saving a checkpoint for the data produced cannot be built. This means that Splunk Enterprise indexes WMI data that it collects through WQL query stanzas as fresh data each time the stanza runs. This can result in the indexing of duplicate events and possibly impact license volume. 
</p><p>If you need to index data regularly, such as event logs, use the appropriate monitor on a universal forwarder. If you must use WMI, do not use a WQL query.
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_examples_of_wmi.conf"><span class="mw-headline" id="Examples_of_wmi.conf">Examples of wmi.conf</span></a></i></b></font></h4>
<p>The following is an example of a <code><font size="2">wmi.conf</font></code> file:
</p>
<div class="samplecode"><code><font size="2"><br>[settings]<br>initial_backoff = 5<br>max_backoff = 20<br>max_retries_at_max_backoff = 2<br>checkpoint_sync_interval = 2<br><br>[WMI:AppAndSys]<br>server = foo, bar<br>interval = 10<br>event_log_file = Application, System, Directory Service<br>disabled = 0<br><br>[WMI:LocalSplunkWmiProcess]<br>interval = 5<br>wql = select * from Win32_PerfFormattedData_PerfProc_Process where Name = "splunk-wmi"<br>disabled = 0<br><br># Listen from three event log channels, capturing log events that occur only<br># while Splunk Enterprise runs. &nbsp;Gather data from three machines.<br>[WMI:TailApplicationLogs]<br>interval = 10<br>event_log_file = Application, Security, System<br>server = srv1, srv2, srv3<br>disabled = 0<br>current_only = 1<br><br># Listen for process-creation events on a remote machine<br>[WMI:ProcessCreation]<br>interval = 1<br>server = remote-machine<br>wql = select * from __InstanceCreationEvent within 1 where TargetInstance isa 'Win32_Process'<br>disabled = 0<br>current_only = 1<br><br># Receive events whenever someone plugs/unplugs a USB device to/from the computer<br>[WMI:USBChanges]<br>interval = 1<br>wql = select * from __InstanceOperationEvent within 1 where TargetInstance ISA 'Win32_PnPEntity' and TargetInstance.Description='USB Mass Storage Device'<br>disabled = 0<br>current_only = 1<br></font></code></div>
<h3> <a name="monitorwmidata_fields_for_wmi_data"><span class="mw-headline" id="Fields_for_WMI_data"> Fields for WMI data </span></a></h3>
<p>When Splunk Enterprise indexes data from WMI-based inputs, it sets the <b>source</b> for received events to <code><font size="2">wmi</font></code>. It sets the <b>source type</b> of the incoming events based on the following conditions: 
</p>
<ul><li> For event log data, Splunk Enterprise sets the source type to <code><font size="2">WinEventLog:&lt;name of log file&gt;</font></code>. For example, <code><font size="2">WinEventLog:Application</font></code>.
</li><li> For WQL data, Splunk Enterprise sets the source type to the name of the stanza that defines the input.  For example, for a stanza named <code><font size="2">[WMI:LocalSplunkdProcess]</font></code>, Splunk sets the source type to <code><font size="2">WMI:LocalSplunkdProcess</font></code>.
</li></ul><p>Splunk Enterprise automatically defines the originating host from the data received.
</p>
<h4><font size="3"><b><i> <a name="monitorwmidata_wmi_and_event_transformations"><span class="mw-headline" id="WMI_and_event_transformations">WMI and event transformations</span></a></i></b></font></h4>
<p>WMI events are not available for transformation at index time. This means you cannot modify or extract WMI events as Splunk Enterprise indexes them. This is because WMI events arrive as a single source (a scripted input), which means they can only be matched as a single source.
</p><p>You can, however, modify and extract WMI events at search time. You can also address WMI-based inputs at parse time by specifying the sourcetype <code><font size="2">[wmi]</font></code>.
</p><p>For more information on how to transform events as they arrive in Splunk Enterprise, see "<a href="#aboutindexedfieldextraction" class="external text">About indexed field extraction</a>" in this manual.
</p>
<h3> <a name="monitorwmidata_troubleshooting_wmi_inputs"><span class="mw-headline" id="Troubleshooting_WMI_inputs"> Troubleshooting WMI inputs </span></a></h3>
<p>If you encounter problems receiving events through WMI providers or are not getting the results you expect, see "Common Issues with Splunk and WMI" in the Troubleshooting Manual.
</p>
<a name="monitorwindowsregistrydata"></a><h2> <a name="monitorwindowsregistrydata_monitor_windows_registry_data"><span class="mw-headline" id="Monitor_Windows_Registry_data"> Monitor Windows Registry data</span></a></h2>
<p>The Windows Registry is the central configuration database on a Windows machine. Nearly all Windows processes and third-party programs interact with it. Without a healthy Registry, Windows does not run. Splunk Enterprise supports the capture of Windows Registry settings and lets you monitor changes to the Registry in real time. 
</p><p>When a program makes a change to a configuration, it writes those changes to the Registry. Later, when the program runs again, it looks into the Registry to read those configurations. You can learn when Windows programs and processes add, update, and delete Registry entries on your system. When a Registry entry changes, Splunk Enterprise captures the name of the process that made the change, as well as the entire path to the entry being changed. 
</p><p>The Windows Registry input monitor runs as a process called <code><font size="2">splunk-regmon.exe</font></code>.
</p>
<h3> <a name="monitorwindowsregistrydata_why_monitor_the_registry.3f"><span class="mw-headline" id="Why_monitor_the_Registry.3F"> Why monitor the Registry? </span></a></h3>
<p>The Registry is probably the most used, yet least understood component of Windows operation. It gets used constantly, with many different programs reading from and writing to it at all times. When something is not functioning as desired, Microsoft often instructs administrators and users alike to make changes to the Registry directly using the RegEdit tool. The ability to capture those edits, and any other changes, in real time is the first step in understanding the importance of the Registry.
</p><p>The Registry's health is also very important. Splunk Enterprise not only tells you when changes to the Registry are made, but also whether or not those changes were successful. If programs and processes can't write to or read from the Registry, bad things can happen to your Windows system, including a complete failure. Splunk Enterprise can alert you to problems interacting with the Registry so that you can restore it from a backup and keep your system running.
</p>
<h3> <a name="monitorwindowsregistrydata_what_do_you_need_to_monitor_the_registry.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_the_Registry.3F">What do you need to monitor the Registry?</span></a></h3>
<p>The following table lists the explicit permissions needed to monitor the Registry. You might need additional permissions based on the Registry keys that you want to monitor.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor the Registry
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>AND<br>* Splunk Enterprise must run as either the local system user<br>OR<br> * Splunk Enterprise must run as a domain user with read access to the Registry hives or keys that you want to monitor
</td></tr></table><h3> <a name="monitorwindowsregistrydata_performance_considerations"><span class="mw-headline" id="Performance_considerations"> Performance considerations </span></a></h3>
<p>When you enable Registry monitoring, you specify which Registry hives to monitor: the user hive (represented as <code><font size="2">HKEY_USERS</font></code> in RegEdit) and/or the machine hive (represented as <code><font size="2">HKEY_LOCAL_MACHINE</font></code>). The user hive contains user-specific configurations required by Windows and programs, and the machine hive contains configuration information specific to the machine, such as the location of services, drivers, object classes and security descriptors.
</p><p>Since the Registry plays a central role in the operation of a Windows machine, enabling both Registry paths results in a lot of data for Splunk Enterprise to monitor. To achieve the best performance, filter the amount of Registry data that Splunk Enterprise indexes by configuring <code><font size="2">inputs.conf</font></code>.
</p><p>Similarly, you can capture a baseline - a snapshot of the current state of your Windows Registry - when you first start Splunk Enterprise, and again every time a specified amount of time has passed. The snapshot allows you to compare what the Registry looks like at a certain point in time, and provides for easier tracking of the changes to the Registry over time.
</p><p>The snapshot process can be somewhat CPU-intensive, and might take several minutes to complete. You can postpone taking a baseline snapshot until you have narrowed the scope of the Registry entries to those you specifically want Splunk Enterprise to monitor. 
</p><p>More information on <code><font size="2">inputs.conf</font></code> and how to use it to filter incoming Registry events is available in "Filter incoming Registry events" later on this page.
</p>
<h3> <a name="monitorwindowsregistrydata_enable_registry_monitoring_in_splunk_web"><span class="mw-headline" id="Enable_Registry_monitoring_in_Splunk_Web">Enable Registry monitoring in Splunk Web</span></a></h3>
<p>To enable Registry monitoring on the local Windows machine, follow the "<a href="#windowsregistrylocal" class="external text">Windows Registry - local</a>" recipe in this manual.
</p>
<h3> <a name="monitorwindowsregistrydata_view_registry_change_data"><span class="mw-headline" id="View_Registry_change_data"> View Registry change data </span></a></h3>
<p>To view Registry change data that Splunk Enterprise has indexed, go to the Search app and search for events with a source of <code><font size="2">WinRegistry</font></code>. An example event, which Group Policy generates when a user logs in to a domain, follows:
</p>
<div class="samplecode"><code><font size="2"><br>3:03:28.505 PM &nbsp;<br>06/19/2011 15:03:28.505<br>event_status="(0)The operation completed successfully."<br>pid=340<br>process_image="c:\WINDOWS\system32\winlogon.exe"<br>registry_type="SetValue"<br>key_path="HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Group Policy\History\DCName"<br>data_type="REG_SZ"<br>data="\\ftw.ad.splunk.com"<br></font></code></div>
<p>Each registry monitoring event contains:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th bgcolor="#C0C0C0"> Attribute
</th><th bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="center" align="left"> <code><font size="2">event_status</font></code>
</td><td valign="center" align="left"> The result of the registry change attempt. This should always be "<code><font size="2">(0) The operation completed successfully.</font></code>". If it is not, there might be problems with the Registry that might eventually require a restore from a backup.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">pid</font></code>
</td><td valign="center" align="left"> The process ID of the process that attempted to make the Registry change.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">process_image</font></code>
</td><td valign="center" align="left"> The name of the process that attempted to make the Registry change.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">registry_type</font></code>
</td><td valign="center" align="left"> The type of Registry operation that the <code><font size="2">process_image</font></code> attempted to invoke.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">key_path</font></code>
</td><td valign="center" align="left"> The Registry key path that the <code><font size="2">process_image</font></code> attempted to make a change to.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">data_type</font></code>
</td><td valign="center" align="left"> The type of Registry data that the <code><font size="2">process_image</font></code> making the Registry change tried to get or set.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">data</font></code>
</td><td valign="center" align="left"> The data that the <code><font size="2">process_image</font></code> making the Registry change tried to read or write.
</td></tr></table><p>You can use the Splunk Enterprise search commands and reporting features to create reports based on the incoming data, or use its alerting features to send alerts if things go wrong.
</p>
<h3> <a name="monitorwindowsregistrydata_filter_incoming_registry_events"><span class="mw-headline" id="Filter_incoming_Registry_events"> Filter incoming Registry events </span></a></h3>
<p>Windows Registries generate a great number of events due to their near-constant use. This can cause problems with licensing - Splunk Registry monitoring can easily generate hundreds of megabytes of data per day.
</p><p>Splunk Windows Registry monitoring uses a configuration file to determine what to monitor on your system, inputs.conf.  This file needs to reside in <code><font size="2">$SPLUNK_HOME\etc\system\local\</font></code> on the server that runs Registry monitoring.
</p><p><code><font size="2">inputs.conf</font></code> contains the specific regular expressions you create to refine and filter the Registry hive paths you want Splunk to monitor.
</p><p>Each stanza in <code><font size="2">inputs.conf</font></code> represents a particular filter whose definition includes:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th bgcolor="#C0C0C0"> Attribute
</th><th bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="center" align="left"> <code><font size="2">proc</font></code>
</td><td valign="center" align="left"> A regular expression containing the path to the process or processes you want to monitor.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">hive</font></code>
</td><td valign="center" align="left"> A regular expression containing the hive path to the entry or entries you want to monitor. Splunk supports the root key value mappings predefined in Windows:
<ul><li> <code><font size="2">\\REGISTRY\\USER\\</font></code>  maps to <code><font size="2">HKEY_USERS</font></code> or <code><font size="2">HKU</font></code>
</li><li> <code><font size="2">\\REGISTRY\\USER\\_Classes</font></code> maps to <code><font size="2">HKEY_CLASSES_ROOT</font></code> or <code><font size="2">HKCR</font></code>
</li><li> <code><font size="2">\\REGISTRY\\MACHINE</font></code> maps to <code><font size="2">HKEY_LOCAL_MACHINE or HKLM</font></code>
</li><li> <code><font size="2">\\REGISTRY\\MACHINE\\SOFTWARE\\Classes</font></code> maps to <code><font size="2">HKEY_CLASSES_ROOT</font></code> or <code><font size="2">HKCR</font></code>
</li><li> <code><font size="2">\\REGISTRY\\MACHINE\\SYSTEM\\CurrentControlSet\\Hardware Profiles\\Current</font></code> maps to <code><font size="2">HKEY_CURRENT_CONFIG</font></code> or <code><font size="2">HKCC</font></code>
</li><li> <b>Note:</b> There is no direct mapping for <code><font size="2">HKEY_CURRENT_USER</font></code> or <code><font size="2">HKCU</font></code>, as Splunk's Registry monitor runs in kernel mode.  However, using <code><font size="2">\\REGISTRY\\USER\\.*</font></code> (note the period and asterisk at the end) generates events that contain the logged-in user's security identifier (SID).  
</li><li> Alternatively, you can specify the user whose Registry keys you wish to monitor by using <code><font size="2">\\REGISTRY\\USER\\&lt;SID&gt;</font></code>, where <code><font size="2">SID</font></code> is the SID of the desired user. 
</li></ul></td></tr><tr><td valign="center" align="left"> <code><font size="2">type</font></code>
</td><td valign="center" align="left"> The subset of event types to monitor. Can be one or more of <code><font size="2">delete, set, create, rename, open, close</font></code> or <code><font size="2">query</font></code>. The values here must be a subset of the values for <code><font size="2">event_types</font></code> that you set in <code><font size="2">sysmon.conf</font></code>.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">baseline</font></code>
</td><td valign="center" align="left"> Whether or not to capture a baseline snapshot for that particular hive path. Set to 1 for yes, and 0 for no.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">baseline_interval</font></code>
</td><td valign="center" align="left"> How long Splunk Enterprise has to have been down before re-taking the snapshot, in seconds.  The default value is 86,400 seconds (1 day).
</td></tr><tr><td valign="center" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="center" align="left"> Whether or not a filter is enabled.  Set to 1 to disable the filter, and 0 to enable it.
</td></tr></table><h3> <a name="monitorwindowsregistrydata_get_a_baseline_snapshot"><span class="mw-headline" id="Get_a_baseline_snapshot"> Get a baseline snapshot </span></a></h3>
<p>When you enable Registry monitoring, you have the option of recording a baseline snapshot of the Registry hives the next time Splunk Enterprise starts. By default, the snapshot covers the HKEY_CURRENT_USER and HKEY_LOCAL_MACHINE hives. It also establishes a timeline for when to retake the snapshot: by default, if Splunk Enterprise has been down for more than 24 hours since the last checkpoint, it retakes the baseline snapshot. You can customize this value for each of the filters in <code><font size="2">inputs.conf</font></code> by setting the value of <code><font size="2">baseline_interval</font></code>, in seconds.
</p>
<a name="real-timewindowsperformancemonitoring"></a><h2> <a name="real-timewindowsperformancemonitoring_monitor_windows_performance"><span class="mw-headline" id="Monitor_Windows_performance"> Monitor Windows performance</span></a></h2>
<p>Splunk Enterprise supports the monitoring of all Windows performance counters in real time and includes support for both local and remote collection of performance data.
</p><p>The Splunk Enterprise performance monitoring utility gives you the abilities of Performance Monitor in a web interface. Splunk Enterprise uses the Performance Data Helper (PDH) API for performance counter queries on local machines.
</p><p>The types of performance objects, counters and instances that are available to Splunk Enterprise depend on the performance libraries installed on the system. Both Microsoft and third-party vendors provide libraries that contain performance counters. For additional information on performance monitoring, review "Performance Counters" (http://msdn.microsoft.com/en-us/library/aa373083%28v=VS.85%29.aspx) on MSDN.
</p><p>Both full instances of Splunk Enterprise and universal forwarders support local collection of performance metrics. Remote performance monitoring is available through WMI (Windows Management Instrumentation) and requires that Splunk Enterprise runs as a user with appropriate Active Directory credentials.
</p><p>The performance monitor input runs as a process called <code><font size="2">splunk-perfmon.exe</font></code>.  It runs once for every input defined, at the interval specified in the input. You can configure performance monitoring with Splunk Web, or either <code><font size="2">inputs.conf</font></code> (for local performance data) or <code><font size="2">wmi.conf</font></code> (for performance data from a remote machine).
</p>
<h3> <a name="real-timewindowsperformancemonitoring_why_monitor_performance_metrics.3f"><span class="mw-headline" id="Why_monitor_performance_metrics.3F">Why monitor performance metrics?</span></a></h3>
<p>Performance monitoring is an important part of the Windows administrator's toolkit. Windows generates a lot of data about a system's health. Proper analysis of that data can make the difference between a healthy, well functioning system, and one that suffers downtime. 
</p>
<h3> <a name="real-timewindowsperformancemonitoring_what_do_you_need_to_monitor_performance_counters.3f"><span class="mw-headline" id="What_do_you_need_to_monitor_performance_counters.3F">What do you need to monitor performance counters?</span></a></h3>
<p>The following table lists the permissions needed to monitor performance counters in Windows. You might need additional permissions based on the performance objects or counters that you want to monitor.
</p><p>For additional information on what's required to monitor performance metrics, read "Security and remote access considerations" later in this topic.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor local performance metrics
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as the Local System user
</td></tr><tr><td valign="top" align="left"> Monitor remote performance metrics on another computer over WMI
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as a domain or remote user with at least read access to WMI on the target computer<br>* Splunk Enterprise must run as a domain or remote user with appropriate access to the Performance Data Helper libraries on the target computer
</td></tr></table><h3> <a name="real-timewindowsperformancemonitoring_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enterprise gets data from remote machines using either a forwarder or WMI. Splunk recommends using a universal forwarder to send performance data from remote machines to an indexer. See "Introducing the universal forwarder" in the Forwarding Data manual.
</p><p>If you choose to install forwarders on your remote machines to collect performance data, then you can install the forwarder as the Local System user on those machines. The Local System user has access to all data on the local machine, but not to remote computers. 
</p><p>If you want Splunk Enterprise to use WMI to get performance data from remote machines, then you must configure both Splunk Enterprise and your network. You cannot install Splunk Enterprise as the Local System user, and the user you choose determines what Splunk Enterprise sees. See "<a href="#monitorwmidata_security_and_remote_access_considerations" class="external text">Security and remote access considerations</a>" in the "Monitor WMI Data" topic in this manual.
</p><p>After you install Splunk Enterprise with a valid user, add that user to the following groups before enabling local performance monitor inputs:
</p>
<ul><li> <b>Performance Monitor Users</b> (domain group)
</li><li> <b>Performance Log Users</b> (domain group)
</li></ul><h3> <a name="real-timewindowsperformancemonitoring_enable_local_windows_performance_monitoring"><span class="mw-headline" id="Enable_local_Windows_performance_monitoring"> Enable local Windows performance monitoring </span></a></h3>
<p>You can configure local performance monitoring either in Splunk Web or with configuration files.
</p><p>Splunk Web is the preferred way to add performance monitoring data inputs. This is because you can make typos when using configuration files, and it's important to specify performance monitor objects exactly as the Performance Monitor API defines them. See "Important information about specifying performance monitor objects in inputs.conf" later in this topic for a full explanation.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_configure_local_windows_performance_monitoring_with_splunk_web"><span class="mw-headline" id="Configure_local_Windows_performance_monitoring_with_Splunk_Web"> Configure local Windows performance monitoring with Splunk Web </span></a></i></b></font></h4>
<p>To configure Windows performance monitoring on the local machine, follow the "<a href="#windowsperformancelocal" class="external text">Windows performance monitoring - local</a>" recipe in this manual.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_configure_local_windows_performance_monitoring_with_configuration_files"><span class="mw-headline" id="Configure_local_Windows_performance_monitoring_with_configuration_files"> Configure local Windows performance monitoring with configuration files </span></a></i></b></font></h4>
<p>inputs.conf controls performance monitoring configurations. To set up performance monitoring using configuration files, create and/or edit <code><font size="2">inputs.conf</font></code> in <code><font size="2">%SPLUNK_HOME%\etc\system\local</font></code>.  If you have not worked with configuration files before, see "About configuration files".
</p><p>The <code><font size="2">[perfmon://&lt;name&gt;]</font></code> stanza defines performance monitoring inputs in <code><font size="2">inputs.conf</font></code>. You specify one stanza per performance object that you wish to monitor.
</p><p>In each stanza, you can specify the following attributes:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="top" width="175" align="left"> <code><font size="2">interval</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> How often, in seconds, to poll for new data.  If this attribute is not present and defined, the input will not run, as there is no default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">object</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> The performance object(s) that you wish to capture. Specify either a string which exactly matches (including case) the name of an existing Performance Monitor object or use a regular expression to reference multiple objects. If this attribute is not present and defined, the input will not run, as there is no default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">counters</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> One or more valid performance counters that are associated with the object specified in <code><font size="2">object</font></code>. Separate multiple counters with semicolons. You can also use an asterisk (*) to specify all available counters under a given <code><font size="2">object</font></code>. If this attribute is not present and defined, the input will not run, as there is no default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">instances</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> One or more valid instances associated with the performance counter specified in <code><font size="2">counters</font></code>.  Multiple instances are separated by semicolons. You can specify all instances by using an asterisk (*), which is the default if you do not define the attribute in the stanza.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> The desired index to route performance counter data to.  If not present, the default index is used.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not to gather the performance data defined in this input. Set to 1 to disable this stanza, and 0 to enable it.  If not present, it defaults to 0 (enabled).
</td></tr><tr><td valign="top" align="left"> <code><font size="2">samplingInterval</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> <b>Advanced option.</b> How often, in milliseconds, that Splunk should collect performance data.
<p>This attribute enables high-frequency performance sampling. When you enable high-frequency performance sampling, Splunk Enterprise collects performance data every interval and reports the average of the data as well as other statistics. It defaults to 100 ms, and must be less than what you specify with the <code><font size="2">interval</font></code> attribute.
</p>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">stats</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> <b>Advanced option.</b> A semicolon-separated list of statistic values which Splunk Enterprise reports for high-frequency performance sampling.
<p>Allowed values are: <code><font size="2">average, min, max, dev</font></code>, and <code><font size="2">count</font></code>.
</p><p>The default is no setting (disabled).
</p>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">mode</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> <b>Advanced option.</b> When you enable high-performance sampling, this attribute controls how Splunk Enterprise outputs events.
<p>Allowed values are: <code><font size="2">single, multikv, multiMS</font></code>, and <code><font size="2">multikvMS</font></code>
</p><p>When you enable either <code><font size="2">multiMS</font></code> or <code><font size="2">multikvMS</font></code>, Splunk Enterprise outputs two events for each performance metric collected. The first event is the average value, and the second is the statistics event. The statistics event has a special sourcetype depending on which output mode you use (<code><font size="2">perfmonMSStats</font></code> for <code><font size="2">multiMS</font></code> and <code><font size="2">perfmonMKMSStats</font></code> for <code><font size="2">multikvMS</font></code>)
</p><p>If you do not enable high-performance sampling, the <code><font size="2">multikvMS</font></code> output mode is the same as the <code><font size="2">multikv</font></code> output mode.
</p><p>The default is <code><font size="2">single</font></code>.
</p>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">useEnglishOnly</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> <b>Advanced option.</b> Controls how Splunk Enterprise indexes performance metrics on systems whose locale is not English. Specifically, it tells Splunk which Windows Performance Monitor API to use when it indexes performance metrics on servers that do not use the English language.
<p>If set to true, Splunk Enterprise collects the performance metrics in English regardless of the system's locale. It uses the <code><font size="2">PdhAddEnglishCounter()</font></code> API to add the counter string. It also disables regular expression and wildcard matching for the <code><font size="2">object</font></code> and <code><font size="2">counter</font></code> attributes.
</p><p>If set to false, Splunk Enterprise collects the performance metrics in the system's language and expects you to configure the <code><font size="2">object</font></code> and <code><font size="2">counter</font></code> attributes in that language. It uses the <code><font size="2">PdhAddCounter()</font></code> API to add the counter string. You can use wildcards and regular expressions, but you must specify valid <code><font size="2">object</font></code>, <code><font size="2">counters</font></code>, and <code><font size="2">instances</font></code> values that are specific to the locale of the operating system.
</p><p>The default is false.
</p>
</td></tr></table><h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_collect_performance_metrics_in_english_regardless_of_system_locale"><span class="mw-headline" id="Collect_performance_metrics_in_English_regardless_of_system_locale">Collect performance metrics in English regardless of system locale</span></a></i></b></font></h4>
<p>You can collect performance metrics in English even if the system that Splunk Enterprise runs on does not use the English language.
</p><p>To do this, use the <code><font size="2">useEnglishOnly</font></code> attribute in stanzas within <code><font size="2">inputs.conf</font></code>. There is no way to configure <code><font size="2">useEnglishOnly</font></code> in Splunk Web.
</p><p><b>Note:</b> There are caveats to using <code><font size="2">useEnglishOnly</font></code> in an inputs.conf stanza. Read about them in <a href="#real-timewindowsperformancemonitoring_on_non-english_installations.2c_the_useenglishonly_attribute_has_limitations" class="external text">the Caveats section</a> later in this topic.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_examples_of_performance_monitoring_input_stanzas"><span class="mw-headline" id="Examples_of_performance_monitoring_input_stanzas">Examples of performance monitoring input stanzas</span></a></i></b></font></h4>
<p>Here are some example stanzas which show you how to use inputs.conf to monitor performance monitor objects.
</p>
<div class="samplecode"><code><font size="2"><br># Query the PhysicalDisk performance object and gather disk access data for<br># all physical drives installed in the system. Store this data in the <br># "perfmon" index.<br># Note: If the interval attribute is set to 0, Splunk resets the interval<br># to 1.<br><br>[perfmon://LocalPhysicalDisk]<br>interval = 0<br>object = PhysicalDisk<br>counters = Disk Bytes/sec;&nbsp;% Disk Read Time;&nbsp;% Disk Write Time;&nbsp;% Disk Time<br>instances = *<br>disabled = 0<br>index = PerfMon<br><br># Gather SQL statistics for all database instances on this SQL server.<br># 'object' attribute uses a regular expression "\$.*" to specify SQL<br># statistics for all available databases.<br>[perfmon://SQLServer_SQL_Statistics]<br>object = MSSQL\$.*:SQL Statistics<br>counters = *<br>instances = *<br><br># Gather information on all counters under the "Process" and "Processor" <br># Perfmon objects.<br># We use '.*' as a wild card to match the 'Process' and 'Processor' objects.<br>[perfmon://ProcessandProcessor]<br>object = Process.*<br>counters = *<br>instances = *<br><br># Collect CPU processor usage metrics in English only on a French system.<br>[perfmon://Processor]<br>object = Processor<br>instances = _Total<br>counters =&nbsp;% Processor Time;% User Time<br>useEnglishOnly = 1<br>interval = 30<br>disabled = 0<br><br># Collect CPU processor usage metrics in the French system's native locale.<br># Note that you must specify the counters in the language of that locale.<br>[perfmon://FrenchProcs]<br>counters = *<br>disabled = 0<br>useEnglishOnly = 0<br>interval = 30<br>object = Processeur<br>instances = *<br></font></code>
</div>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_important_information_about_specifying_performance_monitor_objects_in_inputs.conf"><span class="mw-headline" id="Important_information_about_specifying_performance_monitor_objects_in_inputs.conf"> Important information about specifying performance monitor objects in inputs.conf </span></a></i></b></font></h4>
<h5> <a name="real-timewindowsperformancemonitoring_use_all_lower_case_when_specifying_the_perfmon_keyword"><span class="mw-headline" id="Use_all_lower_case_when_specifying_the_perfmon_keyword"> Use all lower case when specifying the <code><font size="2">perfmon</font></code> keyword</span></a></h5>
<p>When you create a performance monitor input in <code><font size="2">inputs.conf</font></code>, you must use all lower case for the <code><font size="2">perfmon</font></code> keyword, for example:
</p>
<table cellpadding="2"><tr><th bgcolor="#C0C0C0"> Correct
</th><th bgcolor="#C0C0C0"> Incorrect
</th></tr><tr><td align="center" valign="center"> <code><font size="2">[perfmon://CPUTime]</font></code>
</td><td align="center" valign="center"> <code><font size="2">[Perfmon://CPUTime]</font></code><br><code><font size="2">[PERFMON://CPUTime]</font></code>
</td></tr></table><p>If you use capital or mixed-case letters for the keyword, Splunk Enterprise warns of the problem on start-up, and the specified performance monitor input does not run.
</p>
<h5> <a name="real-timewindowsperformancemonitoring_specify_valid_regular_expressions_to_capture_multiple_performance_monitor_objects"><span class="mw-headline" id="Specify_valid_regular_expressions_to_capture_multiple_performance_monitor_objects"> Specify valid regular expressions to capture multiple performance monitor objects </span></a></h5>
<p>When you need to specify multiple objects in a single performance monitor stanza, you must use a valid regular expression to capture those objects. For example, to specify a wildcard to match a string beyond a certain number of characters, do not use <code><font size="2">*</font></code>, but rather <code><font size="2">.*</font></code>. If the object contains a dollar sign or similar special character, you might need to escape it with a backslash (<code><font size="2">\</font></code>).
</p>
<h5> <a name="real-timewindowsperformancemonitoring_except_in_the_above_case.2c_values_must_exactly_match_what_is_in_the_performance_monitor_api"><span class="mw-headline" id="Except_in_the_above_case.2C_values_must_exactly_match_what_is_in_the_Performance_Monitor_API"> Except in the above case, values must exactly match what is in the Performance Monitor API</span></a></h5>
<p>When you specify values for the <code><font size="2">object</font></code>, <code><font size="2">counters</font></code> and <code><font size="2">instances</font></code> attributes in <code><font size="2">[perfmon://]</font></code> stanzas, be sure that those values exactly match those defined in the Performance Monitor API, including case, or the input might return incorrect data, or no data at all. If Splunk is unable to match a performance object, counter or instance value that you've specified, it logs that failure to <code><font size="2">splunkd.log</font></code>. For example:
</p>
<div class="samplecode"><code><font size="2">01-27-2011 21:04:48.681 -0800 ERROR ExecProcessor - message from ""C:\Program Files\Splunk\bin\splunk-perfmon.exe" -noui" splunk-perfmon - PerfmonHelper::enumObjectByNameEx: PdhEnumObjectItems failed for object - 'USB' with error (0xc0000bb8): The specified object is not found on the system.</font></code></div>
<p>The best way to ensure that you specify the correct objects, counters, and instances is to use Splunk Web to add performance monitor data inputs.
</p>
<h3> <a name="real-timewindowsperformancemonitoring_enable_remote_windows_performance_monitoring_over_wmi"><span class="mw-headline" id="Enable_remote_Windows_performance_monitoring_over_WMI"> Enable remote Windows performance monitoring over WMI </span></a></h3>
<p>You can configure remote performance monitoring either in Splunk Web or by using configuration files.
</p><p>When collecting performance metrics over WMI, you must configure Splunk Enterprise to run as an AD user with appropriate access for remote collection of performance metrics. You must do this before attempting to collect those metrics. Both the machine that runs Splunk and the machine(s) Splunk collects performance data from must reside in the same AD domain or forest.
</p><p><b>Note:</b> WMI self-throttles by design to prevent denial of service attacks. Splunk Enterprise also reduces the number of WMI calls it makes over time as a precautionary measure if these calls return an error. Depending on the size, configuration, and security profile of your network, installing a local forwarder on the system from which you want to collect performance metrics might be a better choice.  Consult "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" in this manual for additional information.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_important_information_regarding_wmi-based_performance_metrics"><span class="mw-headline" id="Important_information_regarding_WMI-based_performance_metrics"> Important information regarding WMI-based performance metrics </span></a></i></b></font></h4>
<p>When gathering remote performance metrics through WMI, you might notice that some metrics return zero values, or values that are not in line with values returned by Performance Monitor. This is because of a limitation in the implementation of WMI for performance monitor counters, and is not an issue with Splunk Enterprise or how it retrieves WMI-based data..
</p><p>WMI uses the <code><font size="2">Win32_PerfFormattedData_*</font></code> classes to gather performance metrics. More info on the specific classes is available at "Win32 Classes" (http://msdn.microsoft.com/en-us/library/aa394084%28v=vs.85%29.aspx) on MSDN. 
</p><p>WMI defines the data structures within these classes as either 32- or 64-bit unsigned integers, depending on the version of Windows you are running. Performance Monitor objects, meanwhile, are defined as floating-point variables. This means that you might see WMI-based metrics that appear anomalous, due to rounding factors. 
</p><p>For example, if you collect data on the "Average Disk Queue Length" Performance Monitor counter at the same time you collect the <code><font size="2">Win32_PerfFormattedData_PerfDisk_PhysicalDisk\AvgDiskQueueLength</font></code> metric through WMI, the WMI-based metric might return zero values even though the Performance Monitor metric returns values greater than zero (but less than 0.5). This is because WMI rounds the value down before displaying it.
</p><p>If you require additional granularity in your performance metrics, it's better to configure the performance monitoring inputs on a universal forwarder on each machine from which you wish to collect performance data. You can then forward that data to an indexer. Data retrieved using this method is more reliable than data gathered remotely using WMI-based inputs.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_configure_remote_windows_performance_monitoring_with_splunk_web"><span class="mw-headline" id="Configure_remote_Windows_performance_monitoring_with_Splunk_Web"> Configure remote Windows performance monitoring with Splunk Web </span></a></i></b></font></h4>
<p>To configure Windows performance monitoring on a remote Windows machine, follow the "<a href="#windowsperformanceremote" class="external text">Windows performance monitoring - remote</a>" recipe in this manual.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_configure_remote_windows_performance_monitoring_with_configuration_files"><span class="mw-headline" id="Configure_remote_Windows_performance_monitoring_with_configuration_files"> Configure remote Windows performance monitoring with configuration files </span></a></i></b></font></h4>
<p>Remote performance monitoring configurations are controlled by wmi.conf.  To set up remote performance monitoring using configuration files, create and/or edit <code><font size="2">wmi.conf</font></code> in <code><font size="2">%SPLUNK_HOME%\etc\system\local</font></code>.  If you haven't worked with configuration files before, read "About configuration files" before you begin. 
</p><p><b>Caution:</b> Splunk strongly recommends that you use Splunk Web to create remote performance monitor inputs. This is because the names of performance monitor objects, counters, and instances must <b>exactly</b> match what the Performance Monitor API defines, including case.  Splunk Web uses WMI to get the properly-formatted names, eliminating the potential for typos.
</p><p><code><font size="2">wmi.conf</font></code> contains one stanza for each remote performance monitor object that you wish to monitor.  In each stanza, you specify:
</p>
<h5> <a name="real-timewindowsperformancemonitoring_global_settings"><span class="mw-headline" id="Global_settings"> Global settings </span></a></h5>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" width="175" align="left"> <code><font size="2">initial_backoff</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> How long, in seconds, to wait before retrying a connection to a WMI provider when an error occurs. If Splunk continues to have problems connecting to the provider, then it will double the wait time between connection attempts until either it can connect, or until the wait time is greater than or equal to the integer specified in <code><font size="2">max_backoff</font></code>.
</td><td valign="top" width="75" align="left"> 5
</td></tr><tr><td valign="top" align="left"> <code><font size="2">max_backoff</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> The maximum amount of time, in seconds to attempt to reconnect to a WMI provider.
</td><td valign="top" align="left"> 20
</td></tr><tr><td valign="top" align="left"> <code><font size="2">max_retries_at_max_backoff</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> How many times, after Splunk has reached <code><font size="2">max_backoff</font></code> seconds between reconnection attempts with a WMI provider, to continue to attempt to reconnect to that provider.
</td><td valign="top" align="left"> 2
</td></tr><tr><td valign="top" align="left"> <code><font size="2">checkpoint_sync_interval</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> How long, in seconds, to wait for state data to be flushed to disk.
</td><td valign="top" align="left"> 2
</td></tr></table><h5> <a name="real-timewindowsperformancemonitoring_input-specific_settings"><span class="mw-headline" id="Input-specific_settings"> Input-specific settings </span></a></h5>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" width="175" align="left"> <code><font size="2">interval</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="top" align="left"> How often, in seconds, to poll for new data.  If this attribute is not present, the input will not run, as there is no default.
</td><td valign="top" width="75" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">server</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> One or more valid servers against which you wish to monitor performance. Multiple entries are separated by commas.
</td><td valign="top" align="left"> The local machine
</td></tr><tr><td valign="top" align="left"> <code><font size="2">event_log_file</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> The names of one or more Windows event log channels to poll. This attribute tells Splunk Enterprise that the incoming data is in event log format.<br><br><p><b>Note:</b> Do not use the <code><font size="2">event_log_file</font></code> attribute in a stanza that already contains the <code><font size="2">wql</font></code> attribute.
</p>
</td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">wql</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> A valid Windows Query Language (WQL) statement that specifies the performance object(s), counter(s), and instance(s) you wish to poll remotely. This attribute tells Splunk Enterprise to expect data from a WMI provider.<br><br><p><b>Note:</b> Do not use the <code><font size="2">wql</font></code> attribute in a stanza that already contains the <code><font size="2">event_log_file</font></code> attribute.
</p>
</td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">namespace</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> The namespace in which the WMI provider you want to query resides. The value for this attribute can be either relative (<code><font size="2">Root\CIMV2</font></code>) or absolute (<code><font size="2">\\SERVER\Root\CIMV2</font></code>), but <i>must</i> be relative if you specify the <code><font size="2">server</font></code> attribute.<br><br><p><b>Note:</b> Only use the <code><font size="2">namespace</font></code> attribute in a stanza that contains the <code><font size="2">wql</font></code> attribute.
</p>
</td><td valign="top" align="left"> <code><font size="2">Root\CIMV2</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> The desired index to route performance counter data to.
</td><td valign="top" align="left"> <code><font size="2">default</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">current_only</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> The characteristics and interaction of WMI-based event collections.<br><br><ul><li> if <code><font size="2">wql</font></code> is defined, this attribute tells Splunk Enterprise whether or not it should expect an event notification query. Set to 1 to tell Splunk to expect an event notification query, and 0 to tell it expect a standard query.  See below for additional requirements on WQL and event notification queries.
</li><li> if <code><font size="2">event_log_file</font></code> is defined, tells Splunk whether or not to only capture events that occur when Splunk is running. Set to 1 to tell Splunk to only capture events that occur when Splunk is running, and 0 to gather events from the last checkpoint or, if no checkpoint exists, the oldest events available.
</li></ul></td><td valign="top" align="left"> N/A
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> No
</td><td valign="top" align="left"> Tells Splunk whether or not to gather the performance data defined in this input. Set this to 1 to disable performance monitoring for this stanza, and 0 to enable it.
</td><td valign="top" align="left"> 0
</td></tr></table><p>The following example of <code><font size="2">wmi.conf</font></code> gathers local disk and memory performance metrics and places them into the 'wmi_perfmon' index:
</p>
<div class="samplecode"><code><font size="2"><br>[settings]<br>initial_backoff = 5<br>max_backoff = 20<br>max_retries_at_max_backoff = 2<br>checkpoint_sync_interval = 2<br><br># Gather disk and memory performance metrics from the local system every second.<br># Store event in the "wmi_perfmon" Splunk index.<br><br>[WMI:LocalPhysicalDisk]<br>interval = 1<br>wql = select Name, DiskBytesPerSec, PercentDiskReadTime,PercentDiskWriteTime, PercentDiskTime from \<br>&nbsp;Win32_PerfFormattedData_PerfDisk_PhysicalDisk<br>disabled = 0<br>index = wmi_perfmon<br><br>[WMI:LocalMainMemory]<br>interval = 10<br>wql = select CommittedBytes, AvailableBytes, PercentCommittedBytesInUse, Caption from \<br>&nbsp;Win32_PerfFormattedData_PerfOS_Memory<br>disabled = 0<br>index = wmi_perfmon<br></font></code></div>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_additional_information_on_wql_query_statements"><span class="mw-headline" id="Additional_information_on_WQL_query_statements"> Additional information on WQL query statements </span></a></i></b></font></h4>
<p>WQL queries must be structurally and syntactically correct. If they are not, you might get undesirable results or no results at all when specifying them. In particular, when writing event notification queries (by specifying <code><font size="2">current_only=1</font></code> in the stanza in which a WQL query resides), your WQL statement must contain one of the clauses that specify such a query (<code><font size="2">WITHIN, GROUP,</font></code> and/or <code><font size="2">HAVING</font></code>).  Review this MSDN article on Querying with WQL for additional information.
</p><p>Splunk Web eliminates problems with WQL syntax by generating the appropriate WQL queries when you use it to create performance monitor inputs.
</p>
<h3> <a name="real-timewindowsperformancemonitoring_caveats"><span class="mw-headline" id="Caveats">Caveats</span></a></h3>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_increased_memory_usage_during_collection_of_performance_metrics"><span class="mw-headline" id="Increased_memory_usage_during_collection_of_performance_metrics">Increased memory usage during collection of performance metrics</span></a></i></b></font></h4>
<p>When collecting data on some performance objects, such as the "Thread" object and its associated counters, you might notice increased memory usage in Splunk. This is normal, as certain performance objects consume more memory than others during the collection process.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_processor_time_counters_do_not_return_values_of_higher_than_100"><span class="mw-headline" id="Processor_Time_counters_do_not_return_values_of_higher_than_100">Processor Time counters do not return values of higher than 100</span></a></i></b></font></h4>
<p>Due to how Microsoft tallies CPU usage with the <code><font size="2">Processor:% Processor Time</font></code> and <code><font size="2">Process:% Processor Time</font></code> counters, these counters do not return a value of more than 100 regardless of the number of CPUs or cores in the system. This is by design - these counters subtract the amount of time spent on the Idle process from 100%.
</p>
<h4><font size="3"><b><i> <a name="real-timewindowsperformancemonitoring_on_non-english_installations.2c_the_useenglishonly_attribute_has_limitations"><span class="mw-headline" id="On_non-English_installations.2C_the_useEnglishOnly_attribute_has_limitations">On non-English installations, the useEnglishOnly attribute has limitations</span></a></i></b></font></h4>
<p>When you edit inputs.conf on a non-English system to enable performance monitoring, there are some limitations to how the <code><font size="2">useEnglishOnly</font></code> attribute works.
</p><p>If you set the attribute to <code><font size="2">true</font></code>, you cannot use wildcards or regular expressions for the <code><font size="2">object</font></code> and <code><font size="2">counters</font></code> attributes. These attributes must contain specific entries based on valid English values as defined in the Performance Data Helper library. You can specify a wildcard for the <code><font size="2">instances</font></code> attribute. Here's an example:
</p>
<div class="samplecode"><code><font size="2"><br>[perfmon://Processor]<br>object = Processor<br>instances = _Total<br>counters =&nbsp;% Processor Time;% User Time<br>useEnglishOnly = 1<br>interval = 30<br>disabled = 0<br></font></code></div>
<p>Note the <code><font size="2">counters</font></code> attribute contain values in English even though the system language is not English.
</p><p>If you set the attribute to <code><font size="2">false</font></code>, you can use wildcards and regular expressions for these attributes, but you must specify values based on the operating system's language. An example of a stanza on a system running in French follows:
</p>
<div class="samplecode"><code><font size="2"><br>[perfmon://FrenchProcs]<br>counters = *<br>disabled = 0<br>useEnglishOnly = 0<br>interval = 30<br>object = Processeur<br>instances = *<br></font></code></div>
<p>Note in this example that the <code><font size="2">object</font></code> attribute has been set to <code><font size="2">Processeur</font></code>, which is the French equivalent of <code><font size="2">Processor</font></code>. If you specify English values here, Splunk Enterprise will not find the performance object or instance.
</p>
<h5> <a name="real-timewindowsperformancemonitoring_additional_impacts_of_using_the_useenglishonly_attribute"><span class="mw-headline" id="Additional_impacts_of_using_the_useEnglishOnly_attribute">Additional impacts of using the useEnglishOnly attribute</span></a></h5>
<p>There are additional items to consider when using the attribute.
</p>
<ul><li> When you use Splunk Web to create performance monitor inputs on a non-English operating system, it always specifies <code><font size="2">useEnglishOnly = false</font></code>. 
</li><li> Additionally, you can enable, disable, clone, or delete these stanzas within Splunk Web. You cannot, however, edit them in Splunk Web unless the operating system's locale matches the locale specified in the stanza.
</li><li> You can use Splunk Web to enable, disable, clone, or delete a performance monitor stanza with the <code><font size="2">useEnglishOnly</font></code> attribute set to true. However, you cannot edit them in Splunk Web unless the system's locale is English.
</li></ul><a name="monitorwindowshostinformation"></a><h2> <a name="monitorwindowshostinformation_monitor_windows_host_information"><span class="mw-headline" id="Monitor_Windows_host_information"> Monitor Windows host information</span></a></h2>
<p>Splunk Enterprise supports the monitoring of Windows host information - detailed statistics about the local Windows machine. It can collect the following information about the Windows host:
</p>
<ul><li> <b>General computer:</b> The make and model of the computer, its host name and the Active Directory domain it's in.
</li><li> <b>Operating system:</b> The version and build number of the operating system installed on the computer, as well as any service packs; the computer name; the last time it was started, the amount of installed and free memory, and the system drive.
</li><li> <b>Processor:</b> The make and model of the CPU(s) installed in the system, their speed and version, the number of processor(s) and core(s), and the processor ID.
</li><li> <b>Disk:</b> A listing of all drives available to the system and, if available, their file system type and total and available space.
</li><li> <b>Network Adapter:</b> Information about the installed network adapters in the system, including manufacturer, product name and MAC address.
</li><li> <b>Service:</b> Information about the installed services on the system, including name, display name, description, path, service type, start mode, state, and status.
</li><li> <b>Process:</b> Information on the running processes on the system, including the name, the command line (with arguments), when they were started, and the executable's path.
</li><li> <b>Application:</b> Information on the applications that have been installed on the system, including their names and serial numbers, when and where they were installed, vendor, and version number.
</li></ul><p>Both full instances of Splunk Enterprise and universal forwarders support local collection of host information.
</p><p>The host monitor input runs as a process called <code><font size="2">splunk-winhostmon.exe</font></code>.  This process runs once for every input defined, at the interval specified in the input. You can configure host monitoring using Splunk Web or <code><font size="2">inputs.conf</font></code>.
</p>
<h3> <a name="monitorwindowshostinformation_why_monitor_host_information.3f"><span class="mw-headline" id="Why_monitor_host_information.3F"> Why monitor host information?</span></a></h3>
<p>Windows host monitoring allows you to get detailed information about your Windows systems. You can monitor any changes to the system, such as installation and removal of software, the starting and stopping of services, and even uptime. When a system failure occurs, you can use Windows host monitoring information as a first step into the forensic process. With the Splunk Enterprise search language, you can develop dashboards and views which can give your team at-a-glance statistics on all machines in your Windows network.
</p>
<h3> <a name="monitorwindowshostinformation_what.27s_required_to_monitor_host_information.3f"><span class="mw-headline" id="What.27s_required_to_monitor_host_information.3F"> What's required to monitor host information?</span></a></h3>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor host information
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as the Local System user or a local administrator account to read all local host information
</td></tr></table><h3> <a name="monitorwindowshostinformation_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enterprise must run as the Local System user to collect Windows host information by default.
</p><p>Splunk recommends using a universal forwarder to send host information from remote machines to an indexer. Review "Introducing the universal forwarder" in the Forwarding Data manual for information about how to install, configure and use the forwarder to collect Windows host data.
</p><p>If you choose to install forwarders on your remote machines to collect Windows host data, then you can install the forwarder as the Local System user on these machines. The Local System user has access to all data on the local machine, but not on remote machines.
</p><p>If you run Splunk Enterprise as a user other than the "Local System" user, then that user must have local Administrator rights to the machine from which you want to collect host data. The user requires other explicit permissions, as detailed in "Choose the Windows user Splunk Enterprise should run as" in the Installation manual.
</p>
<h3> <a name="monitorwindowshostinformation_use_splunk_web_to_configure_host_monitoring"><span class="mw-headline" id="Use_Splunk_Web_to_configure_host_monitoring"> Use Splunk Web to configure host monitoring </span></a></h3>
<h5> <a name="monitorwindowshostinformation_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h5>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor host information from the local Windows machine.
</p>
<h5> <a name="monitorwindowshostinformation_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h5>
<p>'<i>1.</i> In the left pane, locate and select <b>Local Windows host monitoring</b>.
</p><p><b>2.</b> In the <b>Collection Name</b> field, enter a unique name for this input that you will remember.
</p><p><b>3.</b> In the <b>Event Types</b> list box, locate the host monitoring event types you want this input to monitor.
</p><p><b>4.</b> Click once on each type you want to monitor. Splunk Enterprise moves the type from the "Available type(s)" window to the "Selected type(s)" window.
</p><p><b>5.</b> To unselect a type, click on its name in the "Selected type(s)" window. Splunk Enterprise moves the counter from the "Selected type(s)" window to the "Available type(s)" window.
</p><p><b>6.</b> To select or unselect all of the types, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the types can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>7.</b> In the <b>Interval</b> field, enter the time, in seconds, between polling attempts for the input.
</p><p><b>8.</b> Click the green <b>Next</b> button. 
</p>
<h5> <a name="monitorwindowshostinformation_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h5>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h5> <a name="monitorwindowshostinformation_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h5>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified host information.
</p>
<h3> <a name="monitorwindowshostinformation_use_inputs.conf_to_configure_host_monitoring"><span class="mw-headline" id="Use_inputs.conf_to_configure_host_monitoring"> Use inputs.conf to configure host monitoring</span></a></h3>
<p>You can edit <code><font size="2">inputs.conf</font></code> to configure host monitoring. For more information on configuring data inputs with <code><font size="2">inputs.conf</font></code>, read "<a href="#configureyourinputs_edit_inputs.conf" class="external text">Configure your inputs</a>" in this manual.
</p><p><b>Note:</b> You can always review the defaults for a configuration file by looking at the examples in <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code> or at the spec file in the Admin manual.
</p>
<ul><li> For more information on how to edit configuration files, see "About configuration files" in the Admin manual.
</li></ul><p>To enable host monitoring inputs by editing <code><font size="2">inputs.conf</font></code>:
</p><p><b>1.</b>  Create an inputs.conf in <code><font size="2">%SPLUNK_HOME%\etc\system\local</font></code> and open it for editing.
</p><p><b>2.</b> Open <code><font size="2">%SPLUNK_HOME%\etc\system\default\inputs.conf</font></code> and review it for the Windows event log inputs you want to enable.
</p><p><b>3.</b> Copy the Windows event log input stanzas you want to enable from <code><font size="2">%SPLUNK_HOME%\etc\system\default\inputs.conf</font></code>.
</p><p><b>4.</b> Paste the stanzas you copied into <code><font size="2">%SPLUNK_HOME%\etc\system\local\inputs.conf</font></code>.
</p><p><b>5.</b> Make edits to the stanzas to collect the Windows event log data you desire.
</p><p><b>6.</b> Save <code><font size="2">%SPLUNK_HOME%\etc\system\local\inputs.conf</font></code> and close it.
</p><p><b>7.</b> Restart Splunk Enterprise.
</p><p>The next section describes the specific configuration values for host monitoring.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowshostinformation_windows_host_monitor_configuration_values"><span class="mw-headline" id="Windows_host_monitor_configuration_values"> Windows host monitor configuration values</span></a></i></b></font></h4>
<p>Splunk Enterprise uses the following attributes in <code><font size="2">inputs.conf</font></code> to monitor Windows host information:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="top" width="175" align="left"> <code><font size="2">interval</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> How often, in seconds, to poll for new data. If you set the interval to a negative number, Splunk Enterprise runs the input one time. If you do not define this attribute, the input will not run, as there is no default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">type</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> The type of host information to monitor. Can be one of <code><font size="2">Computer, operatingSystem, processor, disk, networkAdapter, service, process, driver</font></code>, or <code><font size="2">application</font></code>. The input will not run if this variable is not present.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not to run the input at all. If you set this attribute to <code><font size="2">1</font></code>, then Splunk Enterprise does not run the input.
</td></tr></table><h4><font size="3"><b><i> <a name="monitorwindowshostinformation_examples_of_windows_host_monitoring_configurations"><span class="mw-headline" id="Examples_of_Windows_host_monitoring_configurations"> Examples of Windows host monitoring configurations</span></a></i></b></font></h4>
<p>Following are some examples of how to use the Windows host monitoring configuration attributes in <code><font size="2">inputs.conf</font></code>
</p>
<div class="samplecode"><code><font size="2"><br># Queries computer information.<br>[WinHostMon://computer]<br>type = Computer<br>interval = 300<br><br># Queries OS information. <br># 'interval' set to a negative number tells Splunk Enterprise to<br># run the input once only. <br>[WinHostMon://os]<br>type = operatingSystem<br>interval = -1<br><br># Queries processor information.<br>[WinHostMon://processor]<br>type = processor<br>interval = -1<br><br># Queries hard disk information.<br>[WinHostMon://disk]<br>type = disk<br>interval = -1<br><br># Queries network adapter information.<br>[WinHostMon://network]<br>type = networkAdapter<br>interval = -1<br><br># Queries service information.<br># This example runs the input ever 5 minutes.<br>[WinHostMon://service]<br>type = service<br>interval = 300<br><br># Queries information on running processes.<br># This example runs the input every 5 minutes.<br>[WinHostMon://process]<br>type = process<br>interval = 300<br><br># Queries information on installed applications.<br># This example runs the input every 5 minutes.<br>[WinHostMon://application]<br>type = application<br>interval = 300<br>&nbsp;<br></font></code></div>
<h3> <a name="monitorwindowshostinformation_fields_for_windows_host_monitoring_data"><span class="mw-headline" id="Fields_for_Windows_host_monitoring_data"> Fields for Windows host monitoring data </span></a></h3>
<p>When Splunk Enterprise indexes data from Windows host monitoring inputs, it sets the <b>source</b> for received events to <code><font size="2">windows</font></code>. It sets the <b>source type</b> of the incoming events to <code><font size="2">WinHostMon</font></code>.
</p>
<h3> <a name="monitorwindowshostinformation_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around Windows host information.
</p>
<a name="monitorwindowsprinterinformation"></a><h2> <a name="monitorwindowsprinterinformation_monitor_windows_printer_information"><span class="mw-headline" id="Monitor_Windows_printer_information"> Monitor Windows printer information</span></a></h2>
<p>Splunk Enterprise supports the monitoring of Windows print subsystem information - statistics about all of the printers and drivers, print jobs, and printer ports on the local machine. It can collect the following print system information:
</p>
<ul><li> <b>Printer:</b> Information on the print subsystem, such as the status of installed printers, and when printers get added or deleted.
</li><li> <b>Job:</b> Information on print jobs, including who has printed what, details on the jobs, and the status of existing jobs.
</li><li> <b>Driver:</b> Information on the print driver subsystem, including information on existing print drivers, and when a print driver gets added or removed.
</li><li> <b>Port:</b> Information on printer ports installed on the system, and when they get added or removed.
</li></ul><p>Both full instances of Splunk Enterprise and universal forwarders support local collection of printer subsystem information.
</p><p>The printer monitor input runs as a process called <code><font size="2">splunk-winprintmon.exe</font></code>.  This process runs once for every input defined, at the interval specified in the input. You can configure printer subsystem monitoring using Splunk Web or <code><font size="2">inputs.conf</font></code>.
</p>
<h3> <a name="monitorwindowsprinterinformation_why_monitor_printer_information.3f"><span class="mw-headline" id="Why_monitor_printer_information.3F"> Why monitor printer information?</span></a></h3>
<p>Windows printer monitoring allows you to get detailed information about your Windows printer subsystem. You can monitor any changes to the system, such as installation and removal of printers, print drivers, and ports, the starting and completion of print jobs, and learn who printed what when. When a printer failure occurs, you can use print monitoring information as a first step into the forensic process. With Splunk's search language, you can develop dashboards and views which can give your team at-a-glance statistics on all printers in your Windows network.
</p>
<h3> <a name="monitorwindowsprinterinformation_what.27s_required_to_monitor_printer_information.3f"><span class="mw-headline" id="What.27s_required_to_monitor_printer_information.3F"> What's required to monitor printer information?</span></a></h3>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Required permissions:
</th></tr><tr><td valign="top" align="left"> Monitor host information
</td><td valign="top" align="left"> * Splunk Enterprise must run on Windows<br>* Splunk Enterprise must run as the Local System user to read all local host information
</td></tr></table><h3> <a name="monitorwindowsprinterinformation_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enterprise must run as the Local System user to collect Windows print subsystem information by default.
</p><p>Splunk recommends using a universal forwarder to send printer information from remote machines to an indexer. Review "Introducing the universal forwarder" in the Forwarding Data manual for information about how to install, configure and use the forwarder to collect print subsystem data.
</p><p>If you choose to install forwarders on your remote machines to collect printer subsystem data, then you can install the forwarder as the Local System user on these machines. The Local System user has access to all data on the local machine, but not on remote machines.
</p><p>If you run Splunk Enterprise as a user other than the "Local System" user, then that user must have local Administrator rights to the machine from which you want to collect printer information. The user requires other explicit permissions, as detailed in "Choose the Windows user Splunk Enterprise should run as" in the Installation manual.
</p>
<h3> <a name="monitorwindowsprinterinformation_use_splunk_web_to_configure_printer_information"><span class="mw-headline" id="Use_Splunk_Web_to_configure_printer_information"> Use Splunk Web to configure printer information </span></a></h3>
<h5> <a name="monitorwindowsprinterinformation_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h5>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Local Windows print monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor print information from the local Windows machine.
</p><p><b>3.</b> In the left pane, locate and select <b>Local Windows print monitoring</b>.
</p>
<h5> <a name="monitorwindowsprinterinformation_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h5>
<p><b>1.</b> In the <b>Collection Name</b> field, enter a unique name for this input that you will remember.
</p><p><b>2.</b> In the <b>Event Types</b> list box, locate the print monitoring event types you want this input to monitor.
</p><p><b>3.</b> Click once on each type you want to monitor. Splunk Enterprise moves the type from the "Available type(s)" window to the "Selected type(s)" window.
</p><p><b>4.</b> To unselect a type, click on its name in the "Selected type(s)" window. Splunk Enterprise moves the counter from the "Selected type(s)" window to the "Available type(s)" window.
</p><p><b>5.</b> To select or unselect all of the types, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the types can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>6.</b> In the <b>Baseline</b> control, click the <b>Yes</b> radio button to tell Splunk Enterprise to run the input as soon as it starts, and no further. Click <b>No</b> to tell Splunk Enterprise to run the input at the interval specified in the <b>Interval (in minutes)</b> field.
</p><p><b>7.</b> Click the green <b>Next</b> button. 
</p>
<h5> <a name="monitorwindowsprinterinformation_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h5>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h5> <a name="monitorwindowsprinterinformation_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h5>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified print information.
</p>
<h3> <a name="monitorwindowsprinterinformation_use_inputs.conf_to_configure_host_monitoring"><span class="mw-headline" id="Use_inputs.conf_to_configure_host_monitoring"> Use inputs.conf to configure host monitoring</span></a></h3>
<p>You can edit <code><font size="2">inputs.conf</font></code> to configure host monitoring. For more information on configuring data inputs with <code><font size="2">inputs.conf</font></code>, read "<a href="#configureyourinputs_edit_inputs.conf" class="external text">Configure your inputs</a>" in this manual.
</p><p><b>Note:</b> You can always review the defaults for a configuration file by looking at the examples in <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code> or at the spec file in the Admin manual.
</p>
<ul><li> For more information on how to edit configuration files, see "About configuration files" in the Admin manual.
</li></ul><p>To enable print monitoring inputs by editing <code><font size="2">inputs.conf</font></code>:
</p><p><b>1.</b> Copy inputs.conf from <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code>  to  <code><font size="2">etc\system\local</font></code> .
</p><p><b>2.</b> Use Explorer or the <code><font size="2">ATTRIB</font></code> command to remove the file's "Read Only" flag.
</p><p><b>3.</b> Open the file and edit it to enable Windows print monitoring inputs.
</p><p><b>4.</b> Restart Splunk.
</p><p>The next section describes the specific configuration values for host monitoring.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsprinterinformation_print_monitoring_configuration_values"><span class="mw-headline" id="Print_monitoring_configuration_values"> Print monitoring configuration values</span></a></i></b></font></h4>
<p>Splunk Enterprise uses the following attributes in <code><font size="2">inputs.conf</font></code> to monitor Windows printer subsystem information:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Required?
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="top" align="left"> <code><font size="2">type</font></code>
</td><td valign="top" align="left"> Yes
</td><td valign="center" align="left"> The type of host information to monitor. Can be one of <code><font size="2">printer, job, driver</font></code>, or <code><font size="2">port</font></code>. The input will not run if this variable is not present.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">baseline</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not to generate a baseline of the existing state of the printer, job, driver, or port. If you set this attribtue to <code><font size="2">1,</font></code> then Splunk Enterprise writes a baseline. This might take additional time and CPU resources when Splunk Enterprise starts.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled</font></code>
</td><td valign="top" align="left"> No
</td><td valign="center" align="left"> Whether or not to run the input at all. If you set this attribute to <code><font size="2">1</font></code>, then Splunk Enterprise does not run the input.
</td></tr></table><h4><font size="3"><b><i> <a name="monitorwindowsprinterinformation_examples_of_windows_host_monitoring_configurations"><span class="mw-headline" id="Examples_of_Windows_host_monitoring_configurations"> Examples of Windows host monitoring configurations </span></a></i></b></font></h4>
<p>Following are some examples of how to use the Windows host monitoring configuration attributes in <code><font size="2">inputs.conf</font></code>.
</p>
<code><font size="2"><br># Monitor printers on system.<br>[WinPrintMon://printer]<br>type = printer<br>baseline = 0<br><br># Monitor print jobs.<br>[WinPrintMon://job]<br>type = job<br>baseline = 1<br><br># Monitor printer driver installation and removal.<br>[WinPrintMon://driver]<br>type = driver<br>baseline = 1<br><br># Monitor printer ports.<br>[WinPrintMon://port]<br>type = port<br>baseline = 1<br></font></code>
<h3> <a name="monitorwindowsprinterinformation_fields_for_windows_print_monitoring_data"><span class="mw-headline" id="Fields_for_Windows_print_monitoring_data">Fields for Windows print monitoring data</span></a></h3>
<p>When Splunk Enterprise indexes data from Windows print monitoring inputs, it sets the <b>source</b> for received events to <code><font size="2">windows</font></code>. It sets the <b>source type</b> of the incoming events to <code><font size="2">WinPrintMon</font></code>.
</p>
<h3> <a name="monitorwindowsprinterinformation_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around Windows print monitoring.
</p>
<a name="monitorwindowsnetworkinformation"></a><h2> <a name="monitorwindowsnetworkinformation_monitor_windows_network_information"><span class="mw-headline" id="Monitor_Windows_network_information"> Monitor Windows network information</span></a></h2>
<p>Splunk Enterprise supports the monitoring of Windows network information - detailed statistics about network activity into or out of a Windows machine. It can collect the following network information:
</p>
<ul><li> <b>Network activity:</b> When a Windows machine performs any kind of network action, you can use Splunk Enterprise to monitor it.
</li><li> <b>Address family:</b> Whether or not the network transaction was made over the IPv4 or IPv6 protocols.
</li><li> <b>Packet type:</b> The type of packet sent in the transaction (for example, a 'connect' or 'transport' packet.
</li><li> <b>Protocol:</b> Whether or not the network transaction was made over the TCP or UDP protocols.
</li><li> <b>Hosts:</b> Information about the hosts involved in the network transaction, including the local and remote hosts, the ports which the hosts used to communicate, and any available DNS information.
</li><li> <b>Application:</b> Which application initiated the network transaction.
</li><li> <b>User:</b> The user that initiated the network transaction, including his or her ID and SID.
</li><li> <b>Miscellany:</b> Miscellaneous information about the network transaction, including the transport header size and whether or not the transaction was protected by IPSec.
</li></ul><p>Both full instances of Splunk Enterprise and universal forwarders support local collection of network information.
</p><p>The network monitor input runs as a process called <code><font size="2">splunk-netmon.exe</font></code>.  This process runs once for every input defined, at the interval specified in the input. You can configure network monitoring using Splunk Web or <code><font size="2">inputs.conf</font></code>.
</p><p><b>Important:</b> Windows network monitoring in Splunk Enterprise is only available on 64-bit Windows systems. It does not function on 32-bit Windows systems.
</p>
<h3> <a name="monitorwindowsnetworkinformation_why_monitor_network_information.3f"><span class="mw-headline" id="Why_monitor_network_information.3F"> Why monitor network information?</span></a></h3>
<p>Windows network monitoring allows you to get detailed information about your Windows network activity. You can monitor all transactions on the network, such as the initiation of a network connection by a user or process or whether or not the transaction uses the IPv4 or IPv6 address families. The network monitoring facilities in Splunk Enterprise can allow you to detect and interrupt an incoming (or outgoing) denial of service attack by telling you which machines are involved. With Splunk's search language, you can develop dashboards and views which can give your team at-a-glance statistics on all Windows network operations.
</p>
<h3> <a name="monitorwindowsnetworkinformation_what.27s_required_to_monitor_network_information.3f"><span class="mw-headline" id="What.27s_required_to_monitor_network_information.3F"> What's required to monitor network information?</span></a></h3>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Activity:
</th><th valign="top" bgcolor="#C0C0C0"> Requirements:
</th></tr><tr><td valign="top" align="left"> Monitor network information
</td><td valign="top" align="left">
<ul><li> Splunk must run on Windows
</li><li> The Windows version on the machine must be one of:<br><ul><li> Windows Vista
</li><li> Windows 7
</li><li> Windows 8
</li><li> Windows Server 2008
</li><li> Windows Server 2008 R2, or 
</li><li> Windows Server 2012
</li></ul></li><li> The Windows system must have all available updates and service packs applied, including the Kernel-Mode Driver Framework version 1.11 update on machines that run Windows Vista, Windows 7, Windows Server 2008, and Windows Server 2008 R2.
</li><li> Splunk must run as the Local System user or a local administrator account to read all local host information<br></li></ul></td></tr></table><h3> <a name="monitorwindowsnetworkinformation_security_and_remote_access_considerations"><span class="mw-headline" id="Security_and_remote_access_considerations"> Security and remote access considerations </span></a></h3>
<p>Splunk Enteprise must run as the Local System user to collect Windows network information by default.
</p><p>Splunk recommends using a universal forwarder to send host information from remote machines to an indexer. Review "Introducing the universal forwarder" in the Forwarding Data manual for information about how to install, configure and use the forwarder to collect Windows host data.
</p><p>If you choose to install forwarders on your remote machines to collect Windows network information, then you can install the forwarder as the Local System user on these machines. The Local System user has access to all data on the local machine, but not on remote machines.
</p><p>If you run Splunk Enterprise as a user other than the "Local System" user, then that user must have local Administrator rights to the machine from which you want to collect host data. The user requires other explicit permissions, as detailed in "Choose the Windows user Splunk Enterprise should run as" in the Installation manual.
</p>
<h3> <a name="monitorwindowsnetworkinformation_use_splunk_web_to_configure_host_monitoring"><span class="mw-headline" id="Use_Splunk_Web_to_configure_host_monitoring"> Use Splunk Web to configure host monitoring </span></a></h3>
<h5> <a name="monitorwindowsnetworkinformation_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h5>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Local Windows network monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor network information from the local Windows machine, or <b>Forward</b> to forward network information from another Windows machine. Splunk Enterprise loads the "Add Data - Select Source" page.
</p><p><b>Note:</b> Forwarding network information requires additional setup.
</p><p><b>3.</b> In the left pane, locate and select <b>Local Windows network monitoring</b>.
</p>
<h5> <a name="monitorwindowsnetworkinformation_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h5>
<p><b>1.</b> In the <b>Network Monitor Name</b> field, enter a unique name for this input that you will remember.
</p><p><b>2.</b> Under <b>Address family</b>, check the IP address family types that you want Splunk Enterprise to monitor (either IPv4 or IPv6.)
</p><p><b>3.</b> Under <b>Packet Type</b>, check the packet types you want the input to monitor (any of <b>connect</b>, <b>accept</b>, or <b>transport</b>.)
</p><p><b>4.</b> Under <b>Direction</b>, check the network directions that you want the input to monitor (any of <b>inbound</b> (toward the monitoring host) or <b>outbound</b> (away from the monitoring host).
</p><p><b>5.</b>  Under <b>Protocol</b>, check the network protocol types that you want the input to monitor (any of <b>tcp</b> (Transmission Control Protocol) or <b>udp</b> (User Datagram Protocol).
</p><p><b>6.</b> In the <b>Remote address</b> text field, enter the host name or IP address of a remote host whose network communications with the monitoring host that you want the input to monitor.
</p><p><b>Note:</b> If you want to monitor multiple hosts, you can do so by entering a regular expression in this field.
</p><p><b>7.</b> In the <b>Process</b> text field, enter the partial or full name of a process whose network communications you want the input to monitor.
</p><p><b>Note:</b> As with the remote address, you can monitor multiple processes by entering a regular expression.
</p><p><b>8.</b>  In the <b>User</b> text field, enter the partial or full name of a user whose network communications you want the input to monitor.
</p><p><b>Note:</b> As with the remote address and process entries, you can monitor multiple users by entering a regular expression in this field.
</p><p><b>9.</b> Click the green <b>Next</b> button. 
</p>
<h5> <a name="monitorwindowsnetworkinformation_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h5>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h5> <a name="monitorwindowsnetworkinformation_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h5>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified print information.
</p>
<h3> <a name="monitorwindowsnetworkinformation_use_inputs.conf_to_configure_network_monitoring"><span class="mw-headline" id="Use_inputs.conf_to_configure_network_monitoring"> Use inputs.conf to configure network monitoring</span></a></h3>
<p>You can edit <code><font size="2">inputs.conf</font></code> to configure network monitoring. For more information on configuring data inputs with <code><font size="2">inputs.conf</font></code>, read "<a href="#configureyourinputs_edit_inputs.conf" class="external text">Configure your inputs</a>" in this manual.
</p><p><b>Note:</b> You can always review the defaults for a configuration file by looking at the examples in <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code> or at the spec file in the Admin manual.
</p>
<ul><li> For more information on how to edit configuration files, see "About configuration files" in the Admin manual.
</li></ul><p>To enable network monitoring inputs by editing <code><font size="2">inputs.conf</font></code>:
</p><p><b>1.</b> Copy inputs.conf from <code><font size="2">%SPLUNK_HOME%\etc\system\default</font></code>  to  <code><font size="2">etc\system\local</font></code>.
</p><p><b>2.</b> Use Explorer or the <code><font size="2">ATTRIB</font></code> command to remove the file's "Read Only" flag.
</p><p><b>3.</b> Open the file and edit it to enable Windows network monitoring inputs.
</p><p><b>4.</b> Restart Splunk.
</p><p>The next section describes the specific configuration values for host monitoring.
</p>
<h4><font size="3"><b><i> <a name="monitorwindowsnetworkinformation_windows_host_monitor_configuration_values"><span class="mw-headline" id="Windows_host_monitor_configuration_values"> Windows host monitor configuration values</span></a></i></b></font></h4>
<p>To define a Windows network monitoring input, use the <code><font size="2">[WinNetMon://&lt;name&gt;]</font></code> stanza in <code><font size="2">inputs.conf</font></code>. Splunk Enterprise uses the following attributes to configure the Windows network monitor input:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute:
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description:
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default:
</th></tr><tr><td valign="top" align="left"> disabled = [0|1]
</td><td valign="top" align="left">
<ul><li> Specifies whether the input is enabled or not.
</li><li> Set to 1 to disable the input, and 0 to enable it.
</li></ul></td><td valign="top" align="left"> 0 (enabled)
</td></tr><tr><td valign="top" align="left"> index = &lt;string&gt;
</td><td valign="top" align="left">
<ul><li> Specifies the index that this input should send the data to.
</li><li> This attribute is optional.  
</li></ul></td><td valign="top" align="left"> The default index
</td></tr><tr><td valign="top" align="left"> remoteAddress = &lt;regular expression&gt;
</td><td valign="top" align="left">
<ul><li> If set, matches against the remote IP address involved in the network transaction.
</li><li> Accepts regular expressions which represent IP addresses only, not host names.
</li><li> Filters out events with remote addresses that do not match the regular expression.
</li><li> Passes through events with remote addresses that match the regular expression.
</li><li> Example: 192\.163\..* matches all IP addresses in the 192.163.x.x range.
</li></ul></td><td valign="top" align="left"> (empty string - matches everything)
</td></tr><tr><td valign="top" align="left"> process = &lt;regular expression&gt;
</td><td valign="top" align="left">
<ul><li> If set, matches against the process or application name which performed network access
</li><li> Filters out events generated by processes that do not match the regular expression.
</li><li> Passes through events generated by processes that match the regular expression.
</li></ul></td><td valign="top" align="left"> (empty string - matches all processes or applications)
</td></tr><tr><td valign="top" align="left"> user = &lt;regular expression&gt;
</td><td valign="top" align="left">
<ul><li> If set, matches against the user name which performed network access
</li><li> Filters out events generated by users that do not match the regular expression.
</li><li> Passes through events generated by users that match the regular expression.
</li></ul></td><td valign="top" align="left"> (empty string - includes access by all users)
</td></tr><tr><td valign="top" align="left"> addressFamily = [ipv4;ipv6]
</td><td valign="top" align="left">
<ul><li> If set, matches against the address family used in the network access.
</li><li> Accepts semicolon-separated values, for example "ipv4;ipv6".
</li></ul></td><td valign="top" align="left"> (empty string - includes all IP traffic.)
</td></tr><tr><td valign="top" align="left"> packetType = [connect;accept;transport]
</td><td valign="top" align="left">
<ul><li> If set, matches against the packet type used in the transaction.
</li><li> Accepts semicolon-separated values, for example "connect;transport".
</li></ul></td><td valign="top" align="left"> (empty string - includes all packet types.)
</td></tr><tr><td valign="top" align="left"> direction = [inbound;outbound]
</td><td valign="top" align="left">
<ul><li> If set, matches against the general direction of the network traffic.
</li><li> "Inbound" means traffic coming into the monitoring machine, "outbound" means traffic leaving the monitoring machine.
</li><li> Accepts semicolon-separated values, for example "inbound;outbound".
</li></ul></td><td valign="top" align="left"> (empty string - includes both directions.)
</td></tr><tr><td valign="top" align="left"> protocol = [tcp;udp]
</td><td valign="top" align="left">
<ul><li> If set, matches against the specified network protocol.
</li><li> "tcp" means Transmission Control Protocol, where networks use handshakes to and state to set up transactions.
</li><li> "udp" means User Datagram Protocol, a stateless, "fire and forget" protocol.
</li><li> Accepts semicolon-separated values, for example "tcp;udp".
</li></ul></td><td valign="top" align="left"> (empty string - includes both protocol types.)
</td></tr><tr><td valign="top" align="left"> readInterval = &lt;integer&gt;
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how often, in milliseconds, to read the network monitor filter driver.
</li><li> <b>Advanced option.</b> We recommend that you use the default value unless there is a problem with input performance.
</li><li> Allows for the adjustment of call frequency into the kernel driver. Higher frequencies might affect network performance, while lower frequencies can cause event loss.
</li><li> The minimum legal value is 10 and the maximum legal value is 1000.
</li></ul></td><td valign="top" align="left"> 100
</td></tr><tr><td valign="top" align="left"> driverBufferSize = &lt;integer&gt;
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise the number of network packets it should keep in the network monitor filter driver buffer.
</li><li> <b>Advanced option.</b> We recommend that you use the default value unless there is a problem with input performance.
</li><li> Controls the amount of packets that the driver caches. Lower values might result in event loss, while higher values might increase the size of non-paged memory.
</li><li> The minimum legal value is 128 and the maximum legal value is 8192.
</li></ul></td><td valign="top" align="left"> 1024
</td></tr><tr><td valign="top" align="left"> mode = &lt;string&gt;
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise how to output each event.
</li><li> Splunk Enterprise can output each event in either <code><font size="2">single</font></code> or <code><font size="2">multikv</font></code> (key-value pair) mode.
</li></ul></td><td valign="top" align="left"> <code><font size="2">single</font></code>
</td></tr><tr><td valign="top" align="left"> multikvMaxEventCount = &lt;integer&gt;
</td><td valign="top" align="left">
<ul><li> Tells Splunk Enterprise the maximum amount of events to output when you set <code><font size="2">mode</font></code> to <code><font size="2">multikv</font></code>.
</li><li> <b>Advanced option.</b> We recommend that you use the default value unless there is a problem with input performance.
</li><li> The minimum legal value is 10 and the maximum legal value is 500.
</li></ul></td><td valign="top" align="left"> 100
</td></tr><tr><td valign="top" align="left"> multikvMaxTimeMs = &lt;integer&gt;
</td><td valign="top" align="left">
<ul><li>  Tells Splunk Enterprise the maximum amount of time, in milliseconds, to output mulitkv events when you set <code><font size="2">mode</font></code> to <code><font size="2">multikv</font></code>.
</li><li> <b>Advanced option.</b> We recommend that you use the default value unless there is a problem with input performance.
</li><li> The minimum legal value is 100 and the maximum legal value is 5000.
</li></ul></td><td valign="top" align="left"> 1000
</td></tr></table><h3> <a name="monitorwindowsnetworkinformation_fields_for_windows_network_monitoring_data"><span class="mw-headline" id="Fields_for_Windows_network_monitoring_data"> Fields for Windows network monitoring data </span></a></h3>
<p>When Splunk Enterprise indexes data from Windows network monitoring inputs, it sets the <b>source</b> for received events to <code><font size="2">windows</font></code>. It sets the <b>source type</b> of the incoming events to <code><font size="2">WinNetMon</font></code>.
</p>
<h3> <a name="monitorwindowsnetworkinformation_ensure_that_your_windows_machine_is_fully_patched"><span class="mw-headline" id="Ensure_that_your_Windows_machine_is_fully_patched">Ensure that your Windows machine is fully patched</span></a></h3>
<p>If you encounter issues while running the network monitoring input on a Windows Vista, Windows 7, Windows Server 2008, or Windows Server 2008 R2 machine, make sure that you have updated the machine with all available patches, including the Kernel-Mode Driver Framework version 1.11 Update (http://support.microsoft.com/kb/2685811) that is part of Knowledge Base article 2685811. Network monitoring input might not function if this update is not present on your system.
</p>
<h3> <a name="monitorwindowsnetworkinformation_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around Windows network monitoring.
</p>
<h1>Other ways to get stuff in</h1><a name="monitorfifoqueues"></a><h2> <a name="monitorfifoqueues_monitor_first_in.2c_first_out_.28fifo.29_queues"><span class="mw-headline" id="Monitor_First_In.2C_First_Out_.28FIFO.29_queues"> Monitor First In, First Out (FIFO) queues</span></a></h2>
<p>This topic describes how to configure a First In, First Out (FIFO) input in Splunk Enterprise using <code><font size="2">inputs.conf</font></code>. Splunk Web does not currently support defining FIFO inputs.
</p><p><b>Caution</b>: Data sent via FIFO does not persist in memory and can be an unreliable method for data sources. To ensure your do not lose any data use the <a href="#monitorfilesanddirectories" class="external text">monitor</a> input instead.
</p>
<h3> <a name="monitorfifoqueues_add_a_fifo_input_to_inputs.conf"><span class="mw-headline" id="Add_a_FIFO_input_to_inputs.conf">Add a FIFO input to inputs.conf</span></a></h3>
<p>To add a FIFO input, add a stanza for it to inputs.conf in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  If you have not worked with configuration files before, read "About Configuration Files" in the Admin manual before you begin.
</p><p>Here's the basic syntax for adding a FIFO stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[fifo://&lt;path&gt;]<br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>This input stanza directs Splunk Enterprise to read from a FIFO at the specified path. 
</p><p>You can use the following attributes with FIFO stanzas:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">host = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the host key/field to a static value for this stanza.
<ul><li> Sets the host key's initial value. The key is used during parsing/indexing, in particular to set the host field. It is also the host field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'host::'.
</li></ul></td><td valign="top" align="left"> The IP address or fully qualified domain name of the host where the data originated
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Set the index where events from this input will be stored.
<ul><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'index::'.
</li><li> For more information about the index field, see "How indexing works" in the Managing Indexers and Clusters manual.
</li></ul></td><td valign="top" align="left"> <code><font size="2">main</font></code>, or whatever you have set as your default index.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the sourcetype key/field for events from this input.
<ul><li> Explicitly declares the source type for this data, as opposed to allowing it to be determined automatically. This is important both for searchability and for applying the relevant formatting for this type of data during parsing and indexing.
</li><li> Sets the sourcetype key's initial value. The key is used during parsing/indexing, in particular to set the source type field during indexing. It is also the source type field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'sourcetype::'.
</li><li> For more information about source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a> in this manual.
</li></ul></td><td valign="top" align="left"> * Splunk Enterprise picks a source type based on various aspects of the data. There is no hard-coded default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">source = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the source key/field for events from this input.
<ul><li> <b>Note:</b> Overriding the source key is generally not recommended. Typically, the input layer will provide a more accurate string to aid in problem analysis and investigation, accurately recording the file from which the data was retreived.  Please consider use of source types, tagging, and search wildcards before overriding this value.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'source::'.
</li></ul></td><td valign="top" align="left"> The input file path.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">queue = [parsingQueue|indexQueue]</font></code>
</td><td valign="top" align="left"> * Specifies where the input processor should deposit the events that it reads.
<ul><li> Set to "parsingQueue" to apply <code><font size="2">props.conf</font></code> and other parsing rules to your data.
</li><li> Set to "indexQueue" to send your data directly into the index.
</li></ul></td><td valign="top" align="left"> Defaults to <code><font size="2">parsingQueue</font></code>.
</td></tr></table><a name="monitorchangestoyourfilesystem"></a><h2> <a name="monitorchangestoyourfilesystem_monitor_changes_to_your_file_system"><span class="mw-headline" id="Monitor_changes_to_your_file_system"> Monitor changes to your file system</span></a></h2>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> This feature has been deprecated.
</th></tr><tr><td valign="center" align="left"> This feature has been deprecated as of Splunk Enterprise version 5.0. This means that although it continues to function in version 6.x of Splunk Enterprise, it might be removed in a future version. As an alternative, you can:
<ul><li> Learn how to <a href="#monitorfilesystemchangesonwindows" class="external text">monitor file system changes on Windows systems</a>.
</li><li> Use the auditd daemon on *nix systems and monitor output from the daemon.
</li></ul><p>For a list of all deprecated features, see the topic "Deprecated features" in the Release Notes.
</p>
</td></tr></table><p>The Splunk Enterprise <b>file system change monitor</b> is useful for tracking changes in your file system.  The file system change monitor watches a directory you specify and generates an event when that directory undergoes any change. It is completely configurable and can detect when any file on the system is edited, deleted, or added (not just Splunk-specific files).  For example, you can tell the file system change monitor to watch <code><font size="2">/etc/sysconfig/</font></code> and alert you any time the system's configurations change.  
</p><p>Configure the file system change monitor in inputs.conf. There is no support for configuring the file system change monitor in Splunk Web.
</p><p><b>Important:</b> If you want to use this feature with <b>forwarding</b>, you must follow some guidelines:
</p>
<ul><li> To send the events to a remote indexer, you must use a <b>heavy forwarder</b>. 
</li><li> If you cannot use a heavy forwarder, then you must follow the configuration instructions provided below in <a href="#monitorchangestoyourfilesystem_use_with_a_universal_forwarder" class="external text">"Use with a universal forwarder"</a>.
</li></ul><p><b>Note:</b> This topic is mainly for *nix users. If you want to monitor file system changes on Windows, see "<a href="#monitorfilesystemchangesonwindows" class="external text">Monitor file system changes</a>" in this manual to learn how with Microsoft native auditing tools.
</p>
<h3> <a name="monitorchangestoyourfilesystem_how_the_file_system_change_monitor_works"><span class="mw-headline" id="How_the_file_system_change_monitor_works"> How the file system change monitor works </span></a></h3>
<p>The file system change monitor detects changes using:
</p>
<ul><li> modification date/time
</li><li> group ID 
</li><li> user ID 
</li><li> file mode (read/write attributes, etc.) 
</li><li> optional SHA256 hash of file contents 
</li></ul><p>You can configure the following features of the file system change monitor:
</p>
<ul><li> whitelist using regular expressions
<ul><li> specify files that will be checked, no matter what 
</li></ul></li><li> blacklist using regular expressions
<ul><li> specify files to skip 
</li></ul></li><li> directory recursion
<ul><li> including symbolic link traversal
</li><li> scanning multiple directories, each with their own polling frequency
</li></ul></li><li> cryptographic signing
<ul><li> creates a distributed audit trail of file system changes 
</li></ul></li><li> indexing entire file as an event on add/change 
<ul><li> size cutoffs for sending entire file and/or hashing 
</li></ul></li><li> all change events indexed by, and searchable through, Splunk Enterprise
</li></ul><p><b>Caution:</b> Do not configure the file system change monitor to monitor your root file system. This can be dangerous and time-consuming if directory recursion is enabled. 
</p>
<h3> <a name="monitorchangestoyourfilesystem_configure_the_file_system_change_monitor"><span class="mw-headline" id="Configure_the_file_system_change_monitor"> Configure the file system change monitor </span></a></h3>
<p>By default, the file system change monitor generates <b>audit events</b> whenever the contents of <code><font size="2">$SPLUNK_HOME/etc/</font></code> are changed, deleted, or added to. When you start Splunk Enterprise for the first time, it generates an audit event for each file in the <code><font size="2">$SPLUNK_HOME/etc/</font></code> directory and all subdirectories. Any time after that, any change in configuration (regardless of origin) generates an audit event for the affected file(s).  If you have <code><font size="2">signedaudit=true</font></code>, the file system change audit event will be indexed into the <b>audit index</b> (<code><font size="2">index=_audit</font></code>). If <code><font size="2">signedaudit</font></code> is not turned on, by default, Splunk Enterprise writes the events to the <b>main</b> index unless you specify another index.
</p><p><b>Note:</b> The file system change monitor does not track the user name of the account executing the change, only that a change has occurred. For user-level monitoring, consider using native operating system audit tools, which have access to this information.
</p><p>To use the file system change monitor to watch any directory, add or edit an <code><font size="2">[fschange]</font></code> stanza to <code><font size="2">inputs.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p><b>Note:</b>  You must restart Splunk Enterprise any time you make changes to the <code><font size="2">[fschange]</font></code> stanza.
</p>
<h4><font size="3"><b><i> <a name="monitorchangestoyourfilesystem_syntax"><span class="mw-headline" id="Syntax">Syntax</span></a></i></b></font></h4>
<p>Here is the syntax for the <code><font size="2">[fschange]</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[fschange:&lt;directory or file to monitor&gt;]<br>&lt;attribute1&gt; = &lt;val1&gt;<br>&lt;attribute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>Note the following:
</p>
<ul><li> Splunk Enterprise monitors all adds/updates/deletes to the directory and its subdirectories.
</li><li> Any change generates an event that Splunk indexes.
</li><li> <code><font size="2">&lt;directory or file to monitor&gt;</font></code> defaults to <code><font size="2">$SPLUNK_HOME/etc/</font></code>.
</li></ul><h4><font size="3"><b><i> <a name="monitorchangestoyourfilesystem_attributes"><span class="mw-headline" id="Attributes">Attributes</span></a></i></b></font></h4>
<p>All attributes are optional. Here is the list of available attributes:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">index=&lt;indexname&gt;</font></code>
</td><td valign="top" align="left"> The index to store all events generated.
</td><td valign="top" align="left"> <code><font size="2">main</font></code> (unless you have turned on audit event signing).
</td></tr><tr><td valign="top" align="left"> <code><font size="2">recurse=&lt;true | false&gt;</font></code>
</td><td valign="top" align="left"> If true, recurse all directories within the directory specified in &lt;code[fschange]&lt;/code&gt;.
</td><td valign="top" align="left"> true
</td></tr><tr><td valign="top" align="left"> <code><font size="2">followLinks=&lt;true | false&gt;</font></code>
</td><td valign="top" align="left"> If true, the file system change monitor follows symbolic links.
</td><td valign="top" align="left"> false
<p><b>Caution:</b> If you are not careful when setting <code><font size="2">followLinks</font></code>, file system loops can occur.
</p>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">pollPeriod=N</font></code>
</td><td valign="top" align="left"> Check this directory for changes every N seconds.
</td><td valign="top" align="left"> 3600 seconds
<ul><li><ul><li> If you make a change, the file system audit events could take anywhere between 1 and 3600 seconds to be generated and become available in audit search.
</li></ul></li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">hashMaxSize=N</font></code>
</td><td valign="top" align="left"> * Calculate a SHA1 hash for every file that is less than or equal to N size in bytes.
<ul><li> This hash can be used as an additional method for detecting change in the file/directory.
</li></ul></td><td valign="top" align="left"> -1 (no hashing used for change detection).
</td></tr><tr><td valign="top" align="left"> <code><font size="2">signedaudit=&lt;true | false&gt;</font></code>
</td><td valign="top" align="left"> * Send cryptographically signed add/update/delete events.
<ul><li> Setting to true will generate events in the _audit index.  
</li><li> This should be set to false if you're setting the <code><font size="2">index</font></code> attribute.
</li></ul><p><b>Note:</b> When setting <code><font size="2">signedaudit</font></code> to true, make sure auditing is enabled in <code><font size="2">audit.conf</font></code>. 
</p>
</td><td valign="top" align="left"> false
</td></tr><tr><td valign="top" align="left"> <code><font size="2">fullEvent=&lt;true | false&gt;</font></code>
</td><td valign="top" align="left"> * Send the full event if an add or update change is detected.
<ul><li> Further qualified by the <code><font size="2">sendEventMaxSize</font></code> attribute. 
</li></ul></td><td valign="top" align="left"> false
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sendEventMaxSize=N</font></code>
</td><td valign="top" align="left"> * Only send the full event if the size of the event is less than or equal to N bytes.
<ul><li> This limits the size of indexed file data.
</li></ul></td><td valign="top" align="left"> -1 (unlimited.)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Set the source type for events from this input.
<ul><li> "sourcetype::" is automatically prepended to <code><font size="2">&lt;string&gt;</font></code>.
</li></ul></td><td valign="top" align="left"> <code><font size="2">audittrail</font></code> (if  <code><font size="2">signedaudit=true</font></code>) or  <code><font size="2">fs_notification</font></code> (if  <code><font size="2">signedaudit=false</font></code>)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">filesPerDelay = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * Injects a delay specified by <code><font size="2">delayInMills</font></code> after processing <code><font size="2">&lt;integer&gt;</font></code> files.
<ul><li> This is used to throttle file system monitoring so it doesn't consume as much CPU.
</li></ul></td><td valign="top" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">delayInMills = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * The delay in milliseconds to use after processing every <code><font size="2">&lt;integer&gt;</font></code> files as specified in <code><font size="2">filesPerDelay</font></code>.
<ul><li> This is used to throttle file system monitoring so it doesn't consume as much CPU.
</li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">filters=&lt;filter1&gt;,&lt;filter2&gt;,...&lt;filterN&gt;</font></code>
</td><td valign="top" align="left"> Each of these filters will apply from left to right for each file or directory that is found during the monitors poll cycle.  See the next section for information on defining filters.
</td><td valign="top" align="left"> n/a
</td></tr></table><h4><font size="3"><b><i> <a name="monitorchangestoyourfilesystem_define_a_filter"><span class="mw-headline" id="Define_a_filter">Define a filter</span></a></i></b></font></h4>
<p>To define a filter to use with the <code><font size="2">filters</font></code> attribute, add a <code><font size="2">[filter...]</font></code> stanza as follows:
</p>
<div class="samplecode"><code><font size="2"><br>[filter:blacklist:backups] <br>regex1 = .*bak<br>regex2 = .*bk<br>[filter:whitelist:code] <br>regex1 = .*\.c <br>regex2 = .*\.h <br>&nbsp;<br>[fschange:/etc] <br>filters = backups,code <br></font></code></div>
<p>Splunk Enterprise handles fschange whitelist and blacklist logic similarly to typical firewalls:
</p>
<ul><li> The events run down through the list of filters until they reach their first match.  
</li><li> If the first filter to match an event is a whitelist, then Splunk Enterprise indexes the event. 
</li><li> If the first filter to match an event is a blacklist, the filter prevents the event from getting indexed. 
</li><li> If an event reaches the end of the chain with no matches, then Splunk Enterprise indexes the event. This means that there is an implicit "all pass" filter built in. 
</li></ul><p>To default to a situation where Splunk Enterprise does not index events if they don't match a whitelist explicitly, end the chain with a blacklist that matches all remaining events.
</p><p>For example:
</p>
<div class="samplecode"><code><font size="2"><br>...<br>filters = &lt;filter1&gt;, &lt;filter2&gt;, ... terminal-blacklist<br><br>[filter:blacklist:terminal-blacklist] <br>regex1 = .?<br></font></code></div>
<p><b>Important:</b> If you ever blacklist a directory <b>including via a terminal blacklist at the end of a series of whitelists</b>, then Splunk Enterprise blacklists <b>all</b> its subfolders and files, as they do not pass any whitelist. To accommodate this, whitelist all desired folders and subfolders explicitly ahead of the blacklist items in your filters.
</p>
<h3> <a name="monitorchangestoyourfilesystem_example"><span class="mw-headline" id="Example">Example</span></a></h3>
<p>This configuration monitors files in the specified directory with the extensions <code><font size="2">.config</font></code>, <code><font size="2">.xml</font></code>, <code><font size="2">.properties</font></code>, and <code><font size="2">.log</font></code> and ignores all others. 
</p><p><b>Note:</b> In this example, a directory could be blacklisted. If this is the case, Splunk Enterprise would blacklist <b>all</b> of its subfolders and files as well -- only files in the specified directory would be monitored.
</p>
<div class="samplecode"><code><font size="2"><br>[filter:whitelist:configs]<br>regex1 = .*\.config <br>regex2 = .*\.xml <br>regex3 = .*\.properties <br>regex4 = .*\.log<br>&nbsp;<br>[filter:blacklist:terminal-blacklist]<br>regex1 = .?<br>&nbsp;<br>[fschange:/var/apache] <br>index = sample <br>recurse = true <br>followLinks = false <br>signedaudit = false <br>fullEvent = true <br>sendEventMaxSize = 1048576 <br>delayInMills = 1000 <br>filters = configs,terminal-blacklist <br></font></code></div>
<h3> <a name="monitorchangestoyourfilesystem_use_with_a_universal_forwarder"><span class="mw-headline" id="Use_with_a_universal_forwarder">Use with a universal forwarder</span></a></h3>
<p>To forward file system change monitor events from a universal forwarder, you must set <code><font size="2">signedaudit = false</font></code> and <code><font size="2">index=_audit</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[fschange:&lt;directory or file to monitor&gt;]<br>signedaudit = false<br>index=_audit<br></font></code></div>
<p>With this workaround, Splunk Enterprise indexes file system change monitor events into the <code><font size="2">_audit</font></code> index with <code><font size="2">sourcetype</font></code> set to <code><font size="2">fs_notification</font></code> and <code><font size="2">source</font></code> set to <code><font size="2">fschangemonitor</font></code>, instead of the default value of <code><font size="2">audittrail</font></code> for both <code><font size="2">sourcetype</font></code>  and <code><font size="2">source</font></code> .
</p>
<a name="setupcustominputs"></a><h2> <a name="setupcustominputs_get_data_from_apis_and_other_remote_data_interfaces_through_scripted_inputs"><span class="mw-headline" id="Get_data_from_APIs_and_other_remote_data_interfaces_through_scripted_inputs"> Get data from APIs and other remote data interfaces through scripted inputs</span></a></h2>
<p>Splunk Enterprise can accept events from scripts that you provide. Scripted input is useful in conjunction with some Windows and *nix command-line tools, such as <code><font size="2">vmstat</font></code>, <code><font size="2">iostat</font></code>, <code><font size="2">netstat</font></code>, <code><font size="2">top</font></code>, and so on. You can use scripted input to get data from application program interfaces (APIs) and other remote data interfaces and message queues. You can then use commands like <code><font size="2">vmstat</font></code> and <code><font size="2">iostat</font></code> on that data to generate metrics and status data. 
</p><p><b>Note:</b> This topic describes how to add scripted inputs that you've already written to your set of inputs. To learn how to develop scripted inputs, see Build scripted inputs in the <i>Developing Views and Apps for Splunk Web</i> manual. 
</p><p>Many apps on Splunkbase provide scripted inputs for specific applications. You can find them on the <b>Browse more apps</b> option in the <b>Apps menu</b>.
</p><p>You can configure scripted inputs from the Settings menu or by editing inputs.conf. 
</p><p><b>Note:</b> On Windows platforms, you can enable text-based scripts, such those in perl and python, with an intermediary Windows batch (<code><font size="2">.bat</font></code>) or PowerShell (<code><font size="2">.ps1</font></code>) file.
</p><p><b>Caution:</b> Scripts launched through scripted input inherit the Splunk Enterprise environment. Be sure to clear environment variables that can affect your script's operation. The only environment variable that's likely to cause problems is the library path (most commonly known as <code><font size="2">LD_LIBRARY_PATH</font></code> on Linux, Solaris, and FreeBSD).
</p><p>Splunk Enterprise logs any messages sent to the <code><font size="2">stderr</font></code> I/O channel by scripted inputs to <code><font size="2">splunkd.log</font></code>.
</p>
<h3> <a name="setupcustominputs_add_a_scripted_input_in_splunk_web"><span class="mw-headline" id="Add_a_scripted_input_in_Splunk_Web"> Add a scripted input in Splunk Web </span></a></h3>
<p>To add a scripted input in Splunk Web, follow the "<a href="#scripts" class="external text">Scripts</a>" recipe in this manual.
</p>
<h3> <a name="setupcustominputs_add_a_scripted_input_via_inputs.conf"><span class="mw-headline" id="Add_a_scripted_input_via_inputs.conf"> Add a scripted input via inputs.conf </span></a></h3>
<p>You add a scripted input in <code><font size="2">inputs.conf</font></code> by adding a <code><font size="2">[script]</font></code> stanza.
</p>
<h4><font size="3"><b><i> <a name="setupcustominputs_syntax"><span class="mw-headline" id="Syntax">Syntax</span></a></i></b></font></h4>
<p>Here is the syntax for the <code><font size="2">[script]</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[script://$SCRIPT] <br>&lt;attrbute1&gt; = &lt;val1&gt;<br>&lt;attrbute2&gt; = &lt;val2&gt;<br>...<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">$SCRIPT</font></code> is the fully-qualified path to the location of the script.
</li><li> As a best practice, put your script in the <code><font size="2">bin/</font></code> directory nearest the <code><font size="2">inputs.conf</font></code> where your script is specified. For example, if you are configuring <code><font size="2">$SPLUNK_HOME/etc/system/local/inputs.conf</font></code>, place your script in <code><font size="2">$SPLUNK_HOME/etc/system/bin/</font></code>.  If you're working on an application in <code><font size="2">$SPLUNK_HOME/etc/apps/$APPLICATION/</font></code>, put your script in <code><font size="2">$SPLUNK_HOME/etc/apps/$APPLICATION/bin/</font></code>.
</li></ul><h4><font size="3"><b><i> <a name="setupcustominputs_attributes"><span class="mw-headline" id="Attributes">Attributes</span></a></i></b></font></h4>
<p>All attributes are optional. Here is the list of available attributes:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">interval = &lt;number&gt;|&lt;cron schedule&gt;</font></code>
</td><td valign="top" align="left"> * Indicates how often to execute the specified command. Specify either an integer value representing seconds or a valid cron schedule.
<ul><li> When a <code><font size="2">cron schedule</font></code> is specified, the script does not execute on start up, but rather at the times defined by the cron schedule.
</li><li> Splunk Enterprise keeps one invocation of a script per instance. Intervals are based on when the script completes. So if you have a script configured to run every 10 minutes and the script takes 20 minutes to complete, the next run will occur 30 minutes after the first run.
</li><li> For constant data streams, enter 1 (or a value smaller than the script's interval).
</li><li> For one-shot data streams, enter -1. Setting <code><font size="2">interval</font></code> to -1 will cause the script to run each time the splunk daemon restarts.
</li></ul></td><td valign="top" align="left"> 60 seconds
</td></tr><tr><td valign="top" align="left"> <code><font size="2">index = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the index where events from this input will be stored.
<ul><li> Splunk Enterprise prepends the <code><font size="2">&lt;string&gt;</font></code> with <code><font size="2">index::</font></code>.
</li><li> For more information about the index field, see "How indexing works" in the Managing Indexers and Clusters manual.
</li></ul></td><td valign="top" align="left"> <code><font size="2">main</font></code>, or whatever you have set as your default index.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">sourcetype = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the sourcetype key/field for events from this input.
<ul><li> Explicitly declares the source type for this data, as opposed to allowing it to be determined automatically. This is important both for searchability and for applying the relevant formatting for this type of data during parsing and indexing.
</li><li> Sets the sourcetype key's initial value. The key is used during parsing/indexing, in particular to set the source type field during indexing. It is also the source type field used at search time.
</li><li> The <code><font size="2">&lt;string&gt;</font></code> is prepended with 'sourcetype::'.
</li><li> For more information about source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a>, in this manual.
</li></ul></td><td valign="top" align="left"> Splunk Enterprise picks a source type based on various aspects of the data. There is no hard-coded default.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">source = &lt;string&gt;</font></code>
</td><td valign="top" align="left"> * Sets the source key/field for events from this input.
<ul><li> <b>Note:</b> Splunk Enterprise does not recommend that you override the source key. Typically, the input layer will provide a more accurate string to aid in problem analysis and investigation, accurately recording the file from which the data was retreived.  Consider use of source types, tagging, and search wildcards before overriding this value.
</li><li> Splunk Enterprise prepends <code><font size="2">&lt;string&gt;</font></code> with <code><font size="2">source::</font></code>.
</li></ul></td><td valign="top" align="left"> The input file path
</td></tr><tr><td valign="top" align="left"> <code><font size="2">disabled = &lt;true | false&gt;</font></code>
</td><td valign="top" align="left"> * <code><font size="2">disabled</font></code> is a boolean value that can be set to true if you want to disable the input.
</td><td valign="top" align="left"> <code><font size="2">false</font></code>
</td></tr></table><p>If you want the script to run continuously, write the script to never exit and set it on a short interval. This helps to ensure that if there is a problem the script gets restarted.  Splunk Enterprise keeps track of scripts it has spawned and will shut them down upon exit.
</p>
<h3> <a name="setupcustominputs_using_a_wrapper_script"><span class="mw-headline" id="Using_a_wrapper_script"> Using a wrapper script </span></a></h3>
<p>It is good practice to write a wrapper script for scripted inputs that use commands with arguments. In some cases, the command can contain special characters that Splunk Enterprise escapes when validating text entered in Splunk Web. This causes updates to a previously configured input to fail to save.
</p>
<dl><dd><b>Note:</b> Characters that Splunk Enterprise escapes when validating text are those that should not be in paths, such as equals (<code><font size="2">=</font></code>) and semi-colon (<code><font size="2">;</font></code>).
</dd></dl><p>For example, the following scripted input is not correctly saved when edited in Splunk Web because Splunk Enterprise escapes the equals (=) sign in the parameter to the <code><font size="2">myUtil.py</font></code> utility:
</p>
<div class="samplecode"><code><font size="2">[script://$SPLUNK_HOME/etc/apps/myApp/bin/myUtil.py file=my_datacsv]<br>disabled = false</font></code></div>
<p>To avoid this problem, write a wrapper script that contains the scripted input. (Inputs updated by editing the conf file directly are not subject to this input validation.) For information on writing wrapper scripts, see Scripted inputs overview in the <i>Developing Views and Apps for Splunk Web</i> manual.
</p>
<h3> <a name="setupcustominputs_example_using_inputs.conf"><span class="mw-headline" id="Example_using_inputs.conf"> Example using inputs.conf </span></a></h3>
<p>This example shows the use of the UNIX <code><font size="2">top</font></code> command as a data input source:
</p><p><b>1.</b> Create a new application directory.  This example uses <code><font size="2">scripts/</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>$ mkdir $SPLUNK_HOME/etc/apps/scripts<br></font></code></div>
<p><b>2.</b> All scripts should be run out of a <code><font size="2">bin/</font></code> directory inside your application directory:
</p>
<div class="samplecode"><code><font size="2">$ mkdir $SPLUNK_HOME/etc/apps/scripts/bin<br></font></code></div>
<p><b>3.</b> This example uses a small shell script <code><font size="2">top.sh</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>$ #!/bin/sh<br>top -bn 1 &nbsp;# linux only - different OSes have different parameters<br></font></code></div>
<p><b>4.</b> Make sure the script is executable: 
</p>
<div class="samplecode"><code><font size="2"><br>chmod +x $SPLUNK_HOME/etc/apps/scripts/bin/top.sh<br></font></code></div>
<p><b>5.</b> Test that the script works by running it via the shell: 
</p>
<div class="samplecode"><code><font size="2"><br>$SPLUNK_HOME/etc/apps/scripts/bin/top.sh<br></font></code></div>
<p>The script should send one <code><font size="2">top</font></code> output. 
</p><p><b>6.</b> Add the script entry to <code><font size="2">inputs.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/apps/scripts/local/</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[script:///opt/splunk/etc/apps/scripts/bin/top.sh]<br>interval = 5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# run every 5 seconds<br>sourcetype = top &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# set sourcetype to top<br>source = script://./bin/top.sh &nbsp;&nbsp;# set source to name of script<br></font></code></div>
<p><b>Note:</b> You might need to modify props.conf:
</p>
<ul><li> By default Splunk Enterprise breaks the single <code><font size="2">top</font></code> entry into multiple events. 
</li><li> The easiest way to fix this problem is to tell the server to break only before something that does not exist in the output. 
</li></ul><p>For example, adding the following to <code><font size="2">$SPLUNK_HOME/etc/apps/scripts/default/props.conf</font></code> forces all lines into a single event:
</p>
<div class="samplecode"><code><font size="2"><br>[top]<br>BREAK_ONLY_BEFORE = &lt;stuff&gt;<br></font></code></div>
<p>Since there is no timestamp in the top output we need to tell Splunk Enterprise to use the current time. This is done in <code><font size="2">props.conf</font></code> by setting:
</p>
<div class="samplecode"><code><font size="2"><br>DATETIME_CONFIG = CURRENT<br></font></code></div>
<h4><font size="3"><b><i> <a name="setupcustominputs_set_interval_attribute_to_cron_schedule"><span class="mw-headline" id="Set_interval_attribute_to_cron_schedule">Set interval attribute to cron schedule</span></a></i></b></font></h4>
<p>In the above example, you can also set the <code><font size="2">interval</font></code> attribute to a "cron" schedule by specifying strings like the following:
</p><p><code><font size="2">0 * * * *</font></code>: Means run once an hour, at the top of the hour.
</p><p><code><font size="2">*/15 9-17 * * 1-5</font></code>: Means run every 15 minutes from 9 am until 5 pm, on Monday to Friday.
</p><p><code><font size="2">15,35,55 0-6,20-23 1 */2 *</font></code>: Means run at 15, 35, and 55 minutes after the hour, between midnight and 7 am and again between 8pm and midnight, on the first of every even month (February, April, June and so on).
</p><p>For more information about setting cron schedules, read "CRONTAB(5) on the Crontab website.
</p>
<a name="findmorethingstomonitorwithcrawl"></a><h2> <a name="findmorethingstomonitorwithcrawl_find_more_things_to_monitor_with_crawl"><span class="mw-headline" id="Find_more_things_to_monitor_with_crawl"> Find more things to monitor with crawl</span></a></h2>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> This feature has been deprecated.
</th></tr><tr><td valign="center" align="left"> This feature has been deprecated as of Splunk Enterprise version 6.0. This means that although it continues to function, it might be removed in a future version. As an alternative, you can search for files and directories to monitor manually.
<p>For a list of all deprecated features, see the topic "Deprecated features" in the Release Notes.
</p>
</td></tr></table><p>Use the <code><font size="2">crawl</font></code> search command to search your file system or network for new data sources to add to your Splunk Enterprise index. 
</p><p>You can change default crawler settings by editing crawl.conf. You can override the crawler defaults at the time that you run <code><font size="2">crawl</font></code>.
</p><p><code><font size="2">crawl</font></code> produces a log of crawl activity which it stores in <code><font size="2">$SPLUNK_HOME/var/log/splunk/crawl.log</font></code>.
</p>
<h3> <a name="findmorethingstomonitorwithcrawl_change_crawler_defaults"><span class="mw-headline" id="Change_crawler_defaults"> Change crawler defaults </span></a></h3>
<p>Edit <code><font size="2">$SPLUNK_HOME/etc/system/local/crawl.conf</font></code> to change the default crawler configuration settings. You define the files and network crawlers separately, in their own stanzas.
</p>
<h4><font size="3"><b><i> <a name="findmorethingstomonitorwithcrawl_syntax"><span class="mw-headline" id="Syntax">Syntax</span></a></i></b></font></h4>
<p><code><font size="2">crawl.conf</font></code> contains two stanzas: <code><font size="2">[files]</font></code> and <code><font size="2">[network]</font></code>, which define defaults for the files and network crawlers, respectively.
</p><p>For information on the definable attributes for those stanzas and their default values, read the crawl.conf spec file.
</p>
<h3> <a name="findmorethingstomonitorwithcrawl_example"><span class="mw-headline" id="Example"> Example </span></a></h3>
<p>Here's an example <code><font size="2">crawl.conf</font></code> file with settings defined for both the files and network crawlers:
</p>
<div class="samplecode"><code><font size="2"><br>[files]<br>bad_directories_list= bin, sbin, boot, mnt, proc, tmp, temp, home, mail, .thumbnails, cache, old<br>bad_extensions_list= mp3, mpg, jpeg, jpg, &nbsp;m4, mcp, mid<br>bad_file_matches_list= *example*, *makefile, core.*<br>packed_extensions_list= gz, tgz, tar, zip<br>collapse_threshold= 10<br>days_sizek_pairs_list= 3-0,7-1000, 30-10000<br>big_dir_filecount= 100<br>index=main<br>max_badfiles_per_dir=100<br><br>[network]<br>host = myserver<br>subnet = 24<br></font></code>&lt;/pre&gt;</div>

<h1>Configure event processing</h1><a name="overviewofeventprocessing"></a><h2> <a name="overviewofeventprocessing_overview_of_event_processing"><span class="mw-headline" id="Overview_of_event_processing"> Overview of event processing</span></a></h2>
<p>Events are records of activity in log files, stored in indexes. They are primarily what Splunk Enterprise indexes.  Events provide information about the systems that produce the log files. The term <b>event data</b> refers to the contents of a Splunk index.  
</p><p>Here's a sample event:
</p>
<div class="samplecode"><code><font size="2">172.26.34.223 - - [01/Jul/2005:12:05:27 -0700] "GET /trade/app?action=logout HTTP/1.1" 200 2953</font></code></div>
<p>When Splunk Enterprise indexes events, it: 
</p>
<ul><li> <a href="#configurecharactersetencoding" class="external text">Configures character set encoding</a>.
</li><li> <a href="#indexmulti-lineevents" class="external text">Configures linebreaking for multi-line events</a>.
</li><li> <a href="#handleeventtimestamps" class="external text">Identifies event timestamps</a> (and applies timestamps to events if they do not exist).
</li><li> <a href="#aboutdefaultfields" class="external text">Extracts a set of useful standard fields</a> such as <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>.
</li><li> <a href="#abouteventsegmentation" class="external text">Segments events</a>.
</li><li> <a href="#assignmetadatatoeventsdynamically" class="external text">Dynamically assigns metadata to events</a>, if specified.
</li><li> <a href="#anonymizedatausingconfigurationfiles" class="external text">Anonymizes data</a>, if specified.
</li></ul><p>For an overview of the Splunk Enterprise indexing process, see the Indexing overview chapter of the Managing Indexers and Clusters manual.
</p>
<a name="configurecharactersetencoding"></a><h2> <a name="configurecharactersetencoding_configure_character_set_encoding"><span class="mw-headline" id="Configure_character_set_encoding"> Configure character set encoding</span></a></h2>
<p>Splunk Enterprise allows you to configure <b>character set encoding</b> for your data sources. Splunk Enterprise has built-in character set specifications to support internationalization of your Splunk <b>deployment</b>. Splunk Enterprise supports many languages (including some that do not use Universal Character Set Transformation Format - 8-bit (UTF-8) encoding).
</p><p>Splunk Enterprise attempts to apply UTF-8 encoding to your sources by default. If a source doesn't use UTF-8 encoding or is a non-ASCII file, Splunk Enterprise tries to convert data from the source to UTF-8 encoding unless you specify a character set to use by setting the <code><font size="2">CHARSET</font></code> key in <code><font size="2">props.conf</font></code>.
</p><p>You can retrieve a list of the valid character encoding specifications by using the <code><font size="2">iconv -l</font></code> command on most *nix systems. A port for <code><font size="2">iconv</font></code> on Windows is available.
</p>
<h3> <a name="configurecharactersetencoding_supported_character_sets"><span class="mw-headline" id="Supported_character_sets"> Supported character sets </span></a></h3>
<p>Splunk Enterprise supports an extremely wide range of character sets, including such key ones as:
</p>
<ul><li> UTF-8
</li><li> UTF-16LE
</li><li> Latin-1
</li><li> BIG5
</li><li> SHIFT-JIS 
</li></ul><p>See "Comprehensive list of supported character sets" at the end of this topic for the exhaustive list.
</p><p>Here's a short list of some of the main character sets that Splunk Enterprise supports, along with the languages they correspond to. 
</p>
<table cellpadding="6"><tr><td valign="center" align="left"> <b>Language</b> </td><td valign="center" align="left"> <b>Code</b>
</td></tr><tr><td valign="center" align="left"> Arabic </td><td valign="center" align="left">  CP1256
</td></tr><tr><td valign="center" align="left"> Arabic </td><td valign="center" align="left"> ISO-8859-6
</td></tr><tr><td valign="center" align="left"> Armenian </td><td valign="center" align="left"> ARMSCII-8
</td></tr><tr><td valign="center" align="left"> Belarus </td><td valign="center" align="left"> CP1251
</td></tr><tr><td valign="center" align="left"> Bulgarian </td><td valign="center" align="left"> ISO-8859-5
</td></tr><tr><td valign="center" align="left"> Czech </td><td valign="center" align="left"> ISO-8859-2
</td></tr><tr><td valign="center" align="left"> Georgian </td><td valign="center" align="left"> Georgian-Academy
</td></tr><tr><td valign="center" align="left"> Greek </td><td valign="center" align="left"> ISO-8859-7
</td></tr><tr><td valign="center" align="left"> Hebrew </td><td valign="center" align="left"> ISO-8859-8
</td></tr><tr><td valign="center" align="left"> Japanese </td><td valign="center" align="left"> EUC-JP
</td></tr><tr><td valign="center" align="left"> Japanese </td><td valign="center" align="left"> SHIFT-JIS
</td></tr><tr><td valign="center" align="left"> Korean </td><td valign="center" align="left"> EUC-KR
</td></tr><tr><td valign="center" align="left"> Russian </td><td valign="center" align="left"> CP1251
</td></tr><tr><td valign="center" align="left"> Russian </td><td valign="center" align="left"> ISO-8859-5
</td></tr><tr><td valign="center" align="left"> Russian </td><td valign="center" align="left"> KOI8-R
</td></tr><tr><td valign="center" align="left"> Slovak </td><td valign="center" align="left"> CP1250
</td></tr><tr><td valign="center" align="left"> Slovenian </td><td valign="center" align="left"> ISO-8859-2
</td></tr><tr><td valign="center" align="left"> Thai </td><td valign="center" align="left"> TIS-620
</td></tr><tr><td valign="center" align="left"> Ukrainian </td><td valign="center" align="left"> KOI8-U
</td></tr><tr><td valign="center" align="left"> Vietnamese </td><td valign="center" align="left"> VISCII
</td></tr></table><h3> <a name="configurecharactersetencoding_manually_specify_a_character_set"><span class="mw-headline" id="Manually_specify_a_character_set"> Manually specify a character set </span></a></h3>
<p>To manually specify a character set to apply to an input, set the <code><font size="2">CHARSET</font></code> key in <code><font size="2">props.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[spec]<br>CHARSET=&lt;string&gt;<br></font></code></div>
<p>For example, if you have a host that generates data in Greek (called "GreekSource" in this example) and that uses ISO-8859-7 encoding, set <code><font size="2">CHARSET=ISO-8859-7</font></code> for that host in <code><font size="2">props.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[host::GreekSource]<br>CHARSET=ISO-8859-7<br></font></code></div>
<p><b>Note:</b> Splunk Enterprise only parses character encodings that have UTF-8 mappings. Some EUC-JP characters do not have a mapped UTF-8 encoding.
</p>
<h3> <a name="configurecharactersetencoding_automatically_specify_a_character_set"><span class="mw-headline" id="Automatically_specify_a_character_set"> Automatically specify a character set </span></a></h3>
<p>Splunk Enterprise can automatically detect languages and proper character sets using its sophisticated character set encoding algorithm.  
</p><p>Configure Splunk Enterprise to automatically detect the proper language and character set encoding for a particular input by setting <code><font size="2">CHARSET=AUTO</font></code> for the input in <code><font size="2">props.conf</font></code>. For example, if you want Splunk Enterprise to automatically detect character set encoding for the host "my-foreign-docs", set <code><font size="2">CHARSET=AUTO</font></code> for that host in <code><font size="2">props.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[host::my-foreign-docs]<br>CHARSET=AUTO<br></font></code></div>
<h3> <a name="configurecharactersetencoding_if_splunk_doesn.27t_recognize_a_character_set"><span class="mw-headline" id="If_Splunk_doesn.27t_recognize_a_character_set"> If Splunk doesn't recognize a character set </span></a></h3>
<p>If you want to use a character set encoding that Splunk Enterprise doesn't recognize, train it to recognize the character set by adding a sample file to the following path: 
</p>
<div class="samplecode"><code><font size="2"><br>$SPLUNK_HOME/etc/ngram-models/_&lt;language&gt;-&lt;encoding&gt;.txt<br></font></code></div>
<p>Once you add the character set specification file, you must restart Splunk Enterprise. After you restart, it can recognize sources that use the new character set, and will automatically convert them to UTF-8 format at index time.
</p><p>For example, if you want to use the "vulcan-ISO-12345" character set, copy the specification file to the following path: 
</p>
<div class="samplecode"><code><font size="2"><br>/SPLUNK_HOME/etc/ngram-models/_vulcan-ISO-12345.txt <br></font></code></div>
<h3> <a name="configurecharactersetencoding_comprehensive_list_of_supported_character_sets"><span class="mw-headline" id="Comprehensive_list_of_supported_character_sets">Comprehensive list of supported character sets</span></a></h3>
<p>The common character sets described earlier are a small subset of what the CHARSET attribute can support. Splunk Enterprise also supports a long list of character sets and aliases, identical to the list supported by the *nix <code><font size="2">iconv</font></code> utility. Here's the full list, with aliases indicated in parantheses:
</p>
<ul><li> utf-8 (aka, CESU-8, ANSI_X3.4-1968, ANSI_X3.4-1986, ASCII, CP367, IBM367, ISO-IR-6, ISO646-US ISO_646.IRV:1991, US, US-ASCII, CSASCII)
</li><li> utf-16le (aka, UCS-2LE, UNICODELITTLE)
</li><li> utf-16be (aka, ISO-10646-UCS-2, UCS-2, CSUNICODE, UCS-2BE, UNICODE-1-1, UNICODEBIG, CSUNICODE11, UTF-16)
</li><li> utf-32le (aka, UCS-4LE)
</li><li> utf-32be (aka, ISO-10646-UCS-4, UCS-4, CSUCS4, UCS-4BE, UTF-32)
</li><li>utf-7 (aka, UNICODE-1-1-UTF-7, CSUNICODE11UTF7)
</li><li>c99 (aka, java)
</li><li> utf-ebcdic
</li><li> latin-1 (aka, CP819, IBM819, ISO-8859-1, ISO-IR-100, ISO_8859-1:1987, L1, CSISOLATIN1)
</li><li> latin-2 (aka, ISO-8859-2, ISO-IR-101, ISO_8859-2:1987, L2, CSISOLATIN2)
</li><li> latin-3 (aka, ISO-8859-3, ISO-IR-109, ISO_8859-3:1988, L3, CSISOLATIN3)
</li><li> latin-4 (aka, ISO-8859-4, ISO-IR-110, ISO_8859-4:1988, L4, CSISOLATIN4)
</li><li> latin-5 (aka, ISO-8859-9, ISO-IR-148, ISO_8859-9:1989, L5, CSISOLATIN5)
</li><li> latin-6 (aka, ISO-8859-10, ISO-IR-157 ,ISO_8859-10:1992, L6, CSISOLATIN6)
</li><li> latin-7 (aka, ISO-8859-13, ISO-IR-179 ,L7)
</li><li> latin-8 (aka, ISO-8859-14, ISO-CELTIC, ISO-IR-199, ISO_8859-14:1998, L8)
</li><li> latin-9 (aka, ISO-8859-15, ISO-IR-203, ISO_8859-15:1998)
</li><li> latin-10 (aka, ISO-8859-16, ISO-IR-226, ISO_8859-16:2001, L10, LATIN10)
</li><li> ISO-8859-5 (aka, CYRILLIC, ISO-IR-144, ISO_8859-5:198,8 CSISOLATINCYRILLIC)
</li><li> ISO-8859-6(aka, ARABIC, ASMO-708, ECMA-114, ISO-IR-127, ISO_8859-6:1987, CSISOLATINARABIC, MACARABIC)
</li><li> ISO-8859-7 (aka, ECMA-118, ELOT_928, GREEK, GREEK8, ISO-IR-126, ISO_8859-7:1987, ISO_8859-7:2003, CSISOLATINGREEK)
</li><li> ISO-8859-8 (aka, HEBREW, ISO-8859-8, ISO-IR-138, ISO8859-8, ISO_8859-8:1988, CSISOLATINHEBREW)
</li><li> ISO-8859-11
</li><li> roman-8 (aka, HP-ROMAN8, R8, CSHPROMAN8)
</li><li> KOI8-R (aka, CSKOI8R)
</li><li> KOI8-U
</li><li> KOI8-T
</li><li> GEORGIAN-ACADEMY
</li><li> GEORGIAN-PS
</li><li> ARMSCII-8
</li><li> MACINTOSH (aka, MAC, MACROMAN, CSMACINTOSH) [Note: these MAC* charsets are for MacOS 9; OS/X uses unicode]
</li><li> MACGREEK
</li><li> MACCYRILLIC
</li><li> MACUKRAINE
</li><li> MACCENTRALEUROPE
</li><li> MACTURKISH
</li><li> MACCROATIAN
</li><li> MACICELAND
</li><li> MACROMANIA
</li><li> MACHEBREW
</li><li> MACTHAI
</li><li> NEXTSTEP
</li><li> CP850 (aka, 850, IBM850, CSPC850MULTILINGUAL)
</li><li> CP862 (aka, 862, IBM862, CSPC862LATINHEBREW)
</li><li> CP866 (aka, 866, IBM866, CSIBM866)
</li><li> CP874 (aka, WINDOWS-874)
</li><li> CP932
</li><li> CP936 (aka, MS936, WINDOWS-936)
</li><li> CP949 (aka, UHC)
</li><li> CP950
</li><li> CP1250 (aka, MS-EE, WINDOWS-1250)
</li><li> CP1251 (aka, MS-CYRL, WINDOWS-1251)
</li><li> CP1252 (aka, MS-ANSI, WINDOWS-1252)
</li><li> CP1253 (aka, MS-GREEK, WINDOWS-1253)
</li><li> CP1254 (aka, MS-TURK, WINDOWS-1254)
</li><li> CP1255 (aka, MS-HEBR, WINDOWS-1255)
</li><li> CP1256 (aka, MS-ARAB, WINDOWS-1256)
</li><li> CP1257 (aka, WINBALTRIM, WINDOWS-1257)
</li><li> CP1258 (aka, WINDOWS-1258)
</li><li> CP1361 (aka, JOHAB)
</li><li> BIG-5 (aka, BIG-FIVE, CN-BIG5, CSBIG5)
</li><li> BIG5-HKSCS(aka, BIG5-HKSCS:2001)
</li><li> CN-GB (aka, EUC-CN, EUCCN, GB2312, CSGB2312)
</li><li> EUC-JP (aka, EXTENDED_UNIX_CODE_PACKED_FORMAT_FOR_JAPANESE, CSEUCPKDFMTJAPANESE)
</li><li> EUC-KR (aka, CSEUCKR)
</li><li> EUC-TW (aka, CSEUCTW)
</li><li> GB18030
</li><li> GBK
</li><li> GB_1988-80 (aka, ISO-IR-57, ISO646-CN, CSISO57GB1988, CN)
</li><li> HZ (aka, HZ-GB-2312)
</li><li> GB_2312-80 (aka, CHINESE, ISO-IR-58, CSISO58GB231280)
</li><li> SHIFT-JIS (aka, MS_KANJI, SJIS, CSSHIFTJIS)
</li><li> ISO-IR-87 (aka, JIS0208 JIS_C6226-1983, JIS_X0208 JIS_X0208-1983, JIS_X0208-1990, X0208, CSISO87JISX0208, ISO-IR-159, JIS_X0212, JIS_X0212-1990, JIS_X0212.1990-0, X0212, CSISO159JISX02121990)
</li><li> ISO-IR-14 (aka, ISO646-JP, JIS_C6220-1969-RO, JP, CSISO14JISC6220RO)
</li><li> JISX0201-1976 (aka, JIS_X0201, X0201, CSHALFWIDTHKATAKANA)
</li><li> ISO-IR-149 (aka, KOREAN, KSC_5601, KS_C_5601-1987, KS_C_5601-1989, CSKSC56011987)
</li><li> VISCII (aka, VISCII1.1-1, CSVISCII)
</li><li> ISO-IR-166 (aka, TIS-620, TIS620-0, TIS620.2529-1, TIS620.2533-0, TIS620.2533-1)
</li></ul><p><b>Note:</b> Splunk Enterprise ignores punctuation and case when matching CHARSET, so, for example, "utf-8", "UTF-8", and "utf8" are all considered identical.
</p>
<a name="indexmulti-lineevents"></a><h2> <a name="indexmulti-lineevents_configure_event_line_breaking"><span class="mw-headline" id="Configure_event_line_breaking"> Configure event line breaking</span></a></h2>
<p>Some events consist of more than one line. Splunk Enterprise handles most multiline events correctly by default. If you have multiline events that Splunk Enterprise doesn't handle properly, you need to configure the software to change its line breaking behavior.
</p>
<h3> <a name="indexmulti-lineevents_how_splunk_enterprise_determines_event_boundaries"><span class="mw-headline" id="How_Splunk_Enterprise_determines_event_boundaries">How Splunk Enterprise determines event boundaries</span></a></h3>
<p>Splunk Enterprise determines event boundaries in two steps:
</p><p><b>1.</b> Line breaking, which uses the <code><font size="2">LINE_BREAKER</font></code> attribute's regular expression (regex) value to split the incoming stream of bytes into separate lines. By default, the <code><font size="2">LINE_BREAKER</font></code> is any sequence of newlines and carriage returns (that is, <code><font size="2">([\r\n]+)</font></code>). 
</p><p><b>2.</b> Line merging, which only occurs when the <code><font size="2">SHOULD_LINEMERGE</font></code> attribute is set to "true" (the default). This step uses all the other line merging settings (for example, <code><font size="2">BREAK_ONLY_BEFORE, BREAK_ONLY_BEFORE_DATE, MUST_BREAK_AFTER,</font></code> etc.) to merge the previously-separated lines into events.
</p><p>If the second step does not run (because you set the <code><font size="2">SHOULD_LINEMERGE</font></code> attribute to "false"), then the events are simply the individual lines determined by <code><font size="2">LINE_BREAKER</font></code>. The first step is relatively efficient, while the second is relatively slow. If you are clever with the <code><font size="2">LINE_BREAKER</font></code> regex, you can often make Splunk Enterprise get the desired result by using only the first step, and skipping the second step. This is particularly valuable if a significant amount of your data consists of multiline events.
</p>
<h3> <a name="indexmulti-lineevents_how_to_configure_event_boundaries"><span class="mw-headline" id="How_to_configure_event_boundaries"> How to configure event boundaries</span></a></h3>
<p>Many event logs have a strict one-line-per-event format, but some do not. Usually, Splunk Enterprise can automatically recognize the event boundaries. However, if event boundary recognition is not working right, you can set custom rules in props.conf. 
</p><p>To configure multiline events, first examine the format of the events. Determine a pattern in the events to set as the start or end of an event. Then, edit <code><font size="2">$SPLUNK_HOME/etc/system/local/props.conf</font></code>, and set the necessary attributes to configure your data.
</p><p>There are two ways to handle multiline events:
</p>
<ul><li> Break the data stream into lines and reassemble into events. This method usually simplifies the configuration process, as it gives you access to several attributes that you can use to define line-merging rules. Use the <code><font size="2">LINE_BREAKER</font></code> attribute to break the data stream into multiple lines. Along with this, set <code><font size="2">SHOULD_LINEMERGE=true</font></code> and set your line-merging attributes (<code><font size="2">BREAK_ONLY_BEFORE</font></code>, etc.) to tell Splunk how to reassemble the lines into events. If your data conforms well to the default <code><font size="2">LINE_BREAKER</font></code> setting (any number of newlines and carriage returns),  you don&acirc;&#128;&#153;t need to alter <code><font size="2">LINE_BREAKER</font></code>. Instead, just set <code><font size="2">SHOULD_LINEMERGE=true</font></code> and use the line-merging attributes to reassemble it. 
</li><li> Break the data stream directly into real events using the <code><font size="2">LINE_BREAKER</font></code>  feature. This might increase your indexing speed, but is somewhat more difficult to work with. If you're finding that indexing is slow and a significant amount of your data consists of multiline events, this method can provide significant improvement. Use the <code><font size="2">LINE_BREAKER</font></code> attribute with <code><font size="2">SHOULD_LINEMERGE=false</font></code>.
</li></ul><p>These attributes are described below.
</p>
<h4><font size="3"><b><i> <a name="indexmulti-lineevents_line_breaking_general_attributes"><span class="mw-headline" id="Line_breaking_general_attributes"> Line breaking general attributes </span></a></i></b></font></h4>
<p>These are the <code><font size="2">props.conf</font></code> attributes that affect line breaking: 
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">TRUNCATE = &lt;non-negative integer&gt;</font></code>
</td><td valign="top" align="left"> * Change the default maximum line length (in bytes). Note that although this attribute is a byte measurement, Splunk rounds down line length when this attribute would otherwise land mid-character for multibyte characters.
<ul><li> Set to 0 if you never want truncation (very long lines are, however, often a sign of garbage data).
</li></ul></td><td valign="top" align="left"> 10000 bytes
</td></tr><tr><td valign="top" align="left"> <code><font size="2">LINE_BREAKER = &lt;regular expression&gt;</font></code>
</td><td valign="center" align="left"> * Specifies a regex that determines how the raw text stream gets broken into initial events, before any line merging takes place (if specified by the <code><font size="2">SHOULD_LINEMERGE</font></code> attribute, described below).
<ul><li> The regex must contain a capturing group -- a pair of parentheses that defines an identified subcomponent of the match.
</li><li> Wherever the regex matches, Splunk Enterprise considers the start of the first capturing group to be the end of the previous event, and considers the end of the first capturing group to be the start of the next event.
</li><li> Splunk Enterprise discards the contents of the first capturing group. This content will not be present in any event.  You are telling Splunk that this text comes between lines.
</li><li> <b>Note:</b> You can realize a significant boost to processing speed when you use <code><font size="2">LINE_BREAKER</font></code> to delimit multiline events (as opposed to using <code><font size="2">SHOULD_LINEMERGE</font></code> to reassemble individual lines into multiline events). Consider using this method if a significant portion of your data consists of multiline events.
</li><li> See the props.conf specification file for more details, including information on how to use <code><font size="2">LINE_BREAKER</font></code> with branched expressions. 
</li></ul></td><td valign="top" align="left"> <code><font size="2">([\r\n]+)</font></code> (This means Splunk Enterprise breaks data into an event for each line, delimited by any number of carriage return (<code><font size="2">\r</font></code>) or newline (<code><font size="2">\n</font></code>) characters.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">LINE_BREAKER_LOOKBEHIND = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * When there is leftover data from a previous raw chunk, <code><font size="2">LINE_BREAKER_LOOKBEHIND</font></code> indicates the number of characters before the end of the raw chunk (with the next chunk concatenated) that Splunk applies the <code><font size="2">LINE_BREAKER</font></code> regex. You might want to increase this value from its default if you are dealing with especially large or multiline events.
</td><td valign="top" align="left"> 100 characters
</td></tr><tr><td valign="top" align="left"> <code><font size="2">SHOULD_LINEMERGE =  [true|false]</font></code>
</td><td valign="top" align="left"> * When set to true, Splunk Enterprise combines several input lines into a single event, with configuration based on the attributes described in the next section.
</td><td valign="top" align="left"> true
</td></tr></table><h4><font size="3"><b><i> <a name="indexmulti-lineevents_attributes_that_apply_only_when_should_linemerge_is_set_to_true"><span class="mw-headline" id="Attributes_that_apply_only_when_SHOULD_LINEMERGE_is_set_to_true">Attributes that apply only when SHOULD_LINEMERGE is set to true </span></a></i></b></font></h4>
<p>When <code><font size="2">SHOULD_LINEMERGE=true</font></code> (the default), use these attributes to define line breaking behavior: 
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">BREAK_ONLY_BEFORE_DATE = [true|false]</font></code>
</td><td valign="top" align="left"> * When set to true, Splunk Enterprise creates a new event if, and only if, it encounters a new line with a date.
</td><td valign="center" align="left"> true
<ul><li> <b>Note:</b> If <code><font size="2">DATETIME_CONFIG</font></code> is set to <code><font size="2">CURRENT</font></code> or <code><font size="2">NONE</font></code>, this attribute is not meaningful, because in those cases, Splunk Enterprise does not identify timestamps.
</li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">BREAK_ONLY_BEFORE = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left"> * When set, Splunk Enterprise creates a new event if, and only if, it encounters a new line that matches the regular expression.
</td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MUST_BREAK_AFTER = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left"> * When set and the regular expression matches the current line, Splunk Enterprise always creates a new event for the next input line.
<ul><li> Splunk Enterprise might still break before the current line if another rule matches.
</li></ul></td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MUST_NOT_BREAK_AFTER = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left"> * When set and the current line matches the regular expression, Splunk Enterprise does not break on any subsequent lines until the <code><font size="2">MUST_BREAK_AFTER</font></code> expression matches.
</td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MUST_NOT_BREAK_BEFORE = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left"> * When set and the current line matches the regular expression, Splunk Enterprise does not break the last event before the current line.
</td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_EVENTS = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * Specifies the maximum number of input lines that will be added to any event.
<ul><li> Splunk Enterprise breaks after reading the specified number of lines.
</li></ul></td><td valign="top" align="left"> 256 lines
</td></tr></table><h3> <a name="indexmulti-lineevents_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<h4><font size="3"><b><i> <a name="indexmulti-lineevents_specify_event_breaks"><span class="mw-headline" id="Specify_event_breaks"> Specify event breaks </span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[my_custom_sourcetype]<br>BREAK_ONLY_BEFORE = ^\d+\s*$<br></font></code></div>
<p>This example instructs Splunk Enterprise to divide events by assuming that any line that consists of only digits is the start of a new event. It does this for any data whose source type is set to <code><font size="2">my_custom_sourcetype</font></code>.
</p>
<h4><font size="3"><b><i> <a name="indexmulti-lineevents_merge_multiple_lines_into_a_single_event"><span class="mw-headline" id="Merge_multiple_lines_into_a_single_event"> Merge multiple lines into a single event </span></a></i></b></font></h4>
<p>The following log event contains several lines that are part of the same request. The differentiator between requests is "Path". For this example, assume that all these lines need to be shown as a single event entry.
</p>
<div class="samplecode"><code><font size="2">
<p>{{"2006-09-21, 02:57:11.58",  122, 11, "Path=/LoginUser Query=CrmId=ClientABC&amp;ContentItemId=TotalAccess&amp;SessionId=3A1785URH117BEA&amp;Ticket=646A1DA4STF896EE&amp;SessionTime=25368&amp;ReturnUrl=http://www.clientabc.com, Method=GET, IP=209.51.249.195, Content=", ""}}
</p></font></code><br><code><font size="2">
{{"2006-09-21, 02:57:11.60",  122, 15, "UserData:&lt;User CrmId="clientabc" UserId="p12345678"&gt;&lt;EntitlementList&gt;&lt;/EntitlementList&gt;&lt;/User&gt;", ""}}
</font></code><br><code><font size="2">
{{"2006-09-21, 02:57:11.60",  122, 15, "New Cookie: SessionId=3A1785URH117BEA&amp;Ticket=646A1DA4STF896EE&amp;CrmId=clientabc&amp;UserId=p12345678&amp;AccountId=&amp;AgentHost=man&amp;AgentId=man, MANUser: Version=1&amp;Name=&amp;Debit=&amp;Credit=&amp;AccessTime=&amp;BillDay=&amp;Status=&amp;Language=&amp;Country=&amp;Email=&amp;EmailNotify=&amp;Pin=&amp;PinPayment=&amp;PinAmount=&amp;PinPG=&amp;PinPGRate=&amp;PinMenu=&amp;", ""}}

</font></code></div>
<p>To index this multiple line event properly, use the <code><font size="2">Path</font></code> differentiator in your configuration. Add the following to your <code><font size="2">$SPLUNK_HOME/etc/system/local/props.conf</font></code>:  
</p>
<div class="samplecode"><code><font size="2"><br>[source::source-to-break]<br>SHOULD_LINEMERGE = True<br>BREAK_ONLY_BEFORE = Path=<br></font></code></div>
<p>This code tells Splunk Enterprise to merge the lines of the event, and only break before the term <code><font size="2">Path=</font></code>.
</p>
<h3> <a name="indexmulti-lineevents_multiline_event_line_breaking_and_segmentation_limitations"><span class="mw-headline" id="Multiline_event_line_breaking_and_segmentation_limitations"> Multiline event line breaking and segmentation limitations </span></a></h3>
<p>Splunk Enterprise applies line breaking and segmentation limitations to extremely large events: 
</p>
<ul><li> <b>Lines over 10,000 bytes:</b> Splunk Enterprise breaks lines over 10,000 bytes into multiple lines of 10,000 bytes each when it indexes them. It appends the field <code><font size="2">meta::truncated</font></code> to the end of each truncated section. However, Splunk Enterprise still groups these lines into a single event.
</li><li> <b>Segmentation for events over 100,000 bytes:</b> In search results, Splunk Enterprise only displays the first 100,000 bytes of an event. Segments after those first 100,000 bytes of a very long line are still searchable, however.
</li><li> <b>Segmentation for events over 1,000 segments:</b> In search results, Splunk Enterprise displays the first 1,000 individual segments of an event as segments separated by whitespace and highlighted on mouseover. It displays the rest of the event as raw text without interactive formatting.
</li></ul><h3> <a name="indexmulti-lineevents_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around line breaking.
</p>
<a name="handleeventtimestamps"></a><h2> <a name="handleeventtimestamps_configure_event_timestamps"><span class="mw-headline" id="Configure_event_timestamps"> Configure event timestamps</span></a></h2>
<p>This topic discusses how to configure event timestamps in Splunk Enterprise.
</p><p>Examine this sample event:
</p>
<div class="samplecode"><code><font size="2">172.26.34.223 - - [01/Jul/2005:12:05:27 -0700] "GET /trade/app?action=logout HTTP/1.1" 200 2953</font></code></div>
<p>Notice the time information in the event: <code><font size="2">[01/Jul/2005:12:05:27 -0700]</font></code>. This is what is known as a <b>timestamp</b>. Splunk Enterprise uses timestamps to correlate events by time, create the histogram in Splunk Web, and set time ranges for searches. Most events contain timestamps, and in those cases where an event doesn't contain timestamp information, Splunk Enterprise attempts to assign a timestamp value to the event at index time. 
</p><p>In most cases, Splunk Enterprise will do the right thing with timestamps, but there are situations where you might need to configure timestamp handling. For example, when dealing with some sources or with distributed deployments, you might need to reconfigure timestamp recognition and formatting. 
</p><p>For more information about timestamps, see the <a href="#howsplunkextractstimestamps" class="external text">"Configure timestamps"</a> chapter of this manual.
</p>
<a name="overviewofdefaultfieldextraction"></a><h2> <a name="overviewofdefaultfieldextraction_configure_indexed_field_extraction"><span class="mw-headline" id="Configure_indexed_field_extraction"> Configure indexed field extraction</span></a></h2>
<p>There are three types of fields that Splunk can extract at index time:
</p>
<ul><li> Default fields
</li><li> Custom fields
</li><li> File header fields 
</li></ul><p>Splunk Enterprise always extracts a set of default fields for each event. You can configure it to also extract custom and, for some data, file header fields.
</p><p>For more information on indexed field extraction, see the chapter <a href="#aboutindexedfieldextraction" class="external text">"Configure indexed field extraction"</a> in this manual.
</p>
<a name="anonymizedatausingconfigurationfiles"></a><h2> <a name="anonymizedatausingconfigurationfiles_anonymize_data"><span class="mw-headline" id="Anonymize_data"> Anonymize data</span></a></h2>
<p>This topic discusses how to anonymize data that comes into Splunk Enterprise, such as credit card and Social Security numbers. 
</p><p>You might want to mask sensitive personal data when indexing log events. Credit card numbers and social security numbers are two examples of data that you might not want to appear in an index. This topic describes how to mask part of confidential fields to protect privacy while providing enough remaining data for use in tracking events.
</p><p>Splunk Enterprise lets you anonymize data in two ways:
</p>
<ul><li> Through a regular expression (regex) transform
</li><li> Through a sed script
</li></ul><h3> <a name="anonymizedatausingconfigurationfiles_anonymize_data_with_a_regular_expression_transform"><span class="mw-headline" id="Anonymize_data_with_a_regular_expression_transform"> Anonymize data with a regular expression transform </span></a></h3>
<p>You can configure <code><font size="2">transforms.conf</font></code> to mask data by means of regex expressions.
</p><p>This example masks all but the last four characters of fields <code><font size="2">SessionId</font></code> and <code><font size="2">Ticket number</font></code> in an application server log.
</p><p>An example of the desired output: 
</p><p><code><font size="2">SessionId=###########7BEA&amp;Ticket=############96EE</font></code>
</p><p>A sample input:
</p>
<div class="samplecode"><code><font size="2"><br>"2006-09-21, 02:57:11.58", &nbsp;122, 11, "Path=/LoginUser Query=CrmId=ClientABC&amp;<br>ContentItemId=TotalAccess&amp;SessionId=3A1785URH117BEA&amp;Ticket=646A1DA4STF896EE&amp;<br>SessionTime=25368&amp;ReturnUrl=http://www.clientabc.com, Method=GET,IP=209.51.249.195,<br>Content=", ""<br>"2006-09-21, 02:57:11.60", &nbsp;122, 15, "UserData:&lt;User CrmId="clientabc" <br>UserId="p12345678"&gt;&lt;EntitlementList&gt;&lt;/EntitlementList&gt;&lt;/User&gt;", ""<br>"2006-09-21, 02:57:11.60", &nbsp;122, 15, "New Cookie: SessionId=3A1785URH117BEA&amp;<br>Ticket=646A1DA4STF896EE&amp;CrmId=clientabcUserId=p12345678&amp;AccountId=&amp;AgentHost=man&amp;<br>AgentId=man, MANUser: Version=1&amp;Name=&amp;Debit=&amp;Credit=&amp;AccessTime=&amp;BillDay=&amp;Status=<br>&amp;Language=&amp;Country=&amp;Email=&amp;EmailNotify=&amp;Pin=&amp;PinPayment=&amp;PinAmount=&amp;PinPG=<br>&amp;PinPGRate=&amp;PinMenu=&amp;", ""<br></font></code></div>
<p>To mask the data, modify the <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code> files in your <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> directory.
</p>
<h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_configure_props.conf"><span class="mw-headline" id="Configure_props.conf"> Configure props.conf </span></a></i></b></font></h4>
<p>Edit <code><font size="2">$SPLUNK_HOME/etc/system/local/props.conf</font></code> and add the following stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;spec&gt;]<br>TRANSFORMS-anonymize = session-anonymizer, ticket-anonymizer<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;spec&gt;</font></code> must be one of the following:
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>, the source type of an event.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>, where <code><font size="2">&lt;host&gt;</font></code> is the host of an event.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>, where <code><font size="2">&lt;source&gt;</font></code> is the source of an event. 
</li></ul></li><li> In this example, <code><font size="2">session-anonymizer</font></code> and <code><font size="2">ticket-anonymizer</font></code> are arbitrary TRANSFORMS class names whose actions are defined in stanzas in a corresponding <code><font size="2">transforms.conf</font></code> file.  Use the class names you create in <code><font size="2">transforms.conf</font></code>.
</li></ul><h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_configure_transforms.conf"><span class="mw-headline" id="Configure_transforms.conf"> Configure transforms.conf </span></a></i></b></font></h4>
<p>In <code><font size="2">$SPLUNK_HOME/etc/system/local/transforms.conf</font></code>, add your TRANSFORMS:
</p>
<div class="samplecode"><code><font size="2"><br>[session-anonymizer]<br>REGEX = (?m)^(.*)SessionId=\w+(\w{4}[&amp;"].*)$<br>FORMAT = $1SessionId=########$2<br>DEST_KEY = _raw<br>[ticket-anonymizer]<br>REGEX = (?m)^(.*)Ticket=\w+(\w{4}&amp;.*)$<br>FORMAT = $1Ticket=########$2<br>DEST_KEY = _raw<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">REGEX</font></code> should specify the regular expression that will point to the string in the event you want to anonymize.
</li></ul><p><b>Note:</b> The regex processor does not handle multi-line events. To get around this you must specify that the event is multi-line.  Place <code><font size="2">(?m)</font></code> before the regular expression in <code><font size="2">transforms.conf</font></code>.
</p>
<ul><li> <code><font size="2">FORMAT</font></code> specifies the masked values. <code><font size="2">$1</font></code> is all the text leading up to the regex and <code><font size="2">$2</font></code> is all the text of the event after the regex.
</li></ul><ul><li> <code><font size="2">DEST_KEY = _raw</font></code> specifies to write the value from <code><font size="2">FORMAT</font></code> to the raw value in the log - thus modifying the event.
</li></ul><h3> <a name="anonymizedatausingconfigurationfiles_anonymize_data_through_a_sed_script"><span class="mw-headline" id="Anonymize_data_through_a_sed_script">Anonymize data through a <code><font size="2">sed</font></code> script </span></a></h3>
<p>You can also anonymize your data by using a <code><font size="2">sed</font></code> script to replace or substitute strings in events.
</p><p>Most UNIX users are familiar with <code><font size="2">sed</font></code>, a Unix utility which reads a file and modifies the input as specified by a list of commands. Splunk Enterprise lets you use <code><font size="2">sed</font></code>-like syntax in <code><font size="2">props.conf</font></code> to anonymize your data.  
</p>
<h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_define_the_sed_script_in_props.conf"><span class="mw-headline" id="Define_the_sed_script_in_props.conf"> Define the sed script in props.conf </span></a></i></b></font></h4>
<p>Edit or create a copy of <code><font size="2">props.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local</font></code>.
</p><p>Create a <code><font size="2">props.conf</font></code> stanza that uses <code><font size="2">SEDCMD</font></code> to indicate a <code><font size="2">sed script</font></code>:
</p>
<code><font size="2"><br>[&lt;spec&gt;]<br>SEDCMD-&lt;class&gt; = &lt;sed script&gt;<br></font></code>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;spec&gt;</font></code> must be one of the following:
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>, the source type of an event.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>, where <code><font size="2">&lt;host&gt;</font></code> is the host of an event.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>, where <code><font size="2">&lt;source&gt;</font></code> is the source of an event. 
</li></ul></li></ul><ul><li> The <code><font size="2">sed script</font></code> applies only to the <code><font size="2">_raw</font></code> field at index time. Splunk Enterprise currently supports the following subset of <code><font size="2">sed</font></code> commands: 
<ul><li> replace (<code><font size="2">s</font></code>) 
</li><li> character substitution (<code><font size="2">y</font></code>).
</li></ul></li></ul><p><b>Note:</b> After making changes to <code><font size="2">props.conf</font></code>, restart Splunk Enterprise to enable the configuration changes.
</p>
<h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_replace_strings_with_regex_match"><span class="mw-headline" id="Replace_strings_with_regex_match"> Replace strings with regex match </span></a></i></b></font></h4>
<p>The syntax for a <code><font size="2">sed</font></code> replace is:
</p><p><code><font size="2">SEDCMD-&lt;class&gt; = s/&lt;regex&gt;/&lt;replacement&gt;/flags</font></code>
</p><p>Note the following: 
</p>
<ul><li> <code><font size="2">regex</font></code> is a PERL regular expression.
</li><li> <code><font size="2">replacement</font></code> is a string to replace the regex match. It uses "\n" for back-references, where <code><font size="2">n</font></code> is a single digit.
</li><li> <code><font size="2">flags</font></code> can be either "g" to replace all matches or a number to replace a specified match.
</li></ul><h5> <a name="anonymizedatausingconfigurationfiles_example"><span class="mw-headline" id="Example">Example</span></a></h5>
<p>In the following example, you want to index data containing Social Security and credit card numbers. At index time, you want to mask these values so that only the last four digits are evident in your events. Your <code><font size="2">props.conf</font></code> stanza might look like this:
</p>
<div class="samplecode"><code><font size="2"><br>[source::.../accounts.log]<br>SEDCMD-accounts = s/ssn=\d{5}(\d{4})/ssn=xxxxx\1/g s/cc=(\d{4}-){3}(\d{4})/cc=xxxx-xxxx-xxxx-\2/g<br></font></code></div>
<p>Now, in your accounts events, social security numbers appear as <code><font size="2">ssn=xxxxx6789</font></code> and credit card numbers will appear as <code><font size="2">cc=xxxx-xxxx-xxxx-1234</font></code>.
</p>
<h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_substitute_characters"><span class="mw-headline" id="Substitute_characters"> Substitute characters </span></a></i></b></font></h4>
<p>The syntax for a <code><font size="2">sed</font></code> character substitution is:
</p>
<div class="samplecode"><code><font size="2">SEDCMD-&lt;class&gt; = y/&lt;string1&gt;/&lt;string2&gt;/</font></code></div>
<p>This substitutes each occurrence of the characters in <code><font size="2">string1</font></code> with the characters in <code><font size="2">string2</font></code>.
</p>
<h5> <a name="anonymizedatausingconfigurationfiles_example_2"><span class="mw-headline" id="Example_2">Example</span></a></h5>
<p>Let's say you have a file you want to index, <code><font size="2">abc.log</font></code>, and you want to substitute the capital letters "A", "B", and "C" for every lowercase "a", "b", or "c" in your events. Add the following to your <code><font size="2">props.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[source::.../abc.log]<br>SEDCMD-abc = y/abc/ABC/<br></font></code></div>
<p>Now, if you search for <code><font size="2">source="*/abc.log"</font></code>, you should not find the lowercase letters "a", "b", and "c" in your data at all. Splunk Enterprise substituted "A" for each "a", "B" for each "b", and "C" for each "c'.
</p>
<h3> <a name="anonymizedatausingconfigurationfiles_caveats_for_anonymizing_data"><span class="mw-headline" id="Caveats_for_anonymizing_data">Caveats for anonymizing data</span></a></h3>
<h4><font size="3"><b><i> <a name="anonymizedatausingconfigurationfiles_splunk_enterprise_does_not_parse_structured_data_that_has_been_forwarded_to_an_indexer"><span class="mw-headline" id="Splunk_Enterprise_does_not_parse_structured_data_that_has_been_forwarded_to_an_indexer">Splunk Enterprise does not parse structured data that has been forwarded to an indexer </span></a></i></b></font></h4>
<p>When you forward structured data to an indexer, Splunk Enterprise does not parse this data once it arrives at the indexer, even if you have configured <code><font size="2">props.conf</font></code> on that indexer with <code><font size="2">INDEXED_EXTRACTIONS</font></code>. Forwarded data skips the following queues on the indexer, which precludes any parsing of that data on the indexer:
</p>
<ul><li> <code><font size="2">parsing</font></code>
</li><li> <code><font size="2">aggregation</font></code>
</li><li> <code><font size="2">typing</font></code>
</li></ul><p>The forwarded data must arrive at the indexer already parsed. To achieve this, you must also set up <code><font size="2">props.conf</font></code> on the forwarder that sends the data. This includes configuration of <code><font size="2">INDEXED_EXTRACTIONS</font></code> and any other parsing, filtering, anonymizing, and routing rules. Universal forwarders are capable of performing these tasks solely for structured data. See "<a href="#extractfieldsfromfileheadersatindextime_forward_data_extracted_from_structured_data_files" class="external text">Forward data extracted from structured data files</a>".
</p>
<h1>Configure timestamps</h1><a name="howsplunkextractstimestamps"></a><h2> <a name="howsplunkextractstimestamps_how_timestamp_assignment_works"><span class="mw-headline" id="How_timestamp_assignment_works"> How timestamp assignment works </span></a></h2>
<p><b>Timestamps</b> are very important to Splunk Enterprise. It uses timestamps to correlate <b>events</b> by time, to create the timeline histogram in Splunk Web, and to set time ranges for searches. 
</p><p>Splunk Enterprise assigns timestamps to events at <b>index time</b>.  It usually assigns timestamp values automatically, using information in the raw event data. If an event doesn't contain an explicit timestamp, Splunk Enterprise attempts to assign a timestamp value through other means. For some data, it might need your help to tell it how to recognize the timestamps.
</p><p>Splunk Enterprise stores timestamp values in the <code><font size="2">_time</font></code> field  (in UTC time format).
</p><p>Timestamp processing is one of the key steps in <b>event processing</b>. For more information on event processing, see the chapter in this manual called <a href="#overviewofeventprocessing" class="external text">"Configure event processing"</a>.
</p>
<h3> <a name="howsplunkextractstimestamps_how_splunk_enterprise_assigns_timestamps"><span class="mw-headline" id="How_Splunk_Enterprise_assigns_timestamps"> How Splunk Enterprise assigns timestamps </span></a></h3>
<p>Splunk Enterprise uses the following precedence rules to assign timestamps to events:
</p><p><b>1.</b> Splunk looks for a time or date in the event itself using an explicit <code><font size="2">TIME_FORMAT</font></code>, if provided. You configure the <code><font size="2">TIME_FORMAT</font></code> attribute in <code><font size="2">props.conf</font></code>.
</p><p><b>2.</b> If no <code><font size="2">TIME_FORMAT</font></code> was configured for the data, Splunk Enterprise attempts to automatically identify a time or date in the event itself. It uses the source type of the event (which includes <code><font size="2">TIME_FORMAT</font></code> information) to try to find the timestamp.
</p><p><b>3.</b> If an event doesn't have a time or date, Splunk Enterprise uses the timestamp from the most recent previous event of the same source. 
</p><p><b>4.</b> If no events in a source have a date, Splunk Enterprise tries to find a date in the source name or file name. Time-of-day is not identified in filenames. (This requires that the events have a time, even though they don't have a date.) 
</p><p><b>5.</b> For file sources, if no date can be identified in the file name, Splunk Enterprise uses the file's modification time.
</p><p><b>6.</b> As a last resort, Splunk Enterprise sets the timestamp to the current system time when indexing each event.
</p><p><b>Note:</b> Splunk Enterprise can only extract dates from a source, not times. If you need to extract a time from a source, <a href="#configureindex-timefieldextraction" class="external text">use a transform</a>.
</p>
<h3> <a name="howsplunkextractstimestamps_configure_timestamps"><span class="mw-headline" id="Configure_timestamps"> Configure timestamps </span></a></h3>
<p>Most events don't require any special timestamp handling. Splunk Enterprise automatically recognizes and extracts their timestamps. However, for some sources and distributed deployments, you might need to configure how Splunk Enterprise extracts timestamps, so that they format properly. 
</p><p>There are two ways to configure timestamp extraction:
</p>
<ul><li> Use the "Set Sourcetype" page in Splunk Web to interactively adjust timestamps on sample data. Once you're happy with the results, you can save the changes to a new source type and then apply that source type to your data inputs. See "<a href="#overviewofdatapreview" class="external text">The "Set Sourcetypes" page</a>."
</li></ul><ul><li> Edit props.conf directly. For more information, read <a href="#configuretimestamprecognition" class="external text">Configure timestamp recognition</a>.
</li></ul><p>You can also configure Splunk's timestamp extraction processor to:
</p>
<ul><li> <a href="#applytimezoneoffsetstotimestamps" class="external text">Apply time zone offsets</a>.
</li><li> <a href="#configurepositionaltimestampextraction" class="external text">Pull the correct timestamp from events with more than one timestamp</a>.
</li><li> <a href="#tunetimestampextractionforbetterindexingperformance" class="external text">Improve indexing performance</a>.
</li></ul><h3> <a name="howsplunkextractstimestamps_considerations_when_adding_data_from_new_inputs"><span class="mw-headline" id="Considerations_when_adding_data_from_new_inputs"> Considerations when adding data from new inputs</span></a></h3>
<p>If you index some data from a new input and then discover that you need to adjust the timestamp extraction process, you will need to re-index that data once you've made the configuration changes. Therefore, it's a good idea to preview your data, as described in the chapter <a href="#overviewofdatapreview" class="external text">"Preview your data"</a>. 
</p><p>Alternatively, you can test new data inputs in a test instance of Splunk Enterprise (or just in a separate index on the production Splunk instance) before adding data to your production instance. That way, if you need to make adjustments, you can easily clean out the data and re-index it until you get it right.
</p>
<a name="configuretimestamprecognition"></a><h2> <a name="configuretimestamprecognition_configure_timestamp_recognition"><span class="mw-headline" id="Configure_timestamp_recognition"> Configure timestamp recognition</span></a></h2>
<p>Most events don't require any special timestamp handling. Splunk Enterprise automatically recognizes and extracts their timestamps. However, for some sources and distributed deployments, you might need to configure how Splunk Enterprise extracts timestamps, so that they format properly. 
</p><p>There are two ways to configure timestamp extraction:
</p>
<ul><li> Use the "Set Sourcetype" page in Splunk Web to interactively adjust timestamps on sample data. Once you are happy with the results, you can save the changes to a new source type and then apply that source type to your data inputs. See "<a href="#overviewofdatapreview" class="external text">The "Set Sourcetype" page</a>."
</li></ul><ul><li> Edit props.conf directly.  For information on how to edit <code><font size="2">props.conf</font></code> for timestamp extraction, read on!
</li></ul><h3> <a name="configuretimestamprecognition_the_timestamp_processor"><span class="mw-headline" id="The_timestamp_processor"> The timestamp processor </span></a></h3>
<p>The Splunk Enterprise timestamp processor is located by default in <code><font size="2">$SPLUNK_HOME/etc/datetime.xml</font></code>. You ordinarily do not need to touch this file, unless you're dealing with unusual, custom timestamps. If you need to configure timestamp recognition in some way, you can usually make the necessary changes by setting <code><font size="2">props.conf</font></code> timestamp attributes, as described below. 
</p><p>If you have a custom timestamp that can't be handled by configuring <code><font size="2">props.conf</font></code>, you can substitute your own timestamp processor with the <code><font size="2">DATETIME_CONFIG</font></code> attribute, described in the next section. This attribute specifies the file Splunk Enterprise should use for timestamp processing.
</p>
<h3> <a name="configuretimestamprecognition_edit_timestamp_properties_in_props.conf"><span class="mw-headline" id="Edit_timestamp_properties_in_props.conf"> Edit timestamp properties in props.conf </span></a></h3>
<p>To configure how Splunk Enterprise recognizes timestamps, edit props.conf. There are a number of attributes that pertain to timestamps. In particular, you can determine how Splunk Enterprise recognizes a timestamp by using the <code><font size="2">TIME_FORMAT</font></code> attribute to specify a <code><font size="2">strptime()</font></code> format for the timestamp. You can also set other attributes pertaining to timestamps; for example, to specify where a timestamp is located in an event, what time zone to use, or how to deal with timestamps of varying currency.
</p><p>Edit the <code><font size="2">props.conf</font></code> file in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>To set timestamp recognition, configure one or more of the timestamp attributes in <code><font size="2">props.conf</font></code>. Refer to  the props.conf specification file for detailed information regarding these and other attributes.
</p>
<h4><font size="3"><b><i> <a name="configuretimestamprecognition_syntax_overview"><span class="mw-headline" id="Syntax_overview">Syntax overview</span></a></i></b></font></h4>
<p>Here's an overview of the syntax for the timestamp attributes:
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;spec&gt;]<br>DATETIME_CONFIG = &lt;filename relative to $SPLUNK_HOME&gt;<br>TIME_PREFIX = &lt;regular expression&gt;<br>MAX_TIMESTAMP_LOOKAHEAD = &lt;integer&gt;<br>TIME_FORMAT = &lt;strptime-style format&gt;<br>TZ = &lt;posix time zone string&gt;<br>MAX_DAYS_AGO = &lt;integer&gt;<br>MAX_DAYS_HENCE = &lt;integer&gt;<br>MAX_DIFF_SECS_AGO = &lt;integer&gt;<br>MAX_DIFF_SECS_HENCE = &lt;integer&gt;<br></font></code></div>
<p>In this syntax, <code><font size="2">&lt;spec&gt;</font></code> can be:
</p>
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>, the source type of an event.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>, where <code><font size="2">&lt;host&gt;</font></code> is the host value for an event.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>, where <code><font size="2">&lt;source&gt;</font></code> is the source value for an event.
</li></ul><p>If an event contains data that matches the value of <code><font size="2">&lt;spec&gt;</font></code>, then the timestamp rules specified in the stanza apply to that event. You can have multiple stanzas, to handle different <code><font size="2">&lt;spec&gt;</font></code> values.
</p>
<h4><font size="3"><b><i> <a name="configuretimestamprecognition_timestamp_attributes"><span class="mw-headline" id="Timestamp_attributes">Timestamp attributes</span></a></i></b></font></h4>
<p>These are the timestamp attributes settable through <code><font size="2">props.conf</font></code>:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" width="20%" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" width="50%" bgcolor="#C0C0C0"> Description
</th><th valign="top" width="30%" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" align="left"> <code><font size="2">DATETIME_CONFIG = &lt;filename relative to $SPLUNK_HOME&gt;</font></code>
</td><td valign="top" align="left"> * Specify a file to use to configure the Splunk Enterprise timestamp processor.
<ul><li> Under normal circumstances, you will not need to create your own timestamp processor file or modify the default <code><font size="2">datetime.xml</font></code> file. The other <code><font size="2">props.conf</font></code> attributes, described in this topic, can usually tweak the Splunk Enterprise timestamp recognition capability to meet your needs. However, if your data has a custom timestamp format, you might need to substitute your own version of this file.
</li><li> Set <code><font size="2">DATETIME_CONFIG = NONE</font></code> to prevent the timestamp processor from running. When timestamp processing is off, Splunk Enterprise does not look at the text of the event for the timestamp--it instead uses the event's "time of receipt"; in other words, the time the event is received via its input. For file-based inputs, this means that Splunk Enterprise derives the event timestamp from the modification time of the input file.
</li><li> Set <code><font size="2">DATETIME_CONFIG = CURRENT</font></code> to assign the current system time to each event as it's indexed.
</li><li> <b>Note:</b>  Both <code><font size="2">CURRENT</font></code> and <code><font size="2">NONE</font></code> explicitly disable timestamp identification, so the default event boundary detection (<code><font size="2">BREAK_ONLY_BEFORE_DATE = true</font></code>) is likely not to work as desired.  When using these settings, use <code><font size="2">SHOULD_LINEMERGE</font></code> and/or the <code><font size="2">BREAK_ONLY_* , MUST_BREAK_*</font></code> settings to control event merging.
</li></ul></td><td valign="top" align="left"> <code><font size="2">$SPLUNK_HOME/etc/datetime.xml</font></code>
</td></tr><tr><td valign="top" align="left"> <code><font size="2">TIME_PREFIX = &lt;regular expression&gt;</font></code>
</td><td valign="top" align="left"> * When set, Splunk Enterprise looks for a match for this regex in the event text before attempting to extract a timestamp. The timestamp algorithm only looks for a timestamp in the event text that follows the end of the first regex match.
<ul><li> You should use a regular expression that points exactly before your event's timestamp.  For example, if the timestamp follows the phrase <code><font size="2">abc123</font></code> in your events, you should set <code><font size="2">TIME_PREFIX</font></code> to <code><font size="2">abc123</font></code>.  
</li><li> If the <code><font size="2">TIME_PREFIX</font></code> cannot be found in the event text, timestamp extraction does not take place.
</li></ul></td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * Specify how far (how many characters) into an event Splunk Enterprise should look for a timestamp.
<ul><li> This constraint is applied starting from the location positioned by TIME_PREFIX. 
<ul><li> For example, if TIME_PREFIX positions a location 11 characters into the event, and MAX_TIMESTAMP_LOOKAHEAD is set to 10, timestamp extraction will be constrained to characters 11 through 20.
</li></ul></li><li> If set to 0 or -1, the length constraint for timestamp recognition is effectively disabled. This can have negative performance implications which scale with the length of input lines (or with event size when LINE_BREAKER is redefined for event splitting). 
</li></ul></td><td valign="top" align="left"> 150 characters
</td></tr><tr><td valign="top" align="left"> <code><font size="2">TIME_FORMAT = &lt;strptime-style format&gt;</font></code>
</td><td valign="top" align="left"> * Specifies a <code><font size="2">strptime()</font></code> format string to extract the timestamp.
<ul><li> <code><font size="2">strptime()</font></code> is a Unix standard for designating time formats. For more information, see the section <a href="#configuretimestamprecognition_enhanced_strptime.28.29_support" class="external text">"Enhanced strptime() support"</a>, below.
</li><li> <code><font size="2">TIME_FORMAT</font></code> starts reading after the <code><font size="2">TIME_PREFIX</font></code> (or directly at the start of the event, if there's no <code><font size="2">TIME_PREFIX</font></code> attribute). If you use a <code><font size="2">TIME_PREFIX</font></code>, it <em>must</em>  match up to and including the character before the timestamp begins. If you don't set <code><font size="2">TIME_PREFIX</font></code> but you do set <code><font size="2">TIME_FORMAT</font></code>, the timestamp must appear at the very start of each event; otherwise, Splunk Enterprise will not be able to process the formatting instructions, and every event will contain a warning about the inability to use strptime. (It's possible that you will still end up with a valid timestamp, based on how Splunk attempts to recover from the problem.) 
</li><li> For best results, the <code><font size="2">&lt;strptime-style format&gt;</font></code> should describe the day of the year and the time of day. 
</li><li> If <code><font size="2">&lt;strptime-style format&gt;</font></code> contains an hour component, but no minute component, TIME_FORMAT ignores the hour component. It treats the format as an anomaly and considers the precision to be date-only.
</li></ul></td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">TZ = &lt;time zone identifier&gt;</font></code>
</td><td valign="top" align="left"> * Splunk Enterprise determines a particular event's time zone as follows:
<ul><li><ul><li> If the event has a time zone in its raw text (such as <code><font size="2">UTC</font></code> or <code><font size="2">-08:00</font></code>), use that. 
</li><li> Otherwise, if TZ is set to a valid time zone string, use that. Specify a time zone setting using a value from the zoneinfo TZ database.
</li><li> If an event that arrives at an indexer has originated from a forwarder, and both indexer and forwarder run Splunk Enterprise version 6.0 or later, then use the time zone that the forwarder provides.
</li><li> Otherwise, use the time zone of the system that runs <code><font size="2">splunkd</font></code>. 
</li></ul></li><li> For more details and examples, see "Specify time zones of timestamps" in this manual.
</li></ul></td><td valign="top" align="left"> empty string
</td></tr><tr><td valign="top" align="left"> <code><font size="2">TZ_ALIAS = &lt;key=value&gt;[,&lt;key=value&gt;]...</font></code>
</td><td valign="top" align="left"> * Provides admin-level control over how timezone strings extracted from events are interpreted. For example, EST can mean Eastern (US) Standard Time or Eastern (Australian) Standard Time. There are many other three letter timezone acronyms with multiple expansions.
<ul><li> There is no requirement to use <code><font size="2">TZ_ALIAS</font></code> if the traditional Splunk default mappings for these values work as expected.  For example, EST maps to the Eastern US by default.
</li><li> Has no effect on the <code><font size="2">TZ</font></code> value. It affects only timezone strings from event text, either from any configured <code><font size="2">TIME_FORMAT</font></code> or from pattern-based guess fallback.
</li><li> The setting is a list of <code><font size="2">key=value</font></code> pairs, separated by commas.
</li><li> The key is matched against the text of the timezone specifier of the event, and the value is the timezone specifier to use when mapping the timestamp to UTC/GMT. 
</li><li> The value is another <code><font size="2">TZ</font></code> specifier that expresses the desired offset.
</li><li> Example: <code><font size="2">TZ_ALIAS = EST=GMT+10:00</font></code> (See the props.conf example file in the Configuration File Reference for more examples).
</li></ul></td><td valign="top" align="left"> not set
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_DAYS_AGO = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * Specifies the maximum number of days in the past, from the current date, that an extracted date can be valid.
<ul><li> For example, if <code><font size="2">MAX_DAYS_AGO = 10</font></code>, Splunk ignores dates older than 10 days from the current date.
</li><li> The maximum settable number of days in the past is 10951.
</li></ul></td><td valign="top" align="left"> 2000 days
<ul><li> <b>Note:</b> If you have data that is more than 2000 days old, increase this setting.
</li></ul></td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_DAYS_HENCE = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * Specifies the maximum number of days in the future from the current date that an extracted date can be valid.
<ul><li> For example, if <code><font size="2">MAX_DAYS_HENCE = 3</font></code>, dates that are more than 3 days in the future are ignored.
</li><li> <b>Important:</b> False positives are less likely with a tighter window; change with caution.
</li><li> If your servers have the wrong date set or are in a time zone that is one day ahead, set this value to at least 3.
</li><li> This allows timestamp extractions that are up to a day in the future. 
</li><li> The maximum settable number of days is 10950.
</li></ul></td><td valign="top" align="left"> 2 days
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_DIFF_SECS_AGO = &lt;integer&gt;</font></code>
</td><td valign="center" align="left"> * If the event's timestamp is more than <code><font size="2">&lt;integer&gt;</font></code> seconds <b>before</b> the previous timestamp, Splunk only accepts it if it has the same time format as the majority of timestamps from the source.
<ul><li> <b>Important:</b> If your timestamps are wildly out of order, consider increasing this value.
</li><li> The maximum settable number of seconds is 2147483646.
</li></ul></td><td valign="top" align="left"> 3600 seconds (1 hour)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MAX_DIFF_SECS_HENCE = &lt;integer&gt;</font></code>
</td><td valign="top" align="left"> * If the event's timestamp is more than <code><font size="2">&lt;integer&gt;</font></code> seconds <b>after</b> the previous timestamp, Splunk only accepts it if it has the same time format as the majority of timestamps from the source.
<ul><li> <b>Important:</b> If your timestamps are wildly out of order, or if you have logs that are written less than once a week, consider increasing this value.
</li><li> The maximum settable number of seconds is 2147483646.
</li></ul></td><td valign="top" align="left"> 604800 seconds (1 week)
</td></tr></table><h3> <a name="configuretimestamprecognition_enhanced_strptime.28.29_support"><span class="mw-headline" id="Enhanced_strptime.28.29_support"> Enhanced strptime() support </span></a></h3>
<p>Use the <code><font size="2">TIME_FORMAT</font></code> attribute in <code><font size="2">props.conf</font></code> to configure timestamp parsing. This attribute takes a <code><font size="2">strptime()</font></code> format string, which it uses to extract the timestamp.
</p><p>Splunk Enterprise implements an enhanced version of Unix strptime() that supports additional formats, allowing for microsecond, millisecond, any time width format, and some additional time formats for compatibility. The additional formats include:
</p>
<table cellpadding="6"><tr><td valign="center" align="left">&nbsp;%N</td><td valign="center" align="left"> For GNU date-time nanoseconds. Specify any sub-second parsing by providing the width:&nbsp;%3N = milliseconds,&nbsp;%6N = microseconds,&nbsp;%9N = nanoseconds.
</td></tr><tr><td valign="center" align="left">%Q,%q</td><td valign="center" align="left"> For milliseconds, microseconds for Apache Tomcat.&nbsp;%Q and&nbsp;%q can format any time resolution if the width is specified.
</td></tr><tr><td valign="center" align="left">%I</td><td valign="center" align="left"> For hours on a 12-hour clock format. If&nbsp;%I appears after&nbsp;%S or&nbsp;%s (like "%H:%M:%S.%l"), it takes on the log4cpp meaning of milliseconds.
</td></tr><tr><td valign="center" align="left">%+</td><td valign="center" align="left"> For standard Unix date format timestamps.
</td></tr><tr><td valign="center" align="left">&nbsp;%v</td><td valign="center" align="left"> For BSD and OSX standard date format.
</td></tr><tr><td valign="center" align="left">%Z,&nbsp;%z,&nbsp;%::z,&nbsp;%:::z</td><td valign="center" align="left"> The time zone abbreviation (%Z) or ISO-8601-style numeric timezone (%z-for example, -0800 for PST or +0000 for GMT, or nothing if the time zone cannot be determined.) GNU libc support.
</td></tr><tr><td valign="center" align="left">%o</td><td valign="center" align="left"> For AIX timestamp support (%o used as an alias for&nbsp;%Y).
</td></tr><tr><td valign="center" align="left">%p</td><td valign="center" align="left"> The locale's equivalent of AM or PM. (Note: there may be none.)
</td></tr><tr><td valign="center" align="left">%s</td><td valign="center" align="left"> Epoch (10 digits)
</td></tr></table><p><b>Note:</b> A strptime expression that ends with a literal dot and subsecond specifier such as&nbsp;%Q,&nbsp;%q,&nbsp;%N will treat the terminal dot and conversion specifier as optional.  If the .subseconds portion is absent from the text, it will still extract.
</p>
<h4><font size="3"><b><i> <a name="configuretimestamprecognition_strptime.28.29_format_expression_examples"><span class="mw-headline" id="strptime.28.29_format_expression_examples"> strptime() format expression examples </span></a></i></b></font></h4>
<p>Here are some sample date formats, with the <code><font size="2">strptime()</font></code> expressions that handle them:
</p>
<table cellpadding="6"><tr><td valign="center" align="left"> 1998-12-31 </td><td valign="center" align="left">&nbsp;%Y-%m-%d
</td></tr><tr><td valign="center" align="left"> 98-12-31 </td><td valign="center" align="left">&nbsp;%y-%m-%d
</td></tr><tr><td valign="center" align="left"> 1998 years, 312 days </td><td valign="center" align="left">&nbsp;%Y years,&nbsp;%j days
</td></tr><tr><td valign="center" align="left"> Jan 24, 2003 </td><td valign="center" align="left">&nbsp;%b&nbsp;%d,&nbsp;%Y
</td></tr><tr><td valign="center" align="left"> January 24, 2003 </td><td valign="center" align="left">&nbsp;%B&nbsp;%d,&nbsp;%Y
</td></tr><tr><td valign="center" align="left"> 1397477611.862 </td><td valign="center" align="left">&nbsp;%s.%3N
</td></tr></table><p><b>Note:</b> Splunk Enterprise does not currently recognize non-English month names in timestamps. If you have an app that writes non-English month names to log files, reconfigure the app to use numerical months, if possible.
</p>
<h3> <a name="configuretimestamprecognition_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p>Your data might contain an easily recognizable timestamp, such as:
</p><p>...<code><font size="2">FOR: 04/24/07   PAGE 01</font></code>...
</p><p>To extract that timestamp, add this stanza in <code><font size="2">props.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[host::foo]<br>TIME_PREFIX = FOR: <br>TIME_FORMAT =&nbsp;%m/%d/%y<br></font></code></div>
<p>Another example that includes time zone information:
</p><p>&acirc;&#128;&brvbar;<code><font size="2">Valid_Until=Thu Dec 31 17:59:59 GMT-06:00 2020
</font></code></p><p>To extract the timestamp, add this to &lt;code&gt;props.conf:
</p>
<div class="samplecode"><code><font size="2"><br>[host::bar]<br>TIME_PREFIX = Valid_Until=<br>TIME_FORMAT =&nbsp;%b&nbsp;%d&nbsp;%H:%M:%S&nbsp;%Z%z&nbsp;%Y<br></font></code></div>
<p>Your data might contain other information that Splunk Enterprise parses as timestamps, for example:
</p><p>...<code><font size="2">1989/12/31 16:00:00 ed May 23 15:40:21 2007</font></code>...
</p><p>Splunk Enterprise extracts the date as Dec 31, 1989, which is not useful.  In this case, configure <code><font size="2">props.conf</font></code> to extract the correct timestamp from events from <code><font size="2">host::foo</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[host::foo]<br>TIME_PREFIX = \d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} \w+\s<br>TIME_FORMAT =&nbsp;%b&nbsp;%d&nbsp;%H:%M:%S&nbsp;%Y<br></font></code></div>
<p>This configuration assumes that all timestamps from <code><font size="2">host::foo</font></code> are in the same format.  Configure your <code><font size="2">props.conf</font></code> stanza to be as granular as possible to avoid potential timestamping errors.
</p><p>For detailed information on extracting the correct timestamp from events containing multiple timestamps, see <a href="#configurepositionaltimestampextraction" class="external text">"Configure timestamp assignment for events with multiple timestamps"</a>.
</p>
<h3> <a name="configuretimestamprecognition_configure_timestamps_for_specific_needs"><span class="mw-headline" id="Configure_timestamps_for_specific_needs"> Configure timestamps for specific needs  </span></a></h3>
<p>You can use the attributes described in this topic to configure the Splunk Enterprise timestamp extraction processor for some specialized purposes, such as:
</p>
<ul><li> <a href="#applytimezoneoffsetstotimestamps" class="external text">To apply time zone offsets</a>.
</li><li> <a href="#configurepositionaltimestampextraction" class="external text">To pull the correct timestamp from events with more than one timestamp</a>.
</li><li> <a href="#tunetimestampextractionforbetterindexingperformance" class="external text">To improve indexing performance</a>.
</li></ul><h3> <a name="configuretimestamprecognition_configure_how_timestamps_appear_in_search_results"><span class="mw-headline" id="Configure_how_timestamps_appear_in_search_results"> Configure how timestamps appear in search results</span></a></h3>
<p>You can use your browser's locale setting to configure how the browser formats Splunk Enterprise timestamps in search results. For information on setting the browser locale, see "User language and locale".
</p>
<h3> <a name="configuretimestamprecognition_reconfigure_how_timestamps_appear_in_raw_data"><span class="mw-headline" id="Reconfigure_how_timestamps_appear_in_raw_data">Reconfigure how timestamps appear in raw data </span></a></h3>
<p>Even though Splunk Enterprise uses the browser locale to configure how timestamps appear in search results, the data still remains in its original format in the raw data. You might want to change this, so that the data format is standardized in both raw data and search results.  You can do this by means of <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code>.  Here's an example:
</p><p>Assume the timestamp data in the raw event looks like this:
</p>
<div class="samplecode"><code><font size="2"><br>06/07/2011 10:26:11 PM<br></font></code></div>
<p>but you want it to look like this (to correspond with how it appears in search results):
</p>
<div class="samplecode"><code><font size="2"><br>07/06/2011 10:26:11 PM<br></font></code></div>
<p>This example shows briefly how you can use <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code> to transform the timestamp in the raw event.
</p><p>In <code><font size="2">transforms.conf</font></code>, add this stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[resortdate]<br>REGEX = ^(\d{2})\/(\d{2})\/(\d{4})\s([^/]+)<br>FORMAT = $2/$1/$3 $4<br>DEST_KEY = _raw <br></font></code></div>
<p>In <code><font size="2">props.conf</font></code>, add this stanza, where <code><font size="2">&lt;spec&gt;</font></code> qualifies your data:
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;spec&gt;]<br>TRANSFORMS-sortdate = resortdate<br></font></code></div>
<h3> <a name="configuretimestamprecognition_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around timestamp recognition and configuration.
</p>
<a name="configurepositionaltimestampextraction"></a><h2> <a name="configurepositionaltimestampextraction_configure_timestamp_assignment_for_events_with_multiple_timestamps"><span class="mw-headline" id="Configure_timestamp_assignment_for_events_with_multiple_timestamps"> Configure timestamp assignment for events with multiple timestamps </span></a></h2>
<p>If an event contains more than one timestamp, you can specify which timestamp Splunk Enterprise uses. This is especially useful when indexing events that contain syslog host-chaining data.
</p><p>Configure positional timestamp extraction by editing props.conf. For general information on editing <code><font size="2">props.conf</font></code> for timestamps, see <a href="#configuretimestamprecognition" class="external text">"Configure timestamp recognition"</a>.   
</p>
<h3> <a name="configurepositionaltimestampextraction_configure_positional_timestamp_extraction"><span class="mw-headline" id="Configure_positional_timestamp_extraction"> Configure positional timestamp extraction </span></a></h3>
<p>Configure Splunk Enterprise to recognize a timestamp anywhere in an event by adding <code><font size="2">TIME_PREFIX</font></code> and <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code> attributes to a  <code><font size="2">props.conf</font></code> stanza. By setting a regex value for <code><font size="2">TIME_PREFIX</font></code>, you tell Splunk Enterprise what pattern of characters indicate the point to start looking for the timestamp. Set a value for <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code> to tell Splunk Enterprise how far into an event (past the TIME_PREFIX location) to look for the timestamp.  By constraining lookahead, you can improve both accuracy and performance.
</p><p>When <code><font size="2">TIME_PREFIX</font></code> is set, Splunk Enterprise scans the event text for a match to its regex before it tries to extract a timestamp. The Splunk Enterprise timestamping algorithm only looks for a timestamp in the text following the end of the first regex match. So if <code><font size="2">TIME_PREFIX</font></code> is set to <code><font size="2">abc123</font></code>, only the text following the first occurrence of <code><font size="2">abc123</font></code> is used for timestamp extraction. 
</p><p><code><font size="2">TIME_PREFIX</font></code> also sets the start point for <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code>; the lookahead starts after the matched portion of text in the <code><font size="2">TIME_PREFIX</font></code> regex. For example, if <code><font size="2">TIME_PREFIX</font></code> matches text through the first 11 characters of the event and the timestamp you want to extract is always within the next 30 characters, you can set <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD=30</font></code>.  Timestamp extraction would be limited to text starting with character 12 and ending with character 41.
</p>
<h3> <a name="configurepositionaltimestampextraction_example"><span class="mw-headline" id="Example">Example</span></a></h3>
<p>Say you have an event that looks like this: 
</p>
<code><font size="2"><br>1989/12/31 16:00:00 Wed May 23 15:40:21 2007 ERROR UserManager - Exception thrown <br>Ignoring unsupported search for eventtype: /doc sourcetype="access_combined" <br>NOT eventtypetag=bot<br></font></code>
<p>To identify the timestamp as the second string of time information,  <code><font size="2">May 23 15:40:21 2007</font></code>, configure <code><font size="2">props.conf</font></code> like this: 
</p>
<code><font size="2"><br>[source::/Applications/splunk/var/spool/splunk]<br>TIME_PREFIX = \d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} \w+\s <br>MAX_TIMESTAMP_LOOKAHEAD = 21<br></font></code>
<p>This configuration instructs Splunk Enterprise to locate events that match the first timestamp construction, but <i>ignore</i> that timestamp in favor of a timestamp that occurs within the following 21 characters (a number it gets from the <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code> attribute). Splunk Enterprise will find the second timestamp because it always occurs within that 21-character limit.
</p><p><b>Note:</b> Optimize the speed of timestamp extraction by setting the value of <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD </font></code> to look only as far into an event as needed for the timestamp you want to extract.  In this example, <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD </font></code> is optimized to look just 21 characters into the event past the regex value.
</p>
<a name="applytimezoneoffsetstotimestamps"></a><h2> <a name="applytimezoneoffsetstotimestamps_specify_time_zones_for_timestamps"><span class="mw-headline" id="Specify_time_zones_for_timestamps"> Specify time zones for timestamps</span></a></h2>
<p>If you index data from different time zones, you can use time zone offsets to ensure that they're correctly correlated when you search. You can configure time zones based on the host, source, or source type of an event. 
</p><p>Configure time zones in props.conf. For general information on editing <code><font size="2">props.conf</font></code> for timestamps, see <a href="#configuretimestamprecognition" class="external text">"Configure timestamp recognition"</a>.   
</p>
<h3> <a name="applytimezoneoffsetstotimestamps_how_splunk_applies_time_zones"><span class="mw-headline" id="How_Splunk_applies_time_zones">How Splunk applies time zones</span></a></h3>
<p>By default, Splunk Enterprise applies time zones using these rules, in this order: 
</p><p><b>1.</b> Splunk Enterprise uses any time zone specified in raw event data (for example, PST, -0800).
</p><p><b>2.</b> Splunk Enterprise uses the value of a <code><font size="2">TZ</font></code> attribute set in  <code><font size="2">props.conf</font></code>, if the event matches the host, source, or source type specified by the stanza.
</p><p><b>3.</b> If an event that arrives at an indexer originated at a forwarder, and both the forwarder and the receiving indexer run Splunk Enterprise 6.0 or later, then Splunk Enterprise uses the time zone that the forwarder provides.
</p><p><b>4.</b> Otherwise, Splunk Enterprise uses the time zone of the server that indexes the event. 
</p><p><b>Note:</b> If you change the time zone setting in the system Splunk Enterprise runs on, you must restart Splunk Enterprise for it to pick up the change. 
</p>
<h3> <a name="applytimezoneoffsetstotimestamps_specify_time_zones_in_props.conf"><span class="mw-headline" id="Specify_time_zones_in_props.conf"> Specify time zones in props.conf </span></a></h3>
<p>To configure time zone settings, edit props.conf in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>Configure time zones by adding a <code><font size="2">TZ</font></code> attribute to the appropriate stanza  in <code><font size="2">props.conf</font></code>. The Splunk <code><font size="2">TZ</font></code> attribute recognizes zoneinfo TZ IDs. (See all the time zone TZ IDs in the zoneinfo (TZ) database.) Inside the stanza for a host, source, or source type,  set the <code><font size="2">TZ</font></code> attribute to the TZ ID for the desired time zone. This should be the time zone of the events coming from that host, source, or sourcetype. 
</p><p>Note that the time zone of the indexer is not configured in Splunk Enterprise, but in the underlying operating system. As long as the time is set correctly on the host system of the indexer, the offsets to event time zones will be calculated correctly.
</p>
<h3> <a name="applytimezoneoffsetstotimestamps_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p>Events are coming to this indexer from New York City (in the US/Eastern time zone) and Mountain View, California (US/Pacific). To correctly handle the timestamps for these two sets of events, the <code><font size="2">props.conf</font></code> for the indexer needs the time zone to be specified as US/Eastern and US/Pacific  respectively.
</p><p>The first example sets the time zone to US/Eastern for any events coming from hosts whose names match the regex <code><font size="2">nyc.*</font></code>:
</p>
<code><font size="2"><br>[host::nyc*]<br>TZ = US/Eastern<br></font></code>
<p>The second example sets the time zone to US/Pacific for any events coming from sources in the path <code><font size="2">/mnt/ca/...</font></code>:
</p>
<code><font size="2"><br>[source::/mnt/ca/...]<br>TZ = US/Pacific<br></font></code>
<h3> <a name="applytimezoneoffsetstotimestamps_zoneinfo_.28tz.29_database"><span class="mw-headline" id="zoneinfo_.28TZ.29_database"> zoneinfo (TZ) database </span></a></h3>
<p>The zoneinfo database is a publicly maintained database of time zone values.
</p>
<ul><li> UNIX versions of Splunk rely on a TZ database included with the UNIX distribution you're running on. Most UNIX distributions store the database in the directory: <code><font size="2">/usr/share/zoneinfo</font></code>.
</li><li> Solaris versions of Splunk store TZ information in this directory: <code><font size="2">/usr/share/lib/zoneinfo</font></code>.
</li><li> Windows versions of Splunk ship with a copy of the TZ database. 
</li></ul><p>Refer to the zoneinfo (TZ) database for all permissible <code><font size="2">TZ</font></code> values.
</p>
<h3> <a name="applytimezoneoffsetstotimestamps_map_timezone_strings_extracted_from_event_data"><span class="mw-headline" id="Map_timezone_strings_extracted_from_event_data">Map timezone strings extracted from event data</span></a></h3>
<p>Use the <code><font size="2">TZ_ALIAS</font></code> attribute in <code><font size="2">props.conf</font></code> to change Splunk's interpretation of a timezone acronym string occurring in event data. For example, "EST" means Eastern (US) Standard Time by default, but your event data might be using that value instead to designate Eastern (Australian) Standard Time. To change the meaning of "EST" to the latter, set the attribute like this:
</p>
<code><font size="2"><br>TZ_ALIAS = EST=GMT+10:00<br></font></code> 
<p>Then, when Splunk encounters "EST" in event data, it will interpret it as "GMT+10:00", rather than the default  of "GMT- 5:00".
</p><p>As this example shows, you can map a timezone string to an existing string plus  offset value. You can also just map one TZ string directly to another.
</p><p>When mapping timezone strings, be sure to handle both summer and winter versions of the time zones. If mapping EST, also map EDT, for example - depending on whatever your local pairs are.  Test your software to see what timezone strings it produces.
</p><p>You can specify multiple mappings. The syntax for <code><font size="2">TZ_ALIAS</font></code> is:
</p>
<code><font size="2"><br>TZ_ALIAS = &lt;key=value&gt;[,&lt;key=value&gt;]...<br></font></code>
<p>For more information, including examples, see the props.conf specification and example file in the Configuration File Reference.
</p>
<h3> <a name="applytimezoneoffsetstotimestamps_set_the_time_zone_for_a_user.27s_search_results"><span class="mw-headline" id="Set_the_time_zone_for_a_user.27s_search_results"> Set the time zone for a user's search results </span></a></h3>
<p>When you add or edit users using Splunk's built-in authentication, you can set a user time zone. Search results for that user will appear in the specified time zone.  This setting, however, does not change the actual event data,  whose time zone is determined at index time. For information on setting this value, see "Configure users with Splunk Web" in Securing Splunk.
</p>
<a name="tunetimestampextractionforbetterindexingperformance"></a><h2> <a name="tunetimestampextractionforbetterindexingperformance_tune_timestamp_recognition_for_better_indexing_performance"><span class="mw-headline" id="Tune_timestamp_recognition_for_better_indexing_performance"> Tune timestamp recognition for better indexing performance </span></a></h2>
<p>To speed up indexing, you can adjust how far ahead into events the Splunk Enterprise timestamp processor looks, or even turn off the timestamp processor altogether. You do this by editing props.conf. 
</p><p>For general information on editing <code><font size="2">props.conf</font></code> for timestamps, see <a href="#configuretimestamprecognition" class="external text">"Configure timestamp recognition"</a>.   
</p>
<h3> <a name="tunetimestampextractionforbetterindexingperformance_adjust_timestamp_lookahead"><span class="mw-headline" id="Adjust_timestamp_lookahead"> Adjust timestamp lookahead </span></a></h3>
<p>Timestamp lookahead determines how far (how many characters) into an event the timestamp processor looks for a timestamp. Adjust how far the timestamp processor looks by setting the <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code> attribute. 
</p><p>The default number of characters that the timestamp processor looks into an event is 150. You can set <code><font size="2">MAX_TIMESTAMP_LOOKAHEAD</font></code> to a lower value to speed up indexing. You should particularly do this if the timestamps always occur in the first part of the event.
</p><p><b>Example:</b>
</p><p>This example tells Splunk Enterprise to look for timetamps in just the first 20 characters of events coming from source <code><font size="2">foo</font></code>.
</p>
<div class="samplecode"><code><font size="2"><br>[source::foo]<br>MAX_TIMESTAMP_LOOKAHEAD = 20<br>...<br></font></code></div>
<h3> <a name="tunetimestampextractionforbetterindexingperformance_disable_timestamp_processor"><span class="mw-headline" id="Disable_timestamp_processor"> Disable timestamp processor</span></a></h3>
<p>You can turn off the timestamp processor entirely to improve indexing performance. Turn off timestamp processing for events matching a specified host, source, or sourcetype by setting the <code><font size="2">DATETIME_CONFIG</font></code> attribute to <code><font size="2">NONE</font></code>. When <code><font size="2">DATETIME_CONFIG=NONE</font></code>, Splunk Enterprise does not look at the text of the event for the timestamp. Instead, it uses the event's "time of receipt"; in other words, the time the event is received via its input. For file-based inputs (such as monitor) this means that Splunk Enterprise derives the timestamp from the modification time of the input file. 
</p><p>You can also increase indexing performance by setting <code><font size="2">DATETIME_CONFIG</font></code> to <code><font size="2">CURRENT</font></code>. This causes Splunk Enterprise to assign the current system time to each event at the time of indexing.
</p><p><b>Example:</b>
</p><p>This example turns off timestamp extraction for events that come from the source <code><font size="2">foo</font></code>.
</p>
<div class="samplecode"><code><font size="2"><br>[source::foo]<br>DATETIME_CONFIG = NONE<br>...<br></font></code></div>
<p><b>Note:</b>  Both <code><font size="2">CURRENT</font></code> and <code><font size="2">NONE</font></code> explicitly disable timestamp identification, so the default event boundary detection (<code><font size="2">BREAK_ONLY_BEFORE_DATE = true</font></code>) is likely not to work as desired.  When using these settings, use <code><font size="2">SHOULD_LINEMERGE</font></code> and/or the <code><font size="2">BREAK_ONLY_* , MUST_BREAK_*</font></code> settings to control event merging.
</p>
<h1>Configure indexed field extraction</h1><a name="aboutindexedfieldextraction"></a><h2> <a name="aboutindexedfieldextraction_about_indexed_field_extraction"><span class="mw-headline" id="About_indexed_field_extraction"> About indexed field extraction</span></a></h2>
<p>When Splunk Enterprise indexes data, it parses the data stream into a series of <b>events</b>. As part of this process, it adds a number of  <b>fields</b> to the  <b>event data</b>. These fields include <b>default fields</b> that it adds automatically and any <b>custom fields</b> that you specify.
</p><p>The process of adding fields to events is known as  <b>field extraction</b>. There are two types of field extraction:
</p>
<ul><li> <b>Indexed field extraction</b>, which was described briefly at the start of this topic and which forms the basis for this chapter. Splunk Enterprise stores these fields in the index, and the fields become part of the event data.
</li></ul><ul><li> <b>Search-time field extraction</b>, which takes place when you search through data. Splunk Enterprise creates those fields on the fly and does not store them in the index. See "About fields" in the <i>Knowledge Manager Manual</i> for information about this type of field extraction.
</li></ul><p>There are two types of indexed fields:
</p>
<ul><li> <b>Default fields</b>, which Splunk automatically adds to each event. See <a href="#aboutdefaultfields" class="external text">"About default fields"</a> in this chapter.
</li><li> <b>Custom fields</b>, which you specify.  See <a href="#configureindex-timefieldextraction" class="external text">"Create custom fields at index time"</a> in this manual.
</li></ul><p><b>Note:</b> When working with fields, consider that most machine data either does not have structure or has structure that changes constantly. For this type of data, Splunk Enterprise recommends using search-time field extraction for the purposes of flexibility. Search-time field extraction is trivial to modify within Splunk Enterprise once you set it. 
</p><p>Other types of data might exhibit a more fixed structure, or the structure might already be defined within the data or events in the file. Splunk Enterprise provides the option to read the structure of these kinds of files (such as comma-separated value files (CSV), tab-separated value files (TSV), pipe-separated value files, and JavaScript Object Notation (JSON) data sources) and perform field mapping at index time. To read about how this works, read "<a href="#extractfieldsfromfileheadersatindextime" class="external text">Extract data from files with headers</a>" in this manual.
</p>
<a name="aboutdefaultfields"></a><h2> <a name="aboutdefaultfields_about_default_fields_.28host.2c_source.2c_sourcetype.2c_and_more.29"><span class="mw-headline" id="About_default_fields_.28host.2C_source.2C_sourcetype.2C_and_more.29"> About default fields (host, source, sourcetype, and more) </span></a></h2>
<p>When Splunk indexes data, it tags each event with a number of fields. These fields become part of the index's  <b>event data</b>.  The fields that Splunk adds automatically are known as <b>default fields</b>. 
</p><p>Default fields serve a number of purposes.  For example, the default field <code><font size="2">index</font></code> identifies the index in which the event is located. The default field  <code><font size="2">linecount</font></code> describes the number of lines the event contains, and <code><font size="2">timestamp</font></code> specifies the time at which the event occurred. Splunk uses the values in some of the fields, particularly <code><font size="2">sourcetype</font></code>, when indexing the data, in order to create events properly. Once the data has been indexed, you can use the default fields in your searches.
</p><p>Here's the complete list of default fields:
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Type of field
</th><th bgcolor="#C0C0C0">List of fields
</th><th bgcolor="#C0C0C0">Description
</th></tr><tr><td valign="center" align="left">Internal fields
</td><td valign="center" align="left"><code><font size="2">_raw, _time, _indextime, _cd</font></code>
</td><td valign="center" align="left">These fields contain information that Splunk uses for its internal processes.
</td></tr><tr><td valign="center" align="left">Basic default fields
</td><td valign="center" align="left"><code><font size="2"> host, index, linecount, punct, source, sourcetype, splunk_server, timestamp</font></code>
</td><td valign="center" align="left">These fields provide basic information about an event, such as where it originated, what kind of data it contains,what index it's located in, how many lines it contains, and when it occurred.
</td></tr><tr><td valign="center" align="left">Default datetime fields
</td><td valign="center" align="left"><code><font size="2">date_hour, date_mday, date_minute, date_month, date_second, date_wday, date_year, date_zone</font></code>
</td><td valign="center" align="left">These fields provide additional searchable granularity to event timestamps.
<p><b>Note:</b> Only events that have timestamp information in them as generated by their respective systems will have date_* fields. If an event has a date_* field, it represents the value of time/date directly from the event itself. If you have specified any timezone conversions or changed the value of the time/date at indexing or input time (for example, by setting the timestamp to be the time at index or input time), these fields will not represent that. 
</p>
</td></tr></table><p>For information about default fields from the search perspective, see "Use default fields" in the Knowledge Manager Manual.
</p><p><b>Note:</b> You can also specify additional, custom fields for Splunk to include in the index. See <a href="#configureindex-timefieldextraction" class="external text">"Create custom fields at index-time"</a> in this chapter.
</p><p>This topic focuses on three key default fields: 
</p>
<ul><li> <b>host</b>
</li><li>  <b>source</b>
</li><li> <b>sourcetype</b>
</li></ul><h3> <a name="aboutdefaultfields_defining_host.2c_source.2c_and_sourcetype"><span class="mw-headline" id="Defining_host.2C_source.2C_and_sourcetype"> Defining host, source, and sourcetype </span></a></h3>
<p>The host, source, and sourcetype fields are defined as follows:
</p>
<ul><li> <b>host</b> - An event's host value is typically the hostname, IP address, or fully qualified domain name of the network host from which the event originated. The host value enables you to easily locate data originating from a specific device. For more information on hosts, see <a href="#abouthosts" class="external text">"About hosts"</a>.
</li><li> <b>source</b> - The source of an event is the name of the file, stream, or other input from which the event originates. For data monitored from files and directories, the value of source is the full path, such as <code><font size="2">/archive/server1/var/log/messages.0</font></code> or <code><font size="2">/var/log/</font></code>. The value of source for network-based data sources is the protocol and port, such as UDP:514. 
</li><li> <b>sourcetype</b> - The source type of an event is the format of the data input from which it originates, such as <code><font size="2">access_combined</font></code> or <code><font size="2">cisco_syslog</font></code>. The source type determines how Splunk formats your data. For more information on source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter"</a>.
</li></ul><h3> <a name="aboutdefaultfields_source_vs_sourcetype"><span class="mw-headline" id="Source_vs_sourcetype"> Source vs sourcetype </span></a></h3>
<p>Don't confuse source and sourcetype! They're both default fields, but they're entirely different otherwise:
</p>
<ul><li> The <b>source</b> is the name of the file, stream, or other input from which a particular event originates. 
</li></ul><ul><li> The <b>sourcetype</b> field specifies the format for the event. Splunk uses this field to determine how to format the incoming data stream into individual events.
</li></ul><p><b>Events with the same source type can come from different sources.</b> For example, say you're monitoring <code><font size="2">source=/var/log/messages</font></code> and receiving direct syslog input from <code><font size="2">udp:514</font></code>. If you search <code><font size="2">sourcetype=linux_syslog</font></code>, Splunk will return events from both of those sources.
</p>
<h3> <a name="aboutdefaultfields_under_what_conditions_should_you_override_host_and_sourcetype_assignment.3f"><span class="mw-headline" id="Under_what_conditions_should_you_override_host_and_sourcetype_assignment.3F"> Under what conditions should you override host and sourcetype assignment? </span></a></h3>
<p>Much of the time, Splunk can automatically identify host and sourcetype values that are both correct <i>and</i> useful. But situations do come up that require you to intervene in this process and provide override values.
</p>
<h4><font size="3"><b><i> <a name="aboutdefaultfields_override_host_assignment"><span class="mw-headline" id="Override_host_assignment">Override host assignment</span></a></i></b></font></h4>
<p>You might want to change your default <code><font size="2">host</font></code> assignment when:
</p>
<ul><li> You are bulk-loading archive data that was originally generated from a different host and you want those events to have that host value.
</li><li> Your data is being forwarded from a different host. (The forwarder will be the host unless you specify otherwise.)
</li><li> You are working with a centralized log server environment, which means that all of the data received from that server will have the same host, even if it originated elsewhere. 
</li></ul><p>For detailed information about hosts, see the chapter
<a href="#abouthosts" class="external text">"Configure host values"</a>.
</p>
<h4><font size="3"><b><i> <a name="aboutdefaultfields_override_sourcetype_assignment"><span class="mw-headline" id="Override_sourcetype_assignment">Override sourcetype assignment</span></a></i></b></font></h4>
<p>You might want to change your default <code><font size="2">sourcetype</font></code> assignment when:
</p>
<ul><li> Splunk is unable to automatically format the data properly, resulting in problems such as wrong timestamping or event linebreaking.
</li><li> You want to apply source types to specific events coming through a particular input, such as events that originate from a discrete group of hosts, or even events that are associated with a particular IP address or userid.
</li></ul><p>There are also steps you can take to expand the range of source types that Splunk automatically recognizes, or to simply rename source types. 
</p><p>For detailed information about source types, see the chapter
<a href="#whysourcetypesmatter" class="external text">"Configure source types"</a>.
</p>
<a name="assignmetadatatoeventsdynamically"></a><h2> <a name="assignmetadatatoeventsdynamically_assign_default_fields_dynamically"><span class="mw-headline" id="Assign_default_fields_dynamically"> Assign default fields dynamically</span></a></h2>
<p>This feature allows you to dynamically assign default fields, also known as "metadata", to files as they are being consumed by Splunk. Use this feature to specify source type, host, or source dynamically for incoming data. This feature is useful mainly with scripted data -- either a <b>scripted input</b> or an existing file processed by a script.
</p><p><b>Important:</b>  Splunk does not recommend using dynamic metadata assignment with ongoing file monitoring (tail) inputs. For more information about file inputs, refer to <a href="#monitorfilesanddirectories" class="external text">Monitor files and directories</a> in this manual.
</p><p><b>Note</b>: The modular inputs feature has largely superseded this ***SPLUNK*** header feature.  If you need to present dynamically-generated values of host, source and sourcetype to splunk, consider writing a modular input.
</p><p>To use this feature, you append a single dynamic input header to your file and specify the metadata fields you want to assign values to. The available metadata fields are sourcetype, host, and source. 
</p><p>You can use this method to assign metadata instead of editing inputs.conf, props.conf, and transforms.conf.
</p>
<h3> <a name="assignmetadatatoeventsdynamically_configure_a_single_input_file"><span class="mw-headline" id="Configure_a_single_input_file"> Configure a single input file </span></a></h3>
<p>To use this feature for an existing input file, edit the file (either manually or with a script) to add a single input header:
</p>
<code><font size="2"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;***SPLUNK*** &lt;metadata field&gt;=&lt;string&gt; &lt;metadata field&gt;=&lt;string&gt; ...<br></font></code>
<ul><li> Set <code><font size="2">&lt;metadata field&gt;=&lt;string&gt;</font></code> to a valid metadata/value pair. You can specify multiple pairs. For example, <code><font size="2">sourcetype=log4j host=swan</font></code>.
</li><li> Add the single header anywhere in your file. Any data following the header will be appended with the attributes and values you assign until the end of the file is reached.
</li><li> Add your file to <code><font size="2">$SPLUNK_HOME/var/spool/splunk</font></code> or any other directory being monitored by Splunk.
</li></ul><h3> <a name="assignmetadatatoeventsdynamically_configure_with_a_script"><span class="mw-headline" id="Configure_with_a_script"> Configure with a script </span></a></h3>
<p>In the more common scenario, you write a script to dynamically add an input header to your incoming data stream.  Your script can also set the header dynamically based on the contents of the input file.
</p>
<a name="configureindex-timefieldextraction"></a><h2> <a name="configureindex-timefieldextraction_create_custom_fields_at_index_time"><span class="mw-headline" id="Create_custom_fields_at_index_time"> Create custom fields at index time </span></a></h2>
<p><b>Caution:</b> <b>We do</b> <i><b>not</b></i> <b>recommend</b> that you add custom fields to the set of <b>default fields</b> that Splunk automatically extracts and indexes at <b>index time</b>, such as <code><font size="2">timestamp</font></code>, <code><font size="2">punct</font></code>, <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>. Adding to this list of fields can negatively impact indexing performance and search times, because each indexed field increases the size of the searchable index. Indexed fields are also less flexible--whenever you make changes to your set of fields, you must re-index your entire dataset. For more information, see "Index time versus search time" in the Managing Indexers and Clusters manual.
</p><p>With those caveats, there are times when you might find reason to add custom indexed fields. For example, you might have a situation where certain search-time field extractions are noticeably impacting search performance. This can happen, for example, if you commonly search a large event set with expressions like <code><font size="2">foo!=bar</font></code> or <code><font size="2">NOT foo=bar</font></code>, and the field <code><font size="2">foo</font></code> nearly <i>always</i> takes on the value <code><font size="2">bar</font></code>. 
</p><p>Conversely, you might want to add an indexed field if the value of a search-time extracted field exists outside of the field more often than not. For example, if you commonly search only for <code><font size="2">foo=1</font></code>, but 1 occurs in many events that do <i>not</i> have <code><font size="2">foo=1</font></code>, you might want to add <code><font size="2">foo</font></code> to the list of fields extracted by Splunk at index time.
</p><p>In general, you should try to extract your fields at search time. For more information see "About fields" in the Knowledge Manager manual. 
</p>
<h3> <a name="configureindex-timefieldextraction_define_additional_indexed_fields"><span class="mw-headline" id="Define_additional_indexed_fields"> Define additional indexed fields </span></a></h3>
<p>Define additional indexed fields by editing props.conf,  transforms.conf, and fields.conf.
</p><p>Edit these files in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For more information on configuration files in general, see "About configuration files" in the Admin manual.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_where_to_put_the_configuration_changes_in_a_distributed_environment"><span class="mw-headline" id="Where_to_put_the_configuration_changes_in_a_distributed_environment">Where to put the configuration changes in a distributed environment</span></a></i></b></font></h4>
<p>If you have a <b>distributed search</b> deployment, processing is split between search peers (indexers) and a search head. You must deploy the changes as follows:
</p>
<ul><li> Deploy the <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code> changes to each of the search peers.
</li><li> Deploy the <code><font size="2">fields.conf</font></code> changes to the search head.
</li></ul><p><b>Note:</b> If you are employing heavy forwarders in front of your search peers, the props and transforms processing takes place on the forwarders, not the search peers. Therefore, you must deploy the props and transforms changes to the forwarders, not the search peers.
</p><p>For details on Splunk Enterprise distributed components, read "Components and roles" in the Distributed Deployment Manual.
</p><p>For details on where you need to put configuration settings, read "Configuration parameters and the data pipeline" in the Admin Manual.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_field_name_syntax_restrictions"><span class="mw-headline" id="Field_name_syntax_restrictions">Field name syntax restrictions</span></a></i></b></font></h4>
<p>Splunk only accepts field names that contain alpha-numeric characters or an underscore: 
</p>
<ul><li> Valid characters for field names are <b>a-z, A-Z, 0-9,</b> or <b>_</b> .
</li><li> Field names cannot begin with <b>0-9</b> or <b>_</b> . Leading underscores are reserved for Splunk's internal variables.  
</li><li> International characters are not allowed.
</li></ul><h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_add_a_regex_stanza_for_the_new_field_to_transforms.conf"><span class="mw-headline" id="Add_a_regex_stanza_for_the_new_field_to_transforms.conf"> Add a regex stanza for the new field to transforms.conf </span></a></i></b></font></h4>
<p>Follow this format when you define an index-time field transform in <code><font size="2">transforms.conf</font></code> (Note: Some of these attributes, such as <code><font size="2">LOOKAHEAD</font></code> and <code><font size="2">DEST_KEY</font></code>, are only required for certain use cases):
</p>
<code><font size="2"><br>[&lt;unique_transform_stanza_name&gt;]<br>REGEX = &lt;regular_expression&gt;<br>FORMAT = &lt;your_custom_field_name&gt;::$1<br>WRITE_META = [true|false]<br>DEST_KEY = &lt;KEY&gt;<br>DEFAULT_VALUE = &lt;string&gt;<br>SOURCE_KEY = &lt;KEY&gt;<br>REPEAT_MATCH = [true|false]<br>LOOKAHEAD = &lt;integer&gt;<br></font></code>
<p>Note the following:
</p>
<ul><li> The <code><font size="2">&lt;unique_stanza_name&gt;</font></code> is required for all transforms, as is the <code><font size="2">REGEX</font></code>.
</li></ul><ul><li> <code><font size="2">REGEX</font></code> is a regular expression that operates on your data to extract fields. 
<ul><li> Name-capturing groups in the <code><font size="2">REGEX</font></code> are extracted directly to fields, which means that you don't have to specify a <code><font size="2">FORMAT</font></code> for simple field extraction cases. 
</li><li> If the <code><font size="2">REGEX</font></code> extracts both the field name <i>and</i> its corresponding value, you can use the following special capturing groups to skip specifying the mapping in the <code><font size="2">FORMAT</font></code> attribute:
</li></ul></li></ul><dl><dd><dl><dd> <code><font size="2">_KEY_&lt;string&gt;, _VAL_&lt;string&gt;</font></code>
</dd></dl></dd></dl><ul><li> For example, the following are equivalent:
</li></ul><dl><dd>Using <code><font size="2">FORMAT</font></code>:
</dd></dl><dl><dd><dl><dd> <code><font size="2">REGEX = ([a-z]+)=([a-z]+)</font></code>
</dd><dd> <code><font size="2">FORMAT = $1::$2</font></code>
</dd></dl></dd></dl><dl><dd>Not using <code><font size="2">FORMAT</font></code>:
</dd></dl><dl><dd><dl><dd> <code><font size="2">REGEX = (?&lt;_KEY_1&gt;[a-z]+)=(?&lt;_VAL_1&gt;[a-z]+)</font></code>
</dd></dl></dd></dl><ul><li> <code><font size="2">FORMAT</font></code> is optional. Use it to specify the format of the field/value pair(s) that you are extracting, including any field names or values that you want to add. You don't need to specify the <code><font size="2">FORMAT</font></code> if you have a simple <code><font size="2">REGEX</font></code> with name-capturing groups.
</li><li> <code><font size="2">FORMAT</font></code> behaves differently depending on whether the extraction takes place at search time or index time. 
<ul><li> For index-time transforms, you use <code><font size="2">$n</font></code> to specify the output of each <code><font size="2">REGEX</font></code> match (for example, <code><font size="2">$1</font></code>, <code><font size="2">$2</font></code>, and so on). 
</li><li> If the <code><font size="2">REGEX</font></code> does not have <code><font size="2">n</font></code> groups, the matching fails. 
</li><li> <code><font size="2">FORMAT</font></code> defaults to <code><font size="2">&lt;unique_transform_stanza_name&gt;::$1</font></code>.
</li><li> The special identifier <code><font size="2">$0</font></code> represents what was in the <code><font size="2">DEST_KEY</font></code> before the <code><font size="2">REGEX</font></code> was performed (in the case of index-time field extractions the <code><font size="2">DEST_KEY</font></code> is <code><font size="2">_meta</font></code>). For more information, see "How Splunk builds indexed fields," below.
</li><li> For index-time field extractions, you can set up <code><font size="2">FORMAT</font></code> in several ways. It can be a <code><font size="2">&lt;field-name&gt;::&lt;field-value&gt;</font></code> setup like:
</li></ul></li></ul><dl><dd><dl><dd> <code><font size="2">FORMAT = field1::$1 field2::$2</font></code> (where the <code><font size="2">REGEX</font></code> extracts field values for captured groups "field1" and "field2") 
</dd></dl></dd></dl><dl><dd>or:
</dd></dl><dl><dd><dl><dd> <code><font size="2">FORMAT = $1::$2</font></code> (where the <code><font size="2">REGEX</font></code> extracts both the field name and the field value)
</dd></dl></dd></dl><dl><dd>However you can also set up index-time field extractions that create concatenated fields: 
</dd></dl><dl><dd><dl><dd> <code><font size="2">FORMAT = ipaddress::$1.$2.$3.$4</font></code>
</dd></dl></dd></dl><dl><dd>When you create concatenated fields with <code><font size="2">FORMAT</font></code>, it's important to understand that <code><font size="2">$</font></code> is the only special character. It is treated as a prefix for regex capturing groups <b>only</b> if it is followed by a number and <b>only</b> if that number applies to an existing capturing group. 
</dd></dl><dl><dd>So if your regex has only one capturing group and its value is <code><font size="2">bar</font></code>, then:
</dd></dl><dl><dd><dl><dd> <code><font size="2">FORMAT = foo$1</font></code> would yield <code><font size="2">foobar</font></code>
</dd><dd> <code><font size="2">FORMAT = foo$bar</font></code> would yield <code><font size="2">foo$bar</font></code>
</dd><dd> <code><font size="2">FORMAT = foo$1234</font></code> would yield <code><font size="2">foo$1234</font></code>
</dd><dd> <code><font size="2">FORMAT = foo$1\$2</font></code> would yield <code><font size="2">foobar\$2</font></code>
</dd></dl></dd></dl><ul><li> <code><font size="2">WRITE_META = true</font></code> writes the extracted field name and value to <code><font size="2">_meta</font></code>, which is where Splunk stores indexed fields. This attribute setting is required for all index-time field extractions, except for those where <code><font size="2">DEST_KEY = _meta</font></code> (see the discussion of <code><font size="2">DEST_KEY</font></code>, below). 
<ul><li> For more information about <code><font size="2">_meta</font></code> and its role in indexed field creation, see "How Splunk builds indexed fields," below.
</li></ul></li></ul><ul><li> <code><font size="2">DEST_KEY</font></code> is required for index-time field extractions where <code><font size="2">WRITE_META = false</font></code> or is not set. It specifies where Splunk sends the results of the  <code><font size="2">REGEX</font></code>. 
<ul><li> For index-time searches, <code><font size="2">DEST_KEY = _meta</font></code>, which is where Splunk stores indexed fields. For other possible <code><font size="2">KEY</font></code> values see the <code><font size="2">transforms.conf</font></code> page in this manual.
</li><li> For more information about <code><font size="2">_meta</font></code> and its role in indexed field creation, see <a href="#configureindex-timefieldextraction_how_splunk_builds_indexed_fields" class="external text">"How Splunk builds indexed fields,"</a> below.
</li><li> When you use <code><font size="2">DEST_KEY = _meta</font></code> you should also add <code><font size="2">$0</font></code> to the start of your <code><font size="2">FORMAT</font></code> attribute. <code><font size="2">$0</font></code> represents the <code><font size="2">DEST_KEY</font></code> value before Splunk performs the <code><font size="2">REGEX</font></code> (in other words, <code><font size="2">_meta</font></code>.
</li><li> <b>Note:</b> The <code><font size="2">$0</font></code> value is in no way derived <i>from</i> the <code><font size="2">REGEX</font></code>. 
</li></ul></li></ul><ul><li> <code><font size="2">DEFAULT_VALUE</font></code> is optional. The value for this attribute is written to <code><font size="2">DEST_KEY</font></code> if the <code><font size="2">REGEX</font></code> fails. 
<ul><li> Defaults to empty.
</li></ul></li></ul><ul><li> <code><font size="2">SOURCE_KEY</font></code> is optional. You use it to identify a KEY whose values the <code><font size="2">REGEX</font></code> should be applied to.
<ul><li> By default, <code><font size="2">SOURCE_KEY = _raw</font></code>, which means it is applied to the entirety of all events.
</li><li> Typically used in conjunction with <code><font size="2">REPEAT_MATCH</font></code>.
</li><li> For other possible <code><font size="2">KEY</font></code> values see the <code><font size="2">transforms.conf</font></code> page in this manual.
</li></ul></li></ul><ul><li> <code><font size="2">REPEAT_MATCH</font></code> is optional. Set it to <code><font size="2">true</font></code> to run the <code><font size="2">REGEX</font></code> multiple times on the <code><font size="2">SOURCE_KEY</font></code>. 
<ul><li> <code><font size="2">REPEAT_MATCH</font></code> starts wherever the last match stopped and continues until no more matches are found. Useful for situations where an unknown number of field/value matches are expected per event.
</li><li> Defaults to <code><font size="2">false</font></code>.
</li></ul></li></ul><ul><li> <code><font size="2">LOOKAHEAD</font></code> is optional. Use it to specify how many characters to search into an event. 
<ul><li> Defaults to 4096. You might want to increase your <code><font size="2">LOOKAHEAD</font></code> value if you have events with line lengths longer than 4096 characters.
</li><li> Specifically, if the text you need to match is past this number of characters, you will need to increase this value.  
</li><li> Be aware, however, that complex regexes can have very high costs when scanning larger text segments.  The speed may fall off quadratically or worse when using multiple greedy branches or lookaheads / lookbehinds.
</li></ul></li></ul><p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regexes by using them in searches with the rex search command. Splunk also maintains a list of useful third-party tools for writing and testing regular expressions. 
</p><p><b>Note:</b> The capturing groups in your regex must identify field names that follow <a href="#configureindex-timefieldextraction_define_additional_indexed_fields" class="external text">field name syntax restrictions</a>. They can only contain ASCII characters (a-z, A-Z, 0-9 or _.). International characters will not work.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_link_the_new_field_to_props.conf"><span class="mw-headline" id="Link_the_new_field_to_props.conf"> Link the new field to props.conf </span></a></i></b></font></h4>
<p>To <code><font size="2">props.conf</font></code>, add the following lines:
</p>
<code><font size="2"><br>[&lt;spec&gt;]<br>TRANSFORMS-&lt;class&gt; = &lt;unique_stanza_name&gt;<br></font></code>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;spec&gt;</font></code> can be:
<ul><li> &lt;sourcetype&gt;, the sourcetype of an event.
</li><li> host::&lt;host&gt;, where &lt;host&gt; is the host for an event.
</li><li> source::&lt;source&gt;, where &lt;source&gt; is the source for an event.
</li><li> <b>Note:</b> You can use regex-type syntax when setting the <code><font size="2">&lt;spec&gt;</font></code>. Also, source and source type stanzas match in a case-sensitive manner while host stanzas do not. For more information, see the <code><font size="2">props.conf</font></code> spec file. 
</li></ul></li><li> <code><font size="2">&lt;class&gt;</font></code> is a unique literal string that identifies the namespace of the field (key) you are extracting. <b>Note:</b> <code><font size="2">&lt;class&gt;</font></code> values <i>do not</i> have to follow <a href="#configureindex-timefieldextraction_define_additional_indexed_fields" class="external text">field name syntax restrictions</a> (see above). You can use characters other than a-z, A-Z, and 0-9, and spaces are allowed.
</li><li> <code><font size="2">&lt;unique_stanza_name&gt;</font></code> is the name of your stanza from <code><font size="2">transforms.conf</font></code>.
</li></ul><p><b>Note:</b> For index-time field extraction, <code><font size="2">props.conf</font></code> uses <code><font size="2">TRANSFORMS-&lt;class&gt;</font></code>, as opposed to <code><font size="2">EXTRACT-&lt;class&gt;</font></code>, which is used for configuring search-time field extraction.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_add_an_entry_to_fields.conf_for_the_new_field"><span class="mw-headline" id="Add_an_entry_to_fields.conf_for_the_new_field"> Add an entry to fields.conf for the new field </span></a></i></b></font></h4>
<p>Add an entry to <code><font size="2">fields.conf</font></code> for the new indexed field:
</p>
<code><font size="2"><br>[&lt;your_custom_field_name&gt;]<br>INDEXED=true<br></font></code>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;your_custom_field_name&gt;</font></code> is the name of the custom field you set in the unique stanza that you added to <code><font size="2">transforms.conf</font></code>.
</li><li> Set <code><font size="2">INDEXED=true</font></code> to indicate that the field is indexed.
</li></ul><p><b>Note:</b> If a field of the same name is extracted at search time, you <b>must</b> set <code><font size="2">INDEXED=false</font></code> for the field. In addition, you must <i>also</i> set <code><font size="2">INDEXED_VALUE=false</font></code> if events exist that have values of that field that are not pulled out at index time, but which <i>are</i> extracted at search time. 
</p><p>For example, say you're performing a simple <code><font size="2">&lt;field&gt;::1234</font></code> extraction at index time. This could work, but you would have problems if you also implement a search-time field extraction based on a regex like <code><font size="2">A(\d+)B</font></code>, where the string <code><font size="2">A1234B</font></code> yields a value for that field of <code><font size="2">1234</font></code>. This would turn up events for <code><font size="2">1234</font></code> at search time that Splunk would be unable to locate at index time with the <code><font size="2">&lt;field&gt;::1234</font></code> extraction.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_restart_splunk_for_your_changes_to_take_effect"><span class="mw-headline" id="Restart_Splunk_for_your_changes_to_take_effect"> Restart Splunk for your changes to take effect </span></a></i></b></font></h4>
<p>Changes to configuration files such as <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code> won't take effect until you shut down and restart Splunk on all affected components.
</p>
<h3> <a name="configureindex-timefieldextraction_how_splunk_builds_indexed_fields"><span class="mw-headline" id="How_Splunk_builds_indexed_fields"> How Splunk builds indexed fields </span></a></h3>
<p>Splunk builds indexed fields by writing to <code><font size="2">_meta</font></code>. Here's how it works:
</p>
<ul><li> <code><font size="2">_meta</font></code> is modified by all matching transforms in <code><font size="2">transforms.conf</font></code> that contain either <code><font size="2">DEST_KEY = _meta</font></code> or <code><font size="2">WRITE_META = true</font></code>.
</li><li> Each matching transform can overwrite <code><font size="2">_meta</font></code>, so use <code><font size="2">WRITE_META = true</font></code> to append <code><font size="2">_meta</font></code>.
<ul><li> If you don't use <code><font size="2">WRITE_META</font></code>, then start your <code><font size="2">FORMAT</font></code> with <code><font size="2">$0</font></code>.
</li></ul></li><li> After <code><font size="2">_meta</font></code> is fully built during parsing, Splunk interprets the text in the following way:
<ul><li> The text is broken into units; each unit is separated by whitespace.
</li><li> Quotation marks (" ") group characters into larger units, regardless of whitespace.
</li><li> Backslashes ( \ ) immediately preceding quotation marks disable the grouping properties of quotation marks.
</li><li> Backslashes preceding a backslash disable that backslash.
</li><li> Units of text that contain a double colon (::) are turned into extracted fields.  The text on the left side of the double colon becomes the field name, and the right side becomes the value.
</li></ul></li></ul><p><b>Note:</b> Indexed fields with regex-extracted values containing quotation marks will generally not work, and backslashes might also have problems. Fields extracted at search time do not have these limitations.
</p><p>Here's an example of a set of index-time extractions involving quotation marks and backslashes to disable quotation marks and backslashes:
</p>
<code><font size="2"><br>WRITE_META = true<br>FORMAT = field1::value field2::"value 2" field3::"a field with a \" quotation mark" field4::"a field which <br>ends with a backslash\\"<br></font></code>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_when_splunk_creates_field_names"><span class="mw-headline" id="When_Splunk_creates_field_names"> When Splunk creates field names </span></a></i></b></font></h4>
<p><b>Remember:</b> When Splunk creates field names, it applies <a href="#configureindex-timefieldextraction_define_additional_indexed_fields" class="external text">field name syntax restrictions</a> to them.
</p><p><b>1.</b> All characters that are not in a-z,A-Z, and 0-9 ranges are replaced with an underscore (_).
</p><p><b>2.</b> All leading underscores are removed. In Splunk, leading underscores are reserved for <b>internal fields</b>.
</p>
<h3> <a name="configureindex-timefieldextraction_index-time_field_extraction_examples"><span class="mw-headline" id="Index-time_field_extraction_examples"> Index-time field extraction examples </span></a></h3>
<p>Here are a set of examples of configuration file setups for index-time field extractions. 
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_define_a_new_indexed_field"><span class="mw-headline" id="Define_a_new_indexed_field"> Define a new indexed field </span></a></i></b></font></h4>
<p>This basic example creates an indexed field called <code><font size="2">err_code</font></code>.
</p>
<h5> <a name="configureindex-timefieldextraction_transforms.conf"><span class="mw-headline" id="transforms.conf"> transforms.conf </span></a></h5>
<p>In <code><font size="2">transforms.conf</font></code> add:
</p>
<code><font size="2"><br>[netscreen-error]<br>REGEX = &nbsp;device_id=\[\w+\](?&lt;err_code&gt;[^:]+)<br>FORMAT = err_code::"$1"<br>WRITE_META = true<br></font></code>
<p>This stanza takes <code><font size="2">device_id=</font></code> followed with a word within brackets and a text string terminating with a colon. The source type of the events is <code><font size="2">testlog</font></code>.
</p><p>Comments:
</p>
<ul><li> The <code><font size="2">FORMAT =</font></code> line contains the following values:
<ul><li> <code><font size="2">err_code::</font></code> is the name of the field.
</li><li> $1 refers to the new field written to the index. It is the value extracted by <code><font size="2">REGEX</font></code>. 
</li></ul></li><li> <code><font size="2">WRITE_META = true</font></code> is an instruction to write the content of <code><font size="2">FORMAT</font></code> to the index.
</li></ul><h5> <a name="configureindex-timefieldextraction_props.conf"><span class="mw-headline" id="props.conf"> props.conf </span></a></h5>
<p>Add the following lines to <code><font size="2">props.conf</font></code>: 
</p>
<code><font size="2"><br>[testlog]<br>TRANSFORMS-netscreen = netscreen-error<br></font></code>
<h5> <a name="configureindex-timefieldextraction_fields.conf"><span class="mw-headline" id="fields.conf"> fields.conf </span></a></h5>
<p>Add the following lines to <code><font size="2">fields.conf</font></code>: 
</p>
<code><font size="2"><br>[err_code]<br>INDEXED=true<br></font></code>
<p>Restart Splunk for your configuration file changes to take effect.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_define_two_new_indexed_fields_with_one_regex"><span class="mw-headline" id="Define_two_new_indexed_fields_with_one_regex"> Define two new indexed fields with one regex </span></a></i></b></font></h4>
<p>This example creates two indexed fields called <code><font size="2">username</font></code> and <code><font size="2">login_result</font></code>.
</p>
<h5> <a name="configureindex-timefieldextraction_transforms.conf_2"><span class="mw-headline" id="transforms.conf_2"> transforms.conf </span></a></h5>
<p>In <code><font size="2">transforms.conf</font></code> add:
</p>
<code><font size="2"><br>[ftpd-login]<br>REGEX = Attempt to login by user: (.*): login (.*)\.<br>FORMAT = username::"$1" login_result::"$2"<br>WRITE_META = true<br></font></code>
<p>This stanza finds the literal text <code><font size="2">Attempt to login by user:</font></code>, extracts a username followed by a colon, and then the result, which is followed by a period. A line might look like: 
</p><p><code><font size="2">2008-10-30 14:15:21 mightyhost awesomeftpd INFO Attempt to login by user: root: login FAILED.</font></code>
</p>
<h5> <a name="configureindex-timefieldextraction_props.conf_2"><span class="mw-headline" id="props.conf_2"> props.conf </span></a></h5>
<p>Add the following lines to <code><font size="2">props.conf</font></code>: 
</p>
<code><font size="2"><br>[ftpd-log]<br>TRANSFORMS-login = ftpd-login<br></font></code>
<h5> <a name="configureindex-timefieldextraction_fields.conf_2"><span class="mw-headline" id="fields.conf_2"> fields.conf </span></a></h5>
<p>Add the following lines to <code><font size="2">fields.conf</font></code>: 
</p>
<code><font size="2"><br>[username]<br>INDEXED=true<br><br>[login_result]<br>INDEXED=true<br></font></code>
<p>Restart Splunk for your configuration file changes to take effect.
</p>
<h4><font size="3"><b><i> <a name="configureindex-timefieldextraction_concatenate_field_values_from_event_segments_at_index_time"><span class="mw-headline" id="Concatenate_field_values_from_event_segments_at_index_time"> Concatenate field values from event segments at index time </span></a></i></b></font></h4>
<p>This example shows you how an index-time transform can be used to extract separate segments of an event and combine them to create a single field, using the <code><font size="2">FORMAT</font></code> option.
</p><p>Let's say you have the following event:
</p><p><code><font size="2">20100126 08:48:49 781 PACKET 078FCFD0 UDP Rcv 127.0.0.0 8226 R Q [0084 A NOERROR] A (4)www(8)google(3)com(0)</font></code>
</p><p>Now, what you want to do is get <code><font size="2">(4)www(8)google(3)com(0)</font></code> extracted as a value of a field named <code><font size="2">dns_requestor</font></code>. But you don't want those garbage parentheses and numerals, you just want something that looks like <code><font size="2">www.google.com</font></code>. How do you achieve this?
</p>
<h5> <a name="configureindex-timefieldextraction_transforms.conf_3"><span class="mw-headline" id="transforms.conf_3">transforms.conf</span></a></h5>
<p>You would start by setting up a transform in <code><font size="2">transforms.conf</font></code> named <code><font size="2">dnsRequest</font></code>: 
</p>
<code><font size="2"><br>[dnsRequest]<br>REGEX = UDP[^\(]+\(\d\)(\w+)\(\d\)(\w+)\(\d\)(\w+)<br>FORMAT = dns_requestor::$1.$2.$3 <br></font></code>
<p>This transform defines a custom field named <code><font size="2">dns_requestor</font></code>. It uses its <code><font size="2">REGEX</font></code> to pull out the three segments of the <code><font size="2">dns_requestor</font></code> value. Then it uses <code><font size="2">FORMAT</font></code> to order those segments with periods between them, like a proper URL.
</p><p><b>Note:</b> This method of concatenating event segments into a complete field value is something you can <i>only</i> perform with index-time extractions; search-time extractions have practical restrictions that prevent it. If you find that you must use <code><font size="2">FORMAT</font></code> in this manner, you will have to create a new indexed field to do it.
</p>
<h5> <a name="configureindex-timefieldextraction_props.conf_3"><span class="mw-headline" id="props.conf_3">props.conf</span></a></h5>
<p>Then, the next step would be to define a field extraction in <code><font size="2">props.conf</font></code> that references the <code><font size="2">dnsRequest</font></code> transform and applies it to events coming from the <code><font size="2">server1</font></code> source type:
</p>
<code><font size="2"><br>[server1]<br>TRANSFORMS-dnsExtract = dnsRequest<br></font></code>
<h5> <a name="configureindex-timefieldextraction_fields.conf_3"><span class="mw-headline" id="fields.conf_3">fields.conf</span></a></h5>
<p>Finally, you would enter the following stanza in <code><font size="2">fields.conf</font></code>:
</p>
<code><font size="2"><br>[dns_requestor]<br>INDEXED = true<br></font></code>
<p>Restart Splunk for your configuration file changes to take effect.
</p>
<a name="extractfieldsfromfileheadersatindextime"></a><h2> <a name="extractfieldsfromfileheadersatindextime_extract_data_from_files_with_headers"><span class="mw-headline" id="Extract_data_from_files_with_headers"> Extract data from files with headers </span></a></h2>
<p>Many structured data files, such as comma-separated value (CSV) files, have information in the file header that Splunk Enterprise can use to extract fields during index-time event processing. You can configure Splunk Enterprise to automatically extract these fields.
</p><p>For example, a legacy CSV file usually starts with a header row that contains column headers for the values in subsequent rows, for example:
</p>
<div class="samplecode"><code><font size="2"><br>host,status,message,"start date"<br>srv1.splunk.com,error,"No space left on device",2013-06-10T06:35:00<br>srv2.splunk.com,ok,-,2013-06-11T06:00:00<br></font></code></div>
<h3> <a name="extractfieldsfromfileheadersatindextime_use_configuration_files_to_enable_automatic_header-based_field_extraction"><span class="mw-headline" id="Use_configuration_files_to_enable_automatic_header-based_field_extraction">Use configuration files to enable automatic header-based field extraction</span></a></h3>
<p>To extract data from files with headers (such as comma-separated value files, Internet Information Server (IIS) web server logs, and other structured data files), use a combination of inputs.conf and props.conf. Edit these files in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/local</font></code>. Inputs.conf specifies the files you want to monitor and which sourcetype Splunk Enterprise should use to monitor them, and props.conf defines the sourcetypes themselves.
</p><p>For more information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>Important: Changes that you make to <code><font size="2">props.conf</font></code> (such as enabling automatic header-based field extraction) don't take effect until you restart Splunk Enterprise.
</p>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_props.conf_attributes_for_structured_data"><span class="mw-headline" id="Props.conf_attributes_for_structured_data">Props.conf attributes for structured data </span></a></i></b></font></h4>
<p>Splunk Enterprise includes the following attributes in props.conf for working with files that contain headers. For additional attributes in props.conf, review the props.conf specification file.
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Attribute
</th><th valign="top" bgcolor="#C0C0C0"> Description
</th><th valign="top" bgcolor="#C0C0C0"> Default
</th></tr><tr><td valign="top" width="175" align="left"> <code><font size="2">INDEXED_EXTRACTIONS = {CSV|W3C|TSV|PSV|JSON}</font></code>
</td><td valign="top" align="left"> Specifies the type of file and the extraction and/or parsing method that Splunk Enterprise should use on the file.
</td><td valign="center" align="left"> n/a (not set)
</td></tr><tr><td valign="top" align="left"> <code><font size="2">PREAMBLE_REGEX</font></code>
</td><td valign="top" align="left"> Some files contain preamble lines. This attribute specifies a regular expression which allows Splunk to ignore these preamble lines, based on the pattern specified.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">FIELD_HEADER_REGEX</font></code>
</td><td valign="top" align="left"> A regular expression that specifies a pattern for prefixed header line. Splunk Enterprise looks for the first line that matches that regex and parses it as header fields. Note that the actual header starts after the matching pattern which is not included in the parsed header fields. You can specify special characters in this attribute.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">FIELD_DELIMITER</font></code>
</td><td valign="top" align="left"> Specifies which character delimits or separates fields in the monitored file or source. You can specify special characters in this attribute.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">FIELD_QUOTE</font></code>
</td><td valign="top" align="left"> Specifies the character to use for quotes in the specified file or source. You can specify special characters in this attribute.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">HEADER_FIELD_DELIMITER</font></code>
</td><td valign="top" align="left"> Specifies which character delimits or separates field names in the header line. You can specify special characters in this attribute. If HEADER_FIELD_DELIMITER is not specified, FIELD_DELIMITER applies to the header line.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">HEADER_FIELD_QUOTE</font></code>
</td><td valign="top" align="left"> Specifies which character is used for quotes around field names in the header line. You can specify special characters in this attribute. If HEADER_FIELD_QUOTE is not specified, FIELD_QUOTE applies to the header line.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">HEADER_FIELD_LINE_NUMBER</font></code>
</td><td valign="top" align="left"> Specifies the line number of the line within the file that contains the header fields. If set to 0, Splunk attempts to locate the header fields within the file automatically.
</td><td valign="center" align="left"> 0
</td></tr><tr><td valign="top" align="left"> <code><font size="2">TIMESTAMP_FIELDS = field1,field2,...,fieldn</font></code>
</td><td valign="top" align="left"> Some CSV and structured files have their timestamp encompass multiple fields in the event separated by delimiters. This attribute tells Splunk to specify all such fields which constitute the timestamp in a comma-separated fashion.
</td><td valign="center" align="left"> Splunk Enterprise tries to automatically extract the timestamp of the event.
</td></tr><tr><td valign="top" align="left"> <code><font size="2">FIELD_NAMES</font></code>
</td><td valign="top" align="left"> Some CSV and structured files might have missing headers. This attribute tells Splunk to specify the header field names directly.
</td><td valign="center" align="left"> n/a
</td></tr><tr><td valign="top" align="left"> <code><font size="2">MISSING_VALUE_REGEX</font></code>
</td><td valign="top" align="left"> If Splunk Enterprise finds the specified regular expression in the structured data file, it considers the value for the field in the row to be empty.
</td><td valign="center" align="left"> n/a
</td></tr></table><h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_special_characters_or_values_are_available_for_some_attributes"><span class="mw-headline" id="Special_characters_or_values_are_available_for_some_attributes">Special characters or values are available for some attributes</span></a></i></b></font></h4>
<p>You can specify special characters or values such as spaces, vertical and horizontal tabs, and form feeds in some attributes by using the "\" character and the appropriate letter that represents the special character:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th valign="top" bgcolor="#C0C0C0"> Special value
</th><th valign="top" bgcolor="#C0C0C0"> Props.conf representation
</th></tr><tr><td valign="top" width="175" align="left"> form feed
</td><td valign="top" align="left"> <code><font size="2">\f</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> space
</td><td valign="top" align="left"> <code><font size="2">space</font></code> or <code><font size="2">' '</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> horizontal tab
</td><td valign="top" align="left"> <code><font size="2">\t</font></code> or <code><font size="2">tab</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> vertical tab
</td><td valign="top" align="left"> <code><font size="2">\v</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> whitespace
</td><td valign="top" align="left"> <code><font size="2">whitespace</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> none
</td><td valign="top" align="left"> <code><font size="2">none</font></code> or <code><font size="2">\0</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> file separator
</td><td valign="top" align="left"> <code><font size="2">fs</font></code> or <code><font size="2">\034</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> group separator
</td><td valign="top" align="left"> <code><font size="2">gs</font></code> or <code><font size="2">\035</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> record separator
</td><td valign="top" align="left"> <code><font size="2">rs</font></code> or <code><font size="2">\036</font></code>
</td></tr><tr><td valign="top" width="175" align="left"> unit separator
</td><td valign="top" align="left"> <code><font size="2">us</font></code> or <code><font size="2">\037</font></code>
</td></tr></table><p>You can specify these special characters for the following attributes:
</p>
<ul><li> <code><font size="2">FIELD_DELIMITER</font></code>
</li><li> <code><font size="2">FIELD_HEADER_REGEX</font></code>
</li><li> <code><font size="2">FIELD_QUOTE</font></code>
</li></ul><h3> <a name="extractfieldsfromfileheadersatindextime_edit_configuration_files_to_create_and_reference_source_types"><span class="mw-headline" id="Edit_configuration_files_to_create_and_reference_source_types">Edit configuration files to create and reference source types</span></a></h3>
<p>In order to use these attributes, you must edit <code><font size="2">props.conf</font></code>. You edit <code><font size="2">props.conf</font></code> to create new source types which define how Splunk extracts fields from files with header data in them.
</p><p>After you have edited <code><font size="2">props.conf</font></code>, then edit <code><font size="2">inputs.conf</font></code> to reference the newly created source types in files that Splunk Enterprise indexes.
</p><p>To create and reference the new source types to extract files with headers:
</p><p><b>1.</b>  Using a text editor, open the file <code><font size="2">props.conf</font></code> in the appropriate location as described in "<a href="#extractfieldsfromfileheadersatindextime_enable_automatic_header-based_field_extraction" class="external text">Enable automatic header-based field extraction</a>" earlier in this topic.
</p><p><b>Note:</b> If the file does not exist, you must create it.
</p><p><b>2.</b> Define a new sourcetype by creating a stanza which tells Splunk Enterprise how to extract the file header and structured file data, using the attributes described above. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim]<br>FIELD_DELIMITER=,<br>HEADER_FIELD_DELIMITER=\s<br>FIELD_QUOTE="<br></font></code></div>
<p><b>Note:</b> You can define as many stanzas - and thus, as many sourcetypes - as you like in the file.
</p><p><b>3.</b> Save the props.conf file and close it.
</p><p><b>4.</b> Create a file <code><font size="2">inputs.conf</font></code> in the same directory, if it does not already exist.
</p><p><b>5.</b> Open the file for editing.
</p><p><b>6.</b> Add a stanza which represents the file or files that you want Splunk Enterprise to extract file header and structured data from. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///opt/test/data/StructuredData/HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim.csv]<br>sourcetype=HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim<br></font></code></div>
<p><b>Note:</b> You can add as many stanzas as you wish for files or directories from which you want to extract header and structured data.
</p><p><b>7.</b> Save the inputs.conf file and close it.
</p><p><b>8.</b> Restart Splunk Enterprise for the changes to take effect.
</p>
<h3> <a name="extractfieldsfromfileheadersatindextime_forward_data_extracted_from_structured_data_files"><span class="mw-headline" id="Forward_data_extracted_from_structured_data_files">Forward data extracted from structured data files</span></a></h3>
<p>You can also forward fields extracted from a structured data file (a file with headers) to another Splunk Enterprise instance. 
</p><p>To forward fields extracted from structured data files, follow this procedure:
</p><p><b>1.</b> On the instance that monitors the files, edit <code><font size="2">props.conf</font></code> and <code><font size="2">inputs.conf</font></code> as described in "Edit configuration files to create and reference sourcetypes" earlier in this topic.
</p><p><b>2.</b> Optionally, if you need to transform this data in any way prior to indexing it, edit <code><font size="2">transforms.conf</font></code>.
</p><p><b>3.</b> Next, configure the instance to forward data to another Splunk Enterprise instance.
</p><p><b>Note:</b> Read "Set up forwarding and receiving" in the Forwarding Data Manual for instructions on how to configure data forwarding and receiving.
</p><p><b>4.</b> If you have not already done so, configure Splunk Enterprise to be a receiver on the instance that is to receive the data.
</p><p><b>5</b> Restart Splunk Enterprise on the receiving instance.
</p><p><b>6.</b> Restart Splunk Enterprise on the monitoring instance.
</p><p><b>7.</b> On the receiving instance, use the Search app to confirm that Splunk Enterprise has extracted the fields from the structured data files and indexed them properly.
</p>
<h3> <a name="extractfieldsfromfileheadersatindextime_caveats"><span class="mw-headline" id="Caveats">Caveats</span></a></h3>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_splunk_enterprise_does_not_parse_structured_data_that_has_been_forwarded_to_an_indexer"><span class="mw-headline" id="Splunk_Enterprise_does_not_parse_structured_data_that_has_been_forwarded_to_an_indexer">Splunk Enterprise does not parse structured data that has been forwarded to an indexer </span></a></i></b></font></h4>
<p>When you forward structured data to an indexer, Splunk Enterprise does not parse this data once it arrives at the indexer, even if you have configured <code><font size="2">props.conf</font></code> on that indexer with <code><font size="2">INDEXED_EXTRACTIONS</font></code>. Forwarded data skips the following queues on the indexer, which precludes any parsing of that data on the indexer:
</p>
<ul><li> <code><font size="2">parsing</font></code>
</li><li> <code><font size="2">aggregation</font></code>
</li><li> <code><font size="2">typing</font></code>
</li></ul><p>The forwarded data must arrive at the indexer already parsed. To achieve this, you must also set up <code><font size="2">props.conf</font></code> on the forwarder that sends the data. This includes configuration of <code><font size="2">INDEXED_EXTRACTIONS</font></code> and any other parsing, filtering, anonymizing, and routing rules. Universal forwarders are capable of performing these tasks solely for structured data. See "Forward data extracted from header files" earlier in this topic.
</p>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_splunk_enterprise_only_indexes_header_fields_whose_rows_contain_data"><span class="mw-headline" id="Splunk_Enterprise_only_indexes_header_fields_whose_rows_contain_data">Splunk Enterprise only indexes header fields whose rows contain data</span></a></i></b></font></h4>
<p>When Splunk Enterprise extracts header fields from structured data files, it only extracts those fields where data is present in at least one row. If the header field has no data in any row, Splunk skips that field, and does not index it. Take, for example, the following csv file:
</p>
<div class="samplecode"><code><font size="2"><br>header1,header2,header3,header4,header5<br>one,1,won,,111<br>two,2,too,,222<br>three,3,thri,,333<br>four,4,fore,,444<br>five,5,faiv,,555<br></font></code></div>
<p>When Splunk Enterprise reads this file, it notes that the rows in the <code><font size="2">header4</font></code> column are all empty, and does not index that header field or any of the rows in it. This means that neither <code><font size="2">header4</font></code> nor any of the data in its row can be searched for in the index.
</p><p>If, however, the <code><font size="2">header4</font></code> field contains rows with empty strings (for example, ""), Splunk <i>does</i> index the field and all the rows underneath.
</p>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_splunk_enterprise_does_not_support_renaming_of_header_fields_mid-file"><span class="mw-headline" id="Splunk_Enterprise_does_not_support_renaming_of_header_fields_mid-file">Splunk Enterprise does not support renaming of header fields mid-file</span></a></i></b></font></h4>
<p>Some software, such as Internet Information Server, supports the renaming of header fields in the middle of the file. Splunk does not recognize changes such as this. If you attempt to index a file which has header fields renamed within the file, Splunk does not index the renamed header field.
</p>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_splunk_enterprise_does_not_specify_fields_extracted_from_structured_data_files_as_being_indexed_fields_in_fields.conf"><span class="mw-headline" id="Splunk_Enterprise_does_not_specify_fields_extracted_from_structured_data_files_as_being_indexed_fields_in_fields.conf">Splunk Enterprise does not specify fields extracted from structured data files as being indexed fields in fields.conf</span></a></i></b></font></h4>
<p>Fields extracted from structured data files are indexed, but they are not specified as indexed fields in <code><font size="2">fields.conf</font></code>. This means that the standard field search syntax of <code><font size="2">&lt;field&gt;=&lt;value&gt;</font></code> does not work well for searches on these fields.
</p><p>To search on structured data fields with maximum efficiency, use the <code><font size="2">&lt;field&gt;::&lt;value&gt;</font></code> syntax. This syntax cannot be used to search for fields that are:
</p>
<ul><li> Identified as indexed in <code><font size="2">fields.conf</font></code>.
</li><li> Extracted at <b>search time. </b>
</li></ul><p>See "Use fields to retrieve events" in the <i>Search Manual</i>.
</p>
<h3> <a name="extractfieldsfromfileheadersatindextime_example_configuration_and_data_files"><span class="mw-headline" id="Example_configuration_and_data_files">Example configuration and data files</span></a></h3>
<p>Following are an example inputs.conf and props.conf to give you an idea of how to use the file header extraction attributes.
</p><p>To extract the data locally, edit inputs.conf and props.conf to define inputs and sourcetypes for the structured data files, and use the attributes described above to tell Splunk Enterprise how to deal with the files. To forward this data to another Splunk instance, edit inputs.conf and props.conf on the forwarding instance, and props.conf on the receiving instance.
</p>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_inputs.conf"><span class="mw-headline" id="Inputs.conf">Inputs.conf</span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[monitor:///opt/test/data/StructuredData/CSVWithFewHeaderFieldsWithoutAnyValues.csv]<br>sourcetype=CSVWithFewHeaderFieldsWithoutAnyValues<br><br>[monitor:///opt/test/data/StructuredData/VeryLargeCSVFile.csv]<br>sourcetype=VeryLargeCSVFile<br><br>[monitor:///opt/test/data/StructuredData/UselessLongHeaderToBeIgnored.log]<br>sourcetype=UselessLongHeaderToBeIgnored<br><br>[monitor:///opt/test/data/StructuredData/HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim.csv]<br>sourcetype=HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim<br><br>[monitor:///opt/test/data/FieldHeaderRegex.log]<br>sourcetype=ExtractCorrectHeaders<br></font></code></div>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_props.conf"><span class="mw-headline" id="Props.conf">Props.conf</span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br>[CSVWithFewHeaderFieldsWithoutAnyValues]<br>FIELD_DELIMITER=,<br><br>[VeryLargeCSVFile]<br>FIELD_DELIMITER=,<br><br>[UselessLongHeaderToBeIgnored]<br>HEADER_FIELD_LINE_NUMBER=35<br>TIMESTAMP_FIELDS=Date,Time,TimeZone<br>FIELD_DELIMITER=\s<br>FIELD_QUOTE="<br><br>[HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim]<br>FIELD_DELIMITER=,<br>HEADER_FIELD_DELIMITER=\s<br>FIELD_QUOTE="<br><br>[ExtractCorrectHeaders]<br>FIELD_HEADER_REGEX=Ignore_This_Stuff:\s(.*)<br>FIELD_DELIMITER=,<br><br></font></code></div>
<h4><font size="3"><b><i> <a name="extractfieldsfromfileheadersatindextime_sample_files"><span class="mw-headline" id="Sample_files">Sample files</span></a></i></b></font></h4>
<p>The following are snippets of the files referenced in the above inputs.conf and props.conf examples, to give you an idea of what the files look like.
</p><p><b>Note:</b> You might need to scroll right quite a bit to see all of the content.
</p>
<h5> <a name="extractfieldsfromfileheadersatindextime_csvwithfewheaderfieldswithoutanyvalues.csv"><span class="mw-headline" id="CSVWithFewHeaderFieldsWithoutAnyValues.csv">CSVWithFewHeaderFieldsWithoutAnyValues.csv</span></a></h5>
<div class="samplecode"><code><font size="2"><br>vqmcallhistoryid,serialnumber,vqmavgjbenvdelay,vqmavgjbenvnegdelta,vqmavgjbenvposdelta,vqmbitrate,vqmburstcount,vqmburstlengthavgms,vqmburstlengthavgpkts,vqmburstlostrateavg,vqmburstrvaluelq,vqmccmid,vqmcalldurationms,vqmcallid,vqmcallstart,vqmdegradationdelay,vqmdegradationdiscard,vqmdegradationecholevel,vqmdegradationloss,vqmdegradationnoiselevel,vqmdegradationrecency,vqmdegradationsignallevel,vqmdegradationvocoder,vqmdelayavgmsec,vqmdelaycurrentmsec,vqmdelaydecreasecount,vqmdelayincreasecount,vqmdelaymaxmsec,vqmdelayminmsec,vqmdestifc,vqmdestintname,vqmdiscardrateavg,vqmdiscards,vqmdscp,vqmduplicatepkts,vqmearlypeakjitterms,vqmearlypkts,vqmearlythresholdms,vqmearlythresholdpc,vqmearlytotalcount,vqmearlyunderthresholdcount,vqmexcessburst,vqmexcessgap,vqmexternalrvaluecqin,vqmexternalrvaluecqout,vqmexternalrvaluelqin,vqmexternalrvaluelqout,vqmfrom,vqmgapcount,vqmgaplengthavgms,vqmgaplengthavgpkts,vqmgaplostrateavg,vqmgaprvalue,vqmjbmaxdelay,vqmjbmindelay,vqmjbnomdelay,vqmjbtype,vqmjbresetcount,vqmlatepeakjitterms,vqmlatepkts,vqmlatethresholdms,vqmlatethresholdpc,vqmlatetotalcount,vqmlateunderthreshold,vqmlocaldelayaveragems,vqmlocaldelaymaximumms,vqmlocaldelayminimumms,vqmloss,vqmlossrateavg,vqmmaxjbenvnegdelta,vqmmaxjbenvposdelta,vqmmeanpdvabsmaxavg,vqmmeanpdvavg,vqmmeanpdvmaxavg,vqmmeanpdvtrue,vqmminjbenvnegdelta,vqmminjbenvposdelta,vqmmoscq,vqmmoscqfixed,vqmmoslq,vqmmoslqfixed,vqmmosnominal,vqmmosnominalfixed,vqmmospq,vqmmospqfixed,vqmnetworklossrateavg,vqmonewaydelayaverage,vqmonewaydelayinstant,vqmonewaydelaymaximum,vqmoriginationdelayaverage,vqmoriginationdelayinstant,vqmoriginationdelaymaximum,vqmoutoforder,vqmoverrundiscardpkts,vqmppdvms,vqmpdvaveragems,vqmpdvmaximumms,vqmpktsrcvd,vqmrvaluecq,vqmrvalueg107,vqmrvaluelq,vqmrvaluenominal,vqmreliabilityindex,vqmresynccount,vqmrtdelayaverage,vqmrtdelayinstant,vqmrtdelaymaximum,vqmrtpdesturi,vqmrtpdestinationip,vqmrtpdestinationport,vqmrtpssrc,vqmrtpsourceip,vqmrtpsourceport,vqmrtpsourceuri,vqmsourceintname,vqmsrcifc,vqmstreamquality,vqmterminatedelayaverage,vqmterminatedelayinstant,vqmterminatedelaymaximum,vqmthroughputindex,vqmto,vqmunderrundiscardpkts,vqmvocoderclass,vqmvocodertype,created,modified<br>99152,CFG0730084,-3,-2,356,64000,1,280,14,14.29,36,3499,201000,BW163736844290611-173170743@10.253.143.13,2011-06-29 12:37:37.292,0,4.68,1.43,0.19,0,0,0,0,52,60,15,17,60,10,0,Loopback,0.48,48,46,0,30,1334,10,99.55,10008,9962,0,0,,,,,6096147095,2,100590,5029,0.48,87,200,10,50,1,625,487.5,8767,50,99.58,93,50,,518,,2,0.5,-60,975,488,179,192,999.3,0,0,4.07,,4.12,,4.2,,4.03,,0.02,63,76,76,,,,43,0,6.8,0,520,10054,87,87,89,93,9,79,12,12,12,6096147089,10.255.43.12,10010,706222942,10.253.136.231,25110,6096147095,eth 0/1,2,0,54,80,80,18500,6096147089,48,1,0,2011-06-29 12:41:47.303,2011-06-29 12:41:47.303<br>99154,CFG0730084,-3,-1,251,64000,4,195,9,20.52,28,3494,359000,BW163502270290611594566299@10.253.143.13,2011-06-29 12:35:02.324,0,2.88,1.11,3.44,0,0,0,0,40,40,26,24,50,10,0,Loopback,0.31,54,46,0,31,2455,10,99.8,17769,17732,0,0,,,,,6096147095,5,71556,3577,0.62,87,200,10,50,1,1120,496.5,15437,50,99.73,123,74,,529,,65,0.67,-62,993,496.5,126,139,3404.7,0,0,4.04,,4.07,,4.2,,3.94,,0.36,58,64,69,,,,49,0,286,0,529,17839,86,86,87,93,9,137,8,8,8,6096147089,10.255.43.12,10000,536353626,10.253.136.231,25096,6096147095,eth 0/1,2,0,48,60,70,30400,6096147089,54,1,0,2011-06-29 12:41:47.342,2011-06-29 12:41:47.342</font></code></div>
<h5> <a name="extractfieldsfromfileheadersatindextime_verylargecsvfile.csv"><span class="mw-headline" id="VeryLargeCSVFile.csv">VeryLargeCSVFile.csv</span></a></h5>
<div class="samplecode"><code><font size="2"><br>IncidntNum,Category,Descript,DayOfWeek,Date,Time,PdDistrict,Resolution,Location,X,Y<br>030203898,FRAUD,"FORGERY, CREDIT CARD",Tuesday,02/18/2003,16:30,NORTHERN,NONE,2800 Block of VAN NESS AV,-122.424612993055,37.8014488257836<br>000038261,WARRANTS,WARRANT ARREST,Thursday,04/17/2003,22:45,NORTHERN,"ARREST, BOOKED",POLK ST / SUTTER ST,-122.420120319211,37.7877570602182<br>030203901,LARCENY/THEFT,GRAND THEFT PICKPOCKET,Tuesday,02/18/2003,16:05,NORTHERN,NONE,VAN NESS AV / MCALLISTER ST,-122.42025048261,37.7800745746105<br>030203923,DRUG/NARCOTIC,SALE OF BASE/ROCK COCAINE,Tuesday,02/18/2003,17:00,BAYVIEW,"ARREST, BOOKED",1600 Block of KIRKWOOD AV,-122.390718076188,37.7385560584619<br>030203923,OTHER OFFENSES,CONSPIRACY,Tuesday,02/18/2003,17:00,BAYVIEW,"ARREST, BOOKED",1600 Block of KIRKWOOD AV,-122.390718076188,37.7385560584619<br>030203923,OTHER OFFENSES,PROBATION VIOLATION,Tuesday,02/18/2003,17:00,BAYVIEW,"ARREST, BOOKED",1600 Block of KIRKWOOD AV,-122.390718076188,37.7385560584619<br></font></code></div>
<h5> <a name="extractfieldsfromfileheadersatindextime_uselesslongheadertobeignored.log"><span class="mw-headline" id="UselessLongHeaderToBeIgnored.log">UselessLongHeaderToBeIgnored.log</span></a></h5>
<div class="samplecode"><code><font size="2"><br>************ Start Display Current Environment ************<br>WebSphere Platform 6.1 [ND 6.1.0.21 cf210844.13] &nbsp;running with process name sammys_cell_A\fsgwws189Node_A\sammys_A_c01_s189_m06 and process id 17904<br>Detailed IFix information: ID: 6.1.0-WS-WASSDK-AixPPC32-FP0000021 &nbsp;BuildVrsn: null &nbsp;Desc: Software Developer Kit 6.1.0.21<br>ID: 6.1.0-WS-WAS-AixPPC32-FP0000021 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.21<br>ID: 6.1.0-WS-WASSDK-AixPPC32-FP0000019 &nbsp;BuildVrsn: null &nbsp;Desc: Software Developer Kit 6.1.0.19<br>ID: 6.1.0-WS-WAS-AixPPC32-FP0000019 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.19<br>ID: sdk.FP61021 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.21<br>ID: sdk.FP61019 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.19<br>ID: was.embed.common.FP61021 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.21<br>ID: was.embed.FP61021 &nbsp;BuildVrsn: null &nbsp;Desc: WebSphere Application Server 6.1.0.21<br></font></code></div>
<h5> <a name="extractfieldsfromfileheadersatindextime_headerfieldswithfewemptyfieldnameswithspacedelim.csv"><span class="mw-headline" id="HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim.csv">HeaderFieldsWithFewEmptyFieldNamesWithSpaceDelim.csv</span></a></h5>
<div class="samplecode"><code><font size="2"><br>"Field 1" &nbsp;"Field 3" "Field 4" &nbsp;"Field 6"<br>Value11,Value12,Value13,Value14,Value15,Value16<br>Value21,Value22,Value23,Value24,Value25<br>Value31,Value32,Value33,Value34,Value35, Value36<br></font></code></div>
<h5> <a name="extractfieldsfromfileheadersatindextime_fieldheaderregex.log"><span class="mw-headline" id="FieldHeaderRegex.log">FieldHeaderRegex.log</span></a></h5>
<div class="samplecode"><code><font size="2"><br>Garbage<br>Garbage<br>Garbage<br>Ignore_This_Stuff: Actual_Header1 Actual_Header2<br></font></code></div>
<h3> <a name="extractfieldsfromfileheadersatindextime_answers"><span class="mw-headline" id="Answers">Answers</span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has around extracting fields.
</p>
<h1>Configure host values</h1><a name="abouthosts"></a><h2> <a name="abouthosts_about_hosts"><span class="mw-headline" id="About_hosts"> About hosts</span></a></h2>
<p>An event's <b>host</b> field value is the name of the physical device from which the event originates. Because it is a <b>default field</b>, which means that Splunk Enterprise assigns a host to every event it indexes, you can use it to search for all events that have been generated by a particular host. 
</p><p>The host value is typically the hostname, IP address, or fully qualified domain name of the network host on which the event originated. 
</p>
<h3> <a name="abouthosts_how_splunk_enterprise_assigns_the_host_value"><span class="mw-headline" id="How_Splunk_Enterprise_assigns_the_host_value"> How Splunk Enterprise assigns the host value </span></a></h3>
<p>Splunk Enterprise assigns a host value to each event by examining settings in the following order and using the first host setting it encounters:
</p><p><b>1.</b> Any event-specific host assignment specified in <code><font size="2">transforms.conf</font></code>.
</p><p><b>2.</b> The default host value for the event's input, if any.
</p><p><b>3.</b> The default host value for the Splunk instance (indexer or forwarder) intially consuming the data.
</p><p>An overview of these assignment methods and their use cases follows. Subsequent topics describe the methods in greater detail.
</p>
<h4><font size="3"><b><i> <a name="abouthosts_the_default_host_value"><span class="mw-headline" id="The_default_host_value"> The default host value</span></a></i></b></font></h4>
<p>If no other host rules are specified for a source, Splunk Enterprise assigns the host field a default value that applies to all data coming into the instance from any input. The default host value is the hostname or IP address of the Splunk Enterprise instance (indexer or forwarder) initially consuming the data. When the Splunk Enterprise instance runs on the server where the event occurred, this is correct and no manual intervention is required.
</p><p>For more information, see <a href="#setadefaulthostforasplunkserver" class="external text">"Set a default host for a Splunk Enterprise server"</a> in this manual.
</p>
<h4><font size="3"><b><i> <a name="abouthosts_the_default_host_for_a_file_or_directory_input"><span class="mw-headline" id="The_default_host_for_a_file_or_directory_input"> The default host for a file or directory input </span></a></i></b></font></h4>
<p>If you are running Splunk Enterprise on a central log archive, or you are working with files forwarded from other hosts in your environment, you might need to override the default host assignment for events coming from particular inputs. 
</p><p>There are two methods for assigning a host value to data received through a particular input. You can define a static host value for all data coming through a specific input, or you can have Splunk Enterprise dynamically assign a host value to a portion of the path or filename of the source. The latter method can be helpful when you have a directory structure that segregates each host's log archive in a different subdirectory.
</p><p>For more information, see <a href="#setadefaulthostforaninput" class="external text">"Set a default host for a file or directory input"</a> in this manual.
</p>
<h4><font size="3"><b><i> <a name="abouthosts_event-specific_assignments"><span class="mw-headline" id="Event-specific_assignments"> Event-specific assignments </span></a></i></b></font></h4>
<p>Some situations require you to assign host values by examining the event data. For example, If you have a central log host sending events to Splunk Enterprise, you might have several host servers that feed data to that main log server. To ensure that each event has the host value of its originating server, you need to use the event's data to determine the host value.
</p><p>For more information, see <a href="#overridedefaulthostassignments" class="external text">"Set host values based on event data"</a> in this manual.
</p>
<h3> <a name="abouthosts_handle_incorrectly-assigned_host_values"><span class="mw-headline" id="Handle_incorrectly-assigned_host_values"> Handle incorrectly-assigned host values </span></a></h3>
<p>If your event data gets tagged with the wrong host value, don't worry. There are a number of ways to fix or work around the problem.
</p><p>For details, see <a href="#handleincorrectly-assignedhostvalues" class="external text">"Handle incorrectly-assigned host values"</a> in this manual.
</p>
<h3> <a name="abouthosts_tag_host_values"><span class="mw-headline" id="Tag_host_values"> Tag host values </span></a></h3>
<p>You can tag host values to aid in the execution of robust searches. Tags enable you to cluster groups of hosts into useful, searchable categories.
</p><p>For details, see "About tags and aliases" in the Knowledge Manager manual.
</p>
<a name="setadefaulthostforasplunkserver"></a><h2> <a name="setadefaulthostforasplunkserver_set_a_default_host_for_a_splunk_enterprise_server"><span class="mw-headline" id="Set_a_default_host_for_a_Splunk_Enterprise_server"> Set a default host for a Splunk Enterprise server</span></a></h2>
<p>An event's host value is the IP address, host name, or fully qualified domain name of the physical device on the network from which the event originates. Because Splunk Enterprise assigns a <code><font size="2">host</font></code> value at index time for every event it indexes, host value searches enable you to easily find data originating from a specific device. 
</p>
<h3> <a name="setadefaulthostforasplunkserver_default_host_assignment"><span class="mw-headline" id="Default_host_assignment"> Default host assignment </span></a></h3>
<p>If you have not specified other host rules for a source (using the information in  subsequent topics in this chapter), the default host value for an event is the hostname or IP address of the server running the Splunk instance (forwarder or indexer) consuming the event data. When the event originates on the server on which the Splunk Enterprise instance is running, that host assignment is correct and there's no need to change anything. However, if all your data is being forwarded from a different host or if you're bulk-loading archive data, you might want to change the default host value for that data.
</p><p>To set the default value of the host field, you can use Manager or edit <code><font size="2">inputs.conf</font></code>. 
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforasplunkserver_set_the_default_host_value_using_manager"><span class="mw-headline" id="Set_the_default_host_value_using_Manager"> Set the default host value using Manager </span></a></i></b></font></h4>
<p>Use Manager to set the default host value for a server:
</p><p><b>1.</b> In Splunk Web, click on the <b>Manager</b> link in the upper right-hand corner of the screen.
</p><p><b>2.</b> In Manager, click <b>System settings</b> under <b>System</b>. 
</p><p><b>3.</b> On the System settings page, click <b>General settings</b>.  
</p><p><b>4.</b> On the General settings page, scroll down to the <b>Index settings</b> section and change the <b>Default host name</b>.
</p><p><b>5.</b> Save your changes.
</p><p>This sets the default value of the host field for all events coming into that Splunk Enterprise instance. You can override the value for invidividual sources or events, as described later in this chapter.
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforasplunkserver_set_the_default_host_value_using_inputs.conf"><span class="mw-headline" id="Set_the_default_host_value_using_inputs.conf"> Set the default host value using inputs.conf </span></a></i></b></font></h4>
<p>The default host assignment is set in inputs.conf during installation. You can modify the host value by editing that file in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. 
</p><p>Splunk Enterprise places the host assignment in the <code><font size="2">[default]</font></code> stanza.
</p><p>This is the format of the default host assignment in <code><font size="2">inputs.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[default]<br>host = &lt;string&gt;<br></font></code></div>
<p>Set <code><font size="2">&lt;string&gt;</font></code> to your chosen default host value. <code><font size="2">&lt;string&gt;</font></code> defaults to the IP address or domain name of the host where the data originated.
</p><p><b>Warning:</b> Do <i>not</i> put quotes around the <code><font size="2">&lt;string&gt;</font></code> value: <code><font size="2">host=foo</font></code>, not <code><font size="2">host="foo"</font></code>.
</p><p>Restart Splunk Enterprise to enable any changes you make to <code><font size="2">inputs.conf</font></code>.
</p><p><b>Note:</b> By default, the <code><font size="2">host</font></code> attribute is set to the variable <code><font size="2">$decideOnStartup</font></code>, which means that it's set to the hostname of the machine <code><font size="2">splunkd</font></code> is running on.  The splunk daemon re-interprets the value each time it starts up.
</p>
<h3> <a name="setadefaulthostforasplunkserver_override_the_default_host_value_for_data_received_from_a_specific_input"><span class="mw-headline" id="Override_the_default_host_value_for_data_received_from_a_specific_input"> Override the default host value for data received from a specific input </span></a></h3>
<p>If you are running Splunk Enterprise on a central log archive, or you are working with files forwarded from other hosts in your environment, you might need to override the default host assignment for events coming from particular inputs. 
</p><p>There are two methods for assigning a host value to data received through a particular input. You can define a static host value for all data coming through a specific input, or you can have Splunk Enterprise dynamically assign a host value to a portion of the path or filename of the source. The latter method can be helpful when you have a directory structure that segregates each host's log archive in a different subdirectory.
</p><p>For more information, see <a href="#setadefaulthostforaninput" class="external text">"Set a default host for an file or directory input"</a> in this manual.
</p>
<h3> <a name="setadefaulthostforasplunkserver_override_the_default_host_value_using_event_data"><span class="mw-headline" id="Override_the_default_host_value_using_event_data"> Override the default host value using event data </span></a></h3>
<p>Some situations require you to assign host values by examining the event data. For example, If you have a central log host sending events to Splunk Enterprise, you might have several host servers feeding data to that main log server. To ensure that each event has the host value of its originating server, you need to use the event's data to determine the host value.
</p><p>For more information, see <a href="#overridedefaulthostassignments" class="external text">"Set host values based on event data"</a> in this manual.
</p>
<a name="setadefaulthostforaninput"></a><h2> <a name="setadefaulthostforaninput_set_a_default_host_for_a_file_or_directory_input"><span class="mw-headline" id="Set_a_default_host_for_a_file_or_directory_input"> Set a default host for a file or directory input</span></a></h2>
<p>You can set a host value for all data from a particular file or directory input. You can set the host statically or dynamically:
</p>
<ul><li> If you <b>statically</b> set the host value, Splunk Enterprise assigns the same host to every event that comes in through a designated file or directory input.
</li><li> If you <b>dynamically</b> set the host value, Splunk Enterprise extracts the host name from a portion of the source input using a regular expression or segment of the source's full directory path.
</li></ul><p>You can also assign host values to events coming through a particular file or directory input based on their source or source type values (as well as other kinds of information). For more information, see  "<a href="#overridedefaulthostassignments" class="external text">Set host values based on event data</a>" in this manual. 
</p><p><b>Note:</b> Splunk Enterprise currently does not enable the setting of default host values for event data received through TCP, UDP, or <b>scripted inputs</b>.
</p>
<h3> <a name="setadefaulthostforaninput_statically_set_the_default_host_value"><span class="mw-headline" id="Statically_set_the_default_host_value"> Statically set the default host value </span></a></h3>
<p>This method applies a single default host value to each event received through a specific file or directory input.
</p><p><b>Note:</b>A static host value assignment only affects new data arriving through the input with which it's associated. You cannot assign a default host value to data that has already been indexed. Instead, you can tag the host value.
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_use_splunk_web"><span class="mw-headline" id="Use_Splunk_Web"> Use Splunk Web </span></a></i></b></font></h4>
<p>You can define a host for a file or directory input whenever you add a new input of that type through the "Data inputs" page of Splunk Web's System interface:
</p><p><b>1.</b> Click <b>System</b> in the upper left-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the System pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> On the Files &amp; directories page, either click the name of an existing input to update it or click <b>New</b> to create a new file or directory input.
</p><p><b>5.</b> In the <b>Host</b> section, select the "constant value" option from the <b>Set host</b> dropdown. 
</p><p><b>6.</b> Enter the static host value for the input in the <b>Host field value</b> field.
</p><p><b>7.</b> Click <b>Save</b>.
</p><p>For more information about inputs and input types, see "<a href="#whatsplunkcanmonitor" class="external text">What Splunk Enterprise can monitor</a>" in this manual.
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_edit_inputs.conf"><span class="mw-headline" id="Edit_inputs.conf"> Edit inputs.conf </span></a></i></b></font></h4>
<p>You can directly edit inputs.conf to specify a host value for a monitored file or directory input. Set the <code><font size="2">host</font></code> attribute in the appropriate stanza.
</p>
<code><font size="2"><br>[monitor://&lt;path&gt;]<br>host = &lt;your_host&gt;<br></font></code>
<p>Edit <code><font size="2">inputs.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For more information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>For more information about inputs and input types, see "<a href="#whatsplunkcanmonitor" class="external text">What Splunk Enterprise can monitor</a>" in this manual.
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_example_of_static_host_value_assignment"><span class="mw-headline" id="Example_of_static_host_value_assignment"> Example of static host value assignment </span></a></i></b></font></h4>
<p>This example covers any events coming in from <code><font size="2">/var/log/httpd</font></code>. Any events coming from this input will receive a <code><font size="2">host</font></code> value of <code><font size="2">webhead-1</font></code>.
</p>
<code><font size="2"><br>[monitor:///var/log/httpd]<br>host = webhead-1<br></font></code>
<h3> <a name="setadefaulthostforaninput_dynamically_set_the_default_host_value"><span class="mw-headline" id="Dynamically_set_the_default_host_value"> Dynamically set the default host value  </span></a></h3>
<p>This method dynamically extracts the host value for a file or directory input, either from a segment of the source input path or from a regular expression. For example, if you want to index an archived directory and the name of each file in the directory contains relevant host information, you can extract this information and assign it to the host field.
</p><p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regular expressions by using them in searches with the rex search command. Splunk Enterprise also maintains a list of useful third-party tools for writing and testing regular expressions. 
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_use_splunk_web_2"><span class="mw-headline" id="Use_Splunk_Web_2"> Use Splunk Web </span></a></i></b></font></h4>
<p><b>1.</b> Click <b>System</b> in the upper left-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the System pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> On the Files &amp; directories page, either click the name of an existing input to update it or click <b>New</b> to create a new file or directory input.
</p><p><b>5.</b> In the <b>Host</b> section, select one of the following two options from the <b>Set host</b> dropdown: 
</p>
<ul><li> <b>regex on path</b> - Choose this option if you want to extract the host name with a regular expression. Then enter the regex for the host you want to extract in the <b>Regular expression</b> field.
</li></ul><ul><li> <b>segment in path</b> - Choose this option if you want to extract the host name from a segment in your data source's path. Then enter the segment number in the <b>Segment number</b> field. For example, if the path to the source is <code><font size="2">/var/log/&lt;host server name&gt;</font></code> and you want the third segment (the host server name) to be the host value, enter "3".
</li></ul><p><b>6.</b> Click <b>Save</b>.
</p>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_edit_inputs.conf_2"><span class="mw-headline" id="Edit_inputs.conf_2"> Edit inputs.conf </span></a></i></b></font></h4>
<p>You can set up dynamic host extraction rules by directly configuring <code><font size="2">inputs.conf</font></code>. 
</p><p>Edit <code><font size="2">inputs.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For more information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>Use the <code><font size="2">host_regex</font></code> attribute to override the host field with a value extracted through a regular expression:
</p>
<code><font size="2"><br>[monitor://&lt;path&gt;]<br>host_regex = &lt;your_regular_expression&gt;<br></font></code>
<p>The regular expression extracts the <code><font size="2">host</font></code> value from the filename of each input. The first capturing group of the regular expression is used as the host. 
</p><p><b>Note:</b> If the regular expression fails to match, the default <code><font size="2">host</font></code> attribute is set as the host.
</p><p>Use the <code><font size="2">host_segment</font></code> to override the host field with a value extracted from a segment in your data source's path. For example, if the path to the source is <code><font size="2">/var/log/&lt;host server name&gt;</font></code> and you want the third segment (the host server name) to be the host value, your input stanza would look like:
</p>
<code><font size="2"><br>[monitor://var/log/]<br>host_segment = 3<br></font></code>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_examples_of_dynamic_host_assignment"><span class="mw-headline" id="Examples_of_dynamic_host_assignment"> Examples of dynamic host assignment  </span></a></i></b></font></h4>
<p>In this example, the regular expression assigns all events from <code><font size="2">/var/log/foo.log</font></code> a host value of "foo":
</p>
<code><font size="2"><br>[monitor://var/log]<br>host_regex = /var/log/(\w+)<br></font></code>
<p>This example assigns the host value to the third segment in the path <code><font size="2">apache/logs</font></code>:
</p>
<code><font size="2"><br>[monitor://apache/logs/]<br>host_segment = 3<br></font></code>
<h4><font size="3"><b><i> <a name="setadefaulthostforaninput_caveats"><span class="mw-headline" id="Caveats"> Caveats </span></a></i></b></font></h4>
<p>There are some caveats to using the <code><font size="2">host_segment</font></code> attribute in an inputs.conf stanza:
</p>
<ul><li> You cannot simultaneously specify the <code><font size="2">host_regex</font></code> and <code><font size="2">host_segment</font></code> attributes in the same stanza.
</li></ul><ul><li> When you simultaneously specify a <code><font size="2">host_segment</font></code> and <code><font size="2">source</font></code> attribute in the same stanza, the behavior of the <code><font size="2">host_segment</font></code> attribute changes:
<ul><li> If the value you specify for the source contains a <code><font size="2">/</font></code> (forward slash), then Splunk Enterprise extracts the host value based on the segment number you specify in <code><font size="2">host_segment</font></code>. 
</li><li> If <code><font size="2">source</font></code> does not contain a <code><font size="2">/</font></code>, or you specify a <code><font size="2">host_segment</font></code> value that is larger than the number of segments available in <code><font size="2">source</font></code>, then Splunk Enterprise cannot extract the host value, and instead uses the name of the host that extracted the data. See the following examples:
</li></ul></li></ul><p><b>Example 1:</b> Host name is server01, source path is <code><font size="2">/mnt/logs/server01</font></code>, inputs.conf contains:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs/]<br>host_segment = 3<br></font></code></div>
<p>In this case, Splunk Enterprise extracts the host name <code><font size="2">server01</font></code> from the source path (<code><font size="2">/mnt/logs/server01/*</font></code>) and sets the host field to this value.
</p><p><b>Example 2:</b> Host name is server01, source path is <code><font size="2">/mnt/logs/server01</font></code>, inputs.conf contains:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs/server01]<br>source = /mnt/logs/server01<br>host_segment = 3<br></font></code></div>
<p>In this case, Splunk Enterprise extracts the host name <code><font size="2">server01</font></code> from the <code><font size="2">source</font></code> attribute and sets the host field to this value.
</p><p><b>Example 3:</b> Host name is server02, source path is <code><font size="2">/mnt/logs/server02</font></code>, inputs.conf contains:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor:///mnt/logs/server02]<br>source = serverlogs<br>host_segment = 3<br></font></code></div>
<p>In this case, Splunk Enterprise uses <code><font size="2">server02</font></code> as the host field because it cannot extract the host segment value from the specified <code><font size="2">source</font></code>.
</p><p><b>Note:</b> Do not explicitly specify <code><font size="2">source</font></code> unless absolutely necessary. Consider using source types, tagging, and search wildcards instead of overriding the default source value by specifying this attribute.
</p>
<a name="overridedefaulthostassignments"></a><h2> <a name="overridedefaulthostassignments_set_host_values_based_on_event_data"><span class="mw-headline" id="Set_host_values_based_on_event_data"> Set host values based on event data </span></a></h2>
<p>Splunk Enterprise can assign host names to your events based on data in those events. This topic shows you how to use event data to override default host assignments.
</p>
<h3> <a name="overridedefaulthostassignments_configuration"><span class="mw-headline" id="Configuration"> Configuration </span></a></h3>
<p>To configure per-event overrides, you need to create two stanzas, one in <code><font size="2">transforms.conf</font></code> and another in <code><font size="2">props.conf</font></code>. Edit these files in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For more information about configuration files in general, see "About configuration files" in the Admin manual.
</p>
<h4><font size="3"><b><i> <a name="overridedefaulthostassignments_transforms.conf"><span class="mw-headline" id="transforms.conf"> transforms.conf </span></a></i></b></font></h4>
<p>Create a stanza in <code><font size="2">transforms.conf</font></code> that follows this syntax: 
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;unique_stanza_name&gt;]<br>REGEX = &lt;your_regex&gt;<br>FORMAT = host::$1<br>DEST_KEY = MetaData:Host<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;unique_stanza_name&gt;</font></code> should reflect that it involves a host value. You'll use this name later in the <code><font size="2">props.conf</font></code> stanza.
</li><li> <code><font size="2">&lt;your_regex&gt;</font></code> is a regular expression that identifies where in the event you want to extract the host value.
</li><li> <code><font size="2">FORMAT = host::$1</font></code> writes the <code><font size="2">REGEX</font></code> value into the <code><font size="2">host::</font></code> field.
</li></ul><p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regexes by using them in searches with the rex search command. Splunk Enterprise also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<h4><font size="3"><b><i> <a name="overridedefaulthostassignments_props.conf"><span class="mw-headline" id="props.conf"> props.conf </span></a></i></b></font></h4>
<p>Next, create a stanza in <code><font size="2">props.conf</font></code> that references the <code><font size="2">transforms.conf</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;spec&gt;]<br>TRANSFORMS-&lt;class&gt; = &lt;unique_stanza_name&gt;<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;spec&gt;</font></code> can be:
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>, the source type of an event.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>, where <code><font size="2">&lt;host&gt;</font></code> is the host value for an event.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>, where <code><font size="2">&lt;source&gt;</font></code> is the source value for an event.
</li></ul></li><li> <code><font size="2">&lt;class&gt;</font></code> is any unique identifier that you want to give to your transform.  
</li><li> <code><font size="2">&lt;unique_stanza_name&gt;</font></code> is the name of the stanza you created in <code><font size="2">transforms.conf</font></code>.
</li></ul><h3> <a name="overridedefaulthostassignments_example"><span class="mw-headline" id="Example"> Example </span></a></h3>
<p>Assume that you're starting with the following set of events from the <code><font size="2">houseness.log</font></code> file. The host is in the third position ("fflanda", etc.).
</p>
<div class="samplecode"><code><font size="2"><br>41602046:53 accepted fflanda<br>41602050:29 accepted rhallen<br>41602052:17 accepted fflanda<br></font></code></div>
<p>First, create a new stanza in <code><font size="2">transforms.conf</font></code> with a regex that extracts the host value:
</p>
<div class="samplecode"><code><font size="2"><br>[houseness]<br>DEST_KEY = MetaData:Host<br>REGEX = \s(\w*)$<br>FORMAT = host::$1<br></font></code></div>
<p>Next, reference your <code><font size="2">transforms.conf</font></code> stanza in a <code><font size="2">props.conf</font></code> stanza. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[source::.../houseness.log]<br>TRANSFORMS-rhallen=houseness<br>SHOULD_LINEMERGE = false<br></font></code></div>
<p>The above stanza has the additional attribute/value pair <code><font size="2">SHOULD_LINEMERGE = false</font></code>.  This specifies that Splunk Enterprise should break events at each newline. 
</p><p>The events will now appear in search results like this:
</p><p><img alt="Host event.jpg" src="images/8/84/Host_event.jpg" width="492" height="155"></p>
<a name="handleincorrectly-assignedhostvalues"></a><h2> <a name="handleincorrectly-assignedhostvalues_handle_incorrectly-assigned_host_values"><span class="mw-headline" id="Handle_incorrectly-assigned_host_values"> Handle incorrectly-assigned host values</span></a></h2>
<p>At some point, you might discover that the host value for some of your events is incorrect for some reason. For example, you might be scraping some Web proxy logs into a directory directly on your Splunk Enterprise server and you add that directory as an input without remembering to <a href="#overridedefaulthostassignments" class="external text">override the value of the host field</a>, causing all those events to think their original host value is the same as your Splunk Enterprise host. 
</p><p>If something like that happens, here are your options, in order of complexity:
</p>
<ul><li> Delete and reindex the entire data set.
</li><li> Use a search to delete the specific events that have the incorrect host value, and reindex those events.
</li><li> Tag the incorrect host values, and use the tag to search.
</li><li> Set up a CSV lookup to look up the host, map it in the lookup file to a new field name, and use the new name in searches.
</li><li> Alias the host field to a new field (such as <code><font size="2">temp_host</font></code>), set up a CSV lookup to look up the correct host name using the name <code><font size="2">temp_host</font></code>, then have the lookup overwrite the original <code><font size="2">host</font></code> with the new lookup value (using the <code><font size="2">OUTPUT</font></code> option when defining the lookup).
</li></ul><p>Of these options, the last option will look the nicest if you can't delete and reindex the data, but deleting and reindexing the data will give the best performance.
</p>
<h1>Configure source types</h1><a name="whysourcetypesmatter"></a><h2> <a name="whysourcetypesmatter_why_source_types_matter"><span class="mw-headline" id="Why_source_types_matter"> Why source types matter</span></a></h2>
<p>The <b>source type</b> is one of the <b>default fields</b> that Splunk Enterprise assigns to all incoming data. It tells Splunk Enterprise what kind of data you've got, so that it can format the data intelligently during indexing. And it's a way to categorize your data, so that you can search it easily.
</p>
<h3> <a name="whysourcetypesmatter_the_important_thing_about_source_types"><span class="mw-headline" id="The_important_thing_about_source_types">The important thing about source types</span></a></h3>
<p>Because Splunk Enterprise uses the source type to decide how to format your data, it's extremely important that you assign the correct source type to your data. That way, the indexed version of the data (the <b>event data</b>) looks the way you expect it to, with appropriate <b>timestamps</b> and <b>event</b> breaks. This will make it a lot easier to search your data later on.
</p><p>For the most part, it's easy to assign the right source type to your data. Splunk Enterprise comes with a large number of predefined source types. When consuming data, Splunk Enterprise will usually select the correct source type automatically. Sometimes, though, Splunk Enterprise needs your help. If your data is specialized, you might need to manually select a different predefined source type. If your data is unusual, you might need to create a new source type with customized event processing settings. And if your data source contains heterogeneous data, you might need to assign the source type on a per-event (rather than a per-source) basis.
</p><p>Like any other field, you can also use the source type field to search event data, once the data has been indexed. You'll probably use it a lot in your searches, since the source type is a key way to categorize your data.
</p>
<h3> <a name="whysourcetypesmatter_typical_source_types"><span class="mw-headline" id="Typical_source_types">Typical source types</span></a></h3>
<p>Any common data input format can be a source type. Most source types are log formats. For example, some common source types that Splunk Enterprise automatically recognizes include: 
</p>
<ul><li> <b>access_combined</b>, for NCSA combined format HTTP Web server logs.
</li><li> <b>apache_error</b>, for standard Apache Web server error logs.
</li><li> <b>cisco_syslog</b>, for the standard syslog produced by Cisco network devices (including PIX firewalls, routers, and ACS), usually via remote syslog to a central log host.
</li><li> <b>websphere_core</b>, a core file export from WebSphere.
</li></ul><p><b>Note</b>: For a longer list of source types that Splunk Enterprise automatically recognizes, see <a href="#listofpretrainedsourcetypes" class="external text">"List of pretrained source types"</a> in this manual. 
</p>
<h3> <a name="whysourcetypesmatter_configure_source_types"><span class="mw-headline" id="Configure_source_types">Configure source types</span></a></h3>
<p>There are two basic types of configuration you can do with source types:
</p>
<ul><li> Assign source types explicitly to your incoming data.
</li></ul><ul><li> Create new source types, either from scratch or by modifying an existing source type.
</li></ul><h4><font size="3"><b><i> <a name="whysourcetypesmatter_assign_source_types"><span class="mw-headline" id="Assign_source_types"> Assign source types </span></a></i></b></font></h4>
<p>In most cases, Splunk Enterprise determines the best source type for your data and automatically assigns it to incoming events. In some cases, however, you might need to explicitly assign a source type to your data. You usually do this when defining the data input. For details on how to improve source type assignment, read these topics:
</p>
<ul><li> <a href="#bypassautomaticsourcetypeassignment" class="external text">"Override automatic source type assignment"</a>
</li><li> <a href="#advancedsourcetypeoverrides" class="external text">"Override source types on a per-event basis"</a>
</li><li> <a href="#configurerule-basedsourcetyperecognition" class="external text">"Configure rule-based source type recognition"</a>
</li><li> <a href="#createsourcetypes" class="external text">"Create source types"</a>
</li><li> <a href="#renamesourcetypes" class="external text">"Rename source types"</a>
</li></ul><p>Later in this topic, there is a section that explains <a href="#whysourcetypesmatter_how_splunk_enterprise_assigns_source_types" class="external text">how Splunk Enterprise assigns source types</a>.
</p>
<h4><font size="3"><b><i> <a name="whysourcetypesmatter_create_new_source_types"><span class="mw-headline" id="Create_new_source_types">Create new source types</span></a></i></b></font></h4>
<p>If none of the existing source types fits the needs of your data, you can create a new one. 
</p><p>Splunk's data preview feature provides an easy, UI-based method for adjusting source type settings to fit your data. In essence, it's a visual source type editor. For detailed information, see <a href="#datapreviewandsourcetypes" class="external text">"Assign the right source type with your data."</a>
</p><p>You can also create a new source type by directly editing props.conf and adding a source type stanza. To learn how to create a new source type, read <a href="#createsourcetypes" class="external text">"Create source types."</a>
</p>
<h4><font size="3"><b><i> <a name="whysourcetypesmatter_use_data_preview_to_test_and_modify_source_types"><span class="mw-headline" id="Use_data_preview_to_test_and_modify_source_types">Use data preview to test and modify source types</span></a></i></b></font></h4>
<p>The data preview feature in Splunk Web provides an easy way to view the effect of applying a source type to an input. It lets you preview the resulting events without actually committing them to an index. You can also use data preview to edit timestamp and event breaking settings interactively and then save the modifications as a new source type. For information on how data preview functions as a source type editor, see <a href="#datapreviewandsourcetypes" class="external text">"Assign the right source type with your data"</a>.
</p>
<h3> <a name="whysourcetypesmatter_search_on_source_types"><span class="mw-headline" id="Search_on_source_types">Search on source types</span></a></h3>
<p><code><font size="2">sourcetype</font></code> is the name of the source type search field. You can use the <code><font size="2">sourcetype</font></code> field to find similar types of data from any source type. For example, you could search <code><font size="2">sourcetype=weblogic_stdout</font></code> to find all of your WebLogic server events, even when WebLogic is logging from more than one domain (or "host," in Splunk terms).
</p>
<h3> <a name="whysourcetypesmatter_how_splunk_enterprise_assigns_source_types"><span class="mw-headline" id="How_Splunk_Enterprise_assigns_source_types"> How Splunk Enterprise assigns source types </span></a></h3>
<p>Splunk Enterprise employs a variety of methods to assign source types to event data at index time. As it processes event data, Splunk Enterprise steps through these methods in a defined order of precedence. It starts with hardcoded source type configurations in <code><font size="2">inputs.conf</font></code> and <code><font size="2">props.conf</font></code>, moves on to rule-based source type association, and then works through methods like automatic source type recognition and automatic source type learning. This range of methods enables you to configure how Splunk Enterprise applies source type values to specific kinds of events, while letting Splunk Enterprise assign source type values to other events automatically.
</p><p>The following list shows how Splunk Enterprise goes about determining the source type for a data input. Splunk Enterprise starts with the first method and then descends through the others as necessary, until it's able to determine the source type. The list also provides an overview on how you configure source type assignment for each level.
</p><p><b>1.</b> <b>Explicit source type specification based on the data input</b> 
</p><p>If Splunk Enterprise finds an explicit source type for the data input, it stops here.
</p><p>You configure this in  inputs.conf or <a href="#usesplunkweb" class="external text">Splunk Web</a>. Here is the <code><font size="2">inputs.conf</font></code> syntax for assigning source types to a file input:
</p>
<div class="samplecode"><code><font size="2"><br>[monitor://&lt;path&gt;]<br>sourcetype=&lt;sourcetype&gt;<br></font></code></div>
<p>You can also assign a source type when defining an input in Splunk Web. For information on doing this for file inputs, see <a href="#usesplunkweb" class="external text">"Use Splunk Web"</a> in this manual. The process is similar for network or other types of inputs.
</p><p>For more information, see <a href="#bypassautomaticsourcetypeassignment_specify_source_type_for_an_input" class="external text">"Specify source type for an input"</a>.
</p><p><b>2.</b> <b>Explicit source type specification based on the data source</b>
</p><p>If Splunk Enterprise finds an explicit source type for the particular source, it stops here.
</p><p>You configure this in  props.conf, using this syntax:
</p>
<div class="samplecode"><code><font size="2"><br>[source::&lt;source&gt;] <br>sourcetype=&lt;sourcetype&gt;<br></font></code></div>
<p>For more information, see <a href="#bypassautomaticsourcetypeassignment_specify_source_type_for_a_source" class="external text">"Specify source type for a source"</a>. 
</p><p><b>3.</b> <b>Rule-based source type recognition</b>
</p><p>Splunk Enterprise looks next for any rules you've created for source types.
</p><p>You can create source type classification rules in <code><font size="2">props.conf</font></code>: 
</p>
<code><font size="2"><br>[rule::&lt;rule_name&gt;]<br>sourcetype=&lt;sourcetype&gt;<br>MORE_THAN_[0-100] = &lt;regex&gt;<br>LESS_THAN_[0-100] = &lt;regex&gt;<br></font></code>
<p>For information about setting up source type recognition rules, see <a href="#configurerule-basedsourcetyperecognition" class="external text">"Configure rule-based source type recognition"</a>.
</p><p><b>4.</b> <b>Automatic source type matching</b>
</p><p>Splunk Enterprise next attempts to use automatic source type recognition to match similar-looking files and assign a source type. 
</p><p>Splunk Enterprise calculates signatures for patterns in the first few thousand lines of any file or network input stream. These signatures identify things like repeating word patterns, punctuation patterns, line length, and so on. When Splunk Enterprise calculates a signature, it compares it to its set of signatures for known, "pretrained" source types. If it identifies a match, it assigns that source type to the data.
</p><p>See <a href="#listofpretrainedsourcetypes" class="external text">"List of pretrained source types"</a> in this manual for a list of the source types that Splunk Enterprise can recognize out of the box. 
</p><p><b>5.</b> <b>Delayed rule-based source type association</b>
</p><p>If Splunk Enterprise hasn't identified a source type by now, it looks for any delayed rules.
</p><p>This works like rule-based associations (step 3, above).  You create a <code><font size="2">delayedrule::</font></code> stanza in <code><font size="2">props.conf</font></code>. This is a useful "catch-all" for source types, in case Splunk missed any with intelligent matching (see above). 
</p><p>A good use of delayed rule associations is for generic versions of very specific source types that were defined earlier with <code><font size="2">rule::</font></code> in step 3, above. For example, you could use <code><font size="2">rule::</font></code> to catch event data with specific syslog source types, such as "sendmail syslog" or "cisco syslog" and then have <code><font size="2">delayedrule::</font></code> apply the generic "syslog" source type to the remaining syslog event data.
</p><p>Here's the syntax:
</p>
<code><font size="2"><br>[delayedrule::$RULE_NAME]<br>sourcetype=$SOURCETYPE<br>MORE_THAN_[0-100] = $REGEX<br>LESS_THAN_[0-100] = $REGEX<br></font></code>
<p>For more information about settting up or removing delayed rules for source type recognition, see <a href="#configurerule-basedsourcetyperecognition" class="external text">"Configure rule-based source type recognition"</a>.
</p><p><b>6.</b> <b>Automatic source type learning</b>
</p><p>If Splunk Enterprise is unable to assign a source type for the event using the preceding methods, it creates a new source type for the event signature (see step 4, above). Splunk Enterprise stores learned pattern information in sourcetypes.conf.
</p>
<a name="bypassautomaticsourcetypeassignment"></a><h2> <a name="bypassautomaticsourcetypeassignment_override_automatic_source_type_assignment"><span class="mw-headline" id="Override_automatic_source_type_assignment"> Override automatic source type assignment </span></a></h2>
<p>Splunk Enterprise attempts to assign a source type to your data automatically. You can specify what source type to assign. You can also configure Splunk Enterprise so that it assigns a source type based on either the data input or the data source. 
</p><p>For details on the precedence rules that Splunk Enterprise uses to assign source types to data, read <a href="#whysourcetypesmatter_how_splunk_assigns_source_types" class="external text">How Splunk assigns source types</a>.
</p><p><b>Important:</b> Overrides only work on file and directory monitoring inputs or files you have uploaded. You cannot override the source type on network inputs. Additionally, overrides only affect new data that arrives after you set up the override. To correct the source types of events that have already been indexed, create a tag for the source type instead.
</p><p>This topic describes how to specify a source type based for data based on its:
</p>
<ul><li> <a href="#bypassautomaticsourcetypeassignment_specify_source_type_for_an_input" class="external text">input</a>
</li><li> <a href="#bypassautomaticsourcetypeassignment_specify_source_type_for_a_source" class="external text">source</a> 
</li></ul><h3> <a name="bypassautomaticsourcetypeassignment_specify_source_type_for_an_input"><span class="mw-headline" id="Specify_source_type_for_an_input"> Specify source type for an input </span></a></h3>
<p>You can assign the source type for data coming from a specific input, such as <code><font size="2">/var/log/</font></code>.  You do this in either Splunk Web or the <code><font size="2">inputs.conf</font></code> configuration file.
</p><p><b>Note:</b> While assigning source type by input seems like a simple way to handle things, it isn't very granular--when you use it, Splunk Enterprise assigns the same source type to <b>all</b> data from an input, even if some of the data comes from different sources or hosts. To bypass automatic source type assignment in a more targeted manner, you can arrange for Splunk to assign source types based on the source of the data, as described <a href="#bypassautomaticsourcetypeassignment_specify_source_type_for_a_source" class="external text">later</a> in this topic.
</p>
<h4><font size="3"><b><i> <a name="bypassautomaticsourcetypeassignment_use_splunk_web"><span class="mw-headline" id="Use_Splunk_Web"> Use Splunk Web </span></a></i></b></font></h4>
<p>When you <a href="#whatsplunkcanmonitor" class="external text">define a data input</a>, you can set a source type value that Splunk Enterprise applies to all incoming data from that input. Splunk Enterprise gives you the option of picking a source type from a list or entering a unique source type value of your own. 
</p><p>To select a source type for an input, change the source type settings for the data input type you want to add. For example, for file inputs:
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>5.</b> In the "Add Data" page, browse or enter the name of the file you want to monitor, then click "Next".
</p><p><b>6.</b> In the "Set Sourcetype" page, click the "Sourcetype" drop-down and choose from the list of <a href="#listofpretrainedsourcetypes" class="external text">pretrained source types</a>. Splunk Enterprise updates the page to show how the data looks when it receives the new source type.
</p><p><b>7.</b> If you want to make changes to the source type, use the "Event Breaks", "Timestamp", and "Advanced" tabs to modify settings and refresh the data preview. See "<a href="#overviewofdatapreview" class="external text">The Set Sourcetype page</a>".
</p><p><b>8.</b> If you want to save the source type as a different name, click <b>Save As&acirc;&#128;&brvbar;</b> to open a dialog box to save the new source type. Otherwise, proceed to Step 10.
</p><p><b>9.</b> If you chose to save the source type, Splunk Enterprise displays the "Save Sourcetype" dialog. Enter the name, description, category, and app that the source type should apply to. See "<a href="#modifyeventprocessing_save_modifications_as_a_new_sourcetype" class="external text">Save modifications as a new source type</a>."
</p><p><b>10.</b> Click "Next" to set the source type for the data and proceed to the <a href="#modifyinputsettings" class="external text">Input settings</a>" page.
</p><p>Splunk Enterprise now assigns your selected source type to all events it indexes for that input.
</p>
<h4><font size="3"><b><i> <a name="bypassautomaticsourcetypeassignment_use_the_inputs.conf_configuration_file"><span class="mw-headline" id="Use_the_inputs.conf_configuration_file"> Use the inputs.conf configuration file </span></a></i></b></font></h4>
<p>When you configure an input in inputs.conf, you can specify a source type for the input. Edit <code><font size="2">inputs.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>To specify a source type, include a <code><font size="2">sourcetype</font></code> attribute within the stanza for the input. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[tcp://:9995]<br>connection_host=dns<br>sourcetype=log4j<br>source=tcp:9995<br></font></code></div>
<p>This example sets the source type to "log4j" for any events coming from your TCP input on port 9995.
</p><p><b>Warning:</b> Do <i>not</i> put quotes around the attribute value: <code><font size="2">sourcetype=log4j</font></code>, not <code><font size="2">sourcetype="log4j"</font></code>.
</p>
<h3> <a name="bypassautomaticsourcetypeassignment_specify_source_type_for_a_source"><span class="mw-headline" id="Specify_source_type_for_a_source"> Specify source type for a source </span></a></h3>
<p>Use props.conf to override automated source type matching and explicitly assign a single source type to all data coming from a specific source. 
</p><p>Edit <code><font size="2">props.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For information on configuration files in general, see "About configuration files".
</p><p><b>Important:</b> If you are forwarding data, and you want to assign a source type for a source, you must do this in <code><font size="2">props.conf</font></code> on the forwarder. If you do it in <code><font size="2">props.conf</font></code> on the receiver, the override does not take effect.
</p><p>To override source type assignment, add a stanza for your source to <code><font size="2">props.conf</font></code>.
In the stanza, identify the source path, using regular expression (regex) syntax for flexibility if necessary. Then specify the source type by including a <code><font size="2">sourcetype</font></code> attribute. For example:
</p>
<div class="samplecode"><code><font size="2"><br>[source::.../var/log/anaconda.log(.\d+)?]<br>sourcetype=anaconda <br></font></code></div>
<p>This example sets the source type  to "anaconda" for events from any sources containing the string <code><font size="2">/var/log/anaconda.log</font></code> followed by any number of numeric characters.
</p><p><b>Important:</b> Your stanza source path regexes (such as <code><font size="2">[source::.../web/....log]</font></code>) should be as specific as possible. Avoid using a regex that ends in "...". For example, don't do this:
</p>
<div class="samplecode"><code><font size="2"><br>[source::/home/fflanda/...]<br>sourcetype=mytype<br></font></code></div>
<p>This is dangerous. It tells Splunk to process any gzip files in <code><font size="2">/home/fflanda</font></code> as "mytype" files rather than gzip files.
</p><p>It would be much better to write:
</p>
<div class="samplecode"><code><font size="2"><br>[source::/home/fflanda/....log(.\d+)?]<br>sourcetype=mytype<br></font></code></div>
<p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regexes by using them in searches with the rex search command. Splunk also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<a name="configurerule-basedsourcetyperecognition"></a><h2> <a name="configurerule-basedsourcetyperecognition_configure_rule-based_source_type_recognition"><span class="mw-headline" id="Configure_rule-based_source_type_recognition"> Configure rule-based source type recognition</span></a></h2>
<p>You can use rule-based source type recognition to expand the range of source types that Splunk Enterprise recognizes. In <code><font size="2">props.conf</font></code>, you create a <code><font size="2">rule::</font></code> stanza that associates a specific source type with a set of qualifying criteria. When consuming data, Splunk Enterprise assigns the specified source type to file inputs that meet the rule's qualifications.
</p><p>You can create two kinds of rules in <code><font size="2">props.conf</font></code>: rules and delayed rules. The only difference between the two is the point at which Splunk Enterprise checks them during the source typing process. As it processes each set of incoming data, <a href="#whysourcetypesmatter_how_splunk_assigns_source_types" class="external text">Splunk Enterprise uses several methods to determine source types</a>:
</p>
<ul><li> After <a href="#bypassautomaticsourcetypeassignment" class="external text">checking for explicit source type definitions based on the data input or source</a>, Splunk Enterprise looks at any <code><font size="2">rule::</font></code> stanzas defined in <code><font size="2">props.conf</font></code> and tries to match source types to the data based on the classification rules specified in those stanzas. 
</li><li> If Splunk Enterprise is unable to find a matching source type using the available <code><font size="2">rule::</font></code> stanzas, it tries to use automatic source type matching, where it tries to identify patterns similar to source types it has learned in the past. 
</li><li> If that method fails, Splunk Enterprise then checks any <code><font size="2">delayedrule::</font></code> stanzas in <code><font size="2">props.conf</font></code> and tries to match the data to source types using the rules in those stanzas.
</li></ul><p>For details on the precedence rules that Splunk Enterprise uses to assign source types to data, read <a href="#whysourcetypesmatter_how_splunk_assigns_source_types" class="external text">"How Splunk Enterprise assigns source types"</a>.
</p><p>You can configure your system so that <code><font size="2">rule::</font></code> stanzas contain classification rules for specialized source types, while <code><font size="2">delayedrule::</font></code> stanzas contain classification rules for generic source types. That way, Splunk Enterprise applies the generic source types to broad ranges of events that haven't qualified for more specialized source types. For example, you could use <code><font size="2">rule::</font></code> stanzas to catch data with specific syslog source types, such as <code><font size="2">sendmail_syslog</font></code> or <code><font size="2">cisco_syslog</font></code>, and then configure a <code><font size="2">delayedrule::</font></code> stanza to apply the generic <code><font size="2">syslog</font></code> source type to any remaining syslog data.
</p>
<h3> <a name="configurerule-basedsourcetyperecognition_configuration"><span class="mw-headline" id="Configuration"> Configuration </span></a></h3>
<p>To set source typing rules, edit <code><font size="2">props.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>Create a rule by adding a <code><font size="2">rule::</font></code> or <code><font size="2">delayedrule::</font></code> stanza to <code><font size="2">props.conf</font></code>. Provide a name for the rule in the stanza header, and declare the source type in the body of the stanza. After the source type declaration, list the source type assignment rules. These rules use one or more <code><font size="2">MORE_THAN</font></code> and <code><font size="2">LESS_THAN</font></code> statements to find patterns in the data that fit given regular expressions by specific percentages. 
</p><p>To create a rule, use this syntax:
</p>
<div class="samplecode"><code><font size="2"><br>[rule::&lt;rule_name&gt;] OR [delayedrule::&lt;rule_name&gt;]<br>sourcetype=&lt;source_type&gt;<br>MORE_THAN_[0-99] = &lt;regex&gt;<br>LESS_THAN_[1-100] = &lt;regex&gt;<br></font></code></div>
<p>You set a numerical value in the <code><font size="2">MORE_THAN</font></code> and <code><font size="2">LESS_THAN</font></code> attributes, corresponding to the percentage of input lines that must contain the string specified by the regular expression. For example, <code><font size="2">MORE_THAN_80</font></code> means at least 80% of the lines must contain the associated expression. <code><font size="2">LESS_THAN_20</font></code> means that less than 20% of the lines can contain the associated expression.
</p><p><b>Note:</b> Despite how the attribute is named, the <code><font size="2">MORE_THAN_</font></code> attribute actually means "more than or equal to". Similarly the <code><font size="2">LESS_THAN_</font></code> attribute means "less than or equal to".
</p><p>A rule can contain any number of <code><font size="2">MORE_THAN</font></code> and/or <code><font size="2">LESS_THAN</font></code> conditions. Splunk assigns the rule's source type to a data file only if the data qualifies all the statements in the rule. For example, you could define a rule that assigns a specific source type to a file input only if more than 60% of the lines match one regular expression and less than 20% match another regular expression. 
</p><p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regexes by using them in searches with the rex search command. Splunk Enterprise also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<h3> <a name="configurerule-basedsourcetyperecognition_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<h4><font size="3"><b><i> <a name="configurerule-basedsourcetyperecognition_postfix_syslog_files"><span class="mw-headline" id="Postfix_syslog_files"> Postfix syslog files </span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br># postfix_syslog sourcetype rule<br>[rule::postfix_syslog]<br>sourcetype = postfix_syslog<br># If 80% of lines match this regex, then it must be this type<br>MORE_THAN_80=^\w{3} +\d+ \d\d:\d\d:\d\d .* postfix(/\w+)?\[\d+\]:<br></font></code></div>
<h4><font size="3"><b><i> <a name="configurerule-basedsourcetyperecognition_delayed_rule_for_breakable_text"><span class="mw-headline" id="Delayed_rule_for_breakable_text"> Delayed rule for breakable text </span></a></i></b></font></h4>
<div class="samplecode"><code><font size="2"><br># breaks text on ascii art and blank lines if more than 10% of lines have<br># ascii art or blank lines, and less than 10% have timestamps<br>[delayedrule::breakable_text]<br>sourcetype = breakable_text<br>MORE_THAN_10 = (^(?:---|===|\*\*\*|___|=+=))|^\s*$<br>LESS_THAN_10 = [: ][012]?[0-9]:[0-5][0-9]<br></font></code></div>

<a name="listofpretrainedsourcetypes"></a><h2> <a name="listofpretrainedsourcetypes_list_of_pretrained_source_types"><span class="mw-headline" id="List_of_pretrained_source_types"> List of pretrained source types</span></a></h2>
<p>Splunk Enterprise ships with definitions for a large number of source types. These built-in source types are known as "pretrained" source types. 
</p><p>Splunk Enterprise can automatically recognize and assign many of these pretrained source types to incoming data. Splunk Enterprise also includes some pretrained source types that it does not automatically recognize but that you can manually assign via Splunk Web or <code><font size="2">inputs.conf</font></code>, using methods described in earlier topics in this chapter, such as <a href="#bypassautomaticsourcetypeassignment" class="external text">"Override automatic source type assignment"</a>.
</p><p>It's a good idea to use a pretrained source type if it matches your data, as Splunk Enterprise already knows how to properly index pretrained source types. However, if your data does not fit any pretrained source types, you can create your own source types, as described in <a href="#createsourcetypes" class="external text">"Create source types"</a>. Splunk Enterprise can also index virtually any format of data even without custom properties.
</p><p>For an introduction to source types, see <a href="#whysourcetypesmatter" class="external text">"Why source types matter".</a>
</p>
<h3> <a name="listofpretrainedsourcetypes_automatically_recognized_source_types"><span class="mw-headline" id="Automatically_recognized_source_types"> Automatically recognized source types </span></a></h3>
<table cellpadding="5" cellspacing="0" border="1"><tr><th width="20%" bgcolor="#C0C0C0">Source type name
</th><th width="40%" bgcolor="#C0C0C0">Origin
</th><th width="40%" bgcolor="#C0C0C0">Examples
</th></tr><tr><td valign="center" align="left"><b>access_combined</b>
</td><td valign="center" align="left">NCSA&nbsp;combined&nbsp;format&nbsp;http web server logs (can be generated by apache or other web servers)
</td><td valign="center" align="left"><code><font size="2">10.1.1.43 - webdev [08/Aug/2005:13:18:16 -0700] "GET / HTTP/1.0" 200 0442 "-" "check_http/1.10 (nagios-plugins 1.4)"</font></code>
</td></tr><tr><td valign="center" align="left"><b>access_combined_wcookie</b>
</td><td valign="center" align="left">NCSA combined format http web server logs (can be generated by apache or other web servers), with cookie field added at end
</td><td valign="center" align="left"><code><font size="2">"66.249.66.102.1124471045570513" 59.92.110.121 - - [19/Aug/2005:10:04:07 -0700] "GET /themes/splunk_com/images/logo_splunk.png HTTP/1.1" 200 994 "http://www.splunk.org/index.php/docs" "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050524 Fedora/1.0.4-4 Firefox/1.0.4" "61.3.110.148.1124404439914689"</font></code>
</td></tr><tr><td valign="center" align="left"><b>access_common</b>
</td><td valign="center" align="left">NCSA common format http web server logs (can be generated by apache or other web servers)
</td><td valign="center" align="left"><code><font size="2">10.1.1.140 - - [16/May/2005:15:01:52 -0700] "GET /themes/ComBeta/images/bullet.png HTTP/1.1" 404 304</font></code>
</td></tr><tr><td valign="center" align="left"><b>apache_error</b>
</td><td valign="center" align="left">Standard Apache web server error log
</td><td valign="center" align="left"><code><font size="2">[Sun Aug 7 12:17:35 2005] [error] [client 10.1.1.015] File does not exist: /home/reba/public_html/images/bullet_image.gif</font></code>
</td></tr><tr><td valign="center" align="left"><b>asterisk_cdr</b>
</td><td valign="center" align="left">Standard Asterisk IP PBX call detail record
</td><td valign="center" align="left"><code><font size="2">"","5106435249","1234","default","""James Jesse""&lt;5106435249&gt;","SIP/5249-1ce3","","VoiceMail","u1234","2005-05-26 15:19:25","2005-05-26 15:19:25","2005-05-26 15:19:42",17,17,"ANSWERED","DOCUMENTATION"</font></code>
</td></tr><tr><td valign="center" align="left"><b>asterisk_event</b>
</td><td valign="center" align="left">Standard Asterisk event log (management events)
</td><td valign="center" align="left"><code><font size="2">Aug 24 14:08:05 asterisk[14287]: Manager 'randy' logged on from 127.0.0.1</font></code>
</td></tr><tr><td valign="center" align="left"><b>asterisk_messages</b>
</td><td valign="center" align="left">Standard Asterisk messages log (errors and warnings)
</td><td valign="center" align="left"><code><font size="2">Aug 24 14:48:27 WARNING[14287]: Channel 'Zap/1-1' sent into invalid extension 's' in context 'default', but no invalid handler</font></code>
</td></tr><tr><td valign="center" align="left"><b>asterisk_queue</b>
</td><td valign="center" align="left">Standard Asterisk queue log
</td><td valign="center" align="left"><code><font size="2">1124909007|NONE|NONE|NONE|CONFIGRELOAD|</font></code>
</td></tr><tr><td valign="center" align="left"><b>cisco_syslog </b>
</td><td valign="center" align="left">Standard Cisco syslog produced by all Cisco network devices including PIX firewalls, routers, ACS, etc., usually via remote syslog to a central log host
</td><td valign="center" align="left"><code><font size="2">Sep 14 10:51:11 stage-test.splunk.com Aug 24 2005 00:08:49:&nbsp;%PIX-2-106001: Inbound TCP connection denied from IP_addr/port to IP_addr/port flags TCP_flags on interface int_name Inbound TCP connection denied from 144.1.10.222/9876 to 10.0.253.252/6161 flags SYN on interface outside</font></code>
</td></tr><tr><td valign="center" align="left"><b>db2_diag</b>
</td><td valign="center" align="left">Standard IBM DB2 database administrative and error log
</td><td valign="center" align="left"><code><font size="2">2005-07-01-14.08.15.304000-420 I27231H328         LEVEL: Event PID &nbsp;: 2120              TID &nbsp;: 4760        PROC&nbsp;: db2fmp.exe  INSTANCE: DB2                  NODE&nbsp;: 000  FUNCTION: DB2 UDB, Automatic Table Maintenance, db2HmonEvalStats, probe:900  STOP   &nbsp;: Automatic Runstats: evaluation has finished on database TRADEDB</font></code>
</td></tr><tr><td valign="center" align="left"><b>exim_main</b>
</td><td valign="center" align="left">Exim MTA mainlog
</td><td valign="center" align="left"><code><font size="2">2005-08-19 09:02:43 1E69KN-0001u6-8E =&gt; support-notifications@splunk.com R=send_to_relay T=remote_smtp H=mail.int.splunk.com [10.2.1.10]</font></code>
</td></tr><tr><td valign="center" align="left"><b>exim_reject</b>
</td><td valign="center" align="left">Exim reject log
</td><td valign="center" align="left"><code><font size="2">2005-08-08 12:24:57 SMTP protocol violation: synchronization error (input sent without waiting for greeting): rejected connection from H=gate.int.splunk.com [10.2.1.254]</font></code>
</td></tr><tr><td valign="center" align="left"><b>linux_messages_syslog</b>
</td><td valign="center" align="left">Standard linux syslog (/var/log/messages on most platforms)
</td><td valign="center" align="left"><code><font size="2">Aug 19 10:04:28 db1 sshd(pam_unix)[15979]: session opened for user root by (uid=0)</font></code>
</td></tr><tr><td valign="center" align="left"><b>linux_secure</b>
</td><td valign="center" align="left">Linux securelog
</td><td valign="center" align="left"><code><font size="2">Aug 18 16:19:27 db1 sshd[29330]: Accepted publickey for root from&nbsp;::ffff:10.2.1.5 port 40892 ssh2</font></code>
</td></tr><tr><td valign="center" align="left"><b>log4j</b>
</td><td valign="center" align="left">Log4j standard output produced by any J2EE server using log4j
</td><td valign="center" align="left"><code><font size="2">2005-03-07 16:44:03,110 53223013 [PoolThread-0] INFO  [STDOUT] got some property...</font></code>
</td></tr><tr><td valign="center" align="left"><b>mysqld_error</b>
</td><td valign="center" align="left">Standard mysql error log
</td><td valign="center" align="left"><code><font size="2">050818 16:19:29  InnoDB: Started; log sequence number 0 43644 /usr/libexec/mysqld: ready for connections. Version: '4.1.10a-log'  socket: '/var/lib/mysql/mysql.sock'  port: 3306  Source distribution</font></code>
</td></tr><tr><td valign="center" align="left"><b>mysqld</b>
</td><td valign="center" align="left">Standard mysql query log; also matches mysql's binary log following conversion to text
</td><td valign="center" align="left"><code><font size="2">53 Query SELECT xar_dd_itemid, xar_dd_propid, xar_dd_value  FROM xar_dynamic_data   WHERE xar_dd_propid IN (27)  AND xar_dd_itemid = 2</font></code>
</td></tr><tr><td valign="center" align="left"><b>postfix_syslog</b>
</td><td valign="center" align="left">Standard Postfix MTA log reported via the Unix/Linux syslog facility
</td><td valign="center" align="left"><code><font size="2">Mar 1 00:01:43 avas postfix/smtpd[1822]: 0141A61A83: client=host76-117.pool80180.interbusiness.it[80.180.117.76]</font></code>
</td></tr><tr><td valign="center" align="left"><b>sendmail_syslog</b>
</td><td valign="center" align="left">Standard Sendmail MTA log reported via the Unix/Linux syslog facility
</td><td valign="center" align="left"><code><font size="2">Aug  6 04:03:32 nmrjl00 sendmail[5200]: q64F01Vr001110: to=root, ctladdr=root (0/0), delay=00:00:01, xdelay=00:00:00, mailer=relay, min=00026, relay=[101.0.0.1] [101.0.0.1], dsn=2.0.0, stat=Sent (v00F3HmX004301 Message accepted for delivery)</font></code>
</td></tr><tr><td valign="center" align="left"><b>sugarcrm_log4php</b>
</td><td valign="center" align="left">Standard Sugarcrm activity log reported using the log4php utility
</td><td valign="center" align="left"><code><font size="2">Fri Aug  5 12:39:55 2005,244 [28666] FATAL layout_utils - Unable to load the application list language file for the selected language(en_us) or the default language(en_us)</font></code>
</td></tr><tr><td valign="center" align="left"><b>weblogic_stdout</b>
</td><td valign="center" align="left">Weblogic server log in the standard native BEA format
</td><td valign="center" align="left"><code><font size="2">####&lt;Sep 26, 2005 7:27:24 PM MDT&gt; &lt;Warning&gt; &lt;WebLogicServer&gt; &lt;bea03&gt; &lt;asiAdminServer&gt; &lt;ListenThread.Default&gt; &lt;&lt;WLS Kernel&gt;&gt; &lt;&gt; &lt;BEA-000372&gt; &lt;HostName: 0.0.0.0, maps to multiple IP addresses:169.254.25.129,169.254.193.219&gt; </font></code>
</td></tr><tr><td valign="center" align="left"><b>websphere_activity</b>
</td><td valign="center" align="left">Websphere activity log, also often referred to as the service log
</td><td valign="center" align="left"><code><font size="2">-------------------------------------- ComponentId:   Application Server ProcessId:     2580  ThreadId:      0000001c ThreadName:   Non-deferrable Alarm&nbsp;: 3  SourceId:      com.ibm.ws.channel.framework.impl. WSChannelFrameworkImpl ClassName: MethodName:    Manufacturer:  IBM Product:       WebSphere Version:       Platform 6.0 [BASE 6.0.1.0 o0510.18] ServerName:    nd6Cell01\was1Node01\TradeServer1 TimeStamp:     2005-07-01 13:04:55.187000000 UnitOfWork:    Severity:      3 Category:      AUDIT PrimaryMessage:        CHFW0020I: The Transport Channel Service has stopped the Chain labeled SOAPAcceptorChain2 ExtendedMessage: -------------------------------------------</font></code>
</td></tr><tr><td valign="center" align="left"><b>websphere_core</b>
</td><td valign="center" align="left">Corefile export from Websphere
</td><td valign="center" align="left"><code><font size="2">NULL----------------------------------------------- 0SECTION TITLE subcomponent dump routine NULL=============================== 1TISIGINFO signal 0 received 1TIDATETIME Date: 2005/08/02 at 10:19:24 1TIFILENAME Javacore filename:    /kmbcc/javacore95014.1122945564.txt NULL  ----------------------------------------------- 0SECTION XHPI subcomponent dump routine NULL   ============================== 1XHTIME  Tue Aug  2 10:19:24 20051XHSIGRECV SIGNONE received at 0x0 in &lt;unknown&gt;. Processing terminated. 1XHFULLVERSION J2RE 1.3.1 IBM AIX build ca131-20031105 NULL </font></code>
</td></tr><tr><td valign="center" align="left"><b>websphere_trlog_syserr</b>
</td><td valign="center" align="left">Standard Websphere system error log in IBM's native tr log format
</td><td valign="center" align="left"><code><font size="2">[7/1/05 13:41:00:516 PDT] 000003ae SystemErr     R        at com.ibm.ws.http.channel. inbound.impl.HttpICLReadCallback.complete (HttpICLReadCallback.java(Compiled Code)) (truncated)</font></code>
</td></tr><tr><td valign="center" align="left"><b>websphere_trlog_sysout</b>
</td><td valign="center" align="left">Standard Websphere system out log in IBM's native trlog format; similar to the log4j server log for Resin and Jboss, sample format as the system error log but containing lower severity and informational events
</td><td valign="center" align="left"><code><font size="2">[7/1/05 13:44:28:172 PDT] 0000082d SystemOut     O Fri Jul 01 13:44:28 PDT 2005 TradeStreamerMDB: 100 Trade stock prices updated:   Current Statistics        Total update Quote Price message count = 4400        Time to receive stock update alerts messages (in seconds):               min: -0.013               max: 527.347               avg: 1.0365270454545454        The current price update is:       Update Stock price for s:393 old price = 15.47 new price = 21.50</font></code>
</td></tr><tr><td valign="center" align="left"><b>windows_snare_syslog</b>
</td><td valign="center" align="left">Standard windows event log reported through a 3rd party Intersect Alliance Snare agent to remote syslog on a Unix or Linuxserver
</td><td valign="center" align="left"><code><font size="2">0050818050818 Sep 14 10:49:46 stage-test.splunk.com Windows_Host       MSWinEventLog 0      Security      3030   Day Aug 24 00:16:29 2005      560    Security      admin4 User       Success Audit Test_Host                    Object Open: Object Server: Security Object Type: File Object Name: C:\Directory\secrets1.doc New Handle ID: 1220 Operation ID: {0,117792} Process ID: 924 Primary User Name: admin4 Primary Domain: FLAME Primary Logon ID: (0x0,0x8F9F) Client User Name: - Client Domain: - Client Logon ID: - Accesses SYNCHRONIZE ReadData (or ListDirectory) Privileges -Sep</font></code>
</td></tr></table><h3> <a name="listofpretrainedsourcetypes_special_source_types"><span class="mw-headline" id="Special_source_types"> Special source types </span></a></h3>
<table cellpadding="5" cellspacing="0" border="1"><tr><th width="20%" bgcolor="#C0C0C0">Source type name
</th><th width="40%" bgcolor="#C0C0C0">Origin
</th><th width="40%" bgcolor="#C0C0C0">Examples
</th></tr><tr><td valign="center" align="left"><b>known_binary</b>
</td><td valign="center" align="left">The filename matches a pattern that is generally known to be a binary file, not a log file
</td><td valign="center" align="left">mp3 files, images, .rdf, .dat, etc. This is intended to catch obvious non-text files
</td></tr></table><h3> <a name="listofpretrainedsourcetypes_pretrained_source_types"><span class="mw-headline" id="Pretrained_source_types"> Pretrained source types </span></a></h3>
<p>These are all the pretrained source types, including both those that are automatically recognized and those that are not.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Category
</th><th bgcolor="#C0C0C0">Source type(s)
</th></tr><tr><td width="20%" valign="center" align="left"> Application servers
</td><td valign="center" align="left">log4j, log4php, weblogic_stdout, websphere_activity, websphere_core, websphere_trlog, catalina, ruby_on_rails
</td></tr><tr><td valign="center" align="left">Databases
</td><td valign="center" align="left">db2_diag, mysqld, mysqld_error, mysqld_bin, mysqld_slow
</td></tr><tr><td valign="center" align="left">E-mail
</td><td valign="center" align="left">exim_main, exim_reject, postfix_syslog, sendmail_syslog, procmail
</td></tr><tr><td valign="center" align="left">Operating systems
</td><td valign="center" align="left">linux_messages_syslog, linux_secure, linux_audit, linux_bootlog, anaconda, anaconda_syslog, osx_asl, osx_crashreporter, osx_crash_log, osx_install, osx_secure, osx_daily, osx_weekly, osx_monthly, osx_window_server, windows_snare_syslog, dmesg, ftp, ssl_error, syslog, sar, rpmpkgs
</td></tr><tr><td valign="center" align="left">Network
</td><td valign="center" align="left">novell_groupwise, tcp
</td></tr><tr><td valign="center" align="left">Printers
</td><td valign="center" align="left">cups_access, cups_error, spooler
</td></tr><tr><td valign="center" align="left">Routers and firewalls
</td><td valign="center" align="left">cisco_cdr, cisco:asa, cisco_syslog, clavister
</td></tr><tr><td valign="center" align="left">VoIP
</td><td valign="center" align="left">asterisk_cdr, asterisk_event, asterisk_messages, asterisk_queue
</td></tr><tr><td valign="center" align="left">Webservers
</td><td valign="center" align="left">access_combined, access_combined_wcookie, access_common, apache_error, iis&acirc;&#128;&nbsp;
</td></tr><tr><td valign="center" align="left">Splunk
</td><td valign="center" align="left">splunk_com_php_error, splunkd, splunkd_crash_log, splunkd_misc, splunkd_stderr, splunk-blocksignature, splunk_directory_monitor, splunk_directory_monitor_misc, splunk_search_history, splunkd_remote_searches, splunkd_access, splunkd_ui_access, splunk_web_access, splunk_web_service, splunkd_conf&acirc;&#128;&nbsp;, django_access, django_service, django_error, splunk_help, mongod
</td></tr><tr><td valign="center" align="left">Non-Log files
</td><td valign="center" align="left">csv&acirc;&#128;&nbsp;, psv&acirc;&#128;&nbsp;, tsv&acirc;&#128;&nbsp;, _json&acirc;&#128;&nbsp;, json_no_timestamp, fs_notification, exchange&acirc;&#128;&nbsp;, generic_single_line
</td></tr><tr><td valign="center" align="left">Miscellaneous / Other
</td><td valign="center" align="left">snort, splunk_disk_objects&acirc;&#128;&nbsp;, splunk_resource_usage&acirc;&#128;&nbsp;, kvstore&acirc;&#128;&nbsp;
</td></tr></table><p>&acirc;&#128;&nbsp; These source types use the <code><font size="2">INDEXED_EXTRACTIONS</font></code> attribute, which sets other attributes in <code><font size="2">props.conf</font></code> to specific defaults, and requires special handling to forward to another Splunk Enterprise instance. See "<a href="#extractfieldsfromfileheadersatindextime_forward_data_extracted_from_structured_data_files" class="external text">Forward data extracted from structured data files</a>".
</p>
<h3> <a name="listofpretrainedsourcetypes_finding_out_how_a_pretrained_source_type_is_configured_to_work"><span class="mw-headline" id="Finding_out_how_a_pretrained_source_type_is_configured_to_work">Finding out how a pretrained source type is configured to work</span></a></h3>
<p>To find out what configuration information Splunk Enterprise uses to index a given source type, you can invoke the <code><font size="2">btool</font></code> utility to list out the properties. For more information on using <code><font size="2">btool</font></code>, refer to "Use btool to troubleshoot configurations" in the Troubleshooting manual. 
</p><p>The following example shows how to list out the configuration for the <code><font size="2">tcp</font></code> source type:
</p>
<div class="samplecode"><code><font size="2"><br>$ ./splunk btool props list tcp<br>[tcp]<br>BREAK_ONLY_BEFORE = (=\+)+<br>BREAK_ONLY_BEFORE_DATE = True<br>CHARSET = UTF-8<br>DATETIME_CONFIG = /etc/datetime.xml<br>KV_MODE = none<br>LEARN_SOURCETYPE = true<br>MAX_DAYS_AGO = 2000<br>MAX_DAYS_HENCE = 2<br>MAX_DIFF_SECS_AGO = 3600<br>MAX_DIFF_SECS_HENCE = 604800<br>MAX_EVENTS = 256<br>MAX_TIMESTAMP_LOOKAHEAD = 128<br>MUST_BREAK_AFTER = <br>MUST_NOT_BREAK_AFTER = <br>MUST_NOT_BREAK_BEFORE = <br>REPORT-tcp = tcpdump-endpoints, colon-kv<br>SEGMENTATION = inner<br>SEGMENTATION-all = full<br>SEGMENTATION-inner = inner<br>SEGMENTATION-outer = foo<br>SEGMENTATION-raw = none<br>SEGMENTATION-standard = standard<br>SHOULD_LINEMERGE = True<br>TRANSFORMS = <br>TRANSFORMS-baindex = banner-index<br>TRANSFORMS-dlindex = download-index<br>TRUNCATE = 10000<br>maxDist = 100<br>pulldown_type = true<br></font></code></div>

<a name="advancedsourcetypeoverrides"></a><h2> <a name="advancedsourcetypeoverrides_override_source_types_on_a_per-event_basis"><span class="mw-headline" id="Override_source_types_on_a_per-event_basis"> Override source types on a per-event basis </span></a></h2>
<p>This topic shows you how to configure Splunk Enterprise to override source types on a per-event basis. You do this at parse-time, after Splunk Enterprise has made its initial assignment as described in <a href="#whysourcetypesmatter_how_splunk_enterprise_assigns_source_types" class="external text">"How Splunk Enterprise assigns source types"</a>. 
</p><p>To configure per-event overrides, you use <code><font size="2">transforms.conf</font></code> in tandem with <code><font size="2">props.conf</font></code>. 
</p><p><b>Note:</b> Since this type of override occurs at parse-time, it works only on an indexer or heavy forwarder, not on a universal forwarder. See "Configuration parameters and the data pipeline" in the Admin manual for more information on what configurations are available at different points in the input/parsing/indexing process.
</p><p>For information about configuring basic (<b>not</b> per-event) source type overrides for event data that comes from specific inputs or that has a particular source, see <a href="#bypassautomaticsourcetypeassignment" class="external text">"Override automatic source type assignment"</a> in this manual.
</p>
<h3> <a name="advancedsourcetypeoverrides_configuration"><span class="mw-headline" id="Configuration"> Configuration </span></a></h3>
<p>To configure per-event overrides, you need to create two stanzas, one in <code><font size="2">transforms.conf</font></code> and another in <code><font size="2">props.conf</font></code>. Edit these files in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or in your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For more information about configuration files in general, see "About configuration files" in the Admin manual.
</p>
<h4><font size="3"><b><i> <a name="advancedsourcetypeoverrides_transforms.conf"><span class="mw-headline" id="transforms.conf"> transforms.conf </span></a></i></b></font></h4>
<p>Create a stanza in <code><font size="2">transforms.conf</font></code> that follows this syntax: 
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;unique_stanza_name&gt;]<br>REGEX = &lt;your_regex&gt;<br>FORMAT = sourcetype::&lt;your_custom_sourcetype_value&gt;<br>DEST_KEY = MetaData:Sourcetype<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;unique_stanza_name&gt;</font></code> should reflect that it involves a source type. You'll use this name later in the <code><font size="2">props.conf</font></code> stanza.
</li><li> <code><font size="2">&lt;your_regex&gt;</font></code> is a regular expression that identifies the events that you want to apply a custom source type to (such as events carrying a particular hostname or other field value).
</li><li> <code><font size="2">&lt;your_custom_sourcetype_value&gt;</font></code> is the source type that you want to apply to the regex-selected events.
</li></ul><p><b>Note:</b> For a primer on regular expression syntax and usage, see Regular-Expressions.info. You can test regexes by using them in searches with the rex search command. Splunk also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<h4><font size="3"><b><i> <a name="advancedsourcetypeoverrides_props.conf"><span class="mw-headline" id="props.conf"> props.conf </span></a></i></b></font></h4>
<p>Next, create a stanza in <code><font size="2">props.conf</font></code> that references the <code><font size="2">transforms.conf</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[&lt;spec&gt;]<br>TRANSFORMS-&lt;class&gt; = &lt;unique_stanza_name&gt;<br></font></code></div>
<p>Note the following:
</p>
<ul><li> <code><font size="2">&lt;spec&gt;</font></code> can be:
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>, the source type of an event.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>, where <code><font size="2">&lt;host&gt;</font></code> is the host value for an event.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>, where <code><font size="2">&lt;source&gt;</font></code> is the source value for an event.
</li></ul></li><li> <code><font size="2">&lt;class&gt;</font></code> is any unique identifier that you want to give to your transform.  
</li><li> <code><font size="2">&lt;unique_stanza_name&gt;</font></code> is the name of the stanza you created in <code><font size="2">transforms.conf</font></code>.
</li></ul><h3> <a name="advancedsourcetypeoverrides_example:_assign_a_source_type_to_events_from_a_single_input_but_different_hosts"><span class="mw-headline" id="Example:_Assign_a_source_type_to_events_from_a_single_input_but_different_hosts"> Example: Assign a source type to events from a single input but different hosts</span></a></h3>
<p>Let's say that you have a shared UDP input, "UDP514". Your Splunk Enterprise instance indexes a wide range of data from a number of hosts through this input. You've found that you need to apply a particular source type called "my_log" to data originating from three specific hosts (host1, host2, and host3) reaching Splunk through UDP514.
</p><p>To start, you can use the regex that Splunk typically uses to extract the host field for syslog events. You can find it in <code><font size="2">system/default/transforms.conf</font></code>:
</p>
<div class="samplecode"><code><font size="2"><br>[syslog-host]<br>REGEX =&nbsp;:\d\d\s+(?:\d+\s+|(?:user|daemon|local.?)\.\w+\s+)*\[?(\w[\w\.\-]{2,})\]?\s<br>FORMAT = host::$1<br>DEST_KEY = MetaData:Host<br></font></code></div>
<p>You can easily modify this regex to only match events from the hostnames you want (in this example, host1, host2, and host3):
</p><p><code><font size="2">REGEX =&nbsp;:\d\d\s+(?:\d+\s+|(?:user|daemon|local.?)\.\w+\s+)*\[?(host1|host2|host3)[\w\.\-]*\]?\s</font></code>
</p><p>Now you can use the modified regex in a transform that applies the <code><font size="2">my_log</font></code> source type to events that come from those three hosts: 
</p>
<div class="samplecode"><code><font size="2"><br>[set_sourcetype_my_log_for_some_hosts]<br>REGEX =&nbsp;:\d\d\s+(?:\d+\s+|(?:user|daemon|local.?)\.\w+\s+)*\[?(host1|host2|host3)[\w\.\-]*\]?\s<br>FORMAT = sourcetype::my_log<br>DEST_KEY = MetaData:Sourcetype<br></font></code></div>
<p>Then you can specify that transform in a <code><font size="2">props.conf</font></code> stanza that identifies the specific input for the events:
</p>
<div class="samplecode"><code><font size="2"><br>[source::udp:514]<br>TRANSFORMS-changesourcetype = set_sourcetype_my_log_for_some_hosts<br></font></code></div>

<a name="createsourcetypes"></a><h2> <a name="createsourcetypes_create_source_types"><span class="mw-headline" id="Create_source_types"> Create source types</span></a></h2>
<p>You can create new source types in two ways:
</p>
<ul><li> Use the "Set Sourcetype" in Splunk Web
</li><li> Edit the <code><font size="2">props.conf</font></code> configuration file directly
</li></ul><h3> <a name="createsourcetypes_set_the_source_type_in_splunk_web"><span class="mw-headline" id="Set_the_source_type_in_Splunk_Web"> Set the source type in Splunk Web </span></a></h3>
<p>The "Set Sourcetype" page in Splunk Web provides an easy way to view the effects of applying a source type to your data and to make adjustments to the source type settings as necessary. You can save your changes as a new source type, which you can then assign to data inputs. 
</p><p>The page lets you make the most common types of adjustments to <b>timestamps</b> and <b>event</b> breaks. For other modifications, it lets you edit the underlying <code><font size="2">props.conf</font></code> file directly. As you change settings, you can immediately see the changes to the event data.
</p><p>The page appears only when you specify or upload a single file. It does not appear when you specify any other type of source.
</p><p>To learn more about the page, see "<a href="#overviewofdatapreview" class="external text">The "Set Sourcetype" page</a>" in this manual. 
</p>
<h3> <a name="createsourcetypes_edit_props.conf"><span class="mw-headline" id="Edit_props.conf"> Edit props.conf </span></a></h3>
<p>You can create a new source type by editing  <code><font size="2">props.conf</font></code> and adding a new stanza. For detailed information on <code><font size="2">props.conf</font></code>, read the props.conf specification in the Admin manual. For information on configuration files in general, see "About configuration files" in the Admin manual.
</p><p>The following is an example of an entry in props.conf. This entry defines the <code><font size="2">access_combined</font></code> source type and then assigns that source type to files that match the specified source. You can specify multiple files or directories in a source by using a regular expression.
</p>
<div class="samplecode"><code><font size="2"><br>[access_combined]<br>pulldown_type = true <br>maxDist = 28<br>MAX_TIMESTAMP_LOOKAHEAD = 128<br>REPORT-access = access-extractions<br>SHOULD_LINEMERGE = False<br>TIME_PREFIX = \[<br>category = Web<br>description = National Center for Supercomputing Applications (NCSA) combined fo<br>rmat HTTP web server logs (can be generated by apache or other web servers)<br><br>[source::/opt/weblogs/apache.log]<br>sourcetype = iis<br></font></code></div>
<p>To edit props.conf:
</p><p><b>1.</b> On the host where you want to create a source type, make a copy of <code><font size="2">$SPLUNK_HOME/etc/system/default/props.conf</font></code> and save it in <code><font size="2">$SPLUNK_HOME/etc/system/local</font></code>.
</p><p><b>Note:</b> You might need to create the <code><font size="2">local</font></code> directory.  If you use an app, go to the app directory in <code><font size="2">$SPLUNK_HOME/etc/apps</font></code>.
</p><p><b>2.</b> Using a text editor, open the <code><font size="2">props.conf</font></code> file in <code><font size="2">$SPLUNK_HOME/etc/system/local</font></code>.
</p><p><b>3.</b> Add a stanza for the new source type and specify any attributes that Splunk Enterprise should use when handling the source type.
</p>
<div class="samplecode"><code><font size="2"><br>[my_sourcetype]<br>attribute1 = value<br>attribute2 = value<br></font></code></div>
<p><b>Note:</b> See the props.conf specification for a list of attributes and how they should be used.
</p><p><b>4.</b> Optionally, if you know the name of the file (or files) that Splunk Enterprise should apply the source type to, you can specify them with the <code><font size="2">[source::&lt;source&gt;]</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[my_sourcetype]<br>attribute1 = value<br>attribute2 = value<br><br>[source::.../my/logfile.log]<br>sourcetype = my_sourcetype<br></font></code></div>
<p><b>5.</b> Save the <code><font size="2">props.conf</font></code> file.  
</p><p><b>6.</b> Restart Splunk Enterprise. The new source types take effect after the restart completes.
</p>
<h4><font size="3"><b><i> <a name="createsourcetypes_specify_event_breaks_and_time_stamping"><span class="mw-headline" id="Specify_event_breaks_and_time_stamping">Specify event breaks and time stamping</span></a></i></b></font></h4>
<p>When you create a source type, there are some key attributes that you should specify:
</p>
<ul><li> <b>Event breaks.</b> To learn how to use <code><font size="2">props.conf</font></code> to specify event breaks, see <a href="#indexmulti-lineevents" class="external text">"Configure event linebreaking"</a>.
</li><li> <b>Timestamps.</b> To learn how to use <code><font size="2">props.conf</font></code> to specify timestamps, see <a href="#configuretimestamprecognition" class="external text">"Configure timestamp recognition"</a>, as well as other topics in the "Configure timestamps" chapter of this manual.
</li></ul><p>There are also a number of additional settings that you can configure. See the props.conf specification for more information.
</p>
<a name="renamesourcetypes"></a><h2> <a name="renamesourcetypes_rename_source_types_at_search_time"><span class="mw-headline" id="Rename_source_types_at_search_time"> Rename source types at search time</span></a></h2>
<p>You might want to rename a source type in certain situations. For example, say you accidentally assigned an input to the wrong source type. Or you realize that two differently named source types should be handled exactly the same at search time.
</p><p>You can use the <code><font size="2">rename</font></code> attribute in <code><font size="2">props.conf</font></code> to assign events to a new source type at search time. In case you ever need to search on it, Splunk Enterprise moves the original source type to a separate field, <code><font size="2">_sourcetype</font></code>.
</p><p><b>Note:</b> The indexed events still contain the original source type name. The renaming occurs only at search time. Also, renaming the source type does only that; it does not fix any problems with the indexed format of your event data caused by assigning the wrong source type in the first place.
</p><p>To rename the source type, add the <code><font size="2">rename</font></code> attribute to your source type stanza:
</p>
<code><font size="2"><br>rename = &lt;string&gt;<br></font></code>
<p><b>Note:</b> A source type name can only contain the letters <code><font size="2">a</font></code> though <code><font size="2">z</font></code>, the numerals <code><font size="2">0</font></code> through <code><font size="2">9</font></code>, and the <code><font size="2">_</font></code> (underscore) character.
</p><p>For example, say you're using the source type "cheese_shop" for your application server. Then, accidentally, you index a pile of data as source type "whoops". You can rename "whoops" to "cheese_shop" with this <code><font size="2">props.conf</font></code> stanza:
</p>
<div class="samplecode"><code><font size="2"><br>[whoops]<br>rename=cheese_shop<br></font></code></div>
<p>Now, a search on "cheese_shop" will bring up all the "whoops" events as well as any events that had a "cheese_shop" source type from the start:
</p>
<div class="samplecode"><code><font size="2"><br>sourcetype=cheese_shop<br></font></code></div>
<p>If you ever need to single out the "whoops" events, you can use <code><font size="2">_sourcetype</font></code> in your search:
</p>
<div class="samplecode"><code><font size="2"><br>_sourcetype=whoops<br></font></code></div>
<p><b>Important:</b> Data from a renamed source type will only use the search-time configuration for the target source type ("cheese_shop" in this example). Any field extractions for the original source type ("whoops" in the example) will be ignored.
</p>
<h1>Manage event segmentation</h1><a name="abouteventsegmentation"></a><h2> <a name="abouteventsegmentation_about_event_segmentation"><span class="mw-headline" id="About_event_segmentation"> About event segmentation </span></a></h2>
<p><b>Segmentation</b> is what Splunk Enterprise uses to break events up into searchable <b>segments</b> at <b>index</b> time, and again at <b>search</b> time. 
Segments can be classified as <b>major</b> or <b>minor</b>. Minor segments are breaks within major segments. For example, the IP address <code><font size="2">192.0.2.223</font></code> is a major segment. But this major segment can be broken down into minor segments, such as "<code><font size="2">192</font></code>", as well as groups of minor segments like "<code><font size="2">192.0.2</font></code>". 
</p><p>You can define how detailed the event segmentation should be. This is important because <b>index-time segmentation</b> affects indexing and search speed, storage size, and the ability to use typeahead functionality (where Splunk Web provides items that match text you type into the Search bar). <b>Search-time segmentation</b>, on the other hand, affects search speed and the ability to create searches by selecting items from the results displayed in Splunk Web.
</p><p>For more information about the distinction between "index time" and "search time," see "Index time versus search time" in the Managing Indexers and Clusters manual.
</p><p>You can assign segmentation to specific categories of events in props.conf, as described in <a href="#setthesegmentationforeventdata" class="external text">"Set the segmentation for event data"</a>.
</p>
<h3> <a name="abouteventsegmentation_types_of_event_segmentation"><span class="mw-headline" id="Types_of_event_segmentation"> Types of event segmentation </span></a></h3>
<p>There are three main types, or levels, of segmentation, configurable at index or search time: 
</p>
<ul><li> <b>Inner segmentation</b> breaks events down into the smallest minor segments possible. For example, when an IP address such as <code><font size="2">192.0.2.223</font></code> goes through inner segmentation, it is broken down into <code><font size="2">192</font></code>, <code><font size="2">0</font></code>, <code><font size="2">2</font></code>, and <code><font size="2">223</font></code>. Setting inner segmentation at index time leads to faster indexing and searching and reduced disk usage. However, it restricts the typeahead functionality, so that a user can only type ahead at the minor segment level. 
</li><li> <b>Outer segmentation</b> is the opposite of inner segmentation. Under outer segmentation, Splunk Enterprise only indexes major segments. For example, the IP address <code><font size="2">192.0.2.223</font></code> gets indexed as <code><font size="2">192.0.2.223</font></code>, which means that you cannot search on individual pieces of the phrase. You can still use wildcards, however, to search for pieces of a phrase. For example, you can search for <code><font size="2">192.0*</font></code> and you will get any events that have IP addresses that start with <code><font size="2">192.0</font></code>.  Also, outer segmentation disables the ability to click on different segments of search results, such as the <code><font size="2">192.0</font></code> segment of the same IP address. Outer segmentation tends to be marginally more efficient than full segmentation, while inner segmentation tends to be much more efficient.
</li><li> <b>Full segmentation</b> is a combination of inner and outer segmentation. Under full segmentation, the IP address is indexed both as a major segment and as a variety of minor segments, including minor segment combinations like <code><font size="2">192.0</font></code> and <code><font size="2">192.0.2</font></code>. This is the least efficient indexing option, but it provides the most versatility in terms of searching. 
</li></ul><p>The <code><font size="2">segmenters.conf</font></code> file, located in <code><font size="2">$SPLUNK_HOME/etc/system/default</font></code>, defines all available segmentation types.  By default, index-time segmentation is set to the <code><font size="2">indexing</font></code> type, which is a combination of inner and outer segmentation. Search-time segmentation is set to full segmentation.
</p>
<h4><font size="3"><b><i> <a name="abouteventsegmentation_no_segmentation"><span class="mw-headline" id="No_segmentation"> No segmentation</span></a></i></b></font></h4>
<p>The most space-efficient segmentation setting is to disable segmentation completely. This has significant implications for search, however. By setting Splunk Enterprise to index with no segmentation, you restrict searches to indexed fields, such as time, source, host, and source type.  Searches for keywords will return no results. You must pipe your searches through the search command to further restrict results. Use this setting only if you do not need any advanced search capability.
</p>
<h4><font size="3"><b><i> <a name="abouteventsegmentation_configure_segmentation_types"><span class="mw-headline" id="Configure_segmentation_types">Configure segmentation types</span></a></i></b></font></h4>
<p>segmenters.conf defines segmentation types. You can define custom segmentation types, if necessary.
</p><p>For information on the types of segmentation available by default, look at the <code><font size="2">segmenters.conf</font></code> file in <code><font size="2">$SPLUNK_HOME/etc/system/default</font></code>.  
</p><p><b>Important:</b> Do not modify the default file. If you want to make changes to the existing segmentation stanzas or create new ones altogether, you can copy the default file to <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code> or to a custom app directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>.  For information on configuration files and directory locations, see "About configuration files".
</p>
<h3> <a name="abouteventsegmentation_set_segmentation_types_for_specific_hosts.2c_sources.2c_or_source_types"><span class="mw-headline" id="Set_segmentation_types_for_specific_hosts.2C_sources.2C_or_source_types"> Set segmentation types for specific hosts, sources, or source types </span></a></h3>
<p>You can configure index-time and search-time segmentation to apply to specific hosts, sources, or source types. If you run searches that involve a particular source type on a regular basis, you could use this capability to improve the performance of those searches. Similarly, if you typically index a large number of <code><font size="2">syslog</font></code> events, you could use this feature to help decrease the overall disk space that those events take up. 
</p><p>For details about how to apply segmentation types to specific event categories, see <a href="#setthesegmentationforeventdata" class="external text">"Set the segmentation for event data"</a>.
</p>
<a name="setthesegmentationforeventdata"></a><h2> <a name="setthesegmentationforeventdata_set_the_segmentation_for_event_data"><span class="mw-headline" id="Set_the_segmentation_for_event_data"> Set the segmentation for event data</span></a></h2>
<p>By default, Splunk Enterprise segments events during indexing to allow for the most flexible searching. There are numerous types of segmentation available, and you can create others if necessary. The type of segmentation that you employ affects indexing speed, search speed, and the amount of disk space the indexes occupy. To learn more about segmentation and the trade-offs between the various types of segmentation, refer to <a href="#abouteventsegmentation" class="external text">"About segmentation"</a>. 
</p><p>Splunk Enterprise can also segment events at search time. You can set search-time segmentation in Splunk Web, as described in  <a href="#setsegmentationinsplunkweb" class="external text">"Set search-time segmentation in Splunk Web"</a>. 
</p><p>If you know how you want to search for or process events from a specific host, source, or source type, you can configure index-time segmentation for that specific type of event. You can also configure search-time segmentation options for specific types of events.
</p>
<h3> <a name="setthesegmentationforeventdata_specify_segmentation_in_props.conf"><span class="mw-headline" id="Specify_segmentation_in_props.conf"> Specify segmentation in props.conf </span></a></h3>
<p>Specify segmentation for events of particular hosts, sources, or source types by assigning segmentation types to the appropriate stanzas in <code><font size="2">props.conf</font></code>. In the stanzas, you assign segmentation types, or "rules", that have been defined in segmenters.conf. These can either be predefined types (such as inner, outer, or full), or custom types that you've defined. For more information on defining custom types, read <a href="#abouteventsegmentation_configure_segmentation_types" class="external text">"Configure segmentation types"</a>.
</p><p>The attribute you configure in <code><font size="2">props.conf</font></code> to use these types depends on whether you're configuring index-time or search-time segmentation:
</p>
<ul><li> For index-time segmentation, use the <code><font size="2">SEGMENTATION</font></code> attribute.
</li><li> For search-time segmentation, use the <code><font size="2">SEGMENTATION-&lt;segment selection&gt;</font></code> attribute. 
</li></ul><p>You can define either one of the attributes or both together in the stanza.
</p><p>Add your stanza to <code><font size="2">$SPLUNK_HOME/etc/system/local/props.conf</font></code>. 
</p>
<h4><font size="3"><b><i> <a name="setthesegmentationforeventdata_index-time_segmentation"><span class="mw-headline" id="Index-time_segmentation">Index-time segmentation</span></a></i></b></font></h4>
<p>The <code><font size="2">SEGMENTATION</font></code> attribute determines the segmentation type used at index time.  Here's the syntax:
</p>
<code><font size="2"><br>[&lt;spec&gt;]<br>SEGMENTATION = &lt;seg_rule&gt;<br></font></code>
<p><code><font size="2">[&lt;spec&gt;]</font></code> can be:
</p>
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>: A source type in your event data.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>: A host value in your event data.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>: A source of your event data.
</li></ul><p><code><font size="2">SEGMENTATION = &lt;seg_rule&gt;</font></code>
</p>
<ul><li> This specifies the type of segmentation to use at index time for <code><font size="2">[&lt;spec&gt;]</font></code> events.
</li><li> <code><font size="2">&lt;seg_rule&gt;</font></code>
<ul><li> A segmentation type, or "rule", defined in <code><font size="2">segmenters.conf</font></code> 
</li><li> Common settings are <code><font size="2">inner</font></code>, <code><font size="2">outer</font></code>, <code><font size="2">none</font></code>, and <code><font size="2">full</font></code>, but the default file contains other predefined segmentation rules as well.
</li><li> Create your own custom rule by editing <code><font size="2">$SPLUNK_HOME/etc/system/local/segmenters.conf</font></code>, as described in <a href="#abouteventsegmentation_configure_segmentation_types" class="external text">"Configure segmentation types"</a>.
</li></ul></li></ul><h4><font size="3"><b><i> <a name="setthesegmentationforeventdata_search-time_segmentation"><span class="mw-headline" id="Search-time_segmentation">Search-time segmentation</span></a></i></b></font></h4>
<p>The <code><font size="2">SEGMENTATION-&lt;segment_selection&gt;</font></code> attribute helps determine the segmentation type used at search time.  Here's the syntax:
</p>
<code><font size="2"><br>[&lt;spec&gt;]<br>SEGMENTATION-&lt;segment_selection&gt; = &lt;seg_rule&gt;<br></font></code>
<p><code><font size="2">[&lt;spec&gt;]</font></code> can be:
</p>
<ul><li> <code><font size="2">&lt;sourcetype&gt;</font></code>: A source type in your event data.
</li><li> <code><font size="2">host::&lt;host&gt;</font></code>: A host value in your event data.
</li><li> <code><font size="2">source::&lt;source&gt;</font></code>: A source of your event data.
</li></ul><p><code><font size="2">SEGMENTATION-&lt;segment_selection&gt; = &lt;seg_rule&gt;</font></code>
</p>
<ul><li> This specifies the type of segmentation to use at search time in Splunk Web for <code><font size="2">[&lt;spec&gt;]</font></code> events.
</li></ul><ul><li> <code><font size="2">&lt;segment_selection&gt;</font></code> can be one of the following: <code><font size="2">full</font></code>, <code><font size="2">inner</font></code>, <code><font size="2">outer</font></code>, or <code><font size="2">raw</font></code>.
<ul><li> These four values are the set of options displayed in the <b>Event segmentation</b> dropdown box in the <b>Results display options</b> panel, invoked from <b>Options</b> directly above search results in Splunk Web.  
</li><li> Note that these values are just the set of available Splunk Web dropdown options. You use this attribute to specify the actual segmentation type that the option invokes, which might not be of the same name as the dropdown option itself.  For example, you could even define the "inner" dropdown option to invoke the "outer" segmentation type, not that you'd likely want to.
</li><li> By mapping the dropdown option to a <code><font size="2">&lt;seg_rule&gt;</font></code>, a user can later specify the option when looking at search results to set search-time segmentation, as described in <a href="#setsegmentationinsplunkweb" class="external text">"Set search-time segmentation in Splunk Web"</a>. 
</li></ul></li></ul><ul><li> <code><font size="2">&lt;seg_rule&gt;</font></code>
<ul><li> A segmentation type, or "rule", defined in <code><font size="2">segmenters.conf</font></code> 
</li><li> Common settings are <code><font size="2">inner</font></code>, <code><font size="2">outer</font></code>, <code><font size="2">none</font></code>, and <code><font size="2">full</font></code>, but the default file contains other predefined segmentation rules as well.
</li><li> Create your own custom rule by editing <code><font size="2">$SPLUNK_HOME/etc/system/local/segmenters.conf</font></code>, as described in <a href="#abouteventsegmentation_configure_segmentation_types" class="external text">"Configure segmentation types"</a>.
</li></ul></li></ul><h3> <a name="setthesegmentationforeventdata_example"><span class="mw-headline" id="Example"> Example </span></a></h3>
<p>This example sets both index-time and search-time segmentation rules for <code><font size="2">syslog</font></code> events.
</p><p>Add the following to the <code><font size="2">[syslog]</font></code> source type stanza in <code><font size="2">props.conf</font></code>:
</p>
<code><font size="2"><br>[syslog]<br>SEGMENTATION = inner<br>SEGMENTATION-full= inner<br></font></code>
<p>This stanza changes the index-time segmentation for all events with a <code><font size="2">syslog</font></code> source type to inner segmentation. It also causes the <code><font size="2">full</font></code> radio button in Splunk Web to invoke inner segmentation for those same events. 
</p><p><b>Note:</b> You must restart Splunk Enterprise to apply changes to search-time segmentation. You must re-index your data to apply index-time segmentation changes to existing data.
</p>
<a name="setsegmentationinsplunkweb"></a><h2> <a name="setsegmentationinsplunkweb_set_search-time_event_segmentation_in_splunk_web"><span class="mw-headline" id="Set_search-time_event_segmentation_in_Splunk_Web"> Set search-time event segmentation in Splunk Web</span></a></h2>
<p>Splunk Web allows you to set segmentation for search results. While this has nothing to do with index-time segmentation, search-time segmentation in Splunk Web affects browser interaction and can speed up search results.
</p><p>To set search-result segmentation:
</p><p><b>1.</b> Perform a search.  Look at the results.
</p><p><b>2.</b> Click <b>Options...</b> above the returned set of events. 
</p><p><b>3.</b> In the <b>Event Segmentation</b> dropdown box, choose from the available options: full, inner, outer, or raw. The default is "full".
</p><p>You can configure the meaning of these dropdown options, as described in <a href="#setthesegmentationforeventdata" class="external text">"Set the segmentation for event data"</a>.
</p>
<h1>Improve the data input process</h1><a name="testyourinputs"></a><h2> <a name="testyourinputs_use_a_test_index_to_test_your_inputs"><span class="mw-headline" id="Use_a_test_index_to_test_your_inputs"> Use a test index to test your inputs</span></a></h2>
<p>Before adding new inputs to your production index, it is best to test them out. Add the inputs to a test index. Once you've verified that you're receiving the right data inputs and that the resulting events are in a usable form, you can point the inputs to your default "main" index. You can continue to test new inputs this way over time. 
</p><p>If you find that the inputs you started with are not the ones you want, or that the indexed events don't appear the way you need them to, you can keep working with the test index until you get results you like. When things start looking good, you can edit the inputs to point to your main index instead.
</p><p>You can preview how Splunk Enterprise will index your data into a test index. During preview, you can adjust some event processing settings interactively. See  "<a href="#overviewofdatapreview" class="external text">The "Set Sourcetype" page</a>" for details.
</p>
<h3> <a name="testyourinputs_use_a_test_index"><span class="mw-headline" id="Use_a_test_index"> Use a test index </span></a></h3>
<p>To learn how to create and use custom indexes, read "Set up multiple indexes" in the Managing Indexers and Clusters manual. There are a few basic steps, described in detail in that topic:
</p><p><b>1.</b> Create the test index, using Splunk Web or the CLI or by editing <code><font size="2">indexes.conf</font></code> directly. See "Set up multiple indexes" for details.
</p><p><b>2.</b> When <a href="#configureyourinputs" class="external text">configuring the data inputs</a>, route events to the test index. You can usually do this in Splunk Web. For each input:
</p><p><b>a.</b> When configuring the input from the <b>Add data</b> page, check the <b>More settings</b> option. It reveals several new fields, including one called <b>Index</b>.
</p><p><b>b.</b> In the <b>Index</b> dropdown box, select your test index. All events for that data input will now go to that index.
</p><p><b>c.</b>  Repeat this process for each data input that you want to send to your test index.
</p><p>You can also specify an index when configuring an input in <code><font size="2">inputs.conf</font></code>, as described here. 
</p><p><b>3.</b> When you search, specify the test index in your search command. (By default, Splunk Enterprise searches on the "main" index.) Use the <code><font size="2">index=</font></code> command:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=test_index</font></code><br></div>
<p><b>Note</b>&nbsp;: When searching a test index for events coming in from your newly created input, Splunk recommends that you use the <i>Real-time &gt; All time(real-time)</i> time range for the fields sidebar. The resulting <b>real-time search</b> will show all events being written to that index regardless of the value of their extracted time stamp. This is particularly useful if you are indexing historical data into your index that a search for "Last hour" or "Real-time &gt; 30 minute window" would not show.
</p>
<h3> <a name="testyourinputs_delete_indexed_data_and_start_over"><span class="mw-headline" id="Delete_indexed_data_and_start_over"> Delete indexed data and start over </span></a></h3>
<p>If you want to clean out your test index and start over again, use the CLI <code><font size="2">clean</font></code> command, described here. 
</p>
<h3> <a name="testyourinputs_point_your_inputs_at_the_default_index"><span class="mw-headline" id="Point_your_inputs_at_the_default_index"> Point your inputs at the default index </span></a></h3>
<p>Once you're satisfied with the results and are ready to start indexing for real, you'll want to edit your data inputs so that they point to the default, "main" index, instead of the test index.  This is a simple process, just the reverse of the steps you took to use the test index in the first place. For each data input that you've already set up:
</p><p><b>1.</b> Go back to the place where you initially configured the input. For example, if you configured the input from the <b>Add data</b> page in Splunk Web, return to the configuration screen for that input:
</p><p><b>a.</b> Select <b>System &gt; System configurations &gt; Data inputs</b>. 
</p><p><b>b.</b> Select the input's data type to see a list of all configured inputs of that type.
</p><p><b>c.</b> Select the specific data input that you want to edit. This will take you to a screen where you can edit it.
</p><p><b>d.</b> Select the <b>Display advanced settings</b> option. Go to the field named <b>Index</b>. 
</p><p><b>e.</b> In the <b>Index</b> dropdown box, select the <b>main</b> index. All events for that data input will now go to that index.
</p><p>If you instead used <code><font size="2">inputs.conf</font></code> to configure an input, you can change the index directly in that file, as described here. 
</p><p><b>2.</b> Now when you search, you no longer need to specify an index in your search command. By default, Splunk Enterprise searches on the "main" index.
</p>
<a name="usepersistentqueues"></a><h2> <a name="usepersistentqueues_use_persistent_queues_to_help_prevent_data_loss"><span class="mw-headline" id="Use_persistent_queues_to_help_prevent_data_loss"> Use persistent queues to help prevent data loss</span></a></h2>
<p><b>Persistent queuing</b> lets you store data in an input queue to disk. This can help prevent data loss if the <b>forwarder</b> or <b>indexer</b> gets backed up. 
</p><p>By default, forwarders and indexers have an in-memory input queue of 500KB. If the input stream runs at a faster rate than the forwarder or indexer can process, to a point where the queue is maxed out, undesired consequences occur. In the case of UDP, data drops off the queue and gets lost. For other input types, the application generating the data gets backed up.
</p><p>By implementing persistent queues, you can help prevent this from happening. With persistent queuing, once the in-memory queue is full, the forwarder or indexer writes the input stream to files on disk. It then processes data from the queues (in-memory and disk) until it reaches the point when it can again start processing directly from the data stream.
</p><p><b>Important:</b> Persistent queues help prevent data loss if Splunk Enterprise gets backed up. They are not a panacea, however. You can still lose data if Splunk Enterprise crashes. For example, Splunk holds some input data the in-memory queue, as well as in the persistent queue files. The in-memory data can get lost if a crash occurs. Similarly, data that is in the parsing or indexing pipeline but that has not yet been written to disk can get lost in the event of a crash.
</p><p><b>Note:</b> In Splunk Enterprise version 4.2 and later, the persistent queue capability has been re-implemented in a much improved fashion. It is now a feature of data inputs and is therefore configured in inputs.conf. It is <b>not</b> related in any way to the previous, deprecated persistent queue capability, which was configured through outputs.conf. 
</p>
<h3> <a name="usepersistentqueues_when_can_you_use_persistent_queues.3f"><span class="mw-headline" id="When_can_you_use_persistent_queues.3F"> When can you use persistent queues? </span></a></h3>
<p>Persistent queuing is available for certain types of inputs, but not all. Generally speaking, it is available for inputs of an ephemeral nature, such as network inputs, but not for inputs that have their own form of persistence, such as file monitoring.
</p><p>Persistent queues are available for these input types:
</p>
<ul><li> TCP
</li><li> UDP
</li><li> FIFO
</li><li> Scripted inputs
</li><li> Windows Event Log inputs
</li></ul><p>Persistent queues are not available for these input types:
</p>
<ul><li> Monitor
</li><li> Batch
</li><li> File system change monitor
</li><li> splunktcp (input from Splunk forwarders)
</li></ul><h3> <a name="usepersistentqueues_configure_a_persistent_queue"><span class="mw-headline" id="Configure_a_persistent_queue"> Configure a persistent queue </span></a></h3>
<p>Use the inputs.conf file to configure a persistent queue. 
</p><p>Inputs do not share queues. You configure a persistent queue in the stanza for the specific input. 
</p>
<h4><font size="3"><b><i> <a name="usepersistentqueues_syntax"><span class="mw-headline" id="Syntax">Syntax</span></a></i></b></font></h4>
<p>To create the persistent queue, specify these two attributes within the particular input's stanza: 
</p>
<code><font size="2"><br>persistentQueueSize = &lt;integer&gt;(KB|MB|GB|TB)<br>* Max size of the persistent queue file on disk.<br>* Defaults to 0 (no persistent queue).<br></font></code>
<h4><font size="3"><b><i> <a name="usepersistentqueues_example"><span class="mw-headline" id="Example">Example</span></a></i></b></font></h4>
<p>Here's an example of specifying a persistent queue for a tcp input:
</p>
<div class="samplecode"><code><font size="2"><br>[tcp://9994]<br>persistentQueueSize=100MB<br></font></code></div>
<h3> <a name="usepersistentqueues_persistent_queue_location"><span class="mw-headline" id="Persistent_queue_location">Persistent queue location</span></a></h3>
<p>The persistent queue has a hardcoded location, which varies according to the input type.
</p><p>For network inputs, the persistent queue is located here:
</p>
<code><font size="2"><br>$SPLUNK_HOME/var/run/splunk/[tcpin|udpin]/pq__&lt;port&gt;<br></font></code>
<p><b>Note:</b> There are <i>two</i> underscores in the file name: <code><font size="2">pq__&lt;port&gt;</font></code>, <i>not</i> <code><font size="2">pq_&lt;port&gt;</font></code>.
</p><p>For example:
</p>
<ul><li> The persistent queue for TCP port 2012: <code><font size="2">$SPLUNK_HOME/var/run/splunk/tcpin/pq__2012</font></code>
</li></ul><ul><li> The persistent queue for UDP port 2012: <code><font size="2">$SPLUNK_HOME/var/run/splunk/udpin/pq__2012</font></code>
</li></ul><p>For FIFO inputs, the persistent queue resides under <code><font size="2">$SPLUNK_HOME/var/run/splunk/fifoin/&lt;encoded path&gt;</font></code>.
</p><p>For scripted inputs, it resides under <code><font size="2">$SPLUNK_HOME/var/run/splunk/exec/&lt;encoded path&gt;</font></code>. The FIFO/scripted input stanza in <code><font size="2">inputs.conf</font></code> derives the <code><font size="2">&lt;encoded path&gt;</font></code>.
</p>
<a name="troubleshoottheinputprocess"></a><h2> <a name="troubleshoottheinputprocess_troubleshoot_the_input_process"><span class="mw-headline" id="Troubleshoot_the_input_process"> Troubleshoot the input process</span></a></h2>
<h3> <a name="troubleshoottheinputprocess_not_finding_the_events_you.27re_looking_for.3f"><span class="mw-headline" id="Not_finding_the_events_you.27re_looking_for.3F"> Not finding the events you're looking for? </span></a></h3>
<p>When you add an input to Splunk Enterprise, that input gets added relative to the app you are in. Some apps, like the *nix and Windows apps, write input data to a specific index (in the case of *nix and Windows, that is the 'os' index). If you are not finding data that you are certain is in Splunk Enterprise, be sure that you are looking at the right index. You might want to add the 'os' index to the list of default indexes for the role you are using. For more information about roles, refer to the topic about roles in the Securing Splunk Enterprise manual. For more information about troubleshooting data input issues, read the rest of this topic or see "I can't find my data!" in the Troubleshooting Manual.
</p><p><b>Note:</b> When you add inputs by editing <code><font size="2">inputs.conf</font></code>, Splunk Enterprise might not immediately recognize them. Splunk Enterprise looks for inputs every 24 hours, starting from the time it was last restarted. This means that if you add a new stanza to monitor a directory or file, it could take up to 24 hours for Splunk Enterprise to start indexing the contents of that directory or file. To ensure that your input is immediately recognized and indexed, add the input through Splunk Web or by using the <code><font size="2">add</font></code> command in the CLI.
</p>
<h3> <a name="troubleshoottheinputprocess_troubleshoot_your_tailed_files"><span class="mw-headline" id="Troubleshoot_your_tailed_files"> Troubleshoot your tailed files </span></a></h3>
<p>You can use the <code><font size="2">FileStatus</font></code> Representational State Transfer (REST) endpoint to get the status of your tailed files. For example:
</p>
<div class="samplecode"><code><font size="2"><br>curl https://serverhost:8089/services/admin/inputstatus/TailingProcessor:FileStatus<br></font></code></div>
<p>You can also monitor the fishbucket.
</p><p>The fishbucket is a subdirectory within the Splunk Enterprise directory that keeps a record about each file input. The fishbucket keeps track of how far into a file that Splunk Enterprise has read, so that if you stop and restart splunkd, it knows where in each file input to resume reading. The fishbucket is at <code><font size="2">$SPLUNK_DB/fishbucket/splunk_private_db</font></code>.
</p><p>To monitor the fishbucket, use the REST endpoint. Review the REST API Reference manual for additional information.
</p>
<h3> <a name="troubleshoottheinputprocess_troubleshoot_monitor_inputs"><span class="mw-headline" id="Troubleshoot_monitor_inputs"> Troubleshoot monitor inputs</span></a></h3>
<p>For a variety of information on dealing with monitor input issues, read "Troubleshooting Monitor Inputs" in the Community Wiki.
</p>
<h3> <a name="troubleshoottheinputprocess_can.27t_find_data_coming_from_a_forwarder.3f"><span class="mw-headline" id="Can.27t_find_data_coming_from_a_forwarder.3F"> Can't find data coming from a forwarder? </span></a></h3>
<p>Make sure the forwarder is functioning properly and is visible to the indexer. You can use the Deployment Monitor app to troubleshoot Splunk topologies and get to the root of any forwarder issues. Read the <i>Deploy and Use Splunk Deployment Monitor App</i> manual for details.
</p>
<h1>Recipes</h1><a name="useforwardingagentstogetdata"></a><h2> <a name="useforwardingagentstogetdata_forwarders"><span class="mw-headline" id="Forwarders"> Forwarders </span></a></h2>
<p>Set up inputs on a forwarder the same way you set them up on a Splunk Enterprise indexer. The only difference is that the forwarder does not include Splunk Web, so you must configure inputs with either the CLI or <code><font size="2">inputs.conf</font></code>. Before setting up the inputs, you need to deploy and configure the forwarder, as this recipe describes.
</p><p>You can use Splunk <b>forwarders</b> to send data to indexers, called <b>receivers</b>. This is the preferred way to get remote data into an indexer.
</p><p>To use forwarders, specifically universal forwarders, for getting remote data, you need to set up a forwarder-receiver topology, as well as configure the data inputs:
</p><p><b>1.</b> Install Splunk Enterprise instances as receivers. See the Installation manual.
</p><p><b>2.</b> Use Splunk Web or the CLI to enable receiving on those instances. See "Enable a receiver" in the <i>Forwarding Data</i> manual.
</p><p><b>3.</b> Set up one of the receiving Splunk Enterprise instances as a deployment server. See "Plan a deployment" in the Updating Splunk Enterprise Instances manual.
</p><p><b>4.</b> Deploy at least one app to the deployment server by placing the app into the <code><font size="2">$SPLUNK_HOME/etc/deployment_apps</font></code> directory. See "Create deployment apps" in the Updating Splunk Enterprise Instances manual.
</p><p><b>5.</b> Install, configure, and deploy the forwarders. During configuration:
</p>
<ul><li> Specify a receiving indexer. See *nix and Windows instructions.
</li><li> Specify the deployment server.
</li></ul><p><b>Note:</b> Depending on your forwarding needs, there are a number of best practice deployment scenarios. See "Universal forwarder deployment overview" in the <i>Forwarding Data</i> manual. Some of these scenarios allow you to configure the forwarder during the installation process.
</p><p><b>6.</b> Use Forwarder Management to deploy data input configurations to each universal forwarder. See "<a href="#forwarddata" class="external text">Forward Data</a>" in this manual.
</p><p><b>7.</b> Test the results to confirm that forwarding, along with any configured behaviors like load balancing or filtering, is occurring as expected. Go to the receiver to search the resulting data. 
</p><p>For more information on forwarders, see the <i>Forwarding Data</i> manual, starting with "About forwarding and receiving". Also see <a href="#usingforwardingagents" class="external text">"Use forwarders to get data in"</a> in this manual.
</p>
<a name="filesdirslocal"></a><h2> <a name="filesdirslocal_files_and_directories_-_local"><span class="mw-headline" id="Files_and_directories_-_local"> Files and directories - local </span></a></h2>
<p>Splunk Enterprise can monitor files and directories for events.  If your system generates it, Splunk Enterprise can index, search, report and alert on it.
</p><p>To get data from files and directories into Splunk Enterprise:
</p>
<h3> <a name="filesdirslocal_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. 
You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Files &amp; Directories</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Upload</b> to upload a file, <b>Monitor</b> to monitor a file, or <b>Forward</b> to forward a file.
</p><p><b>Note:</b> Forwarding a file requires additional setup. See "<a href="#forwarddata" class="external text">Forward data</a>" in this manual.
</p>
<h3> <a name="filesdirslocal_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> To add a file or directory input, click <b>Files &amp; Directories.</b>
</p><p><b>2.</b> In the <b>File or Directory</b> field, specify the full path to the file or directory.
</p><p>To monitor a shared network drive, enter the following: <code><font size="2">&lt;myhost&gt;/&lt;mypath&gt;</font></code> (or <code><font size="2">\\&lt;myhost&gt;\&lt;mypath&gt;</font></code> on Windows). Make sure Splunk Enterprise has read access to the mounted drive, as well as to the files you wish to monitor. 
</p><p><b>3.</b> Choose how you want Splunk Enterprise to monitor the file:
</p>
<ul><li> <b>Continuously Monitor</b>. Sets up an ongoing input. Splunk Enterprise monitors the file continuously for new data. Read the next section for advanced options specific to this choice.
</li><li> <b>Index Once</b>. Copies a file on the server into Splunk Enterprise.
</li></ul><p><b>4.</b> Click the green <b>Next</b> button. 
</p>
<ul><li> If you specified a directory in the "File or Directory" field, Splunk Enterprise refreshes the screen to show fields for "whitelist" and "blacklist". These fields let you specify regular expressions that Splunk Enterprise then uses to match files for inclusion (in the case of a whitelist) or exclusion (in the case of a blacklist). See "<a href="#whitelistorblacklistspecificincomingdata" class="external text">Whitelist or blacklist specific incoming data</a>."
</li></ul><ul><li> Otherwise, Splunk Enterprise lets you preview the data.
</li></ul><h3> <a name="filesdirslocal_c._preview_your_data_and_set_its_source_type"><span class="mw-headline" id="C._Preview_your_data_and_set_its_source_type"> C. Preview your data and set its source type </span></a></h3>
<p>When you add a new file input, Splunk Enterprise lets you set the <b>source type</b> of your data and preview how it will look once it has been indexed. This lets you ensure that the data has been formatted properly and make any necessary adjustments. 
</p>
<ul><li> See <a href="#overviewofdatapreview" class="external text">"The "Set Sourcetype" Page"</a> to learn about the "Set Sourcetype" page.
</li><li> See <a href="#accessdatapreview" class="external text">"View and set source types for event data"</a> to learn how to use the page.
</li></ul><p>If you choose to skip data preview, Splunk Web takes you to the <b>Input Settings</b> page.
</p><p><b>Note:</b> Splunk Enterprise cannot show a preview of directories or archived files.
</p>
<h3> <a name="filesdirslocal_d._specify_input_settings"><span class="mw-headline" id="D._Specify_input_settings"> D. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in "<a href="#abouthosts" class="external text">About hosts</a>".
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to for this input. Leave the value as "default", unless you have defined multiple indexes and want to use one of those instead. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="filesdirslocal_e._review_your_choices"><span class="mw-headline" id="E._Review_your_choices"> E. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button in the banner to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified file or directory.
</p><p>For more information on getting data from files and directories, see <a href="#monitorfilesanddirectories" class="external text">"Monitor files and directories"</a> in this manual.
</p>
<a name="filesdirsremote"></a><h2> <a name="filesdirsremote_files_and_directories_-_remote"><span class="mw-headline" id="Files_and_directories_-_remote"> Files and directories - remote</span></a></h2>
<p>The easiest way to get data from remote machines into Splunk Enterprise is with the universal <b>forwarder</b>. You set up the forwarder on the machine that generates the data and then point the forwarder at the Splunk Enterprise indexer. The forwarder gets the data and forwards the events to the indexer, which then processes and stores them and makes them available for searching.
</p><p>There are two steps:
</p><p><b>1.</b> Set up the forwarder on the remote machine and point it at the indexer. See this recipe: <a href="#useforwardingagentstogetdata" class="external text">"Forwarders"</a>.
</p><p><b>2.</b> Set up the forwarder inputs so that they monitor the data. This process is the same as if the data was on a Splunk indexer. However, the forwarder does not have Splunk Web, so you must set up the inputs either with the CLI or by editing <code><font size="2">inputs.conf</font></code> directly. 
</p>
<ul><li> For information on setting up inputs to monitor files, see <a href="#monitorfilesanddirectories" class="external text">"Monitor files and directories"</a> in this manual.  
</li><li> For additional information on how to set up forwarders, see <a href="#usingforwardingagents" class="external text">"Use forwarders to get data"</a> in this manual.
</li></ul><a name="syslogtcp"></a><h2> <a name="syslogtcp_syslog_-_tcp.2fudp"><span class="mw-headline" id="Syslog_-_TCP.2FUDP"> Syslog - TCP/UDP</span></a></h2>
<p>Splunk Enterprise can listen on a TCP or UDP port for data coming from the syslog service on one or more machines. You can get syslog data from these hosts for easy searching, reporting and alerting.  
</p><p>To get syslog data over TCP or UDP, configure Splunk Enterprise to listen on a network port for incoming syslog data:
</p>
<h3> <a name="syslogtcp_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>Add a network input from the Add Data page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>" in this manual.
</p><p>You can get there through two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Pick  <b>TCP</b> or <b>UDP</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home.
</p><p>'<i>2.<b> Click </b>Monitor<b> to monitor a network port on the local machine, or </b></i><b>"Forward</b> to receive network data from another machine.
</p><p><b>Note:</b> Forwarding a file requires additional setup. 
</p><p><b>3.</b> If you selected <b>Forward</b>, choose or create the group of forwarders you want this input to apply to. See "<a href="#forwarddata" class="external text">Forward data</a>" in this manual.
</p><p>'<i>4.<b> Click the green </b></i><b>"Next</b> button.
</p>
<h4><font size="3"><b><i> <a name="syslogtcp_b._specify_the_network_input"><span class="mw-headline" id="B._Specify_the_network_input"> B. Specify the network input </span></a></i></b></font></h4>
<p><b>1.</b> In the left pane, click on <b>TCP / UDP</b> to add an input.
</p><p><b>2.</b> To choose between a TCP or UDP input, click either the <b>TCP</b> or <b>UDP</b> button.
</p><p><b>2.</b> In the <b>Port</b> field, enter a port number. 
</p><p><b>Note:</b> The user you run Splunk Enterprise as must have access to the port. On a stock Unix system, you must run Splunk Enterprise as root to listen on a port below 1024.
</p><p><b>3.</b> In the <b>Source name override</b> field, enter a new source name to override the default source value, if necessary. 
</p><p><b>Important:</b> Consult Splunk Support before changing this value.
</p><p><b>4.</b> If this is a TCP input, you can specify whether this port should accept connections from all hosts or one host in the <b>Only accept connections from</b> field. 
</p>
<ul><li> If you only want the input to accept connections from one host, enter the host name or IP address of the host. You can use wildcards to specify hosts.
</li></ul><p><b>5.</b> Click <b>Next</b> to continue to the <b>Input Settings</b> page.
</p>
<h4><font size="3"><b><i> <a name="syslogtcp_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></i></b></font></h4>
<p>The <b>Input Settings</b> page lets you specify source type, application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b>  Set the <b>Source type</b>. This is a default field added to events. Splunk Enterprise uses the source type to determine processing characteristics, such as timestamps and event boundaries. For information on overriding Splunk's automatic source typing, see <a href="#bypassautomaticsourcetypeassignment" class="external text">"Override automatic source type assignment"</a> in this manual.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting:
</p>
<ul><li> <b>IP.</b> Sets the input processor to rewrite the host with the IP address of the remote server.
</li></ul><ul><li> <b>DNS.</b> Sets the host to the DNS entry of the remote server.
</li></ul><ul><li> <b>Custom.</b> Sets the host to a user-defined label.
</li></ul><p>Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to for this input. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h4><font size="3"><b><i> <a name="syslogtcp_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></i></b></font></h4>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the gray <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified network input.
</p><p>For more information on getting data from the network, see <a href="#monitornetworkports" class="external text">"Get data from TCP and UDP ports"</a> in this manual.
</p>
<a name="windowseventlogslocal"></a><h2> <a name="windowseventlogslocal_windows_event_logs_-_local"><span class="mw-headline" id="Windows_event_logs_-_local"> Windows event logs - local</span></a></h2>
<p>Splunk Enterprise can collect local Windows event logs.  You can use this input to alert on security or search for specific event iDs to determine the health of your Windows systems.
</p><p>To get local Windows event log data, point Splunk at your Event Log service:
</p>
<h3> <a name="windowseventlogslocal_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add a Windows event log input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>" in this manual.
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Local event log collection</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor Event Log data on the local Windows machine, or <b>Forward</b> to forward Event Log data from another Windows machine. Splunk Enterprise loads the "Add Data - Select Source" page.
</p><p><b>3.</b> If you selected <b>Forward</b>, choose or create the group of forwarders you want this input to apply to. See "<a href="#forwarddata" class="external text">Forward data</a>" in this manual.
</p><p><b>4.</b> Click the green <b>Next</b> button.
</p>
<h3> <a name="windowseventlogslocal_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the left pane, locate and select <b>Local Event Logs</b>
</p><p><b>2.</b> In the <b>Select Event Logs</b> list box, locate the Event Log channels you want this input to monitor.
</p><p><b>3.</b> Click once on each Event Log channel you want to monitor. Splunk Enterprise moves the channel from the "Available items" window to the "Selected items" window.
</p><p><b>4.</b> To unselect a channel, click on its name in the "Available Items" window. Splunk Enterprise moves the channel from the "Selected items" window to the "Available items" window.
</p><p><b>5.</b> To select or unselect all of the event logs, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the channels can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>6.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="windowseventlogslocal_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowseventlogslocal_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified Event Log channels.
</p><p>For more information on getting Windows Event Log data, see <a href="#monitorwindowsdata" class="external text">"Monitor Windows event log data"</a> in the Getting Data In manual.
</p>
<a name="windowseventlogsremote"></a><h2> <a name="windowseventlogsremote_windows_event_logs_-_remote"><span class="mw-headline" id="Windows_event_logs_-_remote"> Windows event logs - remote </span></a></h2>
<p>Splunk Enterprise can monitor Windows event logs, both locally and remotely over WMI. You can use this input to alert on security or search for specific event iDs to determine the health of your Windows systems.
</p><p><b>Important:</b> To collect Windows event logs remotely, your Splunk instance must be installed as a user with appropriate permissions to access remote Windows machines. See "<a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">Considerations for deciding how to monitor remote Windows data</a>" in this manual.
</p><p>To get remote Windows event log data, point Splunk Enterprise at a remote Windows machine:
</p>
<h3> <a name="windowseventlogsremote_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. See <b><a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>" in this manual.</b>
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Remote event log collection</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor Event Log data on a remote Windows machine.
</p>
<h3> <a name="windowseventlogsremote_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the left pane, locate and select <b>Remote Event Logs</b>.
</p><p><b>2.</b> In the <b>Event Log collection name</b> field, enter a unique name for this input that you will remember.
</p><p><b>3.</b> In the <b>Choose logs from this host</b> field, enter the host name or IP address of the machine that contains the Event Log channels you want to monitor. 
</p><p><b>4.</b>  Click the <b>Find logs</b> button to refresh the page with a list of available Event Log channels on the server you entered. 
</p><p><b>5.</b> Click once on each Event Log channel you want to monitor. Splunk Enterprise moves the channel from the "Available items" window to the "Selected items" window.
</p><p><b>6.</b> To unselect a channel, click on its name in the "Available Items" window. Splunk Enterprise moves the channel from the "Selected items" window to the "Available items" window.
</p><p><b>7.</b> To select or unselect all of the event logs, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the channels can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>8.</b> In the <b>Collect the same set of logs from additional hosts</b> field, enter host names or IP addresses of additional machines that contain the Event Logs you selected previously. Separate multiple hosts with commas.
</p><p><b>9.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="windowseventlogsremote_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowseventlogsremote_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified Event Log channels.
</p><p>For more information on getting data from Windows event logs, see <a href="#monitorwindowsdata" class="external text">"Monitor Windows event log data"</a> in this manual.
</p>
<a name="windowsregistrylocal"></a><h2> <a name="windowsregistrylocal_windows_registry_-_local"><span class="mw-headline" id="Windows_registry_-_local"> Windows registry - local </span></a></h2>
<p>You can monitor changes to the Registry on Windows machines with Splunk Enterprise. Whether you want to monitor an entire hive or just one key, regardless of activity - the Splunk Enterprise Registry monitoring service can collect that data and let you search, report, and alert on it.
</p><p>To get local Windows Registry change data, connect Splunk Enterprise to the Registry:
</p>
<h3> <a name="windowsregistrylocal_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>"
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Registry monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor Registry data on the local Windows machine.
</p>
<h3> <a name="windowsregistrylocal_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the left pane, locate and select <b>Registry monitoring</b>.
</p><p><b>2.</b> In the <b>Collection Name</b> field, enter a unique name for the input that you will remember.
</p><p><b>3.</b> In the <b>Registry hive</b> field, enter the path to the Registry key that you want Splunk Enterprise to monitor.
</p><p><b>4.</b> If you are not sure of the path, click the <b>Browse</b> button to select the Registry key path that you want Splunk Enterprise to monitor. 
</p><p>The <b>Registry hive</b> window opens and displays the Registry in tree view. Hives, keys and subkeys are represented by folders, and values are represented by document icons.
</p><p><b>Note:</b> The <code><font size="2">HKEY_USERS, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE,</font></code> and <code><font size="2">HKEY_CURRENT_CONFIG</font></code> hives are displayed as top-level objects. The <code><font size="2">HKEY_CLASSES_ROOT</font></code> hive is not shown, due to the number of subkeys present in the first sublevel of that hive. To access <code><font size="2">HKEY_CLASSES_ROOT</font></code> items, choose <code><font size="2">HKEY_LOCAL_MACHINE\Software\Classes</font></code>.
</p><p><b>5.</b> In the <b>Registry hive</b> window, choose the desired Registry key by clicking on the name of the key. 
</p><p>The key's qualified name appears in the <b>Qualified name</b> field at the bottom of the window. 
</p><p><b>6.</b> Click <b>Select</b> to confirm the choice and close the window.
</p><p><b>7.</b> Select <b>Monitor subnodes</b> if you want Splunk Enterprise to monitor the child nodes below the starting hive.
</p><p><b>Note:</b> The <b>Monitor subnodes</b> node determines what Splunk Enterprise adds to the <code><font size="2">inputs.conf</font></code> file that it creates when you define a Registry monitor input in Splunk Web. 
</p><p>If you use the tree view to select a key or hive to monitor and check <b>Monitor subnodes</b>, then Splunk Enterprise adds a <b>regular expression</b> to the stanza for the input you are defining. This regular expression (<code><font size="2">\\\\?.*</font></code>) filters out events that do not directly reference the selected key or any of its subkeys. 
</p><p>If you do not check <b>Monitor subnodes</b>, then Splunk Enterprise adds a regular expression to the input stanza which filters out events that do not directly reference the selected key (including events that reference subkeys of the selected key.)
</p><p>If you do not use the tree view to specify the desired key to monitor, then Splunk Enterprise adds the regular expression only if you have checked <b>Monitor subnodes</b> and have not entered your own regular expression in the <b>Registry hive</b> field.
</p><p><b>8.</b> Under <b>Event types,</b> select the Registry event types that you want Splunk Enterprise to monitor for the chosen Registry hive:
</p>
<table border="1" cellpadding="5" cellspacing="0"><tr bgcolor="#D9EAED"><th bgcolor="#C0C0C0"> Event Type
</th><th bgcolor="#C0C0C0"> Description
</th></tr><tr><td valign="center" align="left"> <b>Set</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Set event when a program executes a SetValue method on a Registry subkey, thus setting a value or overwriting an existing value on an existing Registry entry.
</td></tr><tr><td valign="center" align="left"> <b>Create</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Create event when a program executes a CreateSubKey method within a Registry hive, thus creating a new subkey within an existing Registry hive.
</td></tr><tr><td valign="center" align="left"> <b>Delete</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Delete event when a program executes a DeleteValue or DeleteSubKey method. This method either removes a value for a specific existing key, or removes a key from an existing hive.
</td></tr><tr><td valign="center" align="left"> <b>Rename</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Rename event when you rename a Registry key or subkey in RegEdit.
</td></tr><tr><td valign="center" align="left"> <b>Open</b>
</td><td valign="center" align="left"> Splunk Enterprise generates an Open event when a program executes an OpenSubKey method on a Registry subkey, such as what happens when a program needs configuration information contained in the Registry.
</td></tr><tr><td valign="center" align="left"> <b>Close</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Close event when a program executes a Close method on a Registry key. This happens when a program is done reading the contents of a key, or after you make a change to a key's value in RegEdit and exit the value entry window.
</td></tr><tr><td valign="center" align="left"> <b>Query</b>
</td><td valign="center" align="left"> Splunk Enterprise generates a Query event when a program executes the GetValue method on a Registry subkey.
</td></tr></table><p><b>9.</b> Tell Splunk which processes Splunk Enterprise should monitor for changes to the Registry by entering appropriate values in the <b>Process Path</b> field. Or, leave the default of <code><font size="2">C:\.*</font></code> to monitor all processes.
</p><p><b>10.</b> Tell Splunk Enterprise whether or not you want to take a baseline snapshot of the whole Registry before monitoring Registry changes. To set a baseline, click <b>Yes</b> under <b>Baseline index.</b>
</p><p><b>Note:</b> The baseline snapshot is an index of your entire Registry, at the time the snapshot is taken. Scanning the Registry to set a baseline index is a CPU-intensive process and may take some time.
</p><p><b>11.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="windowsregistrylocal_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowsregistrylocal_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified Registry nodes.
</p><p><b>Caution:</b> When the Registry monitor runs, do not stop or kill the <code><font size="2">splunk-regmon.exe</font></code> process manually. Doing so can result in system instability. To stop the Registry monitor, stop the <code><font size="2">splunkd</font></code> server process from either the Services control panel or the CLI.
</p>
<a name="windowsperformancelocal"></a><h2> <a name="windowsperformancelocal_windows_performance_monitoring_-_local"><span class="mw-headline" id="Windows_performance_monitoring_-_local"> Windows performance monitoring - local </span></a></h2>
<p>Whether you want to watch disk I/O, memory metrics such as free pages or commit charge, or network statistics, Splunk Enterprise is a capable alternative to Windows Performance Monitor.
</p><p>To collect performance metrics with Splunk Enterprise:
</p>
<h3> <a name="windowsperformancelocal_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>" in this manual.
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Local performance monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p>'<i>2.<b> Click </b>Monitor<b> to monitor performance data from the local Windows machine, or </b></i><b>"Forward</b> to receive performance data from another machine.
</p><p><b>3.</b> If you selected <b>Forward</b>, choose or create the group of forwarders you want this input to apply to. See "<a href="#forwarddata" class="external text">Forward data</a>" in this manual.
</p><p><b>4.</b> Click the green <b>Next</b> button.
</p>
<h3> <a name="windowsperformancelocal_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the left pane, locate and select <b>Local Performance Monitoring</b>.
</p><p><b>2.</b> In the <b>Collection Name</b> field, enter a unique name for this input that you will remember.
</p><p><b>3.</b> Click the <b>Select Object</b> button to get a list of the performance objects available on this Windows machine, then choose the object that you want to monitor from the list. Splunk Enterprise displays the "Select Counters" and "Select Instances" list boxes.
</p><p><b>Note:</b> You can only add one performance object per data input. This is due to how Microsoft handles performance monitor objects. Many objects enumerate classes that describe themselves dynamically upon selection. This can lead to confusion as to which performance counters and instances belong to which object, as defined in the input. If you need to monitor multiple objects, create additional data inputs for each object.
</p><p><b>4.</b> In the <b>Select Counters</b> list box, locate the performance counters you want this input to monitor.
</p><p><b>5.</b> Click once on each counter you want to monitor. Splunk Enterprise moves the counter from the "Available counter(s)" window to the "Selected counter(s)" window.
</p><p><b>6.</b> To unselect a counter, click on its name in the "Available Items" window. Splunk Enterprise moves the counter from the "Selected counter(s)" window to the "Available counter(s)" window.
</p><p><b>7.</b> To select or unselect all of the counters, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the counters can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>8.</b> In the <b>Select Instances</b> list box, select the instances that you want this input to monitor by clicking once on the instance in the "Available instance(s)" window. Splunk Enterprise moves the instance to the "Selected instance(s)" window.
</p><p><b>Note:</b> The "_Total" instance is a special instance, and is present for many types of performance counters. This instance is the average of any associated instances under the same counter. Data collected for this instance can be significantly different than for individual instances under the same counter.
</p><p>For example, when monitoring performance data for the "Disk Bytes/Sec" performance counter under the "PhysicalDisk" object on a system with two disks installed, the available instances displayed include one for each physical disk - "0 C:" and "1 D:" - as well as the "_Total" instance. In this case, the "_Total" instance is the average of the two physical disk instances.
</p><p><b>9.</b> In the <b>Polling interval</b> field, enter the time, in seconds, between polling attempts for the input.
</p><p><b>10.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="windowsperformancelocal_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowsperformancelocal_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified performance metrics.
For more information on getting data from files and directories, see <a href="#real-timewindowsperformancemonitoring" class="external text">"Real-time Windows performance monitoring"</a> in this manual.
</p>
<a name="windowsperformanceremote"></a><h2> <a name="windowsperformanceremote_windows_performance_monitoring_-_remote"><span class="mw-headline" id="Windows_performance_monitoring_-_remote"> Windows performance monitoring - remote </span></a></h2>
<p>Whether you want to watch disk I/O, memory metrics such as free pages or commit charge, or network statistics, Splunk Enterprise is a capable alternative to Windows Performance Monitor.
</p><p>To collect performance metrics remotely with Splunk Enterprise:
</p>
<h3> <a name="windowsperformanceremote_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. 
You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p>It doesn't matter which route you use; the Add New page itself is the same either way.
</p><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Remote performance monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor performance data from the local Windows machine, or <b>Forward</b> to forward performance data from another Windows machine. Splunk Enterprise loads the "Add Data - Select Source" page.
</p><p><b>Note:</b> Forwarding performance data requires additional setup.
</p><p><b>3.</b> In the left pane, locate and select <b>Local Performance Monitoring</b>.
</p>
<h3> <a name="windowsperformanceremote_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the <b>Collection Name</b> field, enter a unique name for this input that you will remember.
</p><p><b>2.</b> In the <b>Select Target Host</b> field, enter the host name or IP address of the Windows computer you want to collect performance data from. 
</p><p><b>3.</b> Click the "Query" button to get a list of the performance objects available on the Windows machine you specified in the "Select Target Host" field.
</p><p><b>Note:</b> <code><font size="2">Win32_PerfFormattedData_*</font></code> classes do not show up as available objects in Splunk Web. If you wish to monitor <code><font size="2">Win32_PerfFormattedData_*</font></code> classes, you must <a href="#real-timewindowsperformancemonitoring_configure_remote_windows_performance_monitoring_with_configuration_files" class="external text">add them directly</a> in <code><font size="2">wmi.conf</font></code>.
</p><p><b>4.</b> Choose the object that you want to monitor from the <b>Select Class</b> list. Splunk Enterprise displays the "Select Counters" and "Select Instances" list boxes.
</p><p><b>Note:</b> You can only add one performance object per data input. This is due to how Microsoft handles performance monitor objects. Many objects enumerate classes that describe themselves dynamically upon selection. This can lead to confusion as to which performance counters and instances belong to which object, as defined in the input. If you need to monitor multiple objects, create additional data inputs for each object.
</p><p><b>5.</b> In the <b>Select Counters</b> list box, locate the performance counters you want this input to monitor.
</p><p><b>6.</b> Click once on each counter you want to monitor. Splunk Enterprise moves the counter from the "Available counter(s)" window to the "Selected counter(s)" window.
</p><p><b>7.</b> To unselect a counter, click on its name in the "Available Items" window. Splunk Enterprise moves the counter from the "Selected counter(s)" window to the "Available counter(s)" window.
</p><p><b>8.</b> To select or unselect all of the counters, click on the "add all" or "remove all" links. <b>Important:</b> Selecting all of the counters can result in the indexing of a lot of data, possibly more than your license allows.
</p><p><b>9.</b> In the <b>Select Instances</b> list box, select the instances that you want this input to monitor by clicking once on the instance in the "Available instance(s)" window. Splunk Enterprise moves the instance to the "Selected instance(s)" window.
</p><p><b>Note:</b> The "_Total" instance is a special instance, and is present for many types of performance counters. This instance is the average of any associated instances under the same counter. Data collected for this instance can be significantly different than for individual instances under the same counter.
</p><p>For example, when monitoring performance data for the "Disk Bytes/Sec" performance counter under the "PhysicalDisk" object on a system with two disks installed, the available instances displayed include one for each physical disk - "0 C:" and "1 D:" - as well as the "_Total" instance. In this case, the "_Total" instance is the average of the two physical disk instances.
</p><p><b>10.</b> In the <b>Polling interval</b> field, enter the time, in seconds, between polling attempts for the input.
</p><p><b>11.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="windowsperformanceremote_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowsperformanceremote_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified performance metrics.
</p><p>For more information on getting performance monitor data from remote machines, see <a href="#monitorwmidata" class="external text">"Monitor WMI data"</a> in the Getting Data In manual.
</p>
<a name="windowsactivedirectory"></a><h2> <a name="windowsactivedirectory_windows_active_directory"><span class="mw-headline" id="Windows_Active_Directory"> Windows Active Directory </span></a></h2>
<p>You can collect any kind of Active Directory change data with Splunk. 
</p><p>Do you want or need to know who's been changing passwords, adding user or machine accounts, or delegating authority to Group Policy objects?  All of that information is at your fingertips with Splunk's Active Directory monitor.  What's more, you can choose which part of the AD you want to scan for changes - from one node to the entire AD forest.
</p><p><b>Note:</b> In order to monitor any part of Active Directory, you must <a href="#considerationsfordecidinghowtomonitorwindowsdata" class="external text">run Splunk as a user</a> with read permissions to the Active Directory schema.
</p><p>To get Active Directory data, introduce Splunk Enterprise to your Active Directory:
</p>
<h3> <a name="windowsactivedirectory_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. See "<a href="#howdoyouwanttoadddata" class="external text">How do you want to add data?</a>" in this manual.
</p><p>You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3.</b> Click <b>Active Directory monitoring</b>.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor Active Directory on the local Windows machine.
</p>
<h3> <a name="windowsactivedirectory_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the left pane, locate and select <b>Active Directory monitoring</b>.
</p><p><b>2.</b> In the <b>Collection name</b> field, type in a unique name for the input that you will remember.
</p><p><b>3.</b> Optionally, in the <b>Target domain controller</b> field, enter the host name or IP address of the domain controller you want to use to monitor AD.
</p><p><b>4.</b> Optionally, in the <b>Starting node</b> field, type in the Active Directory node you would like the input to begin monitoring from. You must specify the Lightweight Directory Access Protocol format, for example, <code><font size="2">DC=Splunk-Docs,DC=com</font></code>.
</p><p>You can click the <b>Browse</b> button to browse through a list of available Active Directory nodes to browse through a list of available AD domains.
</p><p><b>5.</b> Check the 'Monitor Subtree' button if you want Splunk Enterprise to monitor all sub-nodes of the node you entered in the "Starting node" field.
</p><p><b>6.</b> Click the green <b>Next</b> button.
</p>
<h3> <a name="windowsactivedirectory_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>2.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>3.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>4.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="windowsactivedirectory_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified Active Directory node.
</p><p>For more information on monitoring Active Directory, see <a href="#auditactivedirectory" class="external text">"Monitor Active Directory"</a> in this manual.
</p>
<a name="scripts"></a><h2> <a name="scripts_scripts"><span class="mw-headline" id="Scripts"> Scripts</span></a></h2>
<p>To add scripted inputs:
</p>
<h3> <a name="scripts_a._go_to_the_add_new_page"><span class="mw-headline" id="A._Go_to_the_Add_New_page"> A. Go to the Add New page </span></a></h3>
<p>You add an input from the Add New page in Splunk Web. 
You can get there by two routes:
</p>
<ul><li> Splunk Home
</li><li> Splunk Settings
</li></ul><p><b>Via Splunk Settings:</b> 
</p><p><b>1.</b> Click <b>Settings</b> in the upper right-hand corner of Splunk Web.
</p><p><b>2.</b> In the Data section of the Settings pop-up, click <b>Data Inputs</b>.  
</p><p><b>3a.</b> Click <b>Scripts</b> to collect data from a script on the local machine. Or,
</p><p><b>3b.</b> Click <b>Scripts</b> under <b>Forwarded Data</b> to get data from a script running on a remote machine.
</p><p><b>4.</b> Click the <b>New</b> button to add an input. 
</p><p><b>Via Splunk Home:</b>
</p><p><b>1.</b> Click the <b>Add Data</b> link in Splunk Home. 
</p><p><b>2.</b> Click <b>Monitor</b> to monitor a script on the local machine, or <b>Forward</b> to forward data from a script on a remote machine. Splunk Enterprise loads the "Add Data - Select Source" page.
</p><p><b>Note:</b> Forwarding data from scripted inputs requires additional setup.
</p><p><b>3.</b> In the left pane, locate and select <b>Scripts</b>.
</p>
<h3> <a name="scripts_b._select_the_input_source"><span class="mw-headline" id="B._Select_the_input_source"> B. Select the input source </span></a></h3>
<p><b>1.</b> In the <b>Script Path</b> drop down, select the path where the script resides. Splunk Enterprise updates the page to include a new drop down, "Script Name."
</p><p><b>2.</b> In the <b>Script Name</b> drop-down, select the script that you want to run. Splunk Enterprise updates the page to populate the "Command" field with the script name.
</p><p><b>Note:</b> If you do not see the script you want, then you must use your operating system file management tools to put it there.
</p><p><b>3.</b> In the <b>Command</b> field, add any arguments needed to invoke the script.
</p><p><b>4.</b> In the <b>Interval</b> field, enter the amount of time (in seconds) that Splunk Enterprise should wait before invoking the script.
</p><p><b>5.</b> Optionally, In the <b>Source Name Override</b> field, enter a new source name to override the default source value, if necessary.
</p><p><b>6.</b> Click the green <b>Next</b> button. 
</p>
<h3> <a name="scripts_c._specify_input_settings"><span class="mw-headline" id="C._Specify_input_settings"> C. Specify input settings </span></a></h3>
<p>The <b>Input Settings</b> page lets you specify application context, default host value, and index. All of these parameters are optional.
</p><p><b>1.</b> Select the source type for the script. You can choose <b>Select</b> to pick from the list of available source types on the local machine, or "Manual" to enter the name of a source type.
</p><p><b>2.</b> Select the appropriate <b>Application context</b> for this input.
</p><p><b>3.</b> Set the <b>Host</b> name value. You have several choices for this setting. Learn more about setting the host value in <a href="#abouthosts" class="external text">"About hosts"</a>.
</p>
<dl><dd><b>Note:</b> <b>Host</b> only sets the <b>host</b> field in the resulting events. It does not direct Splunk Enterprise to look on a specific host on your network.
</dd></dl><p><b>4.</b> Set the <b>Index</b> that Splunk Enterprise should send data to. Leave the value as "default", unless you have defined multiple indexes to handle different types of events. In addition to indexes for user data, Splunk Enterprise has a number of utility indexes, which also appear in this dropdown box. 
</p><p><b>5.</b> Click the green <b>Review</b> button.
</p>
<h3> <a name="scripts_d._review_your_choices"><span class="mw-headline" id="D._Review_your_choices"> D. Review your choices </span></a></h3>
<p>After specifying all your input settings, you can review your selections. Splunk Enterprise lists all options you selected, including but not limited to the type of monitor, the source, the source type, the application context, and the index. 
</p><p>Review the settings. If they do not match what you want, click the white <b>&lt;</b> button to go back to the previous step in the wizard. Otherwise, click the green <b>Submit</b> button.
</p><p>Splunk Enterprise then loads the "Success" page and begins indexing the specified Active Directory node.
</p></div>
</body><script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>

        <script src="js/index.js"></script></html>
