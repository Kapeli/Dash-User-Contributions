<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:og="http://ogp.me/ns#" xmlns:fb="http://ogp.me/ns/fb#" charset="utf-8"><head><meta charset="UTF-8"><title></title>
<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" type="text/css" href="css/main.css">
<link rel="stylesheet" href="css/style.css">
<style>
html,body {
margin: 0px;
padding: 10px;
width: 210mm;
max-width: 210mm;
overflow-x: hidden;
}
pre {
	width: 100%;
	overflow-x: hidden;
}
</style></head><body><h1>Introduction</h1><a name="whatsinthismanual"></a><div class="all-questions"><h2> <a name="whatsinthismanual_welcome_to_the_search_manual"><span class="mw-headline" id="Welcome_to_the_Search_Manual"> Welcome to the Search Manual </span></a></h2>
<p>This manual discusses <b>Splunk Search</b> and how to use the <b>Splunk Enterprise search processing language</b>.
</p><p>If you are new to Splunk Enterprise and search, start with the "Search Tutorial". The Search Tutorial introduces you to the Search and Reporting app and takes you through adding data, searching your data, and building simple reports and dashboards.
</p><p>Before you can start using Splunk search,
</p>
<ul><li> Add data to your Splunk instance. See how to get data into Splunk in the "Getting Data In Manual".
</li><li> Understand how indexing works in Splunk Enterprise. See how Splunk processes data in the "Managing Indexers Manual".
</li><li> Understand fields and knowledge objects, such as host, source type, and event type. See the "Knowledge Manager Manual".
</li></ul><p>For the catalog of search commands and arguments that make up the Splunk Enterprise search processing language, see the Search Reference Manual.
</p><p><b>Distributed search</b> provides a way to scale your deployment by separating the search management and presentation layer from the indexing and search retrieval layer. For an introduction to distributed search, see "Distributed Search Manual".
</p>
<h4><font size="3"><b><i> <a name="whatsinthismanual_make_a_pdf"><span class="mw-headline" id="Make_a_PDF">Make a PDF</span></a></i></b></font></h4>
<p>For a PDF version of this manual, click the red <b>Download the Search Manual as PDF</b> link below the table of contents on the left side of this page. A PDF version of the manual is generated on the fly for you, and you can save it or print it out to read later.
</p>
<h1>Using Splunk Search</h1><a name="whatsinsplunksearch"></a><h2> <a name="whatsinsplunksearch_what.27s_in_splunk_search"><span class="mw-headline" id="What.27s_in_Splunk_Search"> What's in Splunk Search</span></a></h2>
<p>This topic discusses the Search views that are part of the Splunk <b>Search &amp; Reporting</b> app, which is the interface you use to interact with your data. 
</p><p>The unified search and reporting experience also makes it easier for you to author and edit your reports. You can read more about creating and editing reports in the Reporting Manual.
</p>
<h3> <a name="whatsinsplunksearch_the_search_dashboard"><span class="mw-headline" id="The_Search_dashboard"> The Search dashboard </span></a></h3>
<p>Before you run a search, the Search dashboard will include: 
</p>
<ul><li> <b>The search bar.</b> Use the search bar to run your searches in Splunk Web. Just type in your search string and hit enter or click the spyglass icon to the right of the time range picker.
</li><li> <b>The time range picker.</b> Use the time range picker to specify the time period over which to retrieve events. The time range picker has many preset time ranges that you can select from, but you can also enter a custom time range. 
</li><li> <b>How to search.</b> This panel links you to the Search Tutorial and Search Manual to help you learn about searches.
</li><li> <b>What to search.</b> This panel displays a summary of the data that is installed on this Splunk instance and that you are authorized to view. If you click on the <b>Data Summary</b> button, a window opens with tabs for the Hosts, Sources, Sourcetypes in your data.
</li></ul><h3> <a name="whatsinsplunksearch_the_new_search_dashboard"><span class="mw-headline" id="The_New_Search_dashboard"> The New Search dashboard </span></a></h3>
<p>Running a new search takes you to the <b>New Search</b> dashboard. In this view, the search bar and time range picker are also available. The dashboard updates with many more elements such as search action buttons, a search mode selector, counts of events, a job status bar, and results tabs for Events, Patterns, Statistics, and Visualizations.
</p><p>Read more about the elements of the New Search dashboard in the following topics.
</p>
<ul><li> <a href="#performsearchactions" class="external text">Perform actions on running searches</a>
</li><li> <a href="#changethesearchmode" class="external text">Set search mode to adjust your search experience</a>
</li></ul><a name="performsearchactions"></a><h2> <a name="performsearchactions_perform_actions_on_running_searches"><span class="mw-headline" id="Perform_actions_on_running_searches"> Perform actions on running searches </span></a></h2>
<p>Splunk provides a set of controls that you can use to manage "in process" searches and create reports and dashboards. 
</p>
<h3> <a name="performsearchactions_control_search_job_progress"><span class="mw-headline" id="Control_search_job_progress"> Control search job progress </span></a></h3>
<p>After you launch a search, you can access and manage information about the search's  <b>job</b> without leaving the Search page. Once your search is running, paused, or finalized, click <b>Job</b> and choose from the available options there. 
</p><p><img alt="6.2 searchjob options.png" src="images/d/d6/6.2_searchjob_options.png" width="400" height="141"></p><p>You can:
</p>
<ul><li> <b>Edit the job settings.</b> Select this to open the Job Settings dialog, where you can change the job's read permissions, extend the job's lifespan, and get a URL for the job that you can use to share the job with others or put a link to the job in your browser's bookmark bar. 
</li><li> <b>Send the job to the background.</b> Select this if the search job is slow to complete and you would like to run the job in the background while you work on other Splunk activities (including running a new search job). 
</li><li> <b>Inspect the job.</b> Opens a separate window and display information and metrics for the search job via the <b>Search Job Inspector</b>. You can select this action while the search is running or after it completes. For more information, see "View search job properties with the Search Job Inspector" in the Knowledge Manager Manual.
</li><li> <b>Delete the job.</b> Use this to delete a job that is currently running, is paused, or which has finalized. After you have deleted the job you can still save the search as a report.
</li></ul><p>For more information, see "About jobs and job management" in the Knowledge Manager Manual.
</p>
<h3> <a name="performsearchactions_change_the_search_mode"><span class="mw-headline" id="Change_the_search_mode"> Change the search mode </span></a></h3>
<p>The Search mode controls the search experience. You can set it to speed up searches by cutting down on the event data it returns (<i>Fast</i> mode), or you can set it to return as much event information as possible (<i>Verbose</i> mode). In <i>Smart</i> mode (the default setting) it automatically toggles search behavior based on the type of search you're running. 
</p><p><img alt="6.2 searchmode options.png" src="images/9/99/6.2_searchmode_options.png" width="300" height="190"></p><p><br>
This is discussed in more detail in the next topic,  <a href="#changethesearchmode" class="external text">"Set search mode to adjust your search experience"</a>.
</p>
<h3> <a name="performsearchactions_save_the_results"><span class="mw-headline" id="Save_the_results"> Save the results </span></a></h3>
<p>The <b>Save as</b> menu lists options for saving the results of a search as a <b>Report</b>, <b>Dashboard Panel</b>, <b>Alert</b>, and <b>Event type</b>.
</p><p><img alt="6.2 saveas option.png" src="images/8/8a/6.2_saveas_option.png" width="191" height="158"></p><p><br></p>
<ul><li> <b>Report</b>: Save a search as a <b>report</b> to use it again later. You can run the report again on an ad hoc basis by finding the report on the Reports listing page and clicking its name. Read more about how to "Create and edit reports" in the <i>Reporting Manual</i>.
</li><li> <b>Dashboard Panel:</b> Use this option to generate a dashboard <b>panel</b> based on your search and add it to a new or existing <b>dashboard</b>. Learn more about dashboards in "Dashboards and Forms" and "About the Dashboard Editor." Both topics are in the <i>Dashboards and Visualizations</i> manual.
</li><li> <b>Alert:</b> Define an <b>alert</b> based on your search. Alerts run saved searches in the background (either on a <b>schedule</b> or in <b>real time</b>). When the search returns results that meet a condition you have set in the alert definition, the alert is triggered. For more information, see  "About alerts" in the <i>Alerting Manual</i>.
</li><li> <b>Event Type:</b> Classify events that have common characteristics. If the search does not include a <b>pipe operator</b> or a <b>subsearch</b> , you can use this to save it as an event type. For more information, see "About event types" and "Define and maintain event types in Splunk Web" in the <i>Knowledge Manager</i> manual.
</li></ul><h3> <a name="performsearchactions_other_search_actions"><span class="mw-headline" id="Other_search_actions"> Other search actions </span></a></h3>
<p>Between the job progress controls and search mode selector are three buttons which enable you to <b>Share</b>, <b>Export</b>, and <b>Print</b> the results of a search.
</p>
<ul><li> Click <b>Share</b> to share the job. When you select this, the job's lifetime is extended to 7 days and read permissions are set to Everyone.
</li><li> Click <b>Export</b> to export the results. You can select to output to CSV, raw events, XML, or JSON and specify the number of results to export.
</li><li> Click <b>Print</b> to send the results to a printer that has been configured.
</li></ul><p>Additionally, use the <b>Close</b> button next to <b>Save as</b> menu to cancel the search and return to Splunk Home.
</p>
<a name="changethesearchmode"></a><h2> <a name="changethesearchmode_set_search_mode_to_adjust_your_search_experience"><span class="mw-headline" id="Set_search_mode_to_adjust_your_search_experience"> Set search mode to adjust your search experience </span></a></h2>
<p>You can use the search mode selector to provide a search experience that fits your needs.  
</p><p>The search mode selector is at the upper right-hand corner of the search bar. The available modes are <i>Smart</i> (default), <i>Fast,</i> and <i>Verbose:</i>
</p><p><img alt="6.2 searchmode options.png" src="images/9/99/6.2_searchmode_options.png" width="300" height="190"></p><p>Depending on how you set it you can see all the data available for your search (at the expense of longer search times), or you can speed up and streamline your search in certain ways.
</p><p>The <b>Fast</b> and <b>Verbose</b> modes represent the two ends of the search mode spectrum. The default <b>Smart</b> mode switches between them depending on the type of search that you are running. Whenever you first run a saved search, it will run in <b>Smart</b> mode.
</p>
<h3> <a name="changethesearchmode_selecting_the_fast_mode"><span class="mw-headline" id="Selecting_the_Fast_mode">Selecting the Fast mode</span></a></h3>
<p><b>Fast</b> mode prioritizes the performance of the search and does not return nonessential field or event data. This means that the search returns what is essential and required. 
</p>
<ul><li> <b>Disables field discovery.</b> <b>Field discovery</b> is the process Splunk uses to extract fields aside from <b>default fields</b> such as <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>. This means that Splunk only returns information on default fields and fields that are required to fulfill your search (if you are searching on certain fields, it will extract those fields). 
</li><li> <b>Only depicts search results as report result tables or visualizations when you run a reporting search</b> (a search that includes <b>transforming commands</b>). Under the <i>Fast</i> mode you'll only see event lists and see event timelines for searches that <i>do not</i> include transforming commands.
</li></ul><p>For more information about what Splunk Enterprise does when field discovery is enabled or disabled, see "When Splunk Enterprise extracts fields" in the <i>Knowledge Manager Manual</i>.
</p>
<h3> <a name="changethesearchmode_selecting_the_verbose_mode"><span class="mw-headline" id="Selecting_the_Verbose_mode">Selecting the Verbose mode</span></a></h3>
<p><b>Verbose</b> mode returns all of field and event data it possibly can, even if it means the search takes longer to complete, and even if the search includes reporting commands. 
</p>
<ul><li> <b>Discovers all of the fields it can.</b> This includes default fields, automatic search-time field extractions, and all user-defined index-time and search-time field extractions. Discovered fields are displayed in the left-hand fields sidebar in the Events results tab. 
</li><li> <b>Returns an event list view of results and generates the search timeline.</b> It also generates report tables and visualizations if your search includes reporting commands.
</li></ul><p>You may want to use the <i>Verbose</i> mode if you're putting together a transforming search but aren't exactly sure what fields you need to report on, or if you need to verify that you are summarizing the correct events.
</p><p><b>Note:</b> Reports cannot benefit from report acceleration when you run them in <i>Verbose</i> mode. If you enable report acceleration for a report and it has been running faster as a result, be aware that if you switch the mode of the search to <i>Verbose</i> it will run at a slower, non-accelerated pace.
</p><p>Report acceleration is designed to be used with slow-completing searches that have over 100k events and which utilize <b>transforming commands</b>.  For more information see "Accelerate reports," in the Reporting Manual.
</p>
<h3> <a name="changethesearchmode_selecting_the_smart_mode"><span class="mw-headline" id="Selecting_the_Smart_mode">Selecting the Smart mode</span></a></h3>
<p>All reports run in <i>Smart</i> mode, the default search mode, after they are first created. By design, <b>Smart</b> mode returns the best results for whatever search or report you run. If you search on events, you get all the event information you need. If your run a transforming search, Splunk Enterprise favors speed over thoroughness and brings you straight to the report result table or visualization.
</p><p>When you run a <i>Smart</i> mode search that <i>does not</i> include transforming commands, the search behaves as if it were in <i>Verbose</i> mode.
</p>
<ul><li> <b>Discovers all the fields it can.</b>
</li><li> <b>Generates the full event list and event timeline.</b> No event table or visualization will appear because you need transforming commands to make those happen.
</li></ul><p>When you run a <i>Smart</i> mode search that <i>includes</i> transforming commands, the search behaves as if it were in <i>Fast</i> mode.
</p>
<ul><li> <b>Disables field discovery.</b>
</li><li> <b>Does not waste time generating the event list and event timeline</b> and jumps you straight to the report result table or visualization. 
</li></ul><p>For more information about transforming commands and transforming searches, see <a href="#aboutreportingcommands" class="external text">"About reporting commands"</a> in the Search Manual.
</p>
<a name="usingthesearchassistant"></a><h2> <a name="usingthesearchassistant_about_the_search_assistant"><span class="mw-headline" id="About_the_search_assistant"> About the search assistant</span></a></h2>
<p>The Splunk Search Processing Language is extensive and includes many search commands, arguments, and functions. You might have a hard time forming a search because you are not familiar with all the commands and you don't know what information has been extracted from your data. 
</p>
<h3> <a name="usingthesearchassistant_use_search_assistant_to_see_your_data_as_you_build_a_search"><span class="mw-headline" id="Use_search_assistant_to_see_your_data_as_you_build_a_search"> Use search assistant to see your data as you build a search </span></a></h3>
<p>When you're building a search, you don't need to know which search commands and arguments you want to use before forming a search because the search assistant will suggest them for you. 
</p><p>Search assistant shows you typeahead, or contextual matches and completions for each keyword as you type it into the search bar. These contextual matches are based on what's in your data. The entries under <b>matching terms</b> update as you continue to type because the possible completions for your term change as well.
</p><p>Search assistant also displays the number of matches for the search term. This number gives you an idea of how many search results Splunk will return. If a term or phrase doesn't exist in your data, you won't see it listed in search assistant.
</p>
<h3> <a name="usingthesearchassistant_change_settings_for_the_search_assistant"><span class="mw-headline" id="Change_settings_for_the_search_assistant"> Change settings for the search assistant </span></a></h3>
<p>The search assistant is a Python endpoint called by the search bar that returns html to display in a panel that slides down from the search bar. The search assistant gets its description and syntax information from <code><font size="2">searchbnf.conf</font></code>, which defines all the Splunk search commands and their syntax. But, it also uses <code><font size="2">fields.conf</font></code> to suggest fields for autocomplete and <code><font size="2">savedsearches.conf</font></code> to inform users when their search is similar to an existing saved search.
</p><p>You can control the behavior of the search assistant with UI settings in the SearchBar module. These settings define whether to open the search assistant by default (<code><font size="2">autoOpenAssistant</font></code>), to use typeahead (<code><font size="2">useTypeahead</font></code>), to show command help (<code><font size="2">showCommandHelp</font></code>), to show search history (<code><font size="2">showCommandHistory</font></code>), and to show field information (<code><font size="2">showFieldInfo</font></code>). For more information about each of these modules, refer to the " Module Reference".
</p>
<h1>Search Overview</h1><a name="aboutsearch"></a><h2> <a name="aboutsearch_about_search"><span class="mw-headline" id="About_search"> About search</span></a></h2>
<p>This chapter discusses search, the structure of a Splunk search, the search language and its syntax, some tools to help construct and troubleshoot your search, and some tips for writing better searches.
</p>
<h3> <a name="aboutsearch_types_of_searches"><span class="mw-headline" id="Types_of_searches"> Types of searches </span></a></h3>
<p>Before delving into the language and syntax of search, you should ask what you are trying to accomplish. Generally, after getting data into Splunk, you want to:
</p>
<ul><li> Investigate to learn more about the data you just indexed or to find the root cause of an issue.
</li><li> Summarize your search results into a report, whether tabular or other visualization format.
</li></ul><p>Because of this, you might hear us refer to two types of searches: Raw event searches and transforming searches. 
</p>
<h4><font size="3"><b><i> <a name="aboutsearch_raw_event_searches"><span class="mw-headline" id="Raw_event_searches"> Raw event searches </span></a></i></b></font></h4>
<p><b>Raw event searches</b> are searches that just retrieve events from an index or indexes and are typically done when you want to analyze a problem. Some examples of these searches include: checking error codes, correlating events, investigating security issues, and analyzing failures. These searches do not usually include search commands (except <code><font size="2">search</font></code>, itself), and the results are typically a list of raw events.
</p>
<ul><li> Read more about raw event searches in the "Retrieve events" chapter of this manual, beginning with <a href="#aboutretrievingevents" class="external text">"About retrieving events"</a>.
</li></ul><h4><font size="3"><b><i> <a name="aboutsearch_transforming_searches"><span class="mw-headline" id="Transforming_searches"> Transforming searches </span></a></i></b></font></h4>
<p><b>Transforming searches</b> are searches that perform some type of statistical calculation against a set of results. These are searches where you first retrieve events from an index and then pass them into one or more search commands. These searches will always require fields and at least one of a set of statistical commands. Some examples include: getting a daily count of error events, counting the number of times a specific user has logged in, or calculating the 95th percentile of field values.
</p>
<ul><li> Read more about what you can do with search commands in <a href="#aboutthesearchlanguage" class="external text">"About the search language"</a>.
</li><li> Read more about the structure of a search in <a href="#aboutsearchlanguagesyntax" class="external text">"About the search processing language syntax"</a>.
</li><li> Read more about using subsearches to filter results in <a href="#aboutsubsearches" class="external text">"About subsearches"</a>.
</li><li> Read more about transforming searches and commands in the "Report on Search Results" chapter of this manual, beginning with <a href="#aboutreportingcommands" class="external text">"About transforming commands and searches"</a>.
</li></ul><h4><font size="3"><b><i> <a name="aboutsearch_information_density"><span class="mw-headline" id="Information_density"> Information density </span></a></i></b></font></h4>
<p>Whether you're retrieving raw events or building a report, you should also consider whether you are running a search for <i>sparse</i> or <i>dense</i> information:
</p>
<ul><li> <b>Sparse searches</b> are searches that look for single event or an event that occurs infrequently within a large set of data. You've probably heard these referred to as 'needle in a haystack' or "rare term" searches. Some examples of these searches include: searching for a specific and unique IP address or error code.
</li><li> <b>Dense searches</b> are searches that scan through and report on many events. Some examples of these searches include: counting the number of errors that occurred or finding all events from a specific host.
</li></ul><h3> <a name="aboutsearch_search_and_knowledge"><span class="mw-headline" id="Search_and_knowledge"> Search and knowledge </span></a></h3>
<p>As you search, you may begin to recognize patterns and identify more information that could be useful as searchable fields. You can configure Splunk to recognize these new fields as you index new data or you can create new fields as you search. Whatever you learn, you can use, add, and edit this knowledge about fields, events, and transactions to your event data. This capturing of knowledge helps you to construct more efficient searches and build more detailed reports.
</p>
<h3> <a name="aboutsearch_search_with_splunk_web.2c_the_cli.2c_or_rest_api"><span class="mw-headline" id="Search_with_Splunk_Web.2C_the_CLI.2C_or_REST_API"> Search with Splunk Web, the CLI, or REST API </span></a></h3>
<p>Most likely, you'll run a search from Splunk Web in the Search app. But, you might also run a search from the command line interface (CLI) or the REST API. Which tool is best can sometimes depend on what you want from your search.
</p><p><b>When you search with Splunk Web,</b> you're using the Search app, and you can control the search experience by selecting a search mode (Fast, Verbose, Smart). Depending on the mode you select, Splunk automatically discovers and extracts fields other than the default fields, returns results as an events list or a table, and runs the calculations required to generate the event timeline. Calculating the event timeline is very expensive because it creates buckets and keeps the statistics for events and fields in a dispatch directory such that it is available when the user clicks a bar on the timeline. 
</p>
<ul><li> Read more about how to <a href="#changethesearchmode" class="external text">"Set search mode to adjust your search experience"</a> in this chapter.
</li></ul><p><b>When you run a search through the CLI or use the search jobs endpoint in the REST API to create a search,</b> it goes directly to <code><font size="2">splunkd</font></code> without going through <code><font size="2">splunkweb</font></code>. These searches can complete much faster than the searches in Splunk Web because Splunk does not calculate or generate the event timeline. Instead, the results of a CLI search display as a raw events list or a table, depending on the type of search.  
</p>
<ul><li> Read more "About CLI searches" in the Search Reference Manual.
</li><li> Read about "Creating searches using the REST API" in the REST API Reference Manual.
</li></ul><a name="aboutthesearchlanguage"></a><h2> <a name="aboutthesearchlanguage_about_the_search_processing_language"><span class="mw-headline" id="About_the_Search_Processing_Language"> About the Search Processing Language </span></a></h2>
<p>When you hear about the <b>Search Processing Language</b> (<b>SPL</b>), you may have heard the terms distributable, streaming, generating, and transforming used to describe the types of search commands. This topic describes what these terms mean and lists the commands that fall into each category.
</p>
<h3> <a name="aboutthesearchlanguage_search_processing_language_components"><span class="mw-headline" id="Search_Processing_Language_components"> Search Processing Language components </span></a></h3>
<p>The Search Processing Language encompasses all the search commands and their functions, arguments and clauses. Search commands tell Splunk Enterprise what to do to the events you retrieved from the indexes. For example, you need to use a command to filter unwanted information, extract more information, evaluate new fields, calculate statistics, reorder your results, or create a chart. 
</p><p>Some search commands have functions and arguments associated with them. Use these functions and their arguments to specify how the commands act on your results and/or which fields they act upon. For example, use functions to format the data in a chart, describe what kind of statistics to calculate, and specify what fields to evaluate. Some commands also use clauses to specify how to group your search results.
</p>
<h3> <a name="aboutthesearchlanguage_types_of_search_commands"><span class="mw-headline" id="Types_of_search_commands"> Types of search commands </span></a></h3>
<p>There are four broad categorizations for all the search commands: distributable streaming, stateful streaming, transforming, generating.
</p>
<h4><font size="3"><b><i> <a name="aboutthesearchlanguage_distributable_streaming"><span class="mw-headline" id="Distributable_streaming"> Distributable streaming </span></a></i></b></font></h4>
<p>A streaming command operates on each event returned by a search. A distributable streaming command runs on the indexer and can be applied to subsets of indexed data in a parallel manner. For example, the regex command is streaming; it extracts fields and adds them to events at search time. 
</p><p>Distributable streaming commands include: convert, eval, extract (kv), fields, mvexpand, multikv, rename, regex, replace, rex, search, strcat, tags, typer, and where.
</p><p>Other commands can be streaming when they are used with certain options.
</p>
<ul><li> <code><font size="2">bin</font></code> and <code><font size="2">bucket</font></code>, when they are used with a <code><font size="2">span</font></code> option.
</li><li> <code><font size="2">lookup</font></code>, when used with <code><font size="2">local=f</font></code>.
</li></ul><h4><font size="3"><b><i> <a name="aboutthesearchlanguage_centralized_streaming"><span class="mw-headline" id="Centralized_streaming"> Centralized streaming </span></a></i></b></font></h4>
<p>A centralized streaming command applies a transformation to each event returned by a search, but unlike distributable streaming commands, it only works on the search head. You might also hear the term "stateful streaming" to describe these commands.
</p><p>Centralized streaming commands include: head, streamstats, some modes of dedup, and some modes of cluster.
</p>
<h4><font size="3"><b><i> <a name="aboutthesearchlanguage_transforming"><span class="mw-headline" id="Transforming"> Transforming </span></a></i></b></font></h4>
<p>A transforming command orders the results into a data table, that is, it "transforms" the specified cell values for each event into numerical values that Splunk can use for statistical purposes. Transforming commands are not streaming. Also, they are required to transform search result data into the data structures required for visualizations such as column, bar, line, area, and pie charts. 
</p><p>Transforming commands include: chart, timechart, stats, top, rare, contingency, highlight, 
typer, and addtotals when it is used to calculate column totals (not row totals).
</p>
<h4><font size="3"><b><i> <a name="aboutthesearchlanguage_generating"><span class="mw-headline" id="Generating"> Generating </span></a></i></b></font></h4>
<p>A generating command is one that fetches information without any transformations. Generating commands are either event-generating (distributable or centralized) or report-generating and, depending on which they are, will return an events list or a table of results. Generating commands are usually invoked at the beginning of the search and with a leading pipe. That is, there cannot be a search piped into a generating command. The exception to this is the search command, because it is implicit at the start of a search and does not need to be invoked.
</p><p>Distributable event-generating commands include: search and metadata.
</p><p>Centralized event-generating commands include: loadjob, inputcsv, and inputlookup. 
</p><p>Report-generating commands include: dbinspect, datamodel, metadata (although metadata fetches data from all peers, any command run after it will run only on the search head), pivot, and tstats.
</p><p><br></p>
<h4><font size="3"><b><i> <a name="aboutthesearchlanguage_other_commands"><span class="mw-headline" id="Other_commands"> Other commands </span></a></i></b></font></h4>
<p>There are a handful of commands that do not fit into these categories. These commands are non-transforming, not distributable, and not streaming: sort, eventstats, some modes of dedup, and some modes of cluster.
</p>
<a name="aboutsearchlanguagesyntax"></a><h2> <a name="aboutsearchlanguagesyntax_the_search_processing_language_syntax"><span class="mw-headline" id="The_search_processing_language_syntax"> The search processing language syntax</span></a></h2>
<p>A Splunk search consists of a series of commands that are delimited by pipe (|) characters. The first whitespace-delimited string after each pipe character controls the command used. The remainder of the text for each command is handled in a manner specific to the given command.
</p><p>This topic discusses an anatomy of a Splunk Search and some of the syntax rules shared by each of the commands and syntax rules for fields and field values. 
</p>
<h3> <a name="aboutsearchlanguagesyntax_about_the_search_pipeline"><span class="mw-headline" id="About_the_search_pipeline"> About the search pipeline</span></a></h3>
<p>The "search pipeline" refers to the structure of a Splunk search, in which consecutive commands are chained together using a pipe character, "|". The pipe character tells Splunk to use the output or result of one command (to the left of the pipe) as the input for the next command (to the right of the pipe). This enables you to refine or enhance the data at each step along the pipeline until you get the results that you want.
</p><p>A Splunk search starts with search terms at the beginning of the pipeline. These search terms are keywords, phrases, boolean expressions, key/value pairs, etc. that specify which events you want to retrieve from the index(es). See <a href="#aboutretrievingevents" class="external text">"About retrieving events"</a>.
</p><p>The retrieved events can then be passed as inputs into a search command using a pipe character. Search commands tell Splunk what to do to the events after you retrieved them from the index(es). For example, you might use commands to filter unwanted information, extract more information, evaluate new fields, calculate statistics, reorder your results, or create a chart. Some commands have functions and arguments associated with them. These functions and their arguments enable you to specify how the commands act on your results and which fields to act on; for example, how to create a chart, what kind of statistics to calculate, and what fields to evaluate. Some commands also enable you to use clauses to specify how you want to group your search results. 
</p>
<ul><li> For more information about what you can do with search commands, see <a href="#aboutthesearchlanguage" class="external text">"About the search processing language"</a>.
</li><li> For a list of search commands, see the Search Reference manual and the individual search command reference topic for its syntax and usage.
</li></ul><h3> <a name="aboutsearchlanguagesyntax_the_anatomy_of_a_search"><span class="mw-headline" id="The_anatomy_of_a_search"> The anatomy of a search </span></a></h3>
<p>To better understand how search commands act on your data, it helps to visualize all your indexed data as a table. Each search command redefines the shape of your table. 
</p><p>For example, let's take a look at the following search.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=syslog ERROR | top user | fields - percent </font></code><br></div>
<p><img alt="Anatomy of a search.png" src="images/2/2d/Anatomy_of_a_search.png" width="600" height="163"></p><p>The Disk represents all of your indexed data and it's a table of a certain size with columns represent fields and rows representing events. The first intermediate results table shows fewer rows--representing the subset of events retrieved from the index that matched the search terms "sourcetype=syslog ERROR". The second intermediate results table shows fewer columns, representing the results of the top command, "top user", which summarizes the events into a list of the top 10 users and displays the user, count, and percentage. Then, "fields - percent" removes the column that shows the percentage, so you are left with a smaller final results table.
</p>
<h3> <a name="aboutsearchlanguagesyntax_quotes_and_escaping_characters"><span class="mw-headline" id="Quotes_and_escaping_characters"> Quotes and escaping characters </span></a></h3>
<p><b>Generally, you need quotes around phrases and field values that include white spaces, commas, pipes, quotes, and/or brackets.</b> Quotes must be balanced, an opening quote must be followed by an unescaped closing quote. For example:
</p>
<ul><li> A search such as <code><font size="2">error | stats count</font></code> will find the number of events containing the string error. 
</li><li> A search such as <code><font size="2">... | search "error | stats count"</font></code> would return the raw events containing error, a pipe, stats, and count, in that order.
</li></ul><p>Additionally, you want to use quotes around keywords and phrases if you don't want to search for their default meaning, such as Boolean operators and field/value pairs. For example:
</p>
<ul><li> A search for the keyword AND without meaning the Boolean operator: <code><font size="2">error "AND"</font></code>
</li><li> A search for this field/value phrase: <code><font size="2">error "startswith=foo"</font></code>
</li></ul><p><b>The backslash character (\) is used to escape quotes, pipes, and itself.</b> Backslash escape sequences are still expanded inside quotes. For example:
</p>
<ul><li> The sequence \| as part of a search will send a pipe character to the command, instead of having the pipe split between commands. 
</li><li> The sequence \" will send a literal quote to the command, for example for searching for a literal quotation mark or inserting a literal quotation mark into a field using rex.  
</li><li> The \\ sequence will be available as a literal backslash in the command.
</li></ul><p><b>If Splunk does not recognize a backslash sequence, it will not alter it.</b>
</p>
<ul><li> For example \s in a search string will be available as \s to the command, because \s is not a known escape sequence.  
</li><li> However, in the search string \\s will be available as \s to the command, because \\ is a known escape sequence that is converted to \.
</li></ul><p><b>Asterisks, *, can not be searched for using a backslash to escape the character.</b> Splunk treats the asterisk character as a major breaker. Because of this, it will never be in the index. If you want to search for the asterisk character, you will need to run a post-filtering regex search on your data:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=_internal | regex ".*\*.*"</font></code><br></div> 
<p>For more information about major breakers, read "Overview of event processing" in the Getting Data in Manual.
</p>
<h4><font size="3"><b><i> <a name="aboutsearchlanguagesyntax_examples"><span class="mw-headline" id="Examples">Examples </span></a></i></b></font></h4>
<p><b>Example 1:</b> <code><font size="2">myfield</font></code> is created with the value of <code><font size="2">6</font></code>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval myfield="6"</font></code><br></div>
<p><b>Example 2:</b> <code><font size="2">myfield</font></code> is created with the value of <code><font size="2">"</font></code>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval myfield="\""</font></code><br></div>
<p><b>Example 3:</b> <code><font size="2">myfield</font></code> is created with the value of <code><font size="2">\</font></code>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval myfield="\\"</font></code><br></div>
<p><b>Example 4:</b> This would produce an error because of unbalanced quotes.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval myfield="\"</font></code><br></div>
<h3> <a name="aboutsearchlanguagesyntax_fields"><span class="mw-headline" id="Fields"> Fields </span></a></h3>
<p>Events and results flowing through the Splunk search pipeline exist as a collection of fields.   Fields can fundamentally come from the Splunk index -- _time as the time of the event, source as the filename, etc -- or can be derived from a wide variety of sources at search time -- eventtypes, tags, regex extractions using the <code><font size="2">rex&lt;code&gt;/ command, totals coming from the &lt;code&gt;stats</font></code> command, etc.
</p><p>For a given event, a given field name might be present or absent.  If present, it might contain a single value or multiple values.  Each value is a text string.  Values might be of positive length (a string, or text) or zero length (empty strings, or "").
</p><p>Numbers, for example, are strings that contain the number.  For example, a field containing a value of the number 10 contains the characters 1 and 0: "10".  Commands that take numbers from values automatically convert them internally to numbers for calculations.
</p>
<dl><dt> Null field
</dt><dd> A null field is not present on a particular result or event.  Other events or results in the same search might have values for this field.  For example, the <code><font size="2">fillnull</font></code> command adds a field and default value to events or results that lack fields present on other events or results in the search.
</dd></dl><dl><dt> Empty field 
</dt><dd> An empty field is shorthand for a field that contains a single value that is the empty string. 
</dd></dl><dl><dt> Empty value
</dt><dd> A value that is the empty string, or "". You can also describe this as a zero-length string.
</dd></dl><dl><dt> Multvalue field
</dt><dd> A field that has more than one value.  All non-null fields contain an ordered list of strings. The common case is that this is a list of one value. When the list contains more than one entry, it is a multivalue field.  See "<a href="#parsemultivaluefields" class="external text">Manipulate and evaluate fields with multiple values</a>" in the <i>Search Manual</i>.
</dd></dl><a name="writebettersearches"></a><h2> <a name="writebettersearches_write_better_searches"><span class="mw-headline" id="Write_better_searches"> Write better searches</span></a></h2>
<p>This topic discusses some causes of slow searches and suggests simple rules of thumb to help you write searches that will run more efficiently. Many factors can affect the speed of your searches: the volume of data that you are searching, how you've constructed your searches, whether or not you've planned your deployment sufficiently to handle the number of users running searches at the same time, and so on. The key to optimizing your search speed is to make sure that Splunk Enterprise does not do more work than necessary. 
</p>
<h3> <a name="writebettersearches_types_of_searches"><span class="mw-headline" id="Types_of_searches"> Types of searches </span></a></h3>
<p>The recommendations for optimizing searches vary depending on the type of search that you run and the characteristics of the data you're searching. In general, we describe searches based on what you are trying to do: retrieve events or generate reports. If the events you want to retrieve occur frequently in the dataset, we call it a <i>dense search</i>. If the events you want to retrieve are rare in the dataset, we call it a <i>sparse search</i>. 
</p><p>Read more about <a href="#aboutsearch" class="external text">"About search"</a>.
</p>
<h4><font size="3"><b><i> <a name="writebettersearches_raw_event_searches"><span class="mw-headline" id="Raw_event_searches"> Raw event searches </span></a></i></b></font></h4>
<p>Raw event searches return events from a Splunk index without any additional processing to the events that are retrieved. The best rule of thumb to follow when retrieving events from the index is to be specific about the events that you want to retrieve. You can do this with keywords and field/value pairs that are unique to the events. One thing to keep in mind is that sparse searches against large volumes of data will take longer than dense searches against the same data set.
</p>
<h4><font size="3"><b><i> <a name="writebettersearches_report-generating_searches"><span class="mw-headline" id="Report-generating_searches"> Report-generating searches </span></a></i></b></font></h4>
<p>Report-generating searches perform additional processing on events after they've been retrieved from an index. This processing can include filtering, transforming, and other operations using one or more statistical functions against the set of results. Because this processing occurs in memory, the more restrictive and specific you are when specifying the events to retrieve from disk, the faster the search will be.
</p>
<h3> <a name="writebettersearches_tips_for_tuning_your_searches"><span class="mw-headline" id="Tips_for_tuning_your_searches"> Tips for tuning your searches </span></a></h3>
<p>In most cases, your search is slow because of the complexity of your query to retrieve events from index. For example, if you search contains extremely large OR lists, complex subsearches (which break down into OR lists), and types of phrase searches, it will take longer to process. This section discusses some tips for tuning your searches so that they are more efficient.
</p><p><b>Be more specific.</b> That is, narrow down your search as much as possible from the start and limit the data that has to be pulled from disk to an absolute minimum:
</p>
<ul><li> <b>Add strings which only exist in your desired events.</b>
</li><li> <b>Restrict your search to the specific host, index, source, source type, or Splunk server whenever possible.</b> Read more about using fields in your searches in the next section.
</li><li> <b>Limit your search to the specific time window you need.</b> For example, to see what might have led to errors a few minutes ago, search within the last 15 minutes '-15min' or last hour '-1hr', not the last week '-1w'. Read more  <a href="#aboutsearchtimeranges" class="external text">about time ranges in search</a>.
</li><li> <b>Limit the quantity of data retrieved.</b> You can do this easily using the head command: <code><font size="2">sourcetype=access_* | head 1000</font></code>.
</li></ul><p><b>Avoid using NOT expressions when possible.</b> That is, instead of using <code><font size="2">(NOT host=d NOT host=e)</font></code> or <code><font size="2">(host!=d OR host!=e)</font></code>, use <code><font size="2">(host=a OR host=b OR host=c)</font></code>. 
</p><p>If you rarely search across more than one type of data at a time, <b>partition your different types of data into separate indexes and restrict your searches to the specific index</b>. For example, store Web access data in one index and firewall data in another. This is recommended for sparse data, which may otherwise be buried in a large volume of unrelated data. Read more about ways to set up multiple indexes and how to <a href="#searchindexesanddistributedpeers" class="external text">search different indexes</a>.
</p>
<h3> <a name="writebettersearches_use_fields_in_your_searches"><span class="mw-headline" id="Use_fields_in_your_searches"> Use fields in your searches </span></a></h3>
<p>Searches with fields are faster when they use fields that have already been extracted (indexed fields) instead of fields extracted at search time.  
</p>
<h4><font size="3"><b><i> <a name="writebettersearches_use_indexed_and_default_fields_for_improved_search_efficiency"><span class="mw-headline" id="Use_indexed_and_default_fields_for_improved_search_efficiency">Use indexed and default fields for improved search efficiency</span></a></i></b></font></h4>
<p>Use indexed and default fields whenever you can to help search or filter your data efficiently. At index time, Splunk extracts a set of default fields that are common to each event; these fields include <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>. Use these fields to filter your data as early as possible in the search so that processing is done on a minimum amount of data. 
</p><p>For example, if you're building a report on web access errors, search for those specific errors before the reporting command:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* (status=4* OR status=5*) | stats count by status</font></code><br></div>
<h4><font size="3"><b><i> <a name="writebettersearches_disable_field_discovery_to_improve_search_performance"><span class="mw-headline" id="Disable_field_discovery_to_improve_search_performance">Disable field discovery to improve search performance</span></a></i></b></font></h4>
<p>If you don't need additional fields in your search, set <b>Search Mode</b> to a setting that disables field discovery to improve search performance in the timeline view or use the <code><font size="2">fields</font></code> command to specify only the fields that you want to see in your results.
</p><p><img alt="6.2 searchmode options.png" src="images/9/99/6.2_searchmode_options.png" width="300" height="190"></p><p>The tradeoff to disabling field discovery is that doing so prevents automatic <b>field extraction</b>, except for fields that are required to fulfill your search (such as fields that you are specifically searching on) and <b>default fields</b> such as <code><font size="2">_time</font></code>, <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>. The search runs faster because Splunk is no longer trying to extract every field possible from your events.
</p><p><b>Search mode</b> is set to <i>Smart</i> by default. Set it to <i>Verbose</i> if you are running searches with reporting commands, don't know what fields exist in your data, and think you might need them to help you narrow down your search in some way.
</p><p>See <a href="#changethesearchmode" class="external text">"Set search mode to adjust your search experience,"</a> in this manual.
</p><p>Also see the topics about fields and field extractions in the <i>Knowledge Manager Manual</i> and about the fields command in the <i>Search Reference Manual</i>.
</p>
<h3> <a name="writebettersearches_summarize_your_data"><span class="mw-headline" id="Summarize_your_data"> Summarize your data </span></a></h3>
<p>It can take a lot of time to search through very large data sets. If you regularly generate reports on large volumes of data, <b>use summary indexing to pre-calculate the values that you use most often in your reports</b>. Schedule saved searches to collect metrics on a regular basis, and report on the summarized data instead of on raw data. 
</p><p>Read more about how to use summary indexing for increased reporting efficiency.
</p>
<h3> <a name="writebettersearches_use_the_search_job_inspector"><span class="mw-headline" id="Use_the_Search_Job_Inspector"> Use the Search Job Inspector </span></a></h3>
<p>The <b>Search Job Inspector</b> is a tool you can use both to troubleshoot the performance of a search and to determine which phase of the search takes the greatest amounts of time. It dissects the behavior of your searches to help you understand the execution costs of knowledge objects such as event types, tags, lookups, search commands, and other components within the search. 
</p><p>Read more about how to use the search job inspector.
</p>
<h1>Retrieve Events</h1><a name="aboutretrievingevents"></a><h2> <a name="aboutretrievingevents_about_retrieving_events"><span class="mw-headline" id="About_retrieving_events"> About retrieving events</span></a></h2>
<p>When you search in Splunk, you're using the search command to match search terms against segments of your event data. These search terms are keywords, phrases, boolean expressions, field name and value pairs, etc. that specify which events you want to retrieve from the index(es). Read more about how to <a href="#usethesearchcommand" class="external text">"Use the search command"</a> to retrieve events.
</p><p>Your event data may be partitioned into different indexes and across distributed search peers. Read more about how to search across multiple indexes and servers in <a href="#searchindexesanddistributedpeers" class="external text">"Retrieve events from indexes and distributed search peers"</a>.
</p><p>Events are retrieved from an index(es) in reverse time order. The results of a Splunk search are ordered from most recent to least recent by default. You can retrieve events faster if you filter by time, whether you are using the timeline to zoom in on clusters of events or applying time ranges to the search itself. For more information, read how to <a href="#usethetimeline" class="external text">"Use the timeline to investigate events"</a> and <a href="#aboutsearchtimeranges" class="external text">"About time ranges in search"</a>.
</p><p><br></p>
<h3> <a name="aboutretrievingevents_events.2c_event_data.2c_and_fields"><span class="mw-headline" id="Events.2C_event_data.2C_and_fields"> Events, event data, and fields </span></a></h3>
<p>We generally use the phrase <i>event data</i> to refer to your data after it has been added to Splunk's index.  Events, themselves, are a single record of activity or instance of this event data. For example, an event might be a single log entry in a log file. Because Splunk separates individual events by their time information, an event is distinguished from other events by a timestamp.
</p><p>Here's a sample event:
</p><p><code><font size="2">172.26.34.223 - - [01/Jul/2005:12:05:27 -0700] "GET /trade/app?action=logout HTTP/1.1" 200 2953</font></code>
</p><p>Events contain pairs of information, or fields. When you add data and it gets indexed, Splunk automatically extracts some useful fields for you, such as the host the event came from and the type of data source it is.
</p>
<a name="usethesearchcommand"></a><h2> <a name="usethesearchcommand_use_the_search_command_to_retrieve_events"><span class="mw-headline" id="Use_the_search_command_to_retrieve_events"> Use the search command to retrieve events </span></a></h2>
<p>At the beginning of a <a href="#aboutsearchlanguagesyntax" class="external text">search pipeline</a>, the search command is implied, even though you do not explicitly invoke it.
</p><p>Use keywords, phrases, fields, boolean expressions, and comparison expressions to specify exactly which events you want to retrieve from a Splunk index(es). By default, when you search with keywords and phrases, Splunk retrieves events by matching against the raw event field, <code><font size="2">_raw</font></code>, in your data. When you start adding search modifiers, such as fields like <code><font size="2">_time</font></code> and <code><font size="2">tag</font></code>, you're also matching against pieces of information that have been extracted from the <code><font size="2">_raw</font></code> field.
</p>
<h3> <a name="usethesearchcommand_keywords.2c_phrases.2c_and_wildcards"><span class="mw-headline" id="Keywords.2C_phrases.2C_and_wildcards"> Keywords, phrases, and wildcards </span></a></h3>
<p>When searching for strings, which includes keywords and quoted phrases (or anything that's not a search modifier), Splunk searches the <code><font size="2">_raw</font></code> field for the matching events or results. Some examples of keywords and phrases are:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">web</font></code><br></div>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">error</font></code><br></div>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">web error</font></code><br></div>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">"web error"</font></code><br></div>
<p>Note that the search for the quoted phrase "web error" is not that same as the search before it. When you search for <code><font size="2">web error</font></code>, Splunk returns events that contain both "web" and "error". When you search for "web error", Splunk only returns events that contain the phrase "web error".
</p><p>Use the asterisk wildcard, *, to match an unrestricted number of characters in a string. Searching for <code><font size="2">*</font></code> by itself means "match all" and retrieves all events up to the maximum limit. Searching for <code><font size="2">*</font></code> as part of a string matches based on that string. For example:
</p>
<ul><li> <code><font size="2">my*</font></code> matches myhost1, myhost.ny.mydomain.com, myeventtype, etc.
</li><li> <code><font size="2">*host</font></code> matches myhost, yourhost, etc.
</li><li> <code><font size="2">*host*</font></code> matches host1, myhost3, yourhost27.yourdomain.com, etc
</li></ul><p>The more specific your search terms are to the events you want to retrieve, the better chance you have at matching them. For example, searching for "access denied" is always better than searching for "denied". If 90% of your events have the word &acirc;&#128;&#152;error&acirc;&#128;&#153; but only 5% have the word &acirc;&#128;&#152;sshd&acirc;&#128;&#153; (and the events you want to find require both of these words), include &acirc;&#128;&#152;sshd&acirc;&#128;&#153; in the search to make it more efficient.
</p>
<h3> <a name="usethesearchcommand_boolean_expressions"><span class="mw-headline" id="Boolean_expressions"> Boolean expressions </span></a></h3>
<p>Splunk supports the Boolean operators: <code><font size="2">AND</font></code>, <code><font size="2">OR</font></code>, and <code><font size="2">NOT</font></code>; <b>the operators have to be capitalized</b>. The AND operator is always implied between terms, that is: <code><font size="2">web error</font></code> is the same as <code><font size="2">web AND error</font></code>.
</p><p>Splunk evaluates Boolean expressions in the following order:
</p><p><b>1.</b> Expressions within parentheses.
</p><p><b>2.</b> <code><font size="2">OR</font></code> clauses.
</p><p><b>3.</b> <code><font size="2">AND</font></code> or <code><font size="2">NOT</font></code> clauses.
</p>
Without parenthesis, <div class="inlineQuery splunk_search_4_3"><code><font size="2">A=1 AND B=2 OR C=3</font></code><br></div>
will be processed as <div class="inlineQuery splunk_search_4_3"><code><font size="2">A=1 AND ( B=2 OR C=3 )</font></code><br></div> 
<p>You can use parentheses to group Boolean expressions. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">web client error NOT (403 OR 404)</font></code><br></div>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">(A=1 AND B=2 ) OR C=3 </font></code><br></div>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">web client error NOT (403 OR 404)</font></code><br></div>
<p><b>Note:</b> Inclusion is generally better than exclusion. Searching for "access denied" will yield faster results than NOT "access granted".
</p>
<h3> <a name="usethesearchcommand_field_expressions"><span class="mw-headline" id="Field_expressions"> Field expressions </span></a></h3>
<p>When you add data, Splunk extracts pairs of information and saves them as fields. Some fields are common to all events, but others are not. Adding fields to you search term gives you a better chance of matching specific events.
</p><p>If you're searching web access logs for specific HTTP status errors, instead of searching for "web error 404", you can use fields to search for:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">status=404</font></code><br></div>
<p>Read more about how to  "<a href="#usefieldstoretrieveevents" class="external text">Use fields to retrieve events</a>."
</p>
<h4><font size="3"><b><i> <a name="usethesearchcommand_use_comparison_operators_to_match_field_values"><span class="mw-headline" id="Use_comparison_operators_to_match_field_values"> Use comparison operators to match field values </span></a></i></b></font></h4>
<p>You can use comparison operators to match a specific value or a range of field values.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0"> Operator
</th><th bgcolor="#C0C0C0"> Example
</th><th bgcolor="#C0C0C0"> Result
</th></tr><tr><td valign="center" align="left">=
</td><td valign="center" align="left">field=foo
</td><td valign="center" align="left">Multivalued field values that exactly match "foo".
</td></tr><tr><td valign="center" align="left">!=
</td><td valign="center" align="left">field!=foo
</td><td valign="center" align="left">Multivalued field values that don't exactly match "foo".
</td></tr><tr><td valign="center" align="left">&lt;
</td><td valign="center" align="left">field&lt;x
</td><td valign="center" align="left">Numerical field values that are less than x.
</td></tr><tr><td valign="center" align="left">&gt;
</td><td valign="center" align="left">field&gt;x
</td><td valign="center" align="left">Numerical field values that are greater than x.
</td></tr><tr><td valign="center" align="left">&lt;=
</td><td valign="center" align="left">field&lt;=x
</td><td valign="center" align="left">Numerical field values that are less than and equal to x.
</td></tr><tr><td valign="center" align="left">&gt;=
</td><td valign="center" align="left">field&gt;=x
</td><td valign="center" align="left">Numerical field values that are greater than and equal to x.
</td></tr></table><p>For example, to find events that have a delay field that is greater than 10:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">delay &gt; 10</font></code><br></div>
<h3> <a name="usethesearchcommand_use_case.28.29_and_term.28.29_to_match_phrases"><span class="mw-headline" id="Use_CASE.28.29_and_TERM.28.29_to_match_phrases"> Use CASE() and TERM() to match phrases </span></a></h3>
<p>If you want to search for a specific term or phrase in your Splunk index, use the CASE() or TERM() directives to force Splunk to do an exact match of the entire term. 
</p>
<ul><li> CASE forces Splunk to search for case-sensitive matches for terms and field values. 
</li><li> TERM forces Splunk to match whatever is inside the parentheses as a single term in the index, even if it contains characters that are usually recognized as minor segmenters, such as periods or underscores. 
</li></ul><p>When you search for a term that contains minor segmenters, Splunk defaults to treating it as a phrase: It searches for the conjunction of the subterms (the terms between minor breaks) and post-filters the results. For example, when you search for the IP address 127.0.0.1, Splunk searches for: <code><font size="2">127 AND 0 AND 1</font></code>
</p><p>This search is not very efficient if the conjunction of these subterms is common, even if the whole term itself is not common.
</p><p>If you search for TERM(127.0.0.1), Splunk treats the IP address as a single term to match in your raw data.
</p><p>TERM is more useful for cases where the term contains minor segmenters and is bounded by major segmenters, such as spaces or commas. In fact, TERM does not work for terms that are not bounded by major breakers. This is illustrated in the examples below.
</p><p>For more information about how Splunk breaks events up into searchable segments, read "About segmentation" in the Getting Data In Manual.
</p>
<h4><font size="3"><b><i> <a name="usethesearchcommand_examples"><span class="mw-headline" id="Examples"> Examples </span></a></i></b></font></h4>
<p>TERM(127.0.0.1) works for raw data that looks like:
</p>
<div class="samplecode">
<p>127.0.0.1 - admin  
</p>
</div>
<p>However, it fails for data that looks like:
</p>
<div class="samplecode">
<p>ip=127.0.0.1 - user=admin
</p>
</div>
<p>This is because "=" is a minor breaker and the IP address portion of the event is indexed as: ip, 127, 0, 1, ip=127.0.0.1
</p><p>If your data looks like this:
</p>
<div class="samplecode">
<p>ip 127.0.0.1 - user admin
</p>
</div>
<p>TERM(user admin) fails to return results. The space is a major breaker and Splunk would not index the phrase "user admin" as a single term.
</p>
<a name="usefieldstoretrieveevents"></a><h2> <a name="usefieldstoretrieveevents_use_fields_to_retrieve_events"><span class="mw-headline" id="Use_fields_to_retrieve_events"> Use fields to retrieve events</span></a></h2>
<p>Fields are searchable name/value pairings in <b>event data</b>. All fields have names and can be searched with those names. Searches with field expressions are more precise (and therefore more efficient) than searches using only keywords and quoted phrases. 
</p><p>Look at the following search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">host=webserver</font></code><br></div>
<p>In this search, <code><font size="2">host=webserver</font></code> indicates that you are searching for events with <code><font size="2">host</font></code> fields that have values of <code><font size="2">webserver</font></code>. When you run this search, Splunk won't retrieve events with different <code><font size="2">host</font></code> field values. It also won't retrieve events that contain other fields that share <code><font size="2">webserver</font></code> as a value. This means that this search returns a more focused set of results than you might get if you just searched for <code><font size="2">webserver</font></code> in the search bar.
</p><p>For more information, read "About fields" in the Knowledge Manage Manual.
</p>
<h3> <a name="usefieldstoretrieveevents_index-time_and_search-time_fields"><span class="mw-headline" id="Index-time_and_search-time_fields"> Index-time and search-time fields </span></a></h3>
<p>As Splunk Enterprise processes event data, it extracts and defines fields from that data, first at index time, and again at search time. 
</p><p>See "Index time versus search time" in the <i>Managing Indexers and Clusters</i> manual.
</p>
<h4><font size="3"><b><i> <a name="usefieldstoretrieveevents_field_extraction_at_index_time"><span class="mw-headline" id="Field_extraction_at_index_time">Field extraction at index time</span></a></i></b></font></h4>
<p>At <b>index time</b>, Splunk extracts a small set of fields. This set of fields includes <b>default fields</b>, custom indexed fields, and fields indexed from structured data. 
</p><p>Default fields exist in all events. Three important default fields are host, source, and source type. They describe where the event originated. Other default fields include datetime fields, which provide additional searchable granularity to event timestamps. Splunk also automatically adds default fields classified as internal fields. 
</p><p>Custom indexed fields are fields that you have manually configured for index-time extraction. See "Create custom fields at index time" in the <i>Getting Data In</i> manual.
</p><p>Finally, when Splunk Enterprise indexes structured data, it creates index-time field extractions for the fields that it finds. Examples of structured data include:
</p>
<ul><li> comma-separated value files (CSV)
</li><li> tab-separated value files (TSV)
</li><li> pipe-separated value files
</li><li> JavaScript Object Notation (JSON) data sources
</li></ul><h4><font size="3"><b><i> <a name="usefieldstoretrieveevents_field_extraction_at_search_time"><span class="mw-headline" id="Field_extraction_at_search_time">Field extraction at search time</span></a></i></b></font></h4>
<p>At <b>search time</b>, Splunk Enterprise extracts additional fields, depending on its <b>Search Mode</b> setting and whether or not that setting enables field discovery given the type of search being run.
</p>
<h3> <a name="usefieldstoretrieveevents_search_examples"><span class="mw-headline" id="Search_examples"> Search examples </span></a></h3>
<p><b>Example 1:</b> Search for events on all "corp" servers for accesses by the user "strawsky". It then reports the 20 most recent events. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">host=corp* eventtype=access user=strawsky</font></code><br></div>
<p>In this example, <code><font size="2">host</font></code> is a default field, while <code><font size="2">eventtype</font></code> and <code><font size="2">user</font></code> are additional fields that Splunk may have automatically extracted or that you defined. 
</p><p>In general, an event type is a user-defined field that simplifies search by letting you categorize events. You can save a search as an event type and quickly retrieve those events using the <code><font size="2">eventtype</font></code> field. For more information, read "About event types" in the Knowledge Manager Manual.
</p><p><b>Example 2:</b> Search for events from the source "/var/www/log/php_error.log".
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">source="/var/www/log/php_error.log"</font></code><br></div>
<p>The source of an event is the name of the file, stream, or other input from which the event originates. 
</p><p><b>Example 3:</b> Search for all events that have an Apache web access source type. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype="access_*"</font></code><br></div>
<p>The source type of an event is the format of the data input from which it originates. In this search uses a wildcard to match any Apache web access log that begins with "access_". This includes access_common and access_combined (and you might also see access_combined_wcookie).
</p><p><b>Example 4:</b> Search corp1 for events that have more than 4 lines, and omit events that contain the term 400.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">host=corp1 linecount&gt;4 NOT 400</font></code><br></div>
<p>You can use comparison expressions to match field/value pairs. Comparison expressions with "=" and "!=" work with all field/value pairs. Comparison expressions with &lt; &gt; &lt;= &gt;= work only with fields that have numeric values. This example specifies a search for events that have more than 4 lines, <code><font size="2">linecount&gt;4</font></code>. 
</p><p><b>Example 5:</b> Searching with the boolean "NOT" versus the comparison operator "!=" is not the same. The following search returns events where <code><font size="2">field</font></code> is undefined (or NULL).
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">NOT field="value"</font></code><br></div>
<p>The following search returns events where <code><font size="2">field</font></code> exists and does not have the value "value".
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">field!="value"</font></code><br></div>
<p>In the case where the value in question is the wildcard "*", <code><font size="2">NOT field=*</font></code> will return events where field is null/undefined, and <code><font size="2">field!=*</font></code> will never return any events.
</p>
<h3> <a name="usefieldstoretrieveevents_more_about_fields"><span class="mw-headline" id="More_about_fields"> More about fields </span></a></h3>
<p>This topic only discussed a handful of searches with fields. 
</p>
<ul><li> You can see more examples of searches with the default fields <code><font size="2">index</font></code> and <code><font size="2">splunk_server</font></code> in the next topic, <a href="#searchindexesanddistributedpeers" class="external text">"Retrieve events from indexes and distributed search peers"</a>.  
</li><li> You can see more search examples "Using default fields" in the Knowledge Manager Manual.
</li></ul><p>Fields become more important when you start using the Splunk search language to summarize and transform your data into reports. For more information, read <a href="#aboutreportingcommands" class="external text">"About reporting commands"</a>.
</p>
<a name="searchindexesanddistributedpeers"></a><h2> <a name="searchindexesanddistributedpeers_retrieve_events_from_indexes_and_distributed_search_peers"><span class="mw-headline" id="Retrieve_events_from_indexes_and_distributed_search_peers"> Retrieve events from indexes and distributed search peers</span></a></h2>
<p>You have always been able to create new indexes, add more search peers, and manage where you want to store your data. Additionally, when you have data split across different indexes and distributed search peers, you're not limited to searching one index or server at a time. You can search across multiple indexes and servers at once, using the <code><font size="2">index</font></code> and <code><font size="2">splunk_server</font></code> fields, respectively.
</p>
<h3> <a name="searchindexesanddistributedpeers_specify_one_or_multiple_indexes_to_search"><span class="mw-headline" id="Specify_one_or_multiple_indexes_to_search"> Specify one or multiple indexes to search </span></a></h3>
<p>The Splunk administrator can set the default indexes that a user searches. Based on the user's roles and permissions, he may have access to one or many indexes; for example the user may only be able to search main or all public indexes.  The user can then specify a subset of these indexes, either an individual index or multiple indexes, to search. For more information about setting up users and roles, see the "About users and roles" chapter in Securing Splunk. 
</p><p>For more information about managing your indexes and setting up multiple indexes, see the "About managing indexes" chapter in the Managing Indexers and Clusters manual.
</p>
<h4><font size="3"><b><i> <a name="searchindexesanddistributedpeers_control_index_access_via_splunk_web"><span class="mw-headline" id="Control_index_access_via_Splunk_Web"> Control index access via Splunk Web </span></a></i></b></font></h4>
<p><b>1.</b> Navigate to  <b>Manager &gt; Access controls &gt; Roles</b>.  
</p><p><b>2.</b> Select the role that the User has been assigned to.
</p>
<dl><dd> On the bottom of the next screen you'll find the index controls.  
</dd></dl><p><b>3.</b> Control the indexes that particular role has access to, as well as the default search indexes.
</p>
<h4><font size="3"><b><i> <a name="searchindexesanddistributedpeers_syntax"><span class="mw-headline" id="Syntax"> Syntax </span></a></i></b></font></h4>
<p>You can specify different indexes to search in the same way that you specify field names and values. In this case, the field name is <code><font size="2">index</font></code> and the field value is the name of a particular index:
</p>
<code><font size="2"><br>index=&lt;indexname&gt;<br></font></code>
You can use the * wildcard to specify groups of indexes; for example, if you wanted to search both "mail" and "main" indexes, you can search for: <div class="inlineQuery splunk_search_4_3"><code><font size="2">index=mai*</font></code><br></div>
<p>You can also use parentheses to partition different searches to certain indexes. See Example 3 for details.
</p><p><b>Note:</b> When you type "index=" into the search bar, typeahead indicates all the indexes that you can search, based on your roles and permissions settings.
</p>
<h4><font size="3"><b><i> <a name="searchindexesanddistributedpeers_examples"><span class="mw-headline" id="Examples"> Examples </span></a></i></b></font></h4>
<p><b>Example 1:</b> Search across all public indexes.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=*</font></code><br></div>
<p><b>Example 2:</b> Search across all indexes, public and internal.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=* OR index=_*</font></code><br></div>
<p><b>Example 3:</b> Partition different searches to different indexes; in this example, you're searching three different indexes: main, _internal, and mail. You want to see events that match "error" in all three indexes; but also, errors that match "warn" in main or "failed" in mail. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">(index=main (error OR warn)) OR (index=_internal error) OR (index=mail (error OR failed))</font></code><br></div>
<p><b>Example 4:</b> Search across multiple indexes on different distributed Splunk servers.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">(splunk_server=local index=main 404 ip=10.0.0.0/16) OR (splunk_server=remote index=mail user=admin)</font></code><br></div>
<h3> <a name="searchindexesanddistributedpeers_search_across_one_or_more_distributed_search_peers"><span class="mw-headline" id="Search_across_one_or_more_distributed_search_peers"> Search across one or more distributed search peers </span></a></h3>
<p>When performing a distributed search from a search head, you can restrict your searches to specific search peers (also known as "indexer nodes") by default and in your saved and scheduled searches. The names of your Splunk search peers are saved as values in the "splunk_server" field. For more information about distributed search, see "About distributed search" in the Distributed Search manual. 
</p><p>If no search peer is specified, your search accesses all search peers you have permission to access. The default peers that you can access are controlled by the roles and permissions associated with your profile and set by your Splunk admin. For more information, see "About users and roles" in Securing Splunk. 
</p><p>The ability to restrict your searches to specific peers can be useful when there is high latency to certain search peers and you do not want to search them by default. When you specify one or more peers, those are the only servers that are included in the search.
</p><p>You can specify different peers to search in the same way that you specify other field names and values. In this case, the field name is "splunk_server" and the field value is the name of a particular distributed peer:
</p>
<code><font size="2"><br>splunk_server=&lt;peer_name&gt;<br></font></code>
<p><b>Note:</b> You can use the value "local" to refer to the Splunk instance that you are searching from; in other words, the search head itself.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">splunk_server=local</font></code><br></div> 
<p>Keep in mind that <b>field names are case sensitive</b>; Splunk will not recognize a field name if the case doesn't match.
</p>
<h4><font size="3"><b><i> <a name="searchindexesanddistributedpeers_examples_2"><span class="mw-headline" id="Examples_2"> Examples </span></a></i></b></font></h4>
<p><b>Example 1:</b> Return results from specified search peers.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">error (splunk_server=NYsplunk OR splunk_server=CAsplunk) NOT splunk_server=TXsplunk</font></code><br></div>
<p><b>Example 2:</b> Search different indexes on distributed search peers "foo" or "bar".
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">(splunk_server=foo index=main 404 ip=10.0.0.0/16) OR (splunk_server=bar index=mail user=admin)</font></code><br></div>
<h3> <a name="searchindexesanddistributedpeers_not_finding_the_events_you.27re_looking_for.3f"><span class="mw-headline" id="Not_finding_the_events_you.27re_looking_for.3F"> Not finding the events you're looking for?</span></a></h3>
<p>When you add an input to Splunk, that input gets added relative to the app you're in. Some apps write input data to their own specific index (for example, the Splunk App for Unix and Linux uses the 'os' index). 
</p><p>If you're not finding data that you're certain is in Splunk, be sure that you're looking at the right index. You might need to add an app-specific index to the list of default indexes for the role you're using. For more information about roles, refer to the topic about roles in Securing Splunk.
</p>
<a name="classifysimilarevents"></a><h2> <a name="classifysimilarevents_classify_and_group_similar_events"><span class="mw-headline" id="Classify_and_group_similar_events"> Classify and group similar events </span></a></h2>
<p>An event is not the same thing as an event type. An event is a single instance of data &mdash; a single log entry, for example. An event type is a classification used to label and group events.
</p><p>The names of the matching event types for an event are set on the event, in a multivalue field called <code><font size="2">eventtype</font></code>. You can search for these groups of events (for example, SSH logins) the same way you search for any field value.
</p><p>This topic discusses how to classify events (save a search as an event type) and search for tagged fields. For more information about events, how Splunk recognizes them, and what it does when it processes them for indexing, see the "Overview of event processing" topic in the Getting Data In manual.
</p><p><b>Important:</b> You cannot save a search pipeline as an event type; that is, when saving a search as an event type, it cannot include a search command.
</p>
<h3> <a name="classifysimilarevents_save_a_search_as_a_new_event_type"><span class="mw-headline" id="Save_a_search_as_a_new_event_type"> Save a search as a new event type </span></a></h3>
<p>When you search your event data, you're essentially weeding out all unwanted events. Therefore, the results of your search are events that share common characteristics, and you can give them a collective name.  
</p><p>For example, if you often search for failed logins on different host machines, you can save an eventtype for the events and call it <code><font size="2">failed_login</font></code>:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">"failed login" OR "FAILED LOGIN" OR "Authentication failure"  OR "Failed to authenticate user"</font></code><br></div> 
<p>To save this search as an eventtype:
</p><p><b>1.</b> Click <b>Create</b> and select <i>Event Type</i>
</p><p><b>2.</b> In <b>Save As Event Type</b>, give your search a <b>Name</b>.
For our search example, we'll name it "failed_login".
</p><p><img alt="6.2 saveaseventtype dialog.png" src="images/0/00/6.2_saveaseventtype_dialog.png" width="400" height="342"></p><p>If necessary, you can modify the <b>Search string</b> field, which should be populated automatically with the search you just ran. 
</p><p>You can also optionally add a list of tags that should be applied to the event type in the <b>Tag(s)</b> field. For more about this see the subsection about tagging event types, below.
</p><p><b>3.</b> Click "Save" to save your event type name.
</p><p>Now, you can quickly search for all the events that match this event type the same way you can search for any field.
</p><p>For example, you may be interested it in finding failed logins on specific host machines:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">host=target eventtype=failed_login</font></code><br></div>
<p>Or you may want to investigate a suspicious user's activities:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">user=suspicious eventtype=failed_login</font></code><br></div>
<h3> <a name="classifysimilarevents_use_typelearner_to_discover_new_event_types"><span class="mw-headline" id="Use_typelearner_to_discover_new_event_types"> Use typelearner to discover new event types </span></a></h3>
<p>Pass any of your searches into the <code><font size="2">typelearner</font></code> command to see Splunk's suggestions for event types. By default, <code><font size="2">typelearner</font></code> compares the punctuation of the events resulting from the search, grouping those that have similar punctuation and terms together.
</p><p>You can specify a different field for Splunk to group the events; <code><font size="2">typelearner</font></code> works the same way with any field. The result is a set of events (from your search results) that have this field and phrases in common.
</p><p>For more information and examples, see  "typelearner" in the search command reference.
</p>
<h3> <a name="classifysimilarevents_use_tags_to_group_and_find_similar_events"><span class="mw-headline" id="Use_tags_to_group_and_find_similar_events"> Use tags to group and find similar events </span></a></h3>
<p>In your data, you might have groups of events with related field values. To help you search more efficiently for these groups of fields, you can assign tags to their field values. You can assign one or more tags to any extracted field (including event type, host, source, or source type). 
</p><p>Event types can have one or more tags associated with them. You can add these tags while you save a search as an event type and from the event type manager, located in <b>Manager &gt; Event types</b>. From the list of event types in this window, select the one you want to edit. 
</p><p>After you add tags to your event types, you can search for them in the same way you search for any tag. Let's say you saved a search for firewall events as the event type <code><font size="2">firewall_allowed</font></code>, and then saved a search for login events as the event type <code><font size="2">login_successful</font></code>.  If you tagged both of these event types with <i>allow</i>, all events of either of those event types can be retrieved by using the search: 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">tag::eventtype="allow"</font></code><br></div>
<p>You can tag field/value pairs. You can also alias field names. For more information about using tags, see the "Tag and alias field values in Splunk Web" topic in the Knowledge Manager Manual.
</p>
<h4><font size="3"><b><i> <a name="classifysimilarevents_search_for_tagged_field_values"><span class="mw-headline" id="Search_for_tagged_field_values"> Search for tagged field values </span></a></i></b></font></h4>
<p>There are two ways to search for tags. If you are searching for a tag associated with a value on any field, you can use the following syntax:
</p>
<code><font size="2"><br>tag=&lt;tagname&gt;<br></font></code>
<p>Or, if you are looking for a tag associated with a value on a specific field, you can use the following syntax:
</p>
<code><font size="2">tag::&lt;field&gt;=&lt;tagname&gt;<br></font></code>
<h4><font size="3"><b><i> <a name="classifysimilarevents_use_wildcards_to_search_for_tags"><span class="mw-headline" id="Use_wildcards_to_search_for_tags"> Use wildcards to search for tags </span></a></i></b></font></h4>
<p>You can use the asterisk (<code><font size="2">*</font></code>) wildcard when searching keywords and field values, including for eventtypes and tags. 
</p><p>For example, if you have multiple event-type tags for various types of IP addresses, such as <code><font size="2">IP-src</font></code> and <code><font size="2">IP-dst</font></code>, you can search for all of them with:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">tag::eventtype=IP-*</font></code><br></div>
<p>If you wanted to find all hosts whose tags contain "local", you can search for the tag:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">tag::host=*local*</font></code><br></div>
<p>Also, if you wanted to search for the events with eventtypes that have no tags, you can search for the Boolean expression:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">NOT tag::eventtype=*</font></code><br></div>

<a name="usethetimeline"></a><h2> <a name="usethetimeline_use_the_timeline_to_investigate_events"><span class="mw-headline" id="Use_the_timeline_to_investigate_events"> Use the timeline to investigate events </span></a></h2>
<p>The timeline is a visual representation of the number of events that occur at each point in time. It shows the distribution of events over time. Mouseover a bar to see the count of events. Click on a bar to drill-down to that time range. Drilling down in this way does not run a new search, it just filters the results from the previous search. You can use the timeline to highlight patterns or clusters of events or investigate peaks (spikes in activity) and lows (possible server downtime) in event activity.
</p>
<h3> <a name="usethetimeline_change_the_timeline_format"><span class="mw-headline" id="Change_the_timeline_format"> Change the timeline format </span></a></h3>
<p>The timeline is located in the Events tab above the events listing. It shows the count of events over the time range that the search was run. Here, the timeline shows web access events over the <b>Previous business week</b>.
</p><p><img alt="6.2 timeline compact.png" src="images/4/45/6.2_timeline_compact.png" width="700" height="204"></p><p><br>
Format options are located in the <b>Format Timeline</b> menu:
</p><p><img alt="6.2 timeline formatoptions.png" src="images/c/c3/6.2_timeline_formatoptions.png" width="200" height="193"></p><p><br>
You can hide the timeline (Hidden) and display a Compact or Full view of it. You can also toggle the timeline scale between linear (Linear Scale) or logarithmic (Log Scale).
</p><p>When <b>Full</b> is selected, the timeline is taller and displays the count on the y-axis and time on the x-axis.
</p>
<h3> <a name="usethetimeline_zoom_in_and_zoom_out_to_investigate_events"><span class="mw-headline" id="Zoom_in_and_zoom_out_to_investigate_events"> Zoom in and zoom out to investigate events </span></a></h3>
<p>Zoom and selection options are located above the timeline. At first, only the <b>Zoom Out</b> option is available.
</p><p><img alt="6.2 timeline full.png" src="images/3/31/6.2_timeline_full.png" width="700" height="253"></p><p><br>
The timeline legend is on the top right corner of the timeline. This indicates the scale of the timeline. For example, <b>1 minute per column</b> indicates that each column represents a count of events during that minute. Zooming in and out changes the time scale. For example, if you click <b>Zoom Out</b> the legend will indicate that each column now represents an hour instead of a minute. 
</p><p>When you mouse over and select bars in the timeline, the <b>Zoom to Selection</b> or <b>Deselect</b> options become available. 
</p><p><img alt="6.2 timeline selectbars.png" src="images/6/61/6.2_timeline_selectbars.png" width="700" height="249"></p><p><br>
Mouse over and click on the tallest bar or drag your mouse over a cluster of bars in the timeline. The events list updates to display only the events that occurred in that selected time range. The time range picker also updates to the selected time range. You can cancel this selection by clicking <b>Deselect</b>.
</p><p>When you <b>Zoom to Selection</b>, you filter the results of your previous search for your selected time period. The timeline and events list update to show the results of the new search.
</p><p><img alt="6.2 timeline zoomtoselect.png" src="images/0/04/6.2_timeline_zoomtoselect.png" width="700" height="248"></p><p><br>
You cannot <b>Deselect</b> after you zoomed into a selected time range. But, you can <b>Zoom Out</b> again.
</p><p><img alt="6.2 timeline zoomout.png" src="images/1/18/6.2_timeline_zoomout.png" width="700" height="251"></p>
<a name="drilldownoneventdetails"></a><h2> <a name="drilldownoneventdetails_run_a_secondary_search_on_event_details"><span class="mw-headline" id="Run_a_secondary_search_on_event_details"> Run a secondary search on event details</span></a></h2>
<p>After running a search that returns events in the <b>Events</b> tab, click on parts of those events to run different kinds of secondary searches that use the event detail that you have selected.
</p><p>In the <b>Events</b> tab you can run a secondary search when you click on these parts of an event:
</p>
<ul><li> Segment (can be a connected string of segments)
</li><li> Field value
</li><li> Tag
</li><li> Timestamp
</li></ul><h3> <a name="drilldownoneventdetails_secondary_searches_for_field_values.2c_tags.2c_and_segments"><span class="mw-headline" id="Secondary_searches_for_field_values.2C_tags.2C_and_segments">Secondary searches for field values, tags, and segments</span></a></h3>
<p>The secondary searches can perform the following actions for fields, tags, and event segments. 
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0"> Secondary search action
</th><th bgcolor="#C0C0C0"> Description
</th><th bgcolor="#C0C0C0"> Result
</th></tr><tr><td valign="center" align="left"> Add to search
</td><td valign="center" align="left"> Add a focus on the selected event detail to the original search and run it. Transforming search commands and anything following them are discarded.
</td><td valign="center" align="left"> A dataset similar to the one from the original search, filtered to include only events that have the selected field, tag, or segment(s).
</td></tr><tr><td valign="center" align="left"> Exclude from search
</td><td valign="center" align="left"> Add an exclusion of the selected event detail to the original search and run it. Transforming search commands and anything following them are discarded.
</td><td valign="center" align="left"> A dataset similar to the one from the original search, filtered to include only events that do not have the selected field, tag, or segment(s).
</td></tr><tr><td valign="center" align="left"> New search
</td><td valign="center" align="left"> Run a new search that focuses exclusively on the selected field, tag, or segment(s).
</td><td valign="center" align="left"> A new dataset containing any event that includes the field, tag, or segment(s).
</td></tr></table>.
<p>All of these secondary searches use the same time range as the original search.
</p><p>For example, start with this search. It has a time range of <b>Last 7 days</b>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined status=4*</font></code><br></div>
<p>In the results for that first search, open an event and select the value <code><font size="2">69.72.161.186</font></code> for the <code><font size="2">clientip</font></code> field.
</p><p>If you click <b>Add to search</b>, Splunk Enterprise runs this search over the past 7 days.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined status=4*  clientip="69.72.161.186"</font></code><br></div>
<p>If you click <b>Exclude from search</b>, Splunk Enterprise runs this search over the past 7 days.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined status=4* clientip!="69.72.161.186"</font></code><br></div>
<p>If you click <b>New search</b>, Splunk Enterprise runs this search over the past 7 days.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">clientip="69.72.161.186"</font></code><br></div>
<h4><font size="3"><b><i> <a name="drilldownoneventdetails_run_a_secondary_search_based_on_an_event_segment"><span class="mw-headline" id="Run_a_secondary_search_based_on_an_event_segment">Run a secondary search based on an event segment</span></a></i></b></font></h4>
<p>A <b>segment</b> is a searchable part of an event. See "About segmentation" in the <i>Getting Data In Manual</i> to learn how segments are configured and created.
</p><p><b>1.</b> In the Search &amp; Reporting app, run a search or report that returns an event listing in the <b>Events</b> tab.
</p>
<dl><dd> If your search includes <b>transforming commands</b>, set the <b>Search Mode</b> to <b>Verbose</b>.
</dd></dl><p><b>2.</b> Set the event display to <b>List</b> or <b>Raw</b> if it is currently set to <b>Table</b>.
</p><p><b>3.</b> Find an event with a segment or connected set of segments that you want to base a secondary search on and use your cursor to select it. 
</p>
<dl><dd> Splunk Enterprise identifies your segment selection with yellow highlighting.
</dd></dl><p><b>4.</b> Click on the segment.
</p>
<dl><dd> A set of secondary search options appears. The options are <b>Add to search</b>, <b>Exclude from search</b>, and <b>New search</b>. <a href="#drilldownoneventdetails_secondary_searches_for_field_values.2c_tags.2c_and_segments" class="external text">See the table at the top of this topic</a> for explanations of these options. 
</dd></dl><p><img alt="Eventsecsrch segment.png" src="images/1/12/Eventsecsrch_segment.png" width="278" height="184"></p><p><b>5.</b> Click a secondary search option. 
</p>
<dl><dd> Run the secondary search in the current tab and replace your current search, or run the secondary search in a new tab and leave your current search results intact. To run the search in the current tab, click the option text. To run the search in a new tab, click the <b>Open In New Tab</b> icon <img alt="Secsrch run in sep tab icon.png" src="images/0/01/Secsrch_run_in_sep_tab_icon.png" width="23" height="16"> for the option.
</dd></dl><dl><dd> After running <b>Add to search</b> or <b>New search</b> the matching segment is marked with yellow highlighting in the events returned by the secondary search. This does not happen when you run "Exclude from search" because the events returned by that secondary search do not contain the matching segment.
</dd></dl><p><b>6.</b> (Optional) After running the secondary search, click on a marked segment in an event returned by that search. 
</p>
<dl><dd> Two search options appear for the segment: <b>Remove from search</b> and <b>New search</b>. These operate exactly the same <a href="#drilldownoneventdetails_secondary_searches_for_field_values.2c_tags.2c_and_segments" class="external text">as described in the table at the top of this topic</a>.
</dd></dl><p><img alt="Eventsecsrch segment2.png" src="images/4/43/Eventsecsrch_segment2.png" width="366" height="164"></p><p><b>7.</b> (Optional) Click on an option to run the search.
</p>
<dl><dd> You can run the search in the current tab or run it in a new tab, as described in Step 5.
</dd></dl><p><b>Note:</b> If you replace the results of your current search you can return to them by clicking the back button of your browser.
</p>
<h4><font size="3"><b><i> <a name="drilldownoneventdetails_run_a_secondary_search_based_on_a_field_value"><span class="mw-headline" id="Run_a_secondary_search_based_on_a_field_value">Run a secondary search based on a field value</span></a></i></b></font></h4>
<p>Splunk Enterprise <b>extracts fields</b> from events at index time and search time. See "About fields" in the <i>Knowledge Manager Manual</i>.
</p><p><b>1.</b> In the Search &amp; Reporting app, run a search or report that returns an event listing in the <b>Events</b> tab.
</p>
<dl><dd> If your search includes <b>transforming commands</b>, set the <b>Search Mode</b> to <b>Verbose</b>.
</dd></dl><p><b>2.</b> Locate an event with a field value that you want to use in a secondary search.
</p>
<dl><dd> If your event display is set to <b>List</b> or <b>Table</b> the only field values you can click on without opening the event are for selected fields. If your event display is set to <b>Raw</b> you will not see any field values until you open the event.
</dd></dl><p><b>3.</b> (Optional) Open the event by clicking on the show/hide icon in the <b>i</b> column on the left side of the event display.
</p>
<dl><dd> When the event is opened you see a complete list of fields that Splunk Enterprise extracted from the event.
</dd></dl><p><b>4.</b> Click on the field value.
</p>
<dl><dd> A set of secondary search options appears. The options are <b>Add to search</b>, <b>Exclude from search</b>, and <b>New search</b>. <a href="#drilldownoneventdetails_secondary_searches_for_field_values.2c_tags.2c_and_segments" class="external text">See the table at the top of this topic</a> for explanations of these options. 
</dd></dl><p><img alt="Eventsecsrch fieldvalue.png" src="images/6/6d/Eventsecsrch_fieldvalue.png" width="357" height="349"></p>
<dl><dd> If the value is among the top ten values found for its field, the <b>Add to search</b> and <b>Exclude from search</b> options display the number of events that they can return. 
</dd></dl><p><b>5.</b> Click a secondary search option. 
</p>
<dl><dd> Run the secondary search in the current tab and replace your current search, or run the secondary search in a new tab and leave your current search results intact. To run the search in the current tab, click the option text. To run the search in a new tab, click the <b>Open In New Tab</b> icon <img alt="Secsrch run in sep tab icon.png" src="images/0/01/Secsrch_run_in_sep_tab_icon.png" width="23" height="16"> for the option.
</dd></dl><p><b>Note:</b> If you replace the results of your current search you can return to them by clicking the back button of your browser.
</p>
<h4><font size="3"><b><i> <a name="drilldownoneventdetails_run_a_secondary_search_based_on_a_tag"><span class="mw-headline" id="Run_a_secondary_search_based_on_a_tag">Run a secondary search based on a tag</span></a></i></b></font></h4>
<p><b>Tags</b> are associated with field/value pairs. A tag can be associated with multiple field/value pairs. A field/value pair can be associated with multiple tags. See "About tags and aliases" in the <i>Knowledge Manager Manual</i>.
</p><p><b>1.</b> In the Search &amp; Reporting app, run a search or report that returns an event listing in the <b>Events</b> tab.
</p>
<dl><dd> If your search includes <b>transforming commands</b>, set the <b>Search Mode</b> to <b>Verbose</b>.
</dd></dl><dl><dd> When the event display is set to <b>List</b> and an event is closed, tags appear next to selected fields. 
</dd></dl><p><b>2.</b> (Optional) If the tag you want to run a secondary search for is not associated with one of its selected fields, open the event by clicking on its show/hide icon in the <b>i</b> column the left side of the event listing.
</p>
<dl><dd> When you open an event, tags appear next to field values within parentheses. 
</dd></dl><p><b>3.</b> Click on the tag.
</p>
<dl><dd> A set of secondary search options appears. The options are <b>Add to search</b>, <b>Exclude from search</b>, and <b>New search</b>. <a href="#drilldownoneventdetails_secondary_searches_for_field_values.2c_tags.2c_and_segments" class="external text">See the table at the top of this topic</a> for explanations of these options. 
</dd></dl><p><img alt="Eventsecsrch tag.png" src="images/1/14/Eventsecsrch_tag.png" width="382" height="205"></p><p><b>4.</b> Click a secondary search option. 
</p>
<dl><dd> Run the secondary search in the current tab and replace your current search, or run the secondary search in a new tab and leave your current search results intact. To run the search in the current tab, click the option text. To run the search in a new tab, click the <b>Open In New Tab</b> icon <img alt="Secsrch run in sep tab icon.png" src="images/0/01/Secsrch_run_in_sep_tab_icon.png" width="23" height="16"> for the option.
</dd></dl><p><b>Note:</b> If you replace the results of your current search you can return to them by clicking the back button of your browser.
</p>
<h3> <a name="drilldownoneventdetails_secondary_searches_for_event_timestamps"><span class="mw-headline" id="Secondary_searches_for_event_timestamps">Secondary searches for event timestamps</span></a></h3>
<p>Click on an event <b>timestamp</b> to run a secondary search that can retrieve other events that are chronologically close to that event. This can help you find event correlations and perform root cause analysis. 
</p><p>When you open an event you can also click on the <code><font size="2">_time</font></code> field to run this kind of secondary search. 
</p><p>The controls for this search are called a <b>_time accelerator</b>. See <a href="#usetimeaccelerators" class="external text">"Use time to find nearby events"</a> in this manual for details on how the _time accelerator is used.
</p>
<a name="identifyeventpatterns"></a><h2> <a name="identifyeventpatterns_identify_event_patterns_with_the_patterns_tab"><span class="mw-headline" id="Identify_event_patterns_with_the_Patterns_tab"> Identify event patterns with the Patterns tab</span></a></h2>
<p>Events in search results can be grouped into <b>event patterns</b>. Events that belong to an event pattern share common characteristics, and usually can be returned by a specific search string. Event pattern analysis is useful for searches that return a diverse range of events because it quickly shows you the most common kinds of events in your search result dataset. 
</p><p>The Patterns tab simplifies event pattern identification. Click the Pattern tab to view a list of the most common patterns among the set of events returned by your search. Each of these patterns represents a set of events that share a similar structure.
</p><p>Click on a pattern to:
</p>
<ul><li> View the approximate number of events in your results that fit the pattern. 
</li><li> View the search that returns events with this pattern. 
</li><li> Save the pattern search as an event type, if possible. Not all event patterns can be saved as event types.
</li><li> Create an alert based on the pattern. For example, you can create alerts that trigger when certain patterns increase or decrease in frequency. 
</li></ul><h3> <a name="identifyeventpatterns_an_event_patterns_example"><span class="mw-headline" id="An_event_patterns_example">An event patterns example</span></a></h3>
<p>A search on <code><font size="2">sourcetype=cisco_esa</font></code> runs for the week to date. It returns 55,518 events.
</p><p><img alt="Pattern tab example 1.png" src="images/3/32/Pattern_tab_example_1.png" width="720" height="572"></p><p>Most of these events fit into two patterns: one for threat level notices, and another for a database watcher update.
</p><p>To view all of the patterns in the dataset, open the Patterns tab and drag the slider to the <b>Larger</b> side to return larger event patterns. It returns seven patterns. 
</p><p><img alt="Pattern tab example 2.png" src="images/6/6d/Pattern_tab_example_2.png" width="679" height="523"></p><p>The threat level event pattern is the most common one. Some of the listed patterns are relatively rare in this dataset, and finding them in the Events tab listing might be difficult. The Patterns tab makes it easier to see these event patterns and save them as event types if necessary.
</p>
<h3> <a name="identifyeventpatterns_how_the_patterns_tab_works"><span class="mw-headline" id="How_the_Patterns_tab_works">How the Patterns tab works</span></a></h3>
<p>When you click the Patterns tab, Splunk Enterprise runs a secondary search on a subset of the search results that have been received up to that point. This search job analyzes those results and derives the most common event patterns in those results. It then lists those patterns in descending order from most prevalent to least prevalent. It may not include outlier patterns that are based on extremely small groups of events, because they are statistically unreliable.
</p><p>The secondary search can take a long time to complete when the original dataset contains an extremely large variety of event patterns. For example, some searches return datasets containing over 500 patterns, where most of those patterns represent very small collections of events. The algorithm that identifies these patterns is designed to avoid doing too much work for small patterns, but it also attempts to be as accurate as possible.
</p><p>The Patterns tab only accepts <b>real-time searches</b> and <b>transforming searches</b> when you set their <b>search mode</b> to <b>Verbose</b>.
</p>
<h4><font size="3"><b><i> <a name="identifyeventpatterns_event_pattern_keywords"><span class="mw-headline" id="Event_pattern_keywords">Event pattern keywords</span></a></i></b></font></h4>
<p>The Patterns tab defines patterns by the presence or absence of one or more keywords. If the keywords identified for a pattern are added to or excluded from the original search, the search returns events that fit that pattern. Keywords present in a pattern are identified with green text in the pattern list. Excluded keywords are not identified in the event list.
</p><p>In the preceding event pattern example, the threat level event pattern has "threat" as its keyword, meaning that the search that returns events fitting the pattern would look like this:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=cisco_esa threat</font></code><br></div>
<p>If this event pattern were also identified by the exclusion of the keyword "verified," the search that returns events fitting the pattern would look like this:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=cisco_esa threat ( NOT verified )</font></code><br></div>
<p>To see all of the keywords associated with a pattern, click on the pattern.
</p>
<h3> <a name="identifyeventpatterns_use_the_patterns_tab"><span class="mw-headline" id="Use_the_Patterns_tab">Use the Patterns tab</span></a></h3>
<p><b>1.</b> From the Search view, run a search that returns more than 5000 results. 
</p>
<dl><dd> Searches returning more than 5000 results produce reliable patterns. 
</dd></dl><p><b>2.</b> Click the Patterns tab.
</p>
<dl><dd> You do not need to wait for the search to complete, but the pattern listing is more accurate with finalized search results. 
</dd></dl><p><b>3.</b> (Optional) If there appear to be too many patterns or too few, or if you do not see the patterns you expect, move the slider. 
</p>
<dl><dd> Dragging the slider to <b>Larger</b> runs a secondary search job that consolidates some patterns together, resulting in event patterns that represent larger numbers of events, and a wider variety of events inside each pattern group. 
</dd></dl><dl><dd> Dragging the slider to <b>Smaller</b> runs a secondary search job that increases the granularity of the results. The event patterns it finds represent smaller numbers of events. 
</dd></dl><p><b>4.</b> (Optional) Click on a pattern to view information for that pattern.
</p><p><img alt="Dsh FX patterntab pattern deets.png" src="images/0/05/Dsh_FX_patterntab_pattern_deets.png" width="333" height="292"></p>
<dl><dd> <b>Estimated Events</b> is the estimated count of events in the dataset returned by the original search that fit the event pattern. In this example, the original search had 265k events. This pattern accounts for an estimated 7,350 (2.7%) of those events.
</dd></dl><dl><dd> <b>Included Keywords</b> identifies keywords that should be added to the base search to return the pattern. If the Patterns tab identifies keywords that should be excluded from the base search, they appear under an <b>Excluded Keywords</b> section.
</dd></dl><dl><dd> You can see the search that returns events fitting the event pattern under <b>Search</b>. 
</dd></dl><p><b>5.</b> (Optional) In the pattern information area, click <b>View Events</b> to run the search displayed under <b>Search</b>. 
</p>
<dl><dd> When it runs, this search uses the same time range as your original search. 
</dd></dl><p><b>6.</b> (Optional) In the pattern information area, click <b>Save as event type</b> to save the search as an <b>event type</b>. 
</p>
<dl><dd> <b>Save as event type</b> is available only for event patterns based on searches that do not include pipe characters and additional search commands. See "About event types" in this manual.
</dd></dl><p><b>7.</b> (Optional) In the pattern information area, click <b>Create alert</b> to create an <b>alert</b> based on the pattern. 
</p>
<dl><dd> For example, create a scheduled alert that is triggered when the frequency of the event pattern rises above or drops below a threshold. If you know that events that fit an event pattern tend to appear at a steady rate of approximately 100 events per hour, set the alert to run on an hourly schedule and trigger when 150 or more events are returned. See "'About alerts" in the <i>Alerting Manual</i>.
</dd></dl><h3> <a name="identifyeventpatterns_numbers_in_the_patterns_tab"><span class="mw-headline" id="Numbers_in_the_Patterns_tab">Numbers in the Patterns tab</span></a></h3>
<p>When the secondary search finishes, the Patterns tab displays a message explaining how many events it analyzed to obtain the displayed results.
</p><p>The Patterns tab analyzes a subset of the total number of events returned by the original search. The maximum number of events in this subset is 50k. This maximum reduces processing times for the Pattern tab secondary search. If your original search returns less than 50k events, the secondary search analyzes up to 1000 events per timeline bar spanned by the original search. For example, if the original search spans 14 timeline bars, the secondary search analyzes 14,000 events to obtain its patterns listing. 
</p><p>You can control the maximum number of events analyzed by the secondary search by updating the <code><font size="2">max_events</font></code> setting in <code><font size="2">limits.conf</font></code>. This setting defaults to <code><font size="2">50000</font></code>. Do not change this value. A number less than 50,000 reduces the accuracy of your events. A number higher than 50,000 increases the processing time required by the secondary search. 
</p><p>The estimated event count provided in the pattern information area does not apply to the number of events analyzed in the Patterns tab secondary search. It applies to the total number of events returned by the original search. If an event pattern is estimated to represent 7,350 events and the original search returned 265k events, the pattern accounts for 2.7% of the events returned by the search.
</p>
<h3> <a name="identifyeventpatterns_restricting_patterns_tab_usage"><span class="mw-headline" id="Restricting_Patterns_tab_usage">Restricting Patterns tab usage</span></a></h3>
<p>All roles, including the user role, have permission to use the Patterns tab by default. To restrict usage of the Patterns tab, remove the <code><font size="2">pattern_detect</font></code> <b>capability</b>. Roles without this capability do not see the Patterns tab option after they run a search.
</p><p>For more information about capabilities, see "About defining roles with capabilities" in the <i>Securing Splunk</i> manual.
</p>
<h1>Specify Time Ranges</h1><a name="aboutsearchtimeranges"></a><h2> <a name="aboutsearchtimeranges_about_searching_with_time"><span class="mw-headline" id="About_searching_with_time"> About searching with time </span></a></h2>
<p>Time is crucial for determining what went wrong. You often know when something happened, if not exactly what happened. Looking at events that happened around the same time can help correlate results and find the root cause. Searches run with overly-broad time range wastes system resources and produces more results than you can handle. 
</p><p>This section discusses how to use time to narrow your search.
</p>
<ul><li> <a href="#selecttimerangestoapply" class="external text">Select a time range from the time range menu</a>
</li><li> <a href="#specifytimemodifiersinyoursearch" class="external text">Specify time modifiers in your search</a>
</li><li> <a href="#specifyrealtimewindowsinyoursearch" class="external text">Specify time windows in your real-time search</a>
</li><li> <a href="#usetimeaccelerators" class="external text">Use time to find nearby events</a>
</li></ul><a name="selecttimerangestoapply"></a><h2> <a name="selecttimerangestoapply_select_time_ranges_to_apply_to_your_search"><span class="mw-headline" id="Select_time_ranges_to_apply_to_your_search">Select time ranges to apply to your search </span></a></h2>
<p>Use the <b>time range picker</b> to set time boundaries on your searches. You can restrict the search to Preset time ranges, custom Relative time ranges, and custom Real-time time ranges. You can also specify a Date Range, a Date &amp; Time Range, and use more advanced options for specifying the time ranges for a search.
</p><p><b>Note:</b> If you are located in a different timezone, time-based searches use the timestamp of the event from the instance that indexed the data.
</p>
<h3> <a name="selecttimerangestoapply_select_from_a_list_of_preset_time_ranges"><span class="mw-headline" id="Select_from_a_list_of_Preset_time_ranges">Select from a list of Preset time ranges </span></a></h3>
<p>Out of the box, the time range picker includes many time ranges options that are already defined in the configuration file, <code><font size="2">times.conf</font></code>. You can select from a list of Real-time windows, Relative time ranges, and search over All Time.
</p><p><img alt="6.2 timerange presets.png" src="images/3/3f/6.2_timerange_presets.png" width="500" height="343"></p><p><br></p>
<h3> <a name="selecttimerangestoapply_define_custom_relative_time_ranges"><span class="mw-headline" id="Define_custom_Relative_time_ranges"> Define custom Relative time ranges </span></a></h3>
<p>Use custom Relative time range options to specify a time range for your search that is relative to Now. You can select from the list of time range units, "Seconds ago", "Minutes ago", and so on.
</p><p><img alt="6.2 timerange preset2.png" src="images/e/e0/6.2_timerange_preset2.png" width="500" height="304"></p><p><br>
The labels for <b>Earliest</b> and <b>Latest</b> update to match your selection.
</p><p><img alt="6.2 timerange relative.png" src="images/c/c1/6.2_timerange_relative.png" width="500" height="298"></p><p><br>
The preview boxes below the fields update to the time range as you set it.
</p><p>Read more about Relative time ranges in the next topic, <a href="#specifytimemodifiersinyoursearch" class="external text">"Specify time modifiers in your search"</a>.
</p>
<h3> <a name="selecttimerangestoapply_define_custom_real-time_time_ranges"><span class="mw-headline" id="Define_custom_Real-time_time_ranges"> Define custom Real-time time ranges </span></a></h3>
<p>The custom Real-time option enables you to specify the start time for your real-time time range window.
</p><p><img alt="6.2 timerange realtime.png" src="images/0/0f/6.2_timerange_realtime.png" width="500" height="265"></p><p>Read more about real-time time ranges in the topic <a href="#specifyrealtimewindowsinyoursearch" class="external text">"Specify real-time time range windows in your search"</a>.
</p>
<h3> <a name="selecttimerangestoapply_define_custom_date_ranges"><span class="mw-headline" id="Define_custom_Date_ranges"> Define custom Date ranges </span></a></h3>
<p>Use the custom Date Range option to specify calendar dates in your search. You can choose among options to return events: <b>Between</b> a beginning and end date, <b>Before</b> a date, and <b>Since</b> a date.
</p><p><img alt="6.2 timerange date2.png" src="images/2/20/6.2_timerange_date2.png" width="500" height="237"></p><p>For these fields, you can type the date into the text box or select the date from a calendar:
</p><p><img alt="6.2 timerange date.png" src="images/4/41/6.2_timerange_date.png" width="500" height="335"></p>
<h3> <a name="selecttimerangestoapply_define_custom_date_.26_time_ranges"><span class="mw-headline" id="Define_custom_Date_.26_Time_ranges"> Define custom Date &amp; Time ranges </span></a></h3>
<p>Use the custom Date &amp; Time Range option to specify calendar dates and times for the beginning and ending of your search. 
</p><p><img alt="6.2 timerange datetime.png" src="images/3/3e/6.2_timerange_datetime.png" width="500" height="257"></p><p>You can type the date into the text box or select the date from a calendar.
</p>
<h3> <a name="selecttimerangestoapply_use_advanced_time_range_options"><span class="mw-headline" id="Use_Advanced_time_range_options"> Use Advanced time range options </span></a></h3>
<p>Use the Advanced option to specify the earliest and latest search times. You can write the times in Unix (epoch) time or relative time notation. The epoch time value you enter is converted to local time. This timestamp is displayed under the text field so that you can verify your entry. 
</p><p><img alt="6.2 timerange advanced.png" src="images/e/e2/6.2_timerange_advanced.png" width="500" height="259"></p>
<h3> <a name="selecttimerangestoapply_customize_the_time_ranges_you_can_select"><span class="mw-headline" id="Customize_the_time_ranges_you_can_select"> Customize the time ranges you can select </span></a></h3>
<p>Splunk now ships with more built-in time ranges. Splunk administrators can also customize the set of time ranges that you view and select from the drop down menu when you search. For more information about configuring these new time ranges, see the times.conf reference in the Admin Manual.
</p>
<h3> <a name="selecttimerangestoapply_change_the_default_selected_time_range"><span class="mw-headline" id="Change_the_default_selected_time_range"> Change the default selected time range </span></a></h3>
<p>If you want the time range picker to read something other than "All time" by default, you can change this to another time range. It can be set for a specific user, by setting that user's ui-prefs, or for an entire app. To do this, edit or create the ui-prefs.conf to specify a new default time range. 
</p><p>The following example changes the default time range from <b>All Time</b> to <b>Today</b> within the Search app.
</p>
<code><font size="2"><br>[search]<br>dispatch.earliest_time = @d<br>dispatch.latest_time = now<br></font></code>
<p>If you want to change this default for another view, the stanza name needs to match the dashboard ID for that view. These parameter values are defined using relative time modifiers, which you can read more about in the topic <a href="#specifytimemodifiersinyoursearch" class="external text">"Specify time modifiers in your search"</a>.
</p><p>You would create this in <code><font size="2">$SPLUNK_HOME/etc/apps/search/local/ui-prefs.conf</font></code> if you wanted to add it to the search app, only. If you want to specify the global default, add these paramters to <code><font size="2">$SPLUNK_HOME/etc/system/local/ui-prefs.conf</font></code>. For more information, refer to the ui-prefs.conf reference in the Admin Manual.
</p>
<a name="specifytimemodifiersinyoursearch"></a><h2> <a name="specifytimemodifiersinyoursearch_specify_time_modifiers_in_your_search"><span class="mw-headline" id="Specify_time_modifiers_in_your_search"> Specify time modifiers in your search</span></a></h2>
<p>When searching or saving a search, you can specify absolute and relative time ranges using the following attributes:
</p>
<code><font size="2"><br>earliest=&lt;time_modifier&gt; <br>latest=&lt;time_modifier&gt;<br></font></code>
<h3> <a name="specifytimemodifiersinyoursearch_specify_absolute_time_ranges_in_your_search"><span class="mw-headline" id="Specify_absolute_time_ranges_in_your_search"> Specify absolute time ranges in your search </span></a></h3>
<p>For exact time ranges, the syntax of <code><font size="2">time_modifier</font></code> is: <code><font size="2">%m/%d/%Y:%H:%M:%S</font></code>. For example, to specify a time range from 12AM October 19, 2009 to 12AM October 27, 2009:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">earliest=10/19/2009:0:0:0 latest=10/27/2009:0:0:0</font></code><br></div>
<p>If you specify only the "earliest" attribute, "latest" is set to the current time (<i>now</i>) by default. In general, you won't specify "latest" without an "earliest" time.
</p><p><b>When you specify a time range in your search or saved search, it overrides the time range that is selected in the dropdown menu.</b>  However, the time range specified directly in the search string will not apply to subsearches (but the range selected from the dropdown will apply).
</p>
<h3> <a name="specifytimemodifiersinyoursearch_specify_relative_time_ranges_in_your_search"><span class="mw-headline" id="Specify_relative_time_ranges_in_your_search"> Specify relative time ranges in your search </span></a></h3>
<p>You can define the relative time in your search with a string of characters that indicate time amount (integer and unit) and, optionally, a "snap to" time unit: <code><font size="2">[+|-]&lt;time_integer&gt;&lt;time_unit&gt;@&lt;time_unit&gt;</font></code>. Also, when specifying relative time, you can use <i>now</i> to refer to the current time.
</p><p><b>1.</b> Begin your string with a plus (+) or minus (-) to indicate the offset of the time amount.
</p><p><b>2.</b> Define your time amount with a number and a unit. When you specify single time amounts, the number is implied: 's' is the same as '1s', 'm' is the same as '1m', etc. The supported time units are:
</p>
<ul><li> second: s, sec, secs, second, seconds
</li><li> minute: m, min, minute, minutes
</li><li> hour: h, hr, hrs, hour, hours
</li><li> day: d, day, days
</li><li> week: w, week, weeks
</li><li> month: mon, month, months
</li><li> quarter: q, qtr, qtrs, quarter, quarters
</li><li> year: y, yr, yrs, year, years
</li></ul><p><b>3.</b> You can also specify a "snap to" time unit to indicate the nearest or latest time to which your time amount rounds down. To do this, separate the time amount from the "snap to" time unit with an "@" character. 
</p><p>You can define the relative time modifier as <b>only</b> a "snap to" time unit. For example, to "snap to" a specific day of the week, use @w0 for Sunday, @w1 for Monday, etc.
</p><p>If you don't specify a "snap to" time unit, Splunk snaps automatically <b>to the second</b>.
</p>
<h5> <a name="specifytimemodifiersinyoursearch_special_time_units"><span class="mw-headline" id="Special_time_units"> Special time units </span></a></h5>
<p>These abbreviations are reserved for special cases of time units and snap time offsets.
</p>
<table cellpadding="5" cellspacing="0" border="1" width="100%"><tr><th bgcolor="#C0C0C0">Time Unit
</th><th bgcolor="#C0C0C0">Description
</th></tr><tr><td valign="center" align="left"> <code><font size="2">earliest=1</font></code>
</td><td valign="center" align="left"> If you want to search events from the start of UTC epoch time, use <code><font size="2">earliest=1</font></code>. (<code><font size="2">earliest=0</font></code> in the search string indicates that time is not used in the search.)
<p>When <code><font size="2">earliest=1</font></code> and <code><font size="2">latest=now</font></code> or <code><font size="2">latest=&lt;a large number&gt;</font></code>, the search will run over <b>all time</b>. The difference is that:
</p>
<ul><li> Specifying <code><font size="2">latest=now</font></code> (which is the default) does not return future events.
</li><li> Specifying <code><font size="2">latest=&lt;a big number&gt;</font></code> returns future events, which are events that contain timestamps later than the current time, <code><font size="2">now</font></code>.
</li></ul></td></tr><tr><td valign="center" align="left"> <code><font size="2">latest=now</font></code>
</td><td valign="center" align="left"> Specify that the search starts or ends at the current time.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">@q, @qtr, or @quarter</font></code>
</td><td valign="center" align="left"> Specify a snap to the beginning of the most recent quarter: Jan 1, Apr 1, July 1, or Oct 1.
</td></tr><tr><td valign="center" align="left"> <code><font size="2">w0, w1, w2, w3, w4, w5, and w6</font></code>
</td><td valign="center" align="left"> Specify "snap to" <b>days of the week</b>; where w0 is Sunday, w1 is Monday, etc. When you snap to a week, <code><font size="2">@w</font></code> or <code><font size="2">@week</font></code>, it is equivalent to snapping to Sunday or <code><font size="2">@w0</font></code>.
</td></tr></table><h5> <a name="specifytimemodifiersinyoursearch_more_about_snap-to-time"><span class="mw-headline" id="More_about_snap-to-time"> More about snap-to-time </span></a></h5>
<p>When snapping to the nearest or latest time, Splunk always <b>snaps backwards</b> or rounds down to the latest time not after the specified time. For example, if it is 11:59:00 and you "snap to" hours, you will snap to 11:00 not 12:00. 
</p><p>If you don't specify a time offset before the "snap to" amount, Splunk interprets the time as "current time snapped to" the specified amount. For example, if it is currently 11:59 PM on Friday and you use <code><font size="2">@w6</font></code> to "snap to Saturday", the resulting time is the <i>previous</i> Saturday at 12:01 AM.
</p>
<h3> <a name="specifytimemodifiersinyoursearch_examples_of_relative_time_modifiers"><span class="mw-headline" id="Examples_of_relative_time_modifiers"> Examples of relative time modifiers </span></a></h3>
<p>For these examples, the current time is Wednesday, 05 February 2009, 01:37:05 PM.  Also note that 24h is usually but not always equivalent to 1d because of Daylight Savings Time boundaries.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Time modifier
</th><th bgcolor="#C0C0C0">Description
</th><th bgcolor="#C0C0C0">Resulting time
</th><th bgcolor="#C0C0C0">Equivalent modifiers
</th></tr><tr><td valign="center" align="left">now
</td><td valign="center" align="left">Now, the current time
</td><td valign="center" align="left">Wednesday, 05 February 2009, 01:37:05 PM
</td><td valign="center" align="left">now
</td></tr><tr><td valign="center" align="left">-60m
</td><td valign="center" align="left">60 minutes ago
</td><td valign="center" align="left">Wednesday, 05 February 2009, 12:37:05 PM
</td><td valign="center" align="left">-60m@s
</td></tr><tr><td valign="center" align="left">-1h@h
</td><td valign="center" align="left">1 hour ago, to the hour
</td><td valign="center" align="left">Wednesday, 05 February 2009, 12:00:00 PM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">-1d@d
</td><td valign="center" align="left">Yesterday
</td><td valign="center" align="left">Tuesday, 04 February 2009, 12:00:00 AM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">-24h
</td><td valign="center" align="left">24 hours ago (yesterday)
</td><td valign="center" align="left">Tuesday, 04 February 2009, 01:37:05 PM
</td><td valign="center" align="left">-24h@s
</td></tr><tr><td valign="center" align="left">-7d@d
</td><td valign="center" align="left">7 days ago, 1 week ago today
</td><td valign="center" align="left">Wednesday, 28 January 2009, 12:00:00 AM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">-7d@m
</td><td valign="center" align="left">7 days ago, snap to minute boundary
</td><td valign="center" align="left">Wednesday, 28 January 2009, 01:37:00 PM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">@w0
</td><td valign="center" align="left">Beginning of the current week
</td><td valign="center" align="left">Sunday, 02 February 2009, 12:00:00 AM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">+1d@d
</td><td valign="center" align="left">Tomorrow
</td><td valign="center" align="left">Thursday, 06 February 2009, 12:00:00 AM
</td><td valign="center" align="left">
</td></tr><tr><td valign="center" align="left">+24h
</td><td valign="center" align="left">24 hours from now, tomorrow
</td><td valign="center" align="left">Thursday, 06 February 2009, 01:37:05 PM
</td><td valign="center" align="left">+24h@s
</td></tr></table><h3> <a name="specifytimemodifiersinyoursearch_examples_of_chained_relative_time_offsets"><span class="mw-headline" id="Examples_of_chained_relative_time_offsets"> Examples of chained relative time offsets </span></a></h3>
<p>You can also specify offsets from the snap-to-time or "chain" together the time modifiers for more specific relative time definitions.
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Time modifier
</th><th bgcolor="#C0C0C0">Description
</th><th bgcolor="#C0C0C0">Resulting time
</th></tr><tr><td valign="center" align="left"> @d-2h
</td><td valign="center" align="left"> Snap to the beginning of today (12AM) and subtract 2 hours from that time.
</td><td valign="center" align="left"> 10PM last night.
</td></tr><tr><td valign="center" align="left"> -mon@mon+7d
</td><td valign="center" align="left"> One month ago, snapped to the first of the month at midnight, and add 7 days.
</td><td valign="center" align="left"> The 8th of last month (at 12AM).
</td></tr></table><h3> <a name="specifytimemodifiersinyoursearch_examples_of_searches_with_relative_time_modifiers"><span class="mw-headline" id="Examples_of_searches_with_relative_time_modifiers"> Examples of searches with relative time modifiers </span></a></h3>
<p><b>Example 1:</b> Web access errors from the beginning of the week to the current time of your search (now).
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype=webaccess error earliest=@w0</font></code><br></div> 
<p>This search returns matching events starting from 12:00 AM of the Sunday of the current week to the current time. Of course, this means that if you run this search on Monday at noon, you will only see events for 36 hours of data.
</p><p><br><b>Example 2:</b> Web access errors from the current business week (Monday to Friday).
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype=webaccess error earliest=@w1 latest=+7d@w6</font></code><br></div>
<p>This search returns matching events starting from 12:00 AM of the Monday of the current week and ending at 11:59 PM of the Friday of the current week.
</p><p>If you run this search on Monday at noon, you will only see events for 12 hours of data. Whereas, if you run this search on Friday, you will see events from the beginning of the week to the current time on Friday. The timeline however, will display for the full business week.
</p><p><br><b>Example 3:</b> Web access errors from the last full business week.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype=webaccess error earliest=-7d@w1 latest=@w6</font></code><br></div>
<p>This search returns matching events starting from 12:00 AM of last Monday and ending at 11:59 PM of last Friday.
</p>
<a name="specifyrealtimewindowsinyoursearch"></a><h2> <a name="specifyrealtimewindowsinyoursearch_specify_real-time_time_range_windows_in_your_search"><span class="mw-headline" id="Specify_real-time_time_range_windows_in_your_search"> Specify real-time time range windows in your search</span></a></h2>
<p>Time bounds for historical searches are set at the time the search runs. With real-time searches, the time bounds are constantly updating and by default, the results accumulate from the start of the search. You can also specify a time range that represent a sliding window of data, for example, the last 30 seconds. When you specify a sliding window, Splunk takes that amount of time to accumulate data. For example, if your sliding window is 5 minutes, you will not start to see data until after the first 5 minutes have passed. You can override this behavior so that Splunk backfills the initial window with historical data before running in the normal real-time search mode (see "Real-time backfill," below).
</p>
<h3> <a name="specifyrealtimewindowsinyoursearch_real-time_modifier_syntax"><span class="mw-headline" id="Real-time_modifier_syntax"> Real-time modifier syntax </span></a></h3>
<p>To run a search in real time, you can select from predefined Real-time time range windows in the time range list or you can specify a custom real-time window using <b>Custom time...</b> and selecting <b>Real-time</b>.
</p><p>Time ranges for real-time search follow the same syntax as for historical searches, except that you precede the relative time specifier with "rt", so that it's rt&lt;time_modifier&gt;: <code><font size="2">rt[+|-]&lt;time_integer&gt;&lt;time_unit&gt;@&lt;time_unit&gt;</font></code>. Read about the syntax for time modifiers in the topic, <a href="#specifytimemodifiersinyoursearch" class="external text">"Specify time modifiers in your search"</a>.
</p><p><b>These values are not designed to be used from within the search language (inline with a search string).</b> You can use them in times.conf (to add options to the time range picker), to specify the earliest/latest time ranges in the saved search dialog, or if you were directly using the REST API to access the Splunk back end search engine.
</p><p><b>When you use time range windows with real-time searches, some of the events that occur within the latest second may not display in Splunk.</b> This is expected behavior and is due to the latency between the timestamps within the events and the time when the event arrives. Because the time range window is with respect to the timestamps within the events and not the time when the event arrives, events that arrive after the time window won't display.
</p>
<h3> <a name="specifyrealtimewindowsinyoursearch_real-time_searches_over_.22all_time.22"><span class="mw-headline" id="Real-time_searches_over_.22all_time.22">Real-time searches over "all time"</span></a></h3>
<p>It's important to keep in mind that there is a small difference between real-time searches that take place within a set time window (30 seconds, 1 minute, 2 hours) and real-time searches that are set to "all time." 
</p>
<ul><li> <b>In "windowed" real time searches,</b> the events in the search can disappear as they fall outside of the window, and events that are newer than the time the search job was created can appear in the window when they occur.
</li><li> <b>In "all-time" real-time searches,</b> the window spans all of your events, so events do not disappear once they appear in the window, but events that are newer than the time the search job was created can appear in the window as they occur.
</li><li> In comparison, <b>in historical searches,</b> events never disappear from within the set range of time that you are searching and the latest event is always earlier than the job creation time (with the exception of searches that include events that have future-dated timestamps).
</li></ul><h3> <a name="specifyrealtimewindowsinyoursearch_real-time_backfill"><span class="mw-headline" id="Real-time_backfill">Real-time backfill</span></a></h3>
<p>For real-time windowed searches, you can specify that Splunk backfill the initial window with historical data. This is run as a single search, just in two phases: first, a search on historical data to backfill events; then, a normal real-time search. Real-time backfill ensures that real-time dashboards seeded with data on actual visualizations and statistical metrics over time periods are accurate from the start. 
</p><p>You can enable real-time backfill in <code><font size="2">limits.conf</font></code> in the [realtime] stanza:
</p>
<code><font size="2"><br>[realtime]<br><br>default_backfill = &lt;bool&gt;<br>* Specifies if windowed real-time searches should backfill events<br>* Defaults to true<br></font></code>

<a name="usetimeaccelerators"></a><h2> <a name="usetimeaccelerators_use_time_to_find_nearby_events"><span class="mw-headline" id="Use_time_to_find_nearby_events"> Use time to find nearby events </span></a></h2>
<p>Splunk Enterprise uses <b>timestamps</b> to set the time ranges for searches and to create the <b>timeline</b> in Splunk Web.
</p><p>While searching for errors or troubleshooting an issue, looking at events that happened around the same time can help correlate results and find the root cause. This topic discusses how you can search for surrounding events using an event's timestamp and using the timeline.
</p>
<h3> <a name="usetimeaccelerators_use_time_accelerators"><span class="mw-headline" id="Use_time_accelerators"> Use time accelerators </span></a></h3>
<p>The <code><font size="2">_time</font></code> field represents the timestamp of an event. When you run a search to retrieve events, the timestamp for each event is listed under the <b>Time</b> column. 
</p><p>You can click the timestamp of an event and open a dialog box containing controls, called a  <b>_time accelerator. Use the _time accelerator to run a new search that retrieves events chronologically close to that event.</b>
</p><p><img alt="6.2 time accelerators.png" src="images/3/32/6.2_time_accelerators.png" width="300" height="214"></p><p>You can search for events that occurred before the time, after the time, or at the time of the selected event's timestamp. Some examples are: +/- 30 seconds, +/- 1 hour, +/- 5 seconds, and so on.
</p>
<h3> <a name="usetimeaccelerators_use_the_timeline"><span class="mw-headline" id="Use_the_timeline"> Use the timeline </span></a></h3>
<p>The timeline is a histogram of the number of events returned by a Splunk search over a chosen time range. The time range is broken up into smaller time intervals (such as seconds, minutes, hours, or days), and the count of events for each interval is displayed as a column.
</p><p>The location of each column on the timeline corresponds to an instance when the events that match your search occurred. If there are no columns at a time period, no events were found then. The taller the column, the more events occurred at that time. 
</p><p>Spikes in the number of events or no events along the timeline can indicate time periods that you want to investigate.
</p><p>The timeline has <b>drilldown</b> functionality similar to the table and chart drilldown. When you click on a column in the timeline, your search results update to show only the events represented by the column. If you double-click on a column, you re-run the search over the time range represented by the column. Then, you can search for all surrounding events at this time range.
</p>
<h1>Subsearches</h1><a name="aboutsubsearches"></a><h2> <a name="aboutsubsearches_about_subsearches"><span class="mw-headline" id="About_subsearches"> About subsearches</span></a></h2>
<p>A subsearch is a search with a search pipeline as an argument. Subsearches are contained in square brackets and are evaluated first. The result of the subsearch is then used as an argument in the primary or outer search. Subsearches are mainly used for two purposes:
</p>
<ul><li> Parameterize one search, using the output of another search. For example, find every record from IP addresses that visited some specific URL.
</li><li> Run a separate search, and add the output to the first search using the <code><font size="2">append</font></code> command.
</li></ul><p>A subsearch can be used only where the explicit action that you are trying to accomplish is  with the search and not a transformation of the data. For example, you cannot use a subsearch with "<code><font size="2">sourcetype=top | multikv</font></code>", because the <code><font size="2">multikv</font></code> command does not expect a subsearch as an argument. Certain commands, such as <code><font size="2">append</font></code> and <code><font size="2">join</font></code> can accept a subsearch as an argument. 
</p>
<h3> <a name="aboutsubsearches_a_subsearch_example"><span class="mw-headline" id="A_subsearch_example"> A subsearch example </span></a></h3>
<p>The following is an example of using a subsearch to parameterize one search.  You are interested in finding all events from the <b>most active host in the last hour</b>; but, you can't search for a specific host because it might not be the same host every hour. First, you need to identify which host is most active.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=syslog earliest=-1h | top limit=1 host | fields + host</font></code><br></div>
<p>This search will only return one host value. In this example, the result is the host named "crashy". Now, you can search for all the events coming from "crashy":
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=syslog host=crashy</font></code><br></div>
<p>But, instead of running two searches each time you want this information, you can use a subsearch to give you the hostname and pass it to the outer search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=syslog  [search sourcetype=syslog earliest=-1h | top limit=1 host | fields + host]</font></code><br></div>
<h3> <a name="aboutsubsearches_performance_of_subsearches"><span class="mw-headline" id="Performance_of_subsearches"> Performance of subsearches </span></a></h3>
<p>If your subsearch returns a large table of results, it will impact the performance of your search. You can change the number of results that the format command operates over inline with your search by appending the following to the end of your subsearch: <code><font size="2">| format maxresults = &lt;integer&gt;</font></code> . For more information, see the "format" command in the <i>Search Reference</i>. 
</p><p>You can also control the subsearch with settings in <code><font size="2">limits.conf</font></code> for the runtime and maximum number of results returned:
</p>
<div class="samplecode">
<p>[subsearch] <br>
maxout = &lt;integer&gt;
</p>
<ul><li> Maximum number of results to return from a subsearch.
</li><li> This value cannot be greater than or equal to 10500.
</li><li> Defaults to 10000.
</li></ul><p>maxtime = &lt;integer&gt;
</p>
<ul><li> Maximum number of seconds to run a subsearch before finalizing
</li><li> Defaults to 60.
</li></ul><p>ttl = &lt;integer&gt;
</p>
<ul><li> Time to cache a given subsearch's results, in seconds.
</li><li> Do not set this below 120 seconds. 
</li><li> Defaults to 300.
</li></ul></div>
<p>After running a search you can click the <b>Job</b> menu and select <i>Inspect Job</i> to open the Search Job Inspector. Scroll down to the <code><font size="2">remoteSearch</font></code> component, and you can see what the actual query that resulted from your subsearch. For more information, see "View search job properties with the Search Job Inspector" in the <i>Knowledge Manager</i> manual.
</p>
<h3> <a name="aboutsubsearches_result_output_settings_for_subsearch_commands"><span class="mw-headline" id="Result_output_settings_for_subsearch_commands"> Result output settings for subsearch commands </span></a></h3>
<p><code><font size="2">Limits.conf.spec</font></code> indicates that subsearches return a maximum of 100 results by default. You will see variations in the actual number of output results because every command can change what the default <code><font size="2">maxout</font></code> is when it invokes a subsearch. Additionally, the default <code><font size="2">maxout only</font></code> applies to subsearches that are intended to be expanded into a search expression, which is not the case for some commands such as join, append, and appendcols. 
</p>
<ul><li> For example, the append command overrides that default to be the value of <code><font size="2">maxresultrows</font></code>, unless the user has specified a <code><font size="2">maxout</font></code> as an argument to append.
</li><li> The output limit of the join command is controlled by <code><font size="2">subsearch_maxout</font></code> in limits.conf. This defaults to 50000 events.
</li></ul><h3> <a name="aboutsubsearches_answers"><span class="mw-headline" id="Answers"> Answers </span></a></h3>
<p>Have questions? Visit Splunk Answers and see what questions and answers the Splunk community has about using subsearches.
</p>
<a name="usesubsearchtocorrelateevents"></a><h2> <a name="usesubsearchtocorrelateevents_use_subsearch_to_correlate_events"><span class="mw-headline" id="Use_subsearch_to_correlate_events"> Use subsearch to correlate events</span></a></h2>
<p>A subsearch takes the results from one search and uses the results in another search. This enables sequential state-like data analysis. You can use subsearches to correlate data and evaluate events in the context of the whole event set, including data across different indexes or Splunk servers in a distributed environment.
</p><p>For example, you have two or more indexes for different application logs. The event data from these logs share at least one common field. You can use the values of this field to search for events in one index based on a value that is not in another index:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=some_sourcetype NOT [search sourcetype=another_sourcetype | fields field_val]</font></code><br></div>
<p><b>Note:</b> This is equivalent to the SQL "NOT IN" functionality:
</p>
<div class="samplecode">
<p>SELECT * from some_table <br>
WHERE field_value  <br>
NOT IN (SELECT field_value FROM another_table)
</p>
</div>

<a name="changetheformatofsubsearchresults"></a><h2> <a name="changetheformatofsubsearchresults_change_the_format_of_subsearch_results"><span class="mw-headline" id="Change_the_format_of_subsearch_results"> Change the format of subsearch results</span></a></h2>
<p>When you use a subsearch, the <code><font size="2">format</font></code> command is implicitly applied to your subsearch results. The format command changes your subsearch results into a single linear search string. This is used when you want to pass the returned values in the returned fields into the primary search. 
</p><p>If your subsearch returned a table, such as:
</p>
<code><font size="2"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| field1 &nbsp;| field2 &nbsp;|<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------------------<br>event/row1 | val1_1 &nbsp;| val1_2 &nbsp;|<br>event/row2 | val2_1 &nbsp;| val2_2 &nbsp;| <br></font></code>
<p>The format command returns: 
</p>
<code><font size="2"><br>(field1=val1_1 AND field2=val1_2) OR (field1=val2_1 AND field2=val2_2) &nbsp;<br></font></code> 
<p>For more information, see the format search command reference.
</p>
<h3> <a name="changetheformatofsubsearchresults_the_search_and_query_fields"><span class="mw-headline" id="The_search_and_query_fields"> The search and query fields </span></a></h3>
<p>There are a couple of exceptions to this. First, all internal fields (fields that begin with a leading underscore "_*") are ignored and not reformatted in this way. Second, the "search" and "query" fields have their values rendered directly in the reformatted search string. 
</p><p><b>Using "search"</b>
</p><p>Generally, "search" can be useful when you need to append some static data or do some <code><font size="2">eval</font></code> on the data in your subsearch and then pass it to the primary search. When you use "search", the first value of the field is used as the actual search term. For example, if field2 was "search" (in the table above), the format command returns:
</p>
<code><font size="2"><br>(field1=val1_1 AND val1_2) OR (field1=val2_1 AND val2_2)<br></font></code>
<p>You can also use "search" to modify the actual search string that gets passed to the primary search. 
</p><p><b>Using "query"</b>
</p><p>"Query" is useful when you are looking for the values in the fields returned from the subsearch, but not in these exact fields. The "query" field behaves similarly to format. Instead of passing the field/value pairs, as you see with <code><font size="2">format</font></code>, it passes the values:
</p>
<code><font size="2"><br>(val1_1 AND val1_2) OR (val2_1 AND val2_2) <br></font></code>
<h3> <a name="changetheformatofsubsearchresults_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p>The following searches for a <code><font size="2">clID</font></code> associated with a specific <code><font size="2">Name</font></code>. This value is then used to search for several sources.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index="myindex" [search index="myindex" host="myhost" &lt;Name&gt; | top limit=1 clID | fields + clID ]</font></code><br></div>
<p>The subsearch returns the field and value in the format: <code><font size="2">( (clID="0050834ja") )</font></code>
</p><p>If you want to return only the value, <code><font size="2">0050834ja</font></code>, rename the clID field to "search" in the subsearch:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=myindex [search index=myindex host=myhost MyName | top limit=1 clID | fields + clID | rename clID as search ]</font></code><br></div>
<p>If the field is named search (or query) the field name (in this case, clID) is dropped and the subsearch (technically, the implicit <code><font size="2">| format</font></code> command at the end of the subsearch) returns only the value ( ( 0050834ja ) ). If you have multiple values (in the previous search, the top command limits the search result to 1), the subsearch returns each of the values ORed together. For example, the result for three values is <code><font size="2">( ( value1 ) OR ( value2 ) OR ( value3 ) )</font></code>.
</p><p>This is a special case only when the field is named either "search" or "query". Renaming your fields to anything else will make the subsearch use the new field names.
</p>
<h1>Create Statistical Tables and Chart Visualizations</h1><a name="aboutreportingcommands"></a><h2> <a name="aboutreportingcommands_about_transforming_commands_and_searches"><span class="mw-headline" id="About_transforming_commands_and_searches"> About transforming commands and searches </span></a></h2>
<p>This topic discusses how to create reports using <b>transforming searches</b>. A transforming search is a <b>search</b> that uses <b>transforming commands</b> to transform event data returned by a search into statistical data tables required for charts and other kinds of data visualizations. 
</p>
<h3> <a name="aboutreportingcommands_a_transforming_command_primer"><span class="mw-headline" id="A_transforming_command_primer"> A transforming command primer </span></a></h3>
<p>This subsection covers the major categories of transforming commands and provides examples of how they can be used in a search. 
</p><p>The primary transforming commands are:
</p>
<ul><li> <code><font size="2">chart</font></code>: used to create charts that can display any <b>series</b> of data that you want to plot. You can decide what field is tracked on the x-axis of the chart.
</li><li> <code><font size="2">timechart</font></code>: used to create "trend over time" reports, which means that <code><font size="2">_time</font></code> is always the x-axis.
</li><li> <code><font size="2">top</font></code>: generates charts that display the most common values of a field.
</li><li> <code><font size="2">rare</font></code>: creates charts that display the least common values of a field.
</li><li> <code><font size="2">stats</font></code>, <code><font size="2">eventstats</font></code>, and <code><font size="2">streamstats</font></code>: generate reports that display summary statistics.
</li><li> <code><font size="2">associate</font></code>, <code><font size="2">correlate</font></code>, and <code><font size="2">diff</font></code>: create reports that enable you to see associations, correlations, and differences between fields in your data. 
</li></ul><p><b>Note:</b> As you'll see in the following examples, you always place your transforming commands after your search commands, linking them with a <b>pipe operator</b> ("|").
</p><p><code><font size="2">chart</font></code>, <code><font size="2">timechart</font></code>, <code><font size="2">stats</font></code>, <code><font size="2">eventstats</font></code>, and <code><font size="2">streamstats</font></code> are all designed to work in conjunction with statistical functions. The list of available statistical functions includes:
</p>
<ul><li> count, distinct count
</li><li> mean, median, mode
</li><li> min, max, range, percentiles
</li><li> standard deviation, variance
</li><li> sum
</li><li> first occurrence, last occurrence 
</li></ul><p>To find more information about statistical functions and how they're used, see "Functions for stats, chart, and timechart" in the Search Reference Manual. Some statistical functions only work with the <code><font size="2">timechart</font></code> command.
</p><p><b>Note:</b> All searches with transforming commands generate specific structures of data. The different chart types available in Splunk require these data structures to be set up in particular ways. For example not all searches that enable the generation of bar, column, line, and area charts <i>also</i> enable the generation of pie charts. Read the "Data structure requirements for visualizations" topic in the Splunk Data Visualizations Manual to learn more.
</p>
<h3> <a name="aboutreportingcommands_real-time_reporting"><span class="mw-headline" id="Real-time_reporting"> Real-time reporting </span></a></h3>
<p>You can use Splunk's real-time search to calculate metrics in real-time on large incoming data flows without the use of summary indexing. However, because you are reporting on a live and continuous stream of data, the timeline will update as the events stream in and you can only view the table or chart in preview mode. Also, some search commands will be more applicable (for example, streamstats and rtorder) for use in real-time.
</p>
<a name="createtimebasedcharts"></a><h2> <a name="createtimebasedcharts_create_time-based_charts"><span class="mw-headline" id="Create_time-based_charts"> Create time-based charts </span></a></h2>
<p>This topic discusses using the <b>transforming command</b>, timechart, to create time-based reports. 
</p>
<h3> <a name="createtimebasedcharts_the_timechart_command"><span class="mw-headline" id="The_timechart_command"> The timechart command </span></a></h3>
<p>The timechart command generates a table of summary statistics which can then be formatted as a chart visualization where your data is plotted against an x-axis that is always a time field. Use timechart to display statistical trends over time, with the option of splitting the data with another field as a separate series in the chart. Timechart visualizations are usually line, area, or column charts.
</p>
<h3> <a name="createtimebasedcharts_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p><b>Example 1:</b> This report uses internal Splunk log data to visualize the average indexing thruput (indexing kbps) of Splunk processes over time, broken out by processor: 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=_internal "group=thruput" | timechart avg(instantaneous_eps) by processor</font></code><br></div>

<a name="createnontimebasedcharts"></a><h2> <a name="createnontimebasedcharts_create_charts_that_are_not_.28necessarily.29_time-based"><span class="mw-headline" id="Create_charts_that_are_not_.28necessarily.29_time-based"> Create charts that are not (necessarily) time-based </span></a></h2>
<p>This topic discusses using the <b>transforming command</b>, chart, to create visualizations that are not time-based. 
</p>
<h3> <a name="createnontimebasedcharts_the_chart_command"><span class="mw-headline" id="The_chart_command"> The chart command </span></a></h3>
<p>The chart command returns your results in a data structure that supports visualization of your data series as a chart such as a column, line, area, and pie chart.
</p><p>Unlike the <code><font size="2">timechart</font></code> command, which uses the <code><font size="2">_time</font></code> <b>default field</b> as the x-axis, charts created with the <code><font size="2">chart</font></code> command use an arbitrary field as the x-axis. With the chart command, you use the <code><font size="2">over</font></code> keyword to determine what field takes the x-axis.
</p>
<h3> <a name="createnontimebasedcharts_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p><b>Example 1:</b> Use web access data to show you the average count of unique visitors over each weekday.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | chart avg(clientip) over date_wday</font></code><br></div>
<p>One of the options you have is to split the data by another field, meaning that each distinct value of the "split by" field is a separate series in the chart. If your search includes a "split by" clause, place the <code><font size="2">over</font></code> clause before the "split by" clause. 
</p><p>The following report generates a chart showing the sum of kilobytes processed by each <code><font size="2">clientip</font></code> within a given timeframe, split by <code><font size="2">host</font></code>. The finished chart shows the <code><font size="2">kb</font></code> value taking the y-axis while <code><font size="2">clientip</font></code> takes the x-axis. The delay value is broken out by host. After you run this search, format the report as a stacked bar chart.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | chart sum(kb) over clientip by host</font></code><br></div>
<p><b>Example 2:</b> Create a stacked bar chart that splits out the http and https requests hitting your servers. 
</p><p>To do this, first create <code><font size="2">ssl_type</font></code>, a search-time <b>field extraction</b> that contains the inbound port number or the incoming URL request, assuming that it is logged. The finished search would look like this:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | chart count over ssl_type</font></code><br></div>
<p>After you run the search, format the results as a stacked bar chart.
</p>
<a name="visualizefieldvaluehighsandlows"></a><h2> <a name="visualizefieldvaluehighsandlows_visualize_field_value_highs_and_lows"><span class="mw-headline" id="Visualize_field_value_highs_and_lows"> Visualize field value highs and lows</span></a></h2>
<p>This topic discusses how to use the <b>transforming commands</b>, top and rare, to create charts that display the most and least common values.
</p>
<h3> <a name="visualizefieldvaluehighsandlows_the_top_and_rare_commands"><span class="mw-headline" id="The_top_and_rare_commands"> The top and rare commands </span></a></h3>
<p>The top command returns the most frequent values of a specified field in your returned events. The rare command, returns the least common value of a specified field in your returned events. Both commands share the same syntax. If you don't specify a limit, the default number of values displayed in a <code><font size="2">top</font></code> or <code><font size="2">rare</font></code> is ten.
</p><p><br></p>
<h3> <a name="visualizefieldvaluehighsandlows_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p><b>Example 1:</b> Generate a report that sorts through firewall information to list the top 100 destination ports used by your system: 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=firewall | top limit=100 dst_port</font></code><br></div>
<p><b>Example 2:</b> Generate a report that shows you the source ports with the lowest number of denials. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=firewall action=Deny | rare src_port</font></code><br></div>
<h3> <a name="visualizefieldvaluehighsandlows_a_more_complex_example_of_the_top_command"><span class="mw-headline" id="A_more_complex_example_of_the_top_command">A more complex example of the top command</span></a></h3>
<p>Say you're indexing an alert log from a monitoring system, and you have two fields: 
</p>
<ul><li> <code><font size="2">msg</font></code> is the message, such as <code><font size="2">CPU at 100%</font></code>.
</li><li> <code><font size="2">mc_host</font></code> is the host that generates the message, such as <code><font size="2">log01</font></code>.
</li></ul><p>How do you get a report that displays the top <code><font size="2">msg</font></code> and the values of <code><font size="2">mc_host</font></code> that sent them, so you get a table like this:
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><td valign="center" align="left"><b>Messages by mc_host</b>
</td></tr><tr><td valign="center" align="left">CPU at 100%
</td></tr><tr><td valign="center" align="left">log01
</td></tr><tr><td valign="center" align="left">log02
</td></tr><tr><td valign="center" align="left">log03
</td></tr><tr><td valign="center" align="left">Log File Alert
</td></tr><tr><td valign="center" align="left">host02
</td></tr><tr><td valign="center" align="left">host56
</td></tr><tr><td valign="center" align="left">host11
</td></tr></table><p>To do this, set up a search that finds the top <code><font size="2">message</font></code> per <code><font size="2">mc_host</font></code> (using <code><font size="2">limit=1</font></code> to only return one) and then <code><font size="2">sort</font></code> by the message <code><font size="2">count</font></code> in descending order:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=alert_log | top 1 msg by mc_host | sort count</font></code><br></div>

<a name="createreportsthatdisplaysummarystatistics"></a><h2> <a name="createreportsthatdisplaysummarystatistics_create_reports_that_display_summary_statistics"><span class="mw-headline" id="Create_reports_that_display_summary_statistics"> Create reports that display summary statistics</span></a></h2>
<p>This topic discusses using the stats and eventstats <b>transforming commands</b> to create reports that display summary statistics related to a field. 
</p>
<h3> <a name="createreportsthatdisplaysummarystatistics_the_stats_and_eventstats_commands"><span class="mw-headline" id="The_stats_and_eventstats_commands"> The stats and eventstats commands </span></a></h3>
<p>The <code><font size="2">eventstats</font></code> command works in exactly the same manner as the <code><font size="2">stats</font></code> command, except that the aggregation results of the command are added inline to each event, and only the aggregations that are pertinent to each event. 
</p>
<h4><font size="3"><b><i> <a name="createreportsthatdisplaysummarystatistics_using_split-by_clauses"><span class="mw-headline" id="Using_split-by_clauses"> Using split-by clauses </span></a></i></b></font></h4>
<p>To fully utilize the <code><font size="2">stats</font></code> command, you need to include a "split by" clause. For example, the following report won't provide much information:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined | stats avg(kbps)</font></code><br></div>
<p>It gives you the average of <code><font size="2">kbps</font></code> for all events with a sourcetype of <code><font size="2">access_combined</font></code>--a single value. The resulting column chart contains only one column. 
</p><p>But if you break out the report with a split by field, Splunk generates a report that breaks down the statistics by that field. The following report generates a column chart that sorts through the <code><font size="2">access_combined</font></code> logs to get the average thruput (kbps), broken out by host:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined | stats avg(kbps) by host</font></code><br></div>
<h3> <a name="createreportsthatdisplaysummarystatistics_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<p><b>Example 1:</b> Create a report that shows you the CPU utilization of Splunk processes sorted in descending order:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=_internal "group=pipeline" | stats sum(cpu_seconds) by processor | sort sum(cpu_seconds) desc</font></code><br></div>
<p><br><b>Example 2:</b> Create a report to display the average kbps for all events with a sourcetype of <code><font size="2">access_combined</font></code>, broken out by host.
</p><p>You specify the field name for the <code><font size="2">eventstats</font></code> results by adding the <code><font size="2">as</font></code> argument. So the first example above could be restated with "avgkbps" being the name of the new field that contains the results of the <code><font size="2">eventstats avg(kbps)</font></code> operation:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined | eventstats avg(kbps) as avgkbps by host</font></code><br></div>
<p>When you run this set of commands, Splunk adds a new <code><font size="2">avgkbps</font></code> field to each <code><font size="2">sourcetype=access_combined</font></code> event that includes the <code><font size="2">kbps</font></code> field. The value of <code><font size="2">avgkbps</font></code> is the average kbps for that event.
</p>
<a name="findassociationsinfieldvalues"></a><h2> <a name="findassociationsinfieldvalues_look_for_associations.2c_statistical_correlations.2c_and_differences_in_search_results"><span class="mw-headline" id="Look_for_associations.2C_statistical_correlations.2C_and_differences_in_search_results"> Look for associations, statistical correlations, and differences in search results </span></a></h2>
<p>This topic discusses <b>transforming commands</b> that find associations, similarities, and differences among field values in your search results.
</p>
<h3> <a name="findassociationsinfieldvalues_the_associate_command"><span class="mw-headline" id="The_associate_command"> The associate command </span></a></h3>
<p>The associate command identifies events that are associated with each other through field/field value pairs. For example, if one event has a <code><font size="2">referer_domain</font></code> of "http://www.google.com/" and another event has a <code><font size="2">referer_domain</font></code> with the same URL value, then they are associated. 
</p><p>"Tune" the results gained by the <code><font size="2">associate</font></code> command with the <i>supcnt</i>, <i>supfreq</i>, and <i>improv</i> arguments. For more information about these arguments see the associate command reference topic.
</p><p><b>Example:</b> Search the web access sourcetypes and identify events that share at least three field/field-value pair associations. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access* | associate supcnt=3</font></code><br></div>
<h3> <a name="findassociationsinfieldvalues_the_correlate_command"><span class="mw-headline" id="The_correlate_command"> The correlate command </span></a></h3>
<p>The correlate command calculates the statistical correlation between fields. It uses the <code><font size="2">cocur</font></code> operation to calculate the percentage of times that two fields exist in the same set of results.
</p><p><i>Example:'</i> Search across all events where <code><font size="2">eventtype=goodaccess</font></code>, and calculates the co-occurrence correlation between all of those fields. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype=goodaccess | correlate type=cocur</font></code><br></div>
<h3> <a name="findassociationsinfieldvalues_the_diff_command"><span class="mw-headline" id="The_diff_command"> The diff command </span></a></h3>
<p>Use the diff command to compare the differences between two search results. By default it compares the raw text of the search results you select, unless you use the <i>attribute</i> argument to focus on specific field attributes. 
</p><p><b>Example:</b> Compare the IP addresses for the 44th and 45th events returned in the search.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype=goodaccess | diff pos1=44 pos2=45 attribute=ip</font></code><br></div>

<a name="chartmultipledataseries"></a><h2> <a name="chartmultipledataseries_build_a_chart_of_multiple_data_series"><span class="mw-headline" id="Build_a_chart_of_multiple_data_series"> Build a chart of multiple data series</span></a></h2>
<p>Splunk Enterprise <b>transforming commands</b> do not support a direct way to define multiple data <b>series</b> in your charts (or timecharts). However, you CAN achieve this using a combination of the <code><font size="2">stats</font></code> and <code><font size="2">xyseries</font></code> commands. 
</p><p>The <code><font size="2">chart</font></code> and <code><font size="2">timechart</font></code> commands both return tabulated data for graphing, where the x-axis is either some arbitrary field or <code><font size="2">_time</font></code>, respectively. When these commands are used with a split-by field, the output is a table where each column represents a distinct value of the split-by field. 
</p><p>In contrast, the <code><font size="2">stats</font></code> command produces a table where each row represents a single unique combination of the values of the group-by fields. You can then use the <code><font size="2">xyseries</font></code> command to redefine your data series for graphing.
</p><p>For most cases, you can simulate the results of "... | chart n by x,y" with "... | stats n by x,y | xyseries x y n". (For the <code><font size="2">timechart</font></code> equivalent of results, x = <code><font size="2">_time</font></code>.)
</p>
<h3> <a name="chartmultipledataseries_scenario"><span class="mw-headline" id="Scenario"> Scenario </span></a></h3>
<p>Let's say you want to report on data from a cluster of application servers. The events gathered from each server contain information such as counts of active sessions, requests handled since last update, etc. and are placed in the <code><font size="2">applications_servers</font></code> index. You want to display each server instance and the number of sessions per instance on the same timechart so that you can compare the distributions of sessions and load.
</p><p>Ideally, you want to be able to run a timechart report, such as:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=application_servers | timechart sum(handledRequests) avg(sessions) by source</font></code><br></div>
<p>However, timechart does not support multiple data series; so instead, you need run a search similar to the following:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=application_servers | stats sum(handledRequests) as hRs, avg(sessions) as ssns by _time,source | eval s1="handledReqs sessions" | makemv s1 | mvexpand s1 | eval yval=case(s1=="handledReqs",hRs,s1=="sessions",ssns) | eval series=source+":"+s1 | xyseries _time,series,yval</font></code><br></div>
<h3> <a name="chartmultipledataseries_walkthrough"><span class="mw-headline" id="Walkthrough"> Walkthrough </span></a></h3>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | stats sum(handledRequests) as hRs, avg(sessions) as ssns by _time,source</font></code><br></div>
<p>This uses the <code><font size="2">stats</font></code> command to calculate statistics for each source value: The sum of <code><font size="2">handledRequests</font></code> values are renamed as <code><font size="2">hRs</font></code>, and the average number of <code><font size="2">sessions</font></code> are renamed as <code><font size="2">ssns</font></code>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval s1="handledReqs sessions" | makemv s1 | mvexpand s1</font></code><br></div>
<p>This uses the <code><font size="2">eval</font></code> command to add a single-valued field "s1" to each result from the stats command. Then, the makemv command converts sl into a multivalued field, where the first value is "handleReqs" and the second value is "sessions".  The mvexpand then creates separate series for each value of s1.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval yval=case(s1=="handledReqs",hRs,s1=="sessions",ssns)</font></code><br></div>
<p>This uses the eval command to define a new field, yval, and assign values to it based on the case that it matches. So, if the value of s1 is "handledReqs", yval is assigned the "hRs" value. And, if the value of s1 is "sessions", yval is assigned the "ssns" value.  
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval series=source+":"+s1</font></code><br></div>
<p>This uses the eval command to define a new field, series, which concatenates the value of the host and s1 fields. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | xyseries _time,series,yval</font></code><br></div>
<p>Finally, the xyseries command is used to define a chart with _time on the x-axis, yval on the y-axis, and data defined by series.
</p>
<a name="comparehourlysumsmultipledays"></a><h2> <a name="comparehourlysumsmultipledays_compare_hourly_sums_across_multiple_days"><span class="mw-headline" id="Compare_hourly_sums_across_multiple_days"> Compare hourly sums across multiple days</span></a></h2>
<p>The <code><font size="2">timechart command</font></code> creates charts that show trends over time. It has strict boundaries limiting what it can do. There are times when you should use the <code><font size="2">chart command</font></code> command, which can provide more flexibility. 
</p><p>This example demonstrates how to use <code><font size="2">chart</font></code> to compare values collected over several days. You cannot do this with <code><font size="2">timechart</font></code>
</p>
<h3> <a name="comparehourlysumsmultipledays_scenario"><span class="mw-headline" id="Scenario">Scenario</span></a></h3>
<p>These two searches are almost identical. They both show the hourly sum of the <code><font size="2">P</font></code> field over a 24-hour period. The only difference is that one search covers a period ten days in the past, while the other covers a period nine days into the past:
</p><p>Search 1:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">earliest=-10d latest=-9d | timechart span="1h" sum(P)</font></code><br></div>
<p>Search 2:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">earliest=-9d latest=-8d | timechart span="1h" sum(P)</font></code><br></div>
<p>Create a column chart that combines the results of these two searches, so you can see the sum of <code><font size="2">P</font></code> for 3pm, ten days ago side-by-side with the sum of <code><font size="2">P</font></code> for 3pm, nine days ago. 
</p><p><br></p>
<h3> <a name="comparehourlysumsmultipledays_solution"><span class="mw-headline" id="Solution">Solution</span></a></h3>
<p>Using the chart command, set up a search that covers both days. Then, create a "sum of P" column for each distinct <code><font size="2">date_hour</font></code> and <code><font size="2">date_wday</font></code> combination found in the search results. 
</p><p>The finished search looks like this:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">earliest=-10d latest=-8d | chart sum(P) by date_hour date_wday</font></code><br></div>
<p>This produces a single chart with 24 slots, one for each hour of the day. Each slot contains two columns that enable you to compare hourly sums between the two days covered by the time range of the report.
</p><p>For a primer on reporting searches and how they're constructed, see <a href="#aboutreportingcommands" class="external text">"Use reporting commands"</a> in the User Manual.
</p><p>For more information about <code><font size="2">chart&gt;</font></code> and <code><font size="2">timechart</font></code> functions, see "Functions for stats, chart, and timechart" in the Search Reference Manual.
</p>
<a name="drilldownonstatisticaltablerowsandcells"></a><h2> <a name="drilldownonstatisticaltablerowsandcells_run_a_secondary_search_on_table_row_or_cell_information"><span class="mw-headline" id="Run_a_secondary_search_on_table_row_or_cell_information"> Run a secondary search on table row or cell information </span></a></h2>
<p>After running a transforming search that returns a table in the <b>Statistics</b> tab, click on a row or cell of that table to run different kinds of secondary searches. 
</p><p>Splunk Enterprise offers a range of possible secondary search actions for table rows and cells. These actions focus on the field/value pairs represented by the row or cell. 
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0"> Secondary search action
</th><th bgcolor="#C0C0C0"> Description
</th><th bgcolor="#C0C0C0"> Time range
</th><th bgcolor="#C0C0C0"> Result
</th></tr><tr><td valign="center" align="left"> View events
</td><td valign="center" align="left"> Run a search that shows only the events from the original dataset that include the field/value pair(s). Discard all piped search commands.
</td><td valign="center" align="left"> Same as the original search, unless you are clicking on a cell or row that represents a specific span of time, in which case the secondary search uses that span as its time range.
</td><td valign="center" align="left"> An event list similar to the one returned by the original search, filtered to include only events that have the field/value pairs.
</td></tr><tr><td valign="center" align="left"> Other events
</td><td valign="center" align="left"> Run a search that shows only the events from the original dataset that do not include the field/value pair(s). Discard transforming search commands and any commands that follow them.
</td><td valign="center" align="left"> Same as original search.
</td><td valign="center" align="left"> An event list similar to the one from the original search, filtered to include only events that do not have the field/value pair(s).
</td></tr><tr><td valign="center" align="left"> Exclude from results
</td><td valign="center" align="left"> Rerun the original search including all piped search commands. Omit events that include the field/value pair.
</td><td valign="center" align="left"> Same as original search.
</td><td valign="center" align="left"> A table similar to the one returned by the original search, minus events containing the field/value pair.
</td></tr><tr><td valign="center" align="left"> New search
</td><td valign="center" align="left"> Run a new search that focuses exclusively on the field/value pair. No additional values or search commands are included.
</td><td valign="center" align="left"> Same as original search.
</td><td valign="center" align="left"> A list of all events within the time range that have the field/value pair.
</td></tr><tr><td valign="center" align="left"> Narrow to this time range
</td><td valign="center" align="left"> Rerun the original search including all piped search commands.
</td><td valign="center" align="left"> The time range represented by the selected row or cell.
</td><td valign="center" align="left"> A table similar to the one returned by the original search, but only for events that fall within the time range represented by the clicked row. The new table is broken out into rows representing time spans within the new time range.
</td></tr></table><h3> <a name="drilldownonstatisticaltablerowsandcells_run_a_secondary_search_on_a_table_row_or_cell"><span class="mw-headline" id="Run_a_secondary_search_on_a_table_row_or_cell">Run a secondary search on a table row or cell</span></a></h3>
<p><b>1.</b> In the Search &amp; Reporting app, run a transforming search or report that returns a table in the <b>Statistics</b> tab.
</p><p><b>2.</b> Click <b>Format</b> and select the appropriate value for <b>Drilldown</b>. 
</p>
<dl><dd> Select <b>Row</b> if you want to run a secondary search on a row.
</dd></dl><dl><dd> Select <b>Cell</b> if you want to run a secondary search on a cell.
</dd></dl><p><img alt="Tablesearch format dd options.png" src="images/5/58/Tablesearch_format_dd_options.png" width="340" height="267"></p><p><b>3.</b> Click a table row or cell that you would like to run a secondary search on.
</p>
<dl><dd> A list of secondary search options appears. The list also indicates the field/value pairs that are the focus of the secondary search options. The option list also indicates whether the secondary search will use a specific time range.
</dd></dl><dl><dd> The set of options you see depends on a variety of factors. See <a href="#drilldownonstatisticaltablerowsandcells_secondary_search_options_for_rows" class="external text">"Secondary search options for rows"</a> and <a href="#drilldownonstatisticaltablerowsandcells_secondary_search_options_for_cells" class="external text">"Secondary search options for cells"</a>
</dd></dl><p><b>4.</b> Click a secondary search option.
</p>
<dl><dd> Run the secondary search in the current tab and replace your current search, or run the secondary search in a new tab and leave your current search results intact. To run the search in the current tab, click the option text. To run the search in a new tab, click the <b>Open In New Tab</b> icon <img alt="Secsrch run in sep tab icon.png" src="images/0/01/Secsrch_run_in_sep_tab_icon.png" width="23" height="16"> for the option.
</dd></dl><h3> <a name="drilldownonstatisticaltablerowsandcells_secondary_search_options_for_rows"><span class="mw-headline" id="Secondary_search_options_for_rows">Secondary search options for rows</span></a></h3>
<p>There are two possible sets of secondary search options for rows. 
</p><p><b>When you click on a row where the first column represents a value of <code><font size="2">_time</font></code></b>, meaning that the row represents a timespan, you see two secondary search options when you click on the row. 
</p>
<ul><li> View events
</li><li> Narrow to this time range
</li></ul><p><img alt="Tablesecsrch row time.png" src="images/2/2f/Tablesecsrch_row_time.png" width="355" height="246"></p><p><b>When you click on a row where the first column represents a field/value pair</b>, you see these secondary search options when you click on the row. The secondary searches use each field/value pair represented by the row.
</p>
<ul><li> View events
</li><li> Other events
</li></ul><p><img alt="Tablesearch row not time.png" src="images/6/68/Tablesearch_row_not_time.png" width="324" height="192"></p>
<h3> <a name="drilldownonstatisticaltablerowsandcells_secondary_search_options_for_cells"><span class="mw-headline" id="Secondary_search_options_for_cells">Secondary search options for cells</span></a></h3>
<p>The set of secondary search options you see when you click on a cell differ depending on a variety of factors.
</p><p><b>The cell represents a timespan.</b> When you click on a row cell that displays a value of <code><font size="2">_time</font></code>, meaning that it represents a span of time, you see two secondary search options.
</p>
<ul><li> View events
</li><li> Narrow to this time range
</li></ul><p><img alt="Tablesecsrch cell time.png" src="images/6/6a/Tablesecsrch_cell_time.png" width="386" height="221"></p><p><b>The cell represents a split row field value.</b> You see this for cells in tables where the columns represent fields, and you are clicking in a cell that is not in the first column. You see four secondary search options for the field/value pair represented by the column title and the cell value.
</p>
<ul><li> View events
</li><li> Other events
</li><li> Exclude from events
</li><li> New search
</li></ul><p>In addition, you see two secondary search options for the combination of the field/value pair represented by the cell you selected and the other field/value pairs preceding it on its row.
</p>
<ul><li> View events 
</li><li> Other events
</li></ul><p><img alt="Tablesecsrch cell split row.png" src="images/b/b5/Tablesecsrch_cell_split_row.png" width="397" height="330"></p><p><b>The cell represents a split column value.</b> You typically see this in tables where the first column is a time range or split row field and the other columns represent values of another field. The split column cells usually contain a count or similar numeric value.
</p>
<ul><li> Exclude from events (for the field/value pair represented by the column)
</li><li> View events (for the field/value pair represented by the column and the field/value pair or time range represented by the row)
</li></ul><p><img alt="Tablesecsrch cell split column.png" src="images/5/54/Tablesecsrch_cell_split_column.png" width="325" height="271"></p><p><b>The cell represents an event count or percentage and is not a split column value.</b> You see two secondary search options for the combination of the field/value pairs in the cells preceding this cell along its row.
</p>
<ul><li> View events 
</li><li> Other events
</li></ul><p><img alt="Tablesecsrch cell count or pct.png" src="images/5/54/Tablesecsrch_cell_count_or_pct.png" width="395" height="219"></p>
<h3> <a name="drilldownonstatisticaltablerowsandcells_secondary_searches_for_charts_and_visualizations"><span class="mw-headline" id="Secondary_searches_for_charts_and_visualizations">Secondary searches for charts and visualizations</span></a></h3>
<p>You can also click on elements of charts and visualizations to run secondary searches. For more information see "Drilldown behavior" in the <i>Dashboards and Visualizations</i> manual.
</p>
<a name="openinpivot"></a><h2> <a name="openinpivot_open_a_non-transforming_search_in_pivot_to_create_tables_and_charts"><span class="mw-headline" id="Open_a_non-transforming_search_in_Pivot_to_create_tables_and_charts"> Open a non-transforming search in Pivot to create tables and charts </span></a></h2>
<p>Searches that do not contain <b>transforming commands</b> return event lists that you can view in the <b>Events</b> tab, and you can use the <b>Patterns</b> tab to see the dominant patterns amongst those events. However, these non-transforming searches cannot return results in the form of statistical tables. Without statistical tables, Splunk Enterprise cannot create charts or other visualizations. This means that when you run a non-transforming search you do not get results in the <b>Statistics</b> or <b>Visualization</b> tabs.
</p><p>If you run a non-transforming search and want to make tables or charts based on it, go to the <b>Statistics</b> or <b>Visualization</b> tab and open the search in Pivot.
</p><p>In the <b>Pivot Editor</b>, you can build tables and charts without adding to the original search string. As you work with the the Pivot Builder (selecting fields, defining table or visualization elements, and setting up filters) Splunk Enterprise updates the original search and reruns it. You can see how your edits affect the table or visualization that you create. 
</p><p>You can save a table, chart, or other visualization that you create in the Pivot Editor as a report or dashboard panel. Splunk Enterprise creates a corresponding <b>data model</b>. This data model is the foundation of the saved report or dashboard panel. It defines the underlying search and the fields involved in the report or dashboard panel. Without it you cannot rerun the report or view the panel that you saved.
</p>
<h3> <a name="openinpivot_open_a_search_in_pivot"><span class="mw-headline" id="Open_a_search_in_Pivot">Open a search in Pivot</span></a></h3>
<p><b>1.</b> In the Search view, run a non-transforming search. For example:
</p>
<dl><dd> <div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* status=200 action=purchase</font></code><br></div>
</dd></dl><p><b>2.</b> Go to the <b>Statistics</b> or <b>Visualization</b> tab and click <b>Pivot.</b>
</p><p><b>3.</b> Select the set of fields that you want to use to build your pivot table or chart in the Pivot Builder.
</p>
<dl><dd> Each option displays the number of fields it represents in parenthesis:
</dd></dl><dl><dd><dl><dd> <b>All Fields</b> provides all of the fields that were discovered by the search.
</dd></dl></dd></dl><dl><dd><dl><dd> <b>Selected Fields</b> restricts you to the fields identified as <b>Selected Fields</b> for the search on the <b>Fields</b> tab. If you open a search in Pivot without making changes or selecting fields, the <b>Selected Fields</b> option provides the default selected fields:  <code><font size="2">host</font></code>, <code><font size="2">source</font></code>, and <code><font size="2">sourcetype</font></code>. To build your pivot table or chart using a different set of fields, go to the <b>Fields</b> tab and select the fields in the Selected Fields list before you move to the <b>Statistics</b> or <b>Visualization</b> tab and open the search in Pivot. 
</dd></dl></dd></dl><dl><dd><dl><dd> <b>Fields with at least</b> lets you set a coverage threshold for your fieldset. For example, to work with fields that apply to the majority of your events, set the threshold to something high, like 70%. The fieldset you get in Pivot only includes fields that exist in 70% (or more) of the events returned by the search. 
</dd></dl></dd></dl><p><b>4.</b>Click <b>Ok</b> to go to the <b>Pivot Editor</b>.
</p><p><b>5.</b> Build your pivot table or chart. 
</p>
<dl><dd> The <b>Attributes</b> list in the pivot element types (filters, split rows, split columns, and column values) contains the fieldset that you selected in step 3. 
</dd></dl><dl><dd> <b>Note:</b> If you navigate away from the Pivot Editor without saving your table or chart, your work is lost.
</dd></dl><dl><dd> To save your work, see the next subtopic, "Save the finished pivot table or chart."
</dd></dl><p>While in the Pivot Editor, you can click <b>Open in Search</b> to open the pivot search in the Search interface and edit that search. This action takes you out of the Pivot Editor and prevents you from saving any pivot table or chart you created (see the next subtopic). 
</p><p>For more information about using the Pivot Editor to design tables, see "Design pivot tables with the Pivot Editor." 
</p><p>For more information about using the Pivot Editor to design charts and other visualizations, see "Design pivot charts and visualizations with the Pivot Editor."
</p>
<h3> <a name="openinpivot_save_the_finished_pivot_table_or_chart"><span class="mw-headline" id="Save_the_finished_pivot_table_or_chart">Save the finished pivot table or chart</span></a></h3>
<p>You can save a table or chart in the Pivot Editor as a report or dashboard panel. However, Splunk must also create a data model to support the saved report or panel. This data model is required to access the report or panel after you have saved it.
</p><p><b>1.</b> In the Pivot Editor, click <b>Save As</b> and select either <i>Report</i> or <i>Dashboard Panel</i>.
</p>
<dl><dd> Depending on which one you choose, either the Save As Report or Save As Dashboard Panel dialog box appears.
</dd></dl><p><b>2.</b> In the <b>Save As</b> dialog box provide information for the report or dashboard panel that you are saving.
</p>
<dl><dd> For more information about these fields, see the documentation on saving reports or saving dashboard panels.
</dd></dl><p><b>3.</b> In the <b>Save as</b> dialog box type the <b>Model Name</b> and <b>Model ID</b> for the data model that will support the report or dashboard panel. 
</p>
<dl><dd> You can manage the model that Splunk Enterprise creates through this process if your role has admin-level capabilities. 
</dd></dl><p><b>4.</b> Click <b>Save</b> to save the report or dashboard panel and create the data model. 
</p>
<dl><dd> Click a button to view the new report or dashboard panel, or go to the new data model by clicking the name of the model. 
</dd></dl><dl><dd> Click the data model name to go to the Data Model Builder, where you can change the fields associated with the model and add data model objects to the model. 
</dd></dl><h3> <a name="openinpivot_about_permissions_for_objects_created_though_this_method"><span class="mw-headline" id="About_permissions_for_objects_created_though_this_method">About permissions for objects created though this method</span></a></h3>
<p>Newly created data models are private and can only be seen and used by the person who created them. Only users with admin or power roles (or a role with equivalent permissions) can share data models. If the data model is not shared, reports or dashboard panels created with that data model cannot be shared either. In addition, data models cannot be accelerated until they are shared. 
</p><p>If you have created a report or dashboard panel that is for your use only, you do not have to do anything. If you want other users to be able to access the report or dashboard panel, share the related data model, if you have appropriate permissions, or have a user with admin-level permissions share it for you.
</p><p>For more information about data model permissions see "Manage data models" in the <i>Knowledge Manager Manual</i>.
</p>
<h1>Search and Report in Real Time</h1><a name="aboutrealtimesearches"></a><h2> <a name="aboutrealtimesearches_about_real-time_searches_and_reports"><span class="mw-headline" id="About_real-time_searches_and_reports"> About real-time searches and reports </span></a></h2>
<p>With <b>real-time searches</b> and reports, you can search events before they are <b>indexed</b> and preview reports as the events stream in. 
</p><p>You can design <b>alerts</b> based on real-time searches that run continuously in the background. Such <b>real-time alerts</b> can provide timelier notifications than alerts that are based on <b>scheduled reports</b>. For more information, see the "About alerts" topic, in the Alerting Manual.
</p><p>You can also display real-time search results and reports in your custom <b>dashboards</b> using the dashboard editor, panel editor, and <b>simple XML</b>. For more information about the visual dashboard editor, see "Create simple dashboards with the UI" in the Splunk Data Visualizations Manual. 
</p><p>For more information about using real-time dashboards with advanced features that go beyond what the visual dashboard editor can provide, see Build a real-time dashboard in the <i>Developer manual</i>.
</p><p><b>Note:</b> When you use Splunk Enterprise in its default configuration, <i>only users with the Admin role</i> can run and save real-time searches. For more information on managing roles and assigning them to users, see "Add and edit roles" in <i>Securing Splunk Enterprise.</i>
</p>
<h3> <a name="aboutrealtimesearches_real-time_search_mechanics"><span class="mw-headline" id="Real-time_search_mechanics"> Real-time search mechanics </span></a></h3>
<p>Real-time searches search through events as they stream into Splunk Enterprise for indexing. When you kick off a real-time search, Splunk Enterprise scans incoming events that contain index-time fields that indicate they <i>could</i> be a match for your search.
</p><p>As the real-time search runs, the software periodically evaluates the scanned events against your search criteria to find actual matches within the sliding <b>time range window</b> that you have defined for the search. The number of matching events can fluctuate up or down over time as the search discovers matching events at a faster or slower rate. If you are running the search in Splunk Web, the search timeline also displays the matching events that the search has returned within the chosen time range. 
</p><p>Here is an example of a real-time search with a one minute time range window. At the point that this screen capture was taken, the search had scanned a total of 904 events since it was launched. The matching event count of 447 represents the number of events matching the search criteria that had been identified in the past minute. This number fluctuated between 430 and 450 for the following minute. If it had spiked or dropped dramatically, that could have been an indication that something interesting was happening that required a closer look. 
</p><p><img alt="6.1 Aboutrealtimesearches.png" src="images/5/5d/6.1_Aboutrealtimesearches.png" width="700" height="346"></p><p>As you can see, the newest events are on the right-hand side of the timeline. As time passes, they move left until they move off the left-hand side, disappearing from the time range window entirely.
</p><p>A real-time search should continue running until you or another user stops it or deletes the search job; it should not "time out" for any other reason. If your events are stopping it could be a performance-related issue (see <a href="#realtimeperformanceandlimitations" class="external text">"Expected performance and known limitations"</a>). 
</p><p>Real-time searches can take advantage of all search functionality, including advanced functionality like lookups, transactions, and so on. There are also search commands that are to be used specifically in conjunction with real-time searches, such as <code><font size="2">streamstats</font></code> and <code><font size="2">rtorder</font></code>.
</p>
<h3> <a name="aboutrealtimesearches_indexed_real-time_search"><span class="mw-headline" id="Indexed_real-time_search"> Indexed real-time search </span></a></h3>
<p>The number of concurrent real-time searches can greatly affect indexing performance. To lessen the impact on the indexer, you can enable indexed real-time search. This runs the search like a historical search, but also continually updates it with new events as they appear on disk.  
</p><p>To enable indexed real-time search as the default behavior for your real-time searches, edit the limits.conf stanza called <code><font size="2">realtime</font></code> and set <code><font size="2">indexed_realtime_use_by_default = true</font></code>. 
</p><p>Indexed real-time search is used when up-to-the-second accuracy is not needed. The results returned by indexed real-time search will always lag behind a real-time search. You can control the number of seconds of lag with the <code><font size="2">indexed_realtime_disk_sync_delay = &lt;int&gt;</font></code> setting. By default, this delay is 60 seconds.
</p><p>Other settings you can use to configure indexed real-time search behavior follows.
</p>
<div class="samplecode">
<code><font size="2"><br>[realtime]<br><br>indexed_realtime_default_span = &lt;int&gt;<br>* An indexed realtime search is made up of many component historical searches that by default <br>* will span this many seconds. If a component search is not completed in this many seconds the<br>* next historical search will span the extra seconds. To reduce the overhead of running an <br>* indexed realtime search you can change this span to delay longer before starting the next <br>* component historical search.<br>* Precendence: Indexers<br>* Defaults to 1<br><br>indexed_realtime_maximum_span = &lt;int&gt;<br>* While running an indexed realtime search, if the component searches regularly take longer <br>* than indexed_realtime_default_span seconds, then indexed realtime search can fall more than <br>* indexed_realtime_disk_sync_delay seconds behind realtime. Use this setting to set a limit <br>* afterwhich we will drop data to return back to catch back up to the specified delay from <br>* realtime, and only search the default span of seconds. <br>* Precedence: API overrides SearchHead overrides Indexers<br>* Defaults to 0 (unlimited) <br><br>indexed_realtime_cluster_update_interval = &lt;int&gt;<br>* While running an indexed realtime search, if we are on a cluster we need to update the list<br>* of allowed primary buckets. This controls the interval that we do this. And it must be less <br>* than the indexed_realtime_disk_sync_delay. If your buckets transition from Brand New to warm <br>* in less than this time indexed realtime will lose data in a clustered environment.<br>* Precendence: Indexers<br>* Default: 30<br></font></code></div>

<a name="realtimesearchesandreportsinsplunkweb"></a><h2> <a name="realtimesearchesandreportsinsplunkweb_real-time_searches_and_reports_in_splunk_web"><span class="mw-headline" id="Real-time_searches_and_reports_in_Splunk_Web"> Real-time searches and reports in Splunk Web</span></a></h2>
<h3> <a name="realtimesearchesandreportsinsplunkweb_real-time_searches_in_splunk_web"><span class="mw-headline" id="Real-time_searches_in_Splunk_Web"> Real-time searches in Splunk Web </span></a></h3>
<p>You run a real-time search and build a real-time report in exactly the same way you run <b>historical searches</b>. However,  because you are searching a live and continuous stream of data, the timeline updates as the events stream in and you can only view the report in preview mode. Also, some search commands are more applicable to real-time searches than historical searches. For example, streamstats and rtorder were designed for use in real-time searches.
</p><p>To kick off a real-time search in Splunk Web, use the time range menu to select a preset <b>Real-time</b> <b>time range window</b>, such as <i>30 seconds</i> or <i>1 minute.</i>  You can also <a href="#specifyrealtimewindowsinyoursearch" class="external text">specify a sliding time range window</a> to apply to your real-time search.
</p><p>If you have Apache web access data, run the following search to see web traffic events as they stream in.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_*</font></code><br></div>
<p>The raw events that are streamed from the input pipeline are not time-ordered. You can use the <code><font size="2">rtorder</font></code> command to buffer the events from a real-time search and emit them in ascending time order. 
</p><p>The following example keeps a buffer of the last 5 minutes of web traffic events, emitting events in ascending time order once they are more than 5 minutes old.  Newly received events that are older than 5 minutes are discarded if an event after that time has already been emitted.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | rtorder discard=t buffer_span=5m</font></code><br></div>
<p>Real-time search relies on a stream of events. Thus, you cannot run a real-time search with any other leading search command, such as <code><font size="2">| metadata</font></code> which does not produce events or <code><font size="2">| inputcsv</font></code> which just reads in a file. Also, if you try to send the search results to <code><font size="2">| outputcsv</font></code>, the CSV file will not be written until the real-time search is Finalized.
</p>
<h3> <a name="realtimesearchesandreportsinsplunkweb_real-time_reports_in_splunk_web"><span class="mw-headline" id="Real-time_reports_in_Splunk_Web"> Real-time reports in Splunk Web </span></a></h3>
<p>Run a report to preview the IP addresses that access the most web pages. In this case, the <code><font size="2">top</font></code> command returns a table with three columns: clientip, count, and percent. As the data streams in, the table updates with new values.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | top clientip</font></code><br></div>
<p>For each web traffic event, add a <code><font size="2">count</font></code> field that represents the number of events seen so far (but do not include the current event in the count).
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | streamstats count current=false</font></code><br></div>
<p>You can also drilldown into real-time reports. However, real-time drilldown does not spawn another real-time search. Instead, it spawns a historic search, as you will drilldown into the events that have already been retrieved and indexed. For more information, see "Drilldown behavior" in the <i>Dashboards and Visualizations Manual</i>.
</p>
<a name="realtimesearchesandreportsinthecli"></a><h2> <a name="realtimesearchesandreportsinthecli_real-time_searches_and_reports_in_the_cli"><span class="mw-headline" id="Real-time_searches_and_reports_in_the_CLI"> Real-time searches and reports in the CLI</span></a></h2>
<p>To run a real-time search in the CLI, replace the command "search" with "rtsearch":
</p>
<div class="samplecode">
<p>./splunk rtsearch 'eventtype=pageview'
</p>
</div>
<p>Use the <code><font size="2">highlight</font></code> command to emphasize terms in your search results. The following example highlights "GET" in your page view events:
</p>
<div class="samplecode">
<p>./splunk rtsearch 'eventtype=pageview | highlight GET'
</p>
</div>
<p>By default, search results have line wrapping enabled. Use the <code><font size="2">-wrap</font></code> option to turn off line wrapping:
</p>
<div class="samplecode">
<p>./splunk rtsearch 'eventtype=pageview' -wrap 0
</p>
</div>
<p>Real-time reports in the CLI will also display in preview mode and update as the data streams in.
</p>
<div class="samplecode">
<p>./splunk rtsearch 'error | top clientip'
</p>
</div>
<p>Use the <code><font size="2">-preview</font></code> option to suppress the results preview:
</p>
<div class="samplecode">
<p>./splunk rtsearch 'error | top clientip' -preview false
</p>
</div>
<p>If you turn off preview, you can still manage (Save, Pause, Finalize, or Delete) the search from the Jobs page in Splunk Web. After you finalize the search, the report table will display. For more information, see "Supervise jobs with the Jobs page" in the Knowledge Manager Manual.
</p><p>To run a windowed real-time search, use the <code><font size="2">earliest_time</font></code> and <code><font size="2">latest_time</font></code> parameters. 
</p>
<div class="samplecode">
<p>rtsearch 'index=_internal' -earliest_time 'rt-30s'  -latest_time 'rt+30s'
</p>
</div>
<p><b>Note:</b> Real-time searches can only be set at the API level, so the search does not run if you try to specify the time range modifiers within the search string. The <code><font size="2">earliest_time</font></code> and <code><font size="2">latest_time</font></code> parameters should set the same-name arguments in the REST API.
</p><p>You can view all CLI commands by accessing the CLI help reference. For more information, see "Get help with the CLI" in this manual.
</p>
<a name="realtimeperformanceandlimitations"></a><h2> <a name="realtimeperformanceandlimitations_expected_performance_and_known_limitations_of_real-time_searches_and_reports"><span class="mw-headline" id="Expected_performance_and_known_limitations_of_real-time_searches_and_reports"> Expected performance and known limitations of real-time searches and reports</span></a></h2>
<p>Real-time search matches events that have arrived at the port but have not been persisted to disk. The rate of arrival of events and number of matches can determine how much memory is consumed and the impact on the indexing rate. 
</p>
<h3> <a name="realtimeperformanceandlimitations_indexing_throughput"><span class="mw-headline" id="Indexing_throughput"> Indexing throughput </span></a></h3>
<p>Splunk's performance is expected to be acceptable as long as the indexers are not currently heavily loaded and do not have more than a few concurrent real-time searches. However, real-time searches will have a significant impact on performance in high volume environments and network load when you have many concurrent real-time searches.
</p><p>When planning your real-time searches, you should consider how it will affect the performance of both:
</p>
<ul><li> The <b>search peer</b> that must stream the live events.
</li><li> The <b>search head</b> that must process the aggregated stream of live events.
</li></ul><p>The more work that is done on the search peer, the less that is required on the search head, and vice versa. The search peer is important to the overall system function, so you do not want to burden it with too much filtering of live events. However, if the search peer does not filter at all, the processing power and bandwidth required to send all the live events to the search head may prove costly, especially when you have multiple real-time searches running concurrently.
</p><p><b>In cases where the search head can't keep up with the search peer, the queue on the index processor will drop events.</b> However, the events will have a sequence number that you can use to tell when and how many events were dropped.
</p>
<h4><font size="3"><b><i> <a name="realtimeperformanceandlimitations_concurrent_real-time_and_historical_searches"><span class="mw-headline" id="Concurrent_real-time_and_historical_searches"> Concurrent real-time and historical searches </span></a></i></b></font></h4>
<p><b>You can run real-time and historical searches concurrently, within the limits of your hardware.</b> There are no restrictions on separate searches for the same or different users. 
</p>
<h4><font size="3"><b><i> <a name="realtimeperformanceandlimitations_concurrent_real-time_searches"><span class="mw-headline" id="Concurrent_real-time_searches"> Concurrent real-time searches </span></a></i></b></font></h4>
<p><b>Running multiple real-time searches will negatively impact indexing capacity.</b> The real-time search feature is optimized for real-time alerting on sparse, or rare-term, searches and sacrifices indexing capacity for improved latency and reliability.
</p>
<h4><font size="3"><b><i> <a name="realtimeperformanceandlimitations_indexed_real-time_searches"><span class="mw-headline" id="Indexed_real-time_searches"> Indexed real-time searches </span></a></i></b></font></h4>
<p>The number of concurrent real-time searches can greatly affect Splunk's indexing performance. To lessen the impact on the indexer, you can enable indexed real-time search. This will basically run the search like a historical search, but will also continually update it with new events as they appear on disk.
</p><p>Read more about how to enable indexed real-time search in <a href="#aboutrealtimesearches" class="external text">"About real-time searches and reports"</a>.
</p>
<h3> <a name="realtimeperformanceandlimitations_real-time_search_windows"><span class="mw-headline" id="Real-time_search_windows"> Real-time search windows</span></a></h3>
<p><b>Windowed real-time searches are more expensive than non-windowed.</b> The operations required to manage and preview the window contents can result in a windowed real time search not keeping up with a high rate of indexing. If your windowed search does not display the expected number of events, try a non-windowed search. If you are interested only in event counts, try using "timechart count" in your search. 
</p><p>Read more about how to <a href="#specifyrealtimewindowsinyoursearch" class="external text">"Specify real-time time range windows in your search"</a>.
</p>
<a name="restrictrealtimesearch"></a><h2> <a name="restrictrealtimesearch_how_to_restrict_usage_of_real-time_search"><span class="mw-headline" id="How_to_restrict_usage_of_real-time_search"> How to restrict usage of real-time search </span></a></h2>
<p>Because overuse of real-time search can result in performance costs, you may find it necessary to restrict its usage. Splunk gives you different ways of doing this. You can:
</p>
<ul><li> Disable real-time search at the indexer level by editing <code><font size="2">indexes.conf</font></code> for specific indexes.
</li><li> Disable real-time search for particular roles and users.
</li><li> Edit <code><font size="2">limits.conf</font></code> to reduce the number of real-time searches that can be run concurrently at any given time. 
</li><li> Edit <code><font size="2">limits.conf</font></code> to restrict indexer support for real-time searches.
</li></ul><h3> <a name="restrictrealtimesearch_disable_real-time_search_in_indexes.conf"><span class="mw-headline" id="Disable_real-time_search_in_indexes.conf"> Disable real-time search in indexes.conf </span></a></h3>
<p>Searching in real time may be very expensive on the indexer. If you want to disable it on an indexer, you can edit a <code><font size="2">[default]</font></code> setting in that indexer's <code><font size="2">indexes.conf</font></code>.
</p>
<code><font size="2"><br>[default]<br>enableRealtimeSearch = &lt;bool&gt;<br></font></code>
<p><b>Note:</b> A <i>search head</i> that connects to multiple indexers will still be able to get real-time search results from the indexers that do have it enabled.
</p>
<h3> <a name="restrictrealtimesearch_disable_real-time_search_for_a_user_or_role"><span class="mw-headline" id="Disable_real-time_search_for_a_user_or_role"> Disable real-time search for a user or role </span></a></h3>
<p>Real-time search is a <b>capability</b> that you can map to specific users or roles in Splunk Web from <b>Manager &gt; Access Controls</b>. By default, the <b>rtsearch</b> capability is assigned to the Admin and Power roles and not the User role. A role without the rtsearch capability will not be able to run a real-time search on that search head, regardless what indexers that search head is connected to.
</p>
<h3> <a name="restrictrealtimesearch_set_search_limits_on_real-time_searches"><span class="mw-headline" id="Set_search_limits_on_real-time_searches">Set search limits on real-time searches </span></a></h3>
<p>You can use the <code><font size="2">[search]</font></code> stanza in <code><font size="2">limits.conf</font></code> to change the maximum number of real-time searches that can run concurrently on your system.
</p>
<code><font size="2"><br>[search]<br>max_rt_search_multiplier = &lt;decimal number&gt;<br>realtime_buffer = &lt;int&gt;<br></font></code>
<dl><dt> <code><font size="2">max_rt_search_multiplier</font></code>
</dt></dl><ul><li> A number by which the maximum number of historical searches is multiplied to determine the maximum number of concurrent real-time searches. Defaults to 1.
</li><li> <b>Note:</b> The maximum number of real-time searches is computed as: <code><font size="2">max_rt_searches = max_rt_search_multiplier x max_hist_searches</font></code>
</li></ul><dl><dt> <code><font size="2">realtime_buffer</font></code>
</dt></dl><ul><li> The maximum number of accessible events to keep for real-time searches from the UI. Must be &gt;= 1. Defaults to 10000.
</li><li> The real-time buffer acts as a circular buffer once this limit is reached.
</li></ul><h3> <a name="restrictrealtimesearch_set_indexer_limits_for_real-time_search"><span class="mw-headline" id="Set_indexer_limits_for_real-time_search">Set indexer limits for real-time search </span></a></h3>
<p>You can use the <code><font size="2">[realtime]</font></code> stanza in <code><font size="2">limits.conf</font></code> to change the default settings for indexer support of real-time searches. <b>These options can be overridden for individual searches via REST API arguments.</b>
</p>
<code><font size="2"><br>[realtime] <br>queue_size = &lt;int&gt;<br>blocking = [0|1] <br>max_blocking_secs = &lt;int&gt;<br>indexfilter = [0|1]<br></font></code>
<dl><dt> <code><font size="2">queue_size = &lt;int&gt;</font></code>
</dt></dl><ul><li> The size of queue for each real-time search. Must be &gt; 0.
</li><li> Defaults to 10000.
</li></ul><dl><dt> <code><font size="2">blocking =[0|1]</font></code>
</dt></dl><ul><li> Specifies whether the indexer should block if a queue is full.
</li><li> Defaults to false (0).
</li></ul><dl><dt> <code><font size="2">max_blocking_secs = &lt;int&gt;</font></code>
</dt></dl><ul><li> The maximum time to block if the queue is full. This option is meaningless, if <code><font size="2">blocking = false</font></code>.
</li><li> Means "no limit" if set to 0.
</li><li> Defaults to 60.
</li></ul><dl><dt> <code><font size="2">indexfilter = [0|1]</font></code>
</dt></dl><ul><li> Specifies whether the indexer should pre-filter events for efficiency.
</li><li> Defaults to true (1).
</li></ul><h1>Evaluate and Manipulate Fields</h1><a name="aboutevaluatingandmanipulatingfields"></a><h2> <a name="aboutevaluatingandmanipulatingfields_about_evaluating_and_manipulating_fields"><span class="mw-headline" id="About_evaluating_and_manipulating_fields"> About evaluating and manipulating fields</span></a></h2>
<p>This section discusses the search commands that enable you to evaluate new fields, manipulate existing fields, enrich events by adding new fields, and parse fields with multiple values. 
</p>
<ul><li> At the core of evaluating new fields is the eval command and its functions. Unlike the stats command, which enables you to calculate statistics based on fields in your events, eval enables you to create new fields using existing fields and an arbitrary expression. The eval command has many functions. Read more about them in <a href="#usetheevalcommandandfunctions" class="external text">"Use the eval command and functions"</a>.
</li><li> You can easily enrich your data with more information at search time. Read more about how to <a href="#useexternalfieldlookups" class="external text">"Use lookup to add fields from external lookup tables"</a>.
</li><li> The Splunk search language enables you to <a href="#extractfieldswithsearchcommands" class="external text">extract fields in different ways using a variety of search commands</a>.
</li><li> Your events may contain fields with more than one value. The Splunk search language includes a variety of search commands and functions that work with multivalue fields. Read more about how to <a href="#parsemultivaluefields" class="external text">"Manipulate and evaluate fields with multiple values"</a>.
</li></ul><a name="usetheevalcommandandfunctions"></a><h2> <a name="usetheevalcommandandfunctions_use_the_eval_command_and_functions"><span class="mw-headline" id="Use_the_eval_command_and_functions"> Use the eval command and functions</span></a></h2>
<p>The eval command enables you to devise arbitrary expressions that use automatically extracted fields to create a new field that takes the value that is the result of the expression's evaluation. The eval command is immensely versatile and useful. But while some eval expressions are relatively simple, they often can be quite complex.
</p><p>This topic discusses how to use the eval command and its numerous functions.
</p>
<h3> <a name="usetheevalcommandandfunctions_types_of_eval_expressions"><span class="mw-headline" id="Types_of_eval_expressions"> Types of eval expressions </span></a></h3>
<p>An eval expression is a combination of literals, fields, operators, and functions that represent the value of your destination field. The expression can involve a mathematical operation, a string concatenation, a comparison expression, a boolean expression, or a call to one of the eval functions. Eval expressions require that the field's values are valid for the type of operation. 
</p><p>For example, with the exception of addition, arithmetic operations may not produce valid results if the values are not numerical. For addition, eval can concatenate the two operands if they are both strings. When concatenating values with '.', eval treats both values as strings, regardless of their actual type.
</p><p><br><b>Example 1:</b> Use eval to define a field that is the sum of the areas of two circles, A and B.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2"> ... | eval sum_of_areas = pi() * pow(radius_a, 2) + pi() * pow(radius_b, 2)</font></code><br></div>
<p>The area of circle is &pi;r^2, where r is the radius. For circles A and B, the radii are radius_a and radius_b, respectively. This eval expression uses the <code><font size="2">pi</font></code> and <code><font size="2">pow</font></code> functions to calculate the area of each circle and then adds them together, and saves the result in a field named, <code><font size="2">sum_of_areas</font></code>.
</p><p><br><b>Example 2:</b> Use eval to define a location field using the city and state fields. For example, if the city=Philadelphia and state=PA, location="Philadelphia, PA".
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eval location=city.", ".state</font></code><br></div>
<p>This eval expression is a simple string concatenation.
</p><p><br><b>Example 3:</b> Use eval functions to classify where an email came from based on the email address's domain: .com, .net, and .org  addresses are considered <i>local</i>, while anything else is considered <i>abroad</i>. (Of course, domains that are not .com/.net/.org are not necessarily from <i>abroad</i>.)
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype="cisco_esa" mailfrom=*| eval accountname=split(mailfrom,"@") | eval from_domain=mvindex(accountname,-1) | eval location=if(match(from_domain, "[^\n\r\s]+\.(com|net|org)"), "local", "abroad") | stats count by location</font></code><br></div>
<p>This example uses generated email data (<code><font size="2">sourcetype=cisco_esa</font></code>). You should be able to run this example on any email data by replacing the <code><font size="2">sourcetype=cisco_esa</font></code> with your data's <code><font size="2">sourcetype</font></code> value and the <code><font size="2">mailfrom</font></code> field with your data's email address field name (for example, it might be <code><font size="2">To, From, or Cc</font></code>).
</p><p>The <code><font size="2">split()</font></code> function is used to break up the email address in the <code><font size="2">mailfrom</font></code> field. The <code><font size="2">mvindex</font></code> function defines the <code><font size="2">from_domain</font></code> as the portion of the <code><font size="2">mailfrom</font></code> field after the <code><font size="2">@</font></code> symbol.
</p><p>Then, the <code><font size="2">if()</font></code> and <code><font size="2">match()</font></code> functions are used: if the <code><font size="2">from_domain</font></code> value ends with a <code><font size="2">.com, .net., or .org</font></code>, the <code><font size="2">location</font></code> field is assigned <code><font size="2">local</font></code>. If <code><font size="2">from_domain</font></code> does not match, <code><font size="2">location</font></code> is assigned <code><font size="2">abroad</font></code>.
</p><p>The <code><font size="2">eval</font></code> results are then piped into the <code><font size="2">stats</font></code> command to count the number of results for each <code><font size="2">location</font></code> value and produce the following results table:
</p><p><img alt="EvalEx5 resultsTable.png" src="images/f/f3/EvalEx5_resultsTable.png" width="700" height="137"></p><p><b>Note:</b> This example merely illustrates using the <code><font size="2">match()</font></code> function. If you want to classify your events and quickly search for those events, the better approach is to use event types. Read more <b>about event types</b> in the <i>Knowledge manager manual</i>.
</p><p><br></p>
<h3> <a name="usetheevalcommandandfunctions_define_calculated_fields"><span class="mw-headline" id="Define_calculated_fields"> Define calculated fields </span></a></h3>
<p>If you find that you use a particular eval expression on a regular basis, you can consider defining the field as a calculated field in <code><font size="2">props.conf</font></code>. Doing this means that when you're writing a search, you can cut out the eval expression entirely and reference the field like you would any other extracted field. When you run the search, the fields will be extracted at search time and will be added to the events that include the fields in the eval expressions.
</p><p>Read more about how to configure this in "Define calculated fields" in the Knowledge Manager Manual.
</p>
<a name="useexternalfieldlookups"></a><h2> <a name="useexternalfieldlookups_use_lookup_to_add_fields_from_lookup_tables"><span class="mw-headline" id="Use_lookup_to_add_fields_from_lookup_tables"> Use lookup to add fields from lookup tables</span></a></h2>
<p>You can match fields in your events to fields in external sources, such as lookup tables, and use these matches to add more information inline to your events.
</p><p>A lookup table can be a static CSV file, a KV store collection, or the output of a Python script. You can also use the results of a search to populate the CSV file or KV store collection and then set that up as a lookup table. For more information about field lookups, see "Configure CSV and external lookups" and "Configure KV store lookups" in the <i>Knowledge Manager Manual</i>.
</p><p>After you configure a fields lookup, you can invoke it from the Search app with the <code><font size="2">lookup</font></code> command. 
</p><p><b>Example:</b> Given a field lookup named <code><font size="2">dnslookup</font></code>, referencing a Python script that performs a DNS and reverse DNS lookup and accepts either a host name or IP address as arguments -- you can use the lookup command to match the host name values in your events to the host name values in the table, and then add the corresponding IP address values to your events.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | lookup dnslookup host OUTPUT ip</font></code><br></div>
<p>For a more extensive example using the Splunk script <code><font size="2">external_lookup.py</font></code>, see "Reverse DNS Lookups for Host Entries" in the Splunk blogs.
</p>
<a name="extractfieldswithsearchcommands"></a><h2> <a name="extractfieldswithsearchcommands_extract_fields_with_search_commands"><span class="mw-headline" id="Extract_fields_with_search_commands"> Extract fields with search commands</span></a></h2>
<p>You can use a variety of search commands to extract fields in different ways. 
</p>
<ul><li> rex performs field extractions using Perl regular expressions named groups. 
</li><li> extract (or <code><font size="2">kv</font></code>, for "key/value") explicitly extracts field/values using default patterns.
</li><li> multikv extracts field/values on multiline, tabular-formatted events.
</li><li> spath extracts field/values on structured event data, such as XML and JSON.
</li><li> xmlkv and xpath extract field/values on XML-formatted event data. 
</li><li> kvform extracts field/values based on predefined form templates.
</li></ul><h3> <a name="extractfieldswithsearchcommands_extract_fields_using_regular_expressions"><span class="mw-headline" id="Extract_fields_using_regular_expressions"> Extract fields using regular expressions </span></a></h3>
<p>The rex search command performs field extractions using Perl regular expression named groups that you include in the search string. It matches segments of your raw events with the regular expression and saves these values into a field. 
</p><p>In this example, values that occur after the strings "From:" and "To:" are saved into the "from" and "to" fields, respectively. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | rex field=_raw "From: (?&lt;from&gt;.*) To: (?&lt;to&gt;.*)"</font></code><br></div>
<p>If a raw event contains "From: Susan To: Bob", the search extracts the field name/value pairs: "from=Susan" and "to=Bob".
</p><p>For a primer on regular expression syntax and usage, see Regular-Expressions.info. Splunk also maintains a list of useful third-party tools for writing and testing regular expressions.
</p>
<h3> <a name="extractfieldswithsearchcommands_extract_fields_from_.conf_files"><span class="mw-headline" id="Extract_fields_from_.conf_files"> Extract fields from .conf files </span></a></h3>
<p>Use the extract command forces field/value extraction on the result set. If you use the <code><font size="2">extract</font></code> command without specifying any arguments, the fields are extracted by using field extraction stanzas that are added to the <code><font size="2">props.conf</font></code> file. You can use the<code><font size="2">extract</font></code> to test any field extractions that you add manually through conf files.
</p>
<h3> <a name="extractfieldswithsearchcommands_extract_fields_from_events_formatted_as_tables"><span class="mw-headline" id="Extract_fields_from_events_formatted_as_tables"> Extract fields from events formatted as tables </span></a></h3>
<p>Use multikv to force field/value extraction on multiline, tabular-formatted events. It creates a new event for each table row and derives field names from the table title.
</p>
<h3> <a name="extractfieldswithsearchcommands_extract_fields_from_events_formatted_in_xml"><span class="mw-headline" id="Extract_fields_from_events_formatted_in_XML"> Extract fields from events formatted in XML </span></a></h3>
<p>The xmlkv command enables you to force field/value extraction on XML-formatted tags in event data, such as transactions from web pages.
</p>
<h3> <a name="extractfieldswithsearchcommands_extract_fields_from_xml_and_json_documents"><span class="mw-headline" id="Extract_fields_from_XML_and_JSON_documents"> Extract fields from XML and JSON documents </span></a></h3>
<p>The spath command provides a straightforward means for extracting information from structured data formats, such as XML and JSON, and storing the values in fields.
</p>
<h3> <a name="extractfieldswithsearchcommands_extract_fields_from_events_based_on_form_templates"><span class="mw-headline" id="Extract_fields_from_events_based_on_form_templates"> Extract fields from events based on form templates </span></a></h3>
<p>The kvform command extracts field/value pairs from events based on form templates that are predefined and stored in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code>, or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For example, if <code><font size="2">form=sales_order</font></code>, the search looks for a <code><font size="2">sales_order.form</font></code>, and matches all processed events against that form, trying to extract values.
</p>
<a name="parsemultivaluefields"></a><h2> <a name="parsemultivaluefields_manipulate_and_evaluate_fields_with_multiple_values"><span class="mw-headline" id="Manipulate_and_evaluate_fields_with_multiple_values"> Manipulate and evaluate fields with multiple values </span></a></h2>
<p>Splunk parses multivalue fields at search time, and allows you to process the values in the search pipeline. Search commands that work with multivalue fields include makemv, mvcombine, mvexpand, and nomv. The eval and where commands support functions, such as <code><font size="2">mvcount(), mvfilter(), mvindex(), and mvjoin()</font></code> that you can use with multivalue fields. See Functions for eval and where in the <i>Search Reference</i> and the examples in this topic.
</p><p>You can configure multivalue fields in the <code><font size="2">fields.conf</font></code> file to tell Splunk Enterprise how to recognize more than one field value in a single extracted field value. Edit the <code><font size="2">fields.conf</font></code> in <code><font size="2">$SPLUNK_HOME/etc/system/local/</font></code>, or your own custom application directory in <code><font size="2">$SPLUNK_HOME/etc/apps/</font></code>. For more information on how to do this, see "Configure multivalue fields" in the <i>Knowledge Manager Manual</i>.
</p>
<h3> <a name="parsemultivaluefields_manipulate_multivalued_fields"><span class="mw-headline" id="Manipulate_multivalued_fields"> Manipulate multivalued fields </span></a></h3>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_use_nomv_to_convert_a_multivalue_field_into_a_single_value"><span class="mw-headline" id="Use_nomv_to_convert_a_multivalue_field_into_a_single_value"> Use nomv to convert a multivalue field into a single value </span></a></i></b></font></h4>
<p>You can use the <code><font size="2">nomv</font></code> command to convert values of the specified multivalue field into one single value. The <code><font size="2">nomv</font></code> command overrides the multivalue field configurations that are set in <code><font size="2">fields.conf</font></code> file.
</p><p>In this example for sendmail events, you want to combine the values of the senders field into a single value.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" | nomv senders</font></code><br></div>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_use_makemv_to_separate_a_multivalue_field"><span class="mw-headline" id="Use_makemv_to_separate_a_multivalue_field"> Use makemv to separate a multivalue field </span></a></i></b></font></h4>
<p>You can use the <code><font size="2">makemv</font></code> command to separate multivalue fields into multiple single value fields. In this example for sendmail search results, you want to separate the values of the senders field into multiple field values. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" | makemv delim="," senders</font></code><br></div>
<p>After you separate the field values, you can pipe it through other commands. For example, you can display the top senders.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" | makemv delim="," senders | top senders</font></code><br></div>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_use_mvexpand_to_create_multiple_events_based_on_a_multivalue_field"><span class="mw-headline" id="Use_mvexpand_to_create_multiple_events_based_on_a_multivalue_field"> Use mvexpand to create multiple events based on a multivalue field </span></a></i></b></font></h4>
<p>You can use the <code><font size="2">mvexpand</font></code> command to expand the values of a multivalue field into separate events for each value of the multivalue field. In this example, new events are created for each value in the multivalue field, "foo".
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | mvexpand foo</font></code><br></div>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_use_mvcombine_to_create_a_multivalue_field_from_similar_events"><span class="mw-headline" id="Use_mvcombine_to_create_a_multivalue_field_from_similar_events"> Use mvcombine to create a multivalue field from similar events </span></a></i></b></font></h4>
<p>Combine the values of "foo" with ":" delimiter.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | mvcombine delim=":" foo</font></code><br></div>
<h3> <a name="parsemultivaluefields_evaluate_multivalue_fields"><span class="mw-headline" id="Evaluate_multivalue_fields"> Evaluate multivalue fields </span></a></h3>
<p>One of the more common examples of multivalue fields is that of email address fields, which typically appears two or three times in a single sendmail event--one time for the sender, another time for the list of recipients, and possibly a third time for the list of Cc addresses. 
</p>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_count_the_number_of_values_in_a_field"><span class="mw-headline" id="Count_the_number_of_values_in_a_field"> Count the number of values in a field </span></a></i></b></font></h4>
<p>Use the <code><font size="2">mvcount()</font></code> function to count the number of values in a single value or multivalue field.
</p><p>In this example, mvcount() returns the number of email addresses in the To, From, and Cc fields and saves the addresses in the specified "_count" fields.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" | eval To_count=mvcount(to) | eval From_count=mvcount(from) | eval Cc_count=mvcount(cc)</font></code><br></div>
<p><b>Note:</b> If only a single email address exists in the sender field (as you would expect), <code><font size="2">mvcount(from)</font></code> returns 1. If there is no Cc address, the Cc field might not exist for the event. In that situation <code><font size="2">mvcount(cc)</font></code> returns NULL.
</p>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_filter_values_from_a_multivalue_field"><span class="mw-headline" id="Filter_values_from_a_multivalue_field"> Filter values from a multivalue field </span></a></i></b></font></h4>
<p>Use the <code><font size="2">mvfilter()</font></code> function to filter a multivalue field using an arbitrary Boolean expression. The <code><font size="2">mvfilter</font></code> function works with only one field at a time.
</p><p>In this example, mvfilter() keeps all of the values for the field <code><font size="2">email</font></code> that end in <code><font size="2">.net </font></code> or <code><font size="2">.org</font></code>. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" | eval email=mvfilter(match(email, "\.net$") OR match(email, "\.org$"))</font></code><br></div>
<p><b>Note:</b> This example also uses the <code><font size="2">match()</font></code> function to compare the pattern defined in quotes to the value of <code><font size="2">email</font></code>. See Functions for eval and where in the <i>Search Reference</i>.
</p>
<h4><font size="3"><b><i> <a name="parsemultivaluefields_return_a_subset_of_values_from_a_multivalue_field"><span class="mw-headline" id="Return_a_subset_of_values_from_a_multivalue_field"> Return a subset of values from a multivalue field </span></a></i></b></font></h4>
<p>Use the <code><font size="2">mvindex()</font></code> function to reference a specific value or a subset of values in a multivalue field. Since the index numbering starts at 0, if you want to reference the 3rd value of a field, you would specify it as 2. 
</p><p>In this example, mvindex() returns the first email address in the "To" field for every email sent by Sender:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" from=Sender@* | eval to_first=mvindex(to,0)</font></code><br></div> 
<p>If you want to see the top 3 email addresses that Sender writes to, use the following search.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">eventtype="sendmail" from=Sender@* | eval top_three=mvindex(to,0,2)</font></code><br></div>
<p>In this example, <code><font size="2">top_three</font></code> is, itself, a multivalue field.
</p>
<h1>Calculate Statistics </h1><a name="aboutcalculatingstatistics"></a><h2> <a name="aboutcalculatingstatistics_about_calculating_statistics"><span class="mw-headline" id="About_calculating_statistics"> About calculating statistics</span></a></h2>
<p>This chapter discusses how to calculate summary statistics on events. When you think about calculating statistics with Splunk's search processing language (SPL), the <code><font size="2">stats</font></code> command is probably what comes to mind first. The stats command generates reports that display summary statistics in a tabular format. Additionally, you can use the <code><font size="2">chart</font></code> and <code><font size="2">timechart</font></code> commands to create charted visualizations for summary statistics and the <code><font size="2">geostats</font></code> command to create map visualizations for summary statistics of events that include geographical location fields. 
</p><p>The <code><font size="2">stats</font></code>, <code><font size="2">chart</font></code>, and <code><font size="2">timechart</font></code> commands (and their related commands <code><font size="2">eventstats</font></code>, <code><font size="2">geostats</font></code> and <code><font size="2">streamstats</font></code>) are designed to work in conjunction with statistical functions. For examples of searches using these commands and functions, read <a href="#usethestatscommandandfunctions" class="external text">"Use the stats command and functions"</a>.
</p><p>Later topics discuss how to:
</p>
<ul><li> <a href="#usestatswithevalexpressionsandfunctions" class="external text">"Use stats with eval expressions and functions"</a> to calculate statistics.
</li><li> <a href="#addsparklinestosearchresults" class="external text">"Add sparklines to report tables"</a>.
</li></ul><a name="usethestatscommandandfunctions"></a><h2> <a name="usethestatscommandandfunctions_use_the_stats_command_and_functions"><span class="mw-headline" id="Use_the_stats_command_and_functions"> Use the stats command and functions</span></a></h2>
<p>This topic discusses how to use the statistical functions with the <b>transforming commands</b> <code><font size="2">chart</font></code>, <code><font size="2">timechart</font></code>, <code><font size="2">stats</font></code>, <code><font size="2">eventstats</font></code>, and <code><font size="2">streamstats</font></code>. 
</p>
<h3> <a name="usethestatscommandandfunctions_about_the_stats_commands_and_functions"><span class="mw-headline" id="About_the_stats_commands_and_functions"> About the stats commands and functions </span></a></h3>
<p>The <code><font size="2">stats</font></code>, <code><font size="2">streamstats</font></code>, and <code><font size="2">eventstats</font></code> commands each enable you to calculate summary statistics on the results of a search or the events retrieved from an index. The <code><font size="2">stats</font></code> command works on the search results as a whole. The <code><font size="2">streamstats</font></code> command calculates statistics for each event at the time the event is seen, in a streaming manner. The <code><font size="2">eventstats</font></code> command calculates statistics on all search results and adds the aggregation inline to each event for which it is relevant. See more about the differences between these commands in the next section.
</p><p>The <code><font size="2">chart command</font></code> returns your results in a data structure that supports visualization as a chart (such as a column, line, area, and pie chart). You can decide what field is tracked on the x-axis of the chart.  The <code><font size="2">timechart command</font></code> returns your results formatted as a time-series chart, where your data is plotted against an x-axis that is always a time field. Read more about Splunk's visualization features and options in the Visualization Reference of the Data Visualization Manual.
</p><p>The <code><font size="2">stats</font></code>, <code><font size="2">chart</font></code>, and <code><font size="2">timechart</font></code> commands (and their related commands <code><font size="2">eventstats</font></code> and <code><font size="2">streamstats</font></code>) are designed to work in conjunction with statistical functions. The list of statistical functions lets you count the occurrence of a field and calculate sums, averages, ranges, and so on, of the field values.
</p><p>For the list of statistical functions and how they're used, see "Functions for stats, chart, and timechart" in the Search Reference Manual. 
</p>
<h3> <a name="usethestatscommandandfunctions_stats.2c_eventstats.2c_and_streamstats"><span class="mw-headline" id="Stats.2C_eventstats.2C_and_streamstats"> Stats, eventstats, and streamstats </span></a></h3>
<p>The <code><font size="2">eventstats</font></code> and <code><font size="2">streamstats</font></code> commands are variations on the <code><font size="2">stats</font></code> command.
</p><p>The <code><font size="2">stats</font></code> command works on the search results as a whole and returns only the fields that you specify. For example, the following search returns a table with two columns (and 10 rows).
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | head 10 | stats sum(bytes) as ASumOfBytes by clientip</font></code><br></div>
<p>The <code><font size="2">ASumOfBytes</font></code> and <code><font size="2">clientip</font></code> fields are the only fields that exist after the stats command. For example, the following search returns empty cells in the <code><font size="2">bytes</font></code> column because it is not a result field.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | head 10 | stats sum(bytes) as ASumOfBytes by clientip | table bytes, ASumOfBytes, clientip</font></code><br></div>
<p>To see more fields other than <code><font size="2">ASumOfBytes</font></code> and <code><font size="2">clientip</font></code> in the results, you need to include them in the stats command. Also, if you want to perform calculations on any of the original fields in your raw events, you need to do that before the stats command. 
</p><p>The <code><font size="2">eventstats</font></code> command computes the same statistics as the <code><font size="2">stats</font></code> command, but it also aggregates the results to the original raw data. When you run the following search, it returns an events list instead of a results table, because the eventstats command does not change the raw data.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | head 10 | eventstats sum(bytes) as ASumOfBytes by clientip</font></code><br></div>
<p>You can use the <code><font size="2">table</font></code> command to format the results as a table that displays the fields you want. Now, you can also view the values of <code><font size="2">bytes</font></code> (or any of the original fields in your raw events) in your results.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | head 10 | eventstats sum(bytes) as ASumOfBytes by clientip | table bytes, ASumOfBytes, clientip</font></code><br></div>
<p>The <code><font size="2">streamstats</font></code> command also aggregates the calculated statistics to the original raw event, but it does this at the time the event is seen. To demonstrate this, include the <code><font size="2">_time</font></code> field in the earlier search and use <code><font size="2">streamstats</font></code>.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | head 10 | sort _time | streamstats sum(bytes) as ASumOfBytes by clientip | table _time, clientip, bytes, ASumOfBytes</font></code><br></div>
<p>Instead of a total sum for each <code><font size="2">clientip</font></code> (as returned by <code><font size="2">stats</font></code> and <code><font size="2">eventstats</font></code>), this search calculates a sum for each event based on the time that it is seen. The <code><font size="2">streamstats</font></code> command is useful for reporting on events at a known time range.
</p><p><br></p>
<h3> <a name="usethestatscommandandfunctions_examples"><span class="mw-headline" id="Examples"> Examples </span></a></h3>
<h4><font size="3"><b><i> <a name="usethestatscommandandfunctions_example_1"><span class="mw-headline" id="Example_1"> Example 1 </span></a></i></b></font></h4>
<p>This example creates a chart of how many new users go online each hour of the day. 
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | sort _time | streamstats dc(userid) as dcusers | delta dcusers as deltadcusers | timechart sum(deltadcusers)</font></code><br></div>
<p>The <code><font size="2">dc</font></code> (or <code><font size="2">distinct_count</font></code>) function returns a count of the unique values of <code><font size="2">userid</font></code> and renames the resulting field <code><font size="2">dcusers</font></code>.
</p><p>If you don't rename the function, for example "dc(userid) as dcusers", the resulting calculation is automatically saved to the function call, such as "dc(userid)".
</p><p>The <code><font size="2">delta</font></code> command is used to find the different between the current and previous dcusers value. Then, the sum of this delta is charted over time.
</p>
<h4><font size="3"><b><i> <a name="usethestatscommandandfunctions_example_2"><span class="mw-headline" id="Example_2"> Example 2 </span></a></i></b></font></h4>
<p>This example calculates the median for a field, then charts the count of events where the field has a value less than the median.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | eventstats median(bytes) as medbytes | eval snap=if(bytes&gt;=medbytes, bytes, "smaller") | timechart count by snap</font></code><br></div>
<p>Eventstats is used to calculate the median for all the values of bytes from the previous search.
</p>
<h4><font size="3"><b><i> <a name="usethestatscommandandfunctions_example_3"><span class="mw-headline" id="Example_3"> Example 3 </span></a></i></b></font></h4>
<p>This example calculates the standard deviation and variance of calculated fields.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=log4j ERROR earliest=-7d@d latest=@d | eval warns=errorGroup+"-"+errorNum | stats count as Date_Warns_Count by date_mday,warns | stats stdev(Date_Warns_Count), var(Date_Warns_Count) by warns</font></code><br></div>
<p>This search returns errors from the last 7 days and creates the new field, warns, from extracted fields errorGroup and errorNum. The stats command is used twice. First, it calculates the daily count of warns for each day. Then, it calculates the standard deviation and variance of that count per warns.
</p>
<h4><font size="3"><b><i> <a name="usethestatscommandandfunctions_example_4"><span class="mw-headline" id="Example_4"> Example 4 </span></a></i></b></font></h4>
<p>You can use the calculated fields as filter parameters for your search.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | eval URILen = len(useragent) | eventstats avg(URILen) as AvgURILen, stdev(URILen) as StdDevURILen| where URILen &gt; AvgURILen+(2*StdDevURILen) | chart count by URILen span=10 cont=true
</font></code><br></div>
<p>In this example, eventstats is used to calculate the average and standard deviation of the URI lengths from <code><font size="2">useragent</font></code>. Then, these numbers are used as filters for the retrieved events.
</p>
<a name="usestatswithevalexpressionsandfunctions"></a><h2> <a name="usestatswithevalexpressionsandfunctions_use_stats_with_eval_expressions_and_functions"><span class="mw-headline" id="Use_stats_with_eval_expressions_and_functions"> Use stats with eval expressions and functions</span></a></h2>
<p>This topic discusses how to use eval expressions and functions within your stats calculation. 
</p>
<ul><li> For more information about the eval command and syntax, see the eval reference in the <i>Search Reference Manual</i>.
</li><li> For the list of eval functions, see "Functions for eval and where" in the <i>Search Reference Manual</i>.
</li><li> Also, you can read more about using the eval command to <a href="#aboutevaluatingandmanipulatingfields" class="external text">"Evaluate and manipulate fields"</a> in the next chapter of this manual.
</li></ul><h3> <a name="usestatswithevalexpressionsandfunctions_example_1:_distinct_counts_of_matching_events"><span class="mw-headline" id="Example_1:_Distinct_counts_of_matching_events"> Example 1: Distinct counts of matching events </span></a></h3>
<p>Let's say you have errors and you want to count the IP addresses where the errors originate. This is similar to a search for events, filtered for a specific code, and then used with the stats command to count the IP addresses:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | search error=404 | stats dc(ip)</font></code><br></div>
<p>The best way to do this with an eval expression is:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | stats dc(eval(if(error==404),ip,NULL)) AS dc_ip</font></code><br></div>
<h3> <a name="usestatswithevalexpressionsandfunctions_example_2:_categorizing_and_counting_fields"><span class="mw-headline" id="Example_2:_Categorizing_and_counting_fields"> Example 2: Categorizing and counting fields </span></a></h3>
<p>Find out how much of your organization's email comes from com/net/org or other top level domains.
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype="cisco_esa" mailfrom=* | eval accountname=split(mailfrom,"@") | eval from_domain=mvindex(accountname,-1) | stats count(eval(match(from_domain, "[^\n\r\s]+\.com"))) AS ".com", count(eval(match(from_domain, "[^\n\r\s]+\.net"))) AS ".net", count(eval(match(from_domain, "[^\n\r\s]+\.org"))) AS ".org", count(eval(NOT match(from_domain, "[^\n\r\s]+\.(com|net|org)"))) AS "other"</font></code><br></div>
<p>The first half of this search uses eval to break up the email address in the <code><font size="2">mailfrom</font></code> field and define the <code><font size="2">from_domain</font></code> as the portion of the <code><font size="2">mailfrom</font></code> field after the <code><font size="2">@</font></code> symbol.
</p><p>The results are then piped into the <code><font size="2">stats</font></code> command. The <code><font size="2">count()</font></code> function is used to count the results of the <code><font size="2">eval</font></code> expression. Here, <code><font size="2">eval</font></code> uses the <code><font size="2">match()</font></code> function to compare the <code><font size="2">from_domain</font></code> to a regular expression that looks for the different suffixes in the domain. If the value of <code><font size="2">from_domain</font></code> matches the regular expression, the <code><font size="2">count</font></code> is updated for each suffix, <code><font size="2">.com, .net, and .org</font></code>. Other domain suffixes are counted as <code><font size="2">other</font></code>.
</p><p>This produces the following results table:
</p><p><img alt="StatsEx5 resultsTable.png" src="images/f/f3/StatsEx5_resultsTable.png" width="700" height="134"></p><p><b>Note:</b> This example used generated email data (<code><font size="2">sourcetype=cisco_esa</font></code>). You should be able to run this example on any email data by replacing the <code><font size="2">sourcetype=cisco_esa</font></code> with your data's <code><font size="2">sourcetype</font></code> value and the <code><font size="2">mailfrom</font></code> field with your data's email address field name (for example, it might be <code><font size="2">To, From, or Cc</font></code>).
</p>
<a name="addsparklinestosearchresults"></a><h2> <a name="addsparklinestosearchresults_add_sparklines_to_search_results"><span class="mw-headline" id="Add_sparklines_to_search_results"> Add sparklines to search results</span></a></h2>
<p>If you are working with <code><font size="2">stats</font></code> and <code><font size="2">chart</font></code> searches, you can increase their usefulness and overall information density by adding sparklines to their result tables. Sparklines are inline charts that appear within table cells in search results, and are designed to display time-based trends associated with the primary key of each row. 
</p><p>For example, say you have this search, set to run over events from the past 15 minutes:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=_internal | chart count by sourcetype</font></code><br></div>
<p>This search returns a two-column results table that shows event counts for the source types that have been indexed to <code><font size="2">_internal</font></code> in the last 15 minutes. The first column lists each <code><font size="2">sourcetype</font></code> found in the past hour's set of <code><font size="2">_internal</font></code> index events; this is the primary key for the table. The second column,  <code><font size="2">count</font></code>, displays the event counts for each listed source type:
</p><p><img alt="Sparklines basic example-1.png" src="images/8/80/Sparklines_basic_example-1.png" width="614" height="216"></p><p>You can add sparklines to the results of this search by adding the <code><font size="2">sparkline</font></code> function to the search itself:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">index=_internal | chart sparkline count by sourcetype</font></code><br></div>
<p>This results in a table that is almost the same as the preceding one, except that now, for each row you have a sparkline chart that shows the event count trend for each listed source type over the past 15 minutes. 
</p><p><img alt="Sparklines basic example-2.png" src="images/3/37/Sparklines_basic_example-2.png" width="612" height="210"></p><p>Now you can easily see patterns in your data that may have been invisible before. Some search activity apparently caused a bump in most <code><font size="2">index=_internal</font></code> source types about three quarters into the 15 minute span. And <code><font size="2">splunkd</font></code> has what almost looks like a regular heartbeat running over the entire span of time.
</p><p><b>Note:</b> Each sparkline in a table displays information in relation to the other events represented in that sparkline, but not in relation to the other sparklines. A peak in one sparkline does not necessarily have the same value as a peak in another sparkline. 
</p>
<h3> <a name="addsparklinestosearchresults_using_sparklines_with_the_stats_and_chart_commands"><span class="mw-headline" id="Using_sparklines_with_the_stats_and_chart_commands">Using sparklines with the stats and chart commands</span></a></h3>
<p>You always use the sparklines feature in conjunction with <code><font size="2">chart</font></code> and <code><font size="2">stats</font></code> searches, because it is a function of those two search commands. It is not a command by itself. The functionality of sparklines is the same for both search commands. 
</p><p><b>Note:</b> Sparklines are not available as a dashboard chart visualization by themselves, but you can set up a dashboard panel with a table visualization that displays sparklines. For more information, see the "Visualization reference" topic in the Splunk Data Visualizations Manual.
</p><p>For more information about the <code><font size="2">chart</font></code> and <code><font size="2">stats</font></code> commands, including details on the syntax around the <code><font size="2">sparkline</font></code> function, see "chart" and "stats" in the Search Reference.
</p>
<h4><font size="3"><b><i> <a name="addsparklinestosearchresults_example:_stats.2c_sparklines.2c_and_earthquake_data"><span class="mw-headline" id="Example:_Stats.2C_sparklines.2C_and_earthquake_data">Example: Stats, sparklines, and earthquake data</span></a></i></b></font></h4>
<p>Here are some examples of <code><font size="2">stats</font></code> searches that use sparklines to provide additional information about earthquake data. 
</p>
<table cellpadding="10" cellspacing="0" border="1" width="100%"><tr><td valign="center" align="left">This example uses earthquake data downloaded from the USGS Earthquakes website. You can download a current CSV file from the <b>USGS Earthquake Feeds</b> and add it as an input to Splunk, but the field names and format will be slightly different from the example shown here.
</td></tr></table><p>Let's say you want to use the USGS Earthquakes data to show the regions that had the most earthquakes over the past week, with a column that shows the average quake magnitude for each region. You could use the following search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">source=usgs | stats sparkline count, avg(Magnitude) by Region | sort count</font></code><br></div>
<p>This search returns the following table, with sparklines that illustrate the quake count over the course of the week for each of the top earthquake regions (in this case, <code><font size="2">Region</font></code> is the table's primary key): 
</p><p><img alt="Spk quakeCount example.png" src="images/a/a3/Spk_quakeCount_example.png" width="616" height="278"></p><p>Right away you can see differences in quake distribution between the top 10 quake regions. Some areas, like Southern Alaska and the Virgin Islands, had a pretty steady series of quakes, while the Fox Islands and Vanuatu experienced their seismic activity all at one point. 
</p><p>You can easily get the minimum and maximum count for a particular region by mousing over the sparkline; in this example you can see that in Southern Alaska, the minimum count of quakes experienced in a single day during the 7-day period was 1, while the maximum count per day was 6.
</p><p>But what if you want your sparkline to represent not only the earthquake count, but also the relative average magnitude of the quakes affecting each region? In other words, how can you make the sparkline line chart represent average quake magnitude for each "time bucket" (segment) of the chart?
</p><p>Try a search like this:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">source=usgs | stats sparkline(avg(Magnitude),6h) as magnitude_trend, count, avg(Magnitude) by Region | sort count</font></code><br></div> 
<p>This search produces a sparkline for each region that shows the average quake magnitude for the quake events that fall into each segment of the sparkline.. 
</p><p>But it does a bit more than that. It also asks that the sparkline divide itself up into smaller chunks of time. The preceding table had a sparkline that was divided up by day, so each data point in the sparkline represented an event count for a full 24 hour period. This is why those sparklines were so short.
</p><p>The addition of the <code><font size="2">6h</font></code> to the search language overrides this default and makes Splunk display sparklines that are broken up into discrete six-hour chunks, which makes it easier to see the distribution of events along the sparkline for the chosen time range.
</p><p>The search also renames the sparkline column as "magnitude_trend" to make it easier to understand.
</p><p><img alt="Spk magTrend example.png" src="images/7/75/Spk_magTrend_example.png" width="630" height="278"></p><p>Now you can see that the quakes off the Andreanof Islands were all of roughly similar magnitude, while the quakes in Puerto Rico varied in intensity. And it's now easier to see that central California's relatively mild quakes hit at the start and end of the 7-day period. You can also discern that the quakes in the Virgin Islands didn't occur with the steady frequency that the previous search suggested, while the quakes off Southern Alaska were slightly more regular than previously indicated.
</p>
<h1>Group and Correlate Events</h1><a name="abouteventcorrelation"></a><h2> <a name="abouteventcorrelation_about_event_grouping_and_correlation"><span class="mw-headline" id="About_event_grouping_and_correlation"> About event grouping and correlation</span></a></h2>
<p>Event correlation is finding relationships between seemingly unrelated events in data from multiple sources to answer questions like, "how far apart in time did a specific set of events occur?" or "what's the total amount of time it took for a transaction to complete?"
</p><p>Splunk Enterprise supports event correlations using time and geographic location, transactions, sub-searches, field lookups, and joins.
</p>
<ul><li> Identify relationships based on the time proximity or geographic location of the events. Use this correlation in any security or operations investigation, where you might need to see all or any subset of events that take place over a given time period or location.
</li><li> Track a series of related events, which may come from separate IT systems and data sources, together as a single transaction. Identify the amount of time it took to complete the transaction and the number of events within a single transaction.
</li><li> Use a sub-search to take the results of one search and use them in another. Create conditional searches, where you see the results of a search only if the sub-search meets certain thresholds. 
</li><li> Correlate your data to external sources with lookups. 
</li><li> Use SQL-like inner and outer joins to link two completely different data sets together based on one or more common fields. 
</li></ul><p>This chapter discusses three methods for using Splunk to correlate or group events:
</p>
<ul><li> <a href="#usetimetoidentifyrelationshipsbetweenevents" class="external text">Use time to identify relations between events</a>
</li><li> <a href="#usesubsearchtocorrelateevents" class="external text">Use subsearch to correlate events</a>
</li><li> <a href="#identifyandgroupeventsintotransactions" class="external text">Use transactions to identify and group related events</a>
</li></ul><p>You can also use <a href="#useexternalfieldlookups" class="external text">field lookups</a> and other features of the search language. Depending on your search criteria and how you want to define your groupings, you may be able to use a search command, such as append, associate, contingency, join, or stats. Sometimes, there is no single command that you can use. 
</p><p>If you're not sure where to start, the following flow chart can help you decide whether to use a lookup, define a transaction, or try another search command to define your event grouping.
</p><p><img alt="Search event grouping flowchart.png" src="images/8/8e/Search_event_grouping_flowchart.png" width="700" height="550"></p><p><br>
In most cases, you can accomplish more with the stats command or the transaction command; and these are recommended over using the <code><font size="2">join</font></code> and <code><font size="2">append</font></code> commands. You can read more about when to use <code><font size="2">stats</font></code> and <code><font size="2">transaction</font></code> in the topic <a href="#abouttransactions" class="external text">"About transactions"</a> later in this chapter. You can also read more about the stats commands in the <a href="#aboutcalculatingstatistics" class="external text">"Calculate Statistics"</a> chapter of this manual.
</p><p><b>Note:</b> The information for this diagram was provided by Nick Mealy.
</p>
<a name="usetimetoidentifyrelationshipsbetweenevents"></a><h2> <a name="usetimetoidentifyrelationshipsbetweenevents_use_time_to_identify_relationships_between_events"><span class="mw-headline" id="Use_time_to_identify_relationships_between_events"> Use time to identify relationships between events</span></a></h2>
<p>Time is crucial for determining what went wrong &acirc;&#128;&#147; you often know when. Splunk enables you to identify baseline patterns or trends in your events and compare it against current activity. 
</p><p>You can run a series of time-based searches to investigate and identify abnormal activity and then use the timeline to drill into specific time periods. Looking at events that happened around the same time can help correlate results and find the root cause. 
</p><p>Read more about how to <a href="#usethetimeline" class="external text">"Use the timeline to investigate events"</a> in this manual.
</p>
<a name="abouttransactions"></a><h2> <a name="abouttransactions_about_transactions"><span class="mw-headline" id="About_transactions"> About transactions</span></a></h2>
<p>A <b>transaction</b> is any group of conceptually-related events that spans time, such as a series of events related to the online reservation of a hotel room by a single customer, or a set of events related to a firewall intrusion incident. A <b>transaction type</b> is a configured transaction, saved as a field and used in conjunction with the <code><font size="2">transaction</font></code> command. Any number of data sources can generate transactions over multiple log entries.  
</p>
<h3> <a name="abouttransactions_transaction_search"><span class="mw-headline" id="Transaction_search"> Transaction search </span></a></h3>
<p>A transaction search is useful for a single observation of any physical event stretching over multiple logged events. Use the transaction command to define a transaction or override transaction options specified in <code><font size="2">transactiontypes.conf</font></code>.
</p><p>A common <b>transaction search</b> use is to group multiple events into a single meta-event that represents a single physical event. For example, an <b>out of memory problem</b> could trigger several database events to be logged, and they can all be grouped together into a transaction.  
</p><p>To learn more, read <a href="#identifyandgroupeventsintotransactions" class="external text">"Identify and group events into transactions"</a> in this manual.
</p>
<h3> <a name="abouttransactions_when_to_use_stats_instead_of_transactions"><span class="mw-headline" id="When_to_use_stats_instead_of_transactions"> When to use stats instead of transactions </span></a></h3>
<p>Both the stats command and the transaction command are similar in that they enable you to aggregate individual events together based on field values.  
</p><p>The <code><font size="2">stats</font></code> command is meant to calculate statistics on events grouped by one or more fields and discard the events (unless you are using eventstats or streamstats). On the other hand, except for the duration between first and last events and the count of events, the <code><font size="2">transaction</font></code> command does not compute statistics over the grouped events. Additionally, it retains the raw event and other field values from the original event and enables you to group events using much more complex criteria, such as limiting the grouping by time span or delays and requiring terms to define the start or end of a group. 
</p><p>The <code><font size="2">transaction</font></code> command is most useful in two specific cases:
</p><p><b>1.</b> When a unique ID (from one or more fields) alone is not sufficient to discriminate between two transactions. This is the case when the identifier is reused, for example web sessions identified by cookie or client IP. In this case, time spans or pauses are also used to segment the data into transactions. In other cases, when an identifier is reused, for example in DHCP logs, a particular message may identify the beginning or end of a transaction.
</p><p><b>2.</b> When it is desirable to see the raw text of the events combined rather than an analysis on the constituent fields of the events.
</p><p>In other cases, it's usually better to use the <code><font size="2">stats</font></code> command, which performs more efficiently, especially in a distributed environment. Often there is a unique ID in the events and <code><font size="2">stats</font></code> can be used.
</p><p>For example, to compute the statistics on the duration of trades identified by the unique ID <code><font size="2">trade_id</font></code>, the following searches will yield the same answer:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | transaction trade_id | chart count by duration span=log2</font></code><br></div>
<p>and
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | stats range(_time) as duration by trade_id | chart count by duration span=log2</font></code><br></div>
<p>If however, the <code><font size="2">trade_id</font></code> values are reused but each trade ends with some text, such as "END", the only solution is to use this <code><font size="2">transaction</font></code> search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | transaction trade_id endswith=END | chart count by duration span=log2</font></code><br></div>
<p>On the other hand, if <code><font size="2">trade_id</font></code> values are reused, but not within a 10 minute duration, the solution is to use the following <code><font size="2">transaction</font></code> search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">... | transaction trade_id maxpause=10m | chart count by duration span=log2</font></code><br></div> 
<p><br>
Read more about <a href="#abouteventcorrelation" class="external text">"About event grouping and correlation"</a> in an earlier chapter in this manual.
</p>
<h3> <a name="abouttransactions_transactions_and_macro_search"><span class="mw-headline" id="Transactions_and_macro_search"> Transactions and macro search </span></a></h3>
<p>Transactions and macro searches are a powerful combination that allow substitution into your transaction searches.  Make a transaction search and then save it with <code><font size="2">$field$</font></code> to allow substitution. 
</p><p>For an example of how to use macro searches and transactions, see <a href="#usesearchmacros" class="external text">"Create and use search macros"</a> in the this manual.
</p>
<a name="identifyandgroupeventsintotransactions"></a><h2> <a name="identifyandgroupeventsintotransactions_identify_and_group_events_into_transactions"><span class="mw-headline" id="Identify_and_group_events_into_transactions"> Identify and group events into transactions</span></a></h2>
<p>Splunk Enterprise lets you search for related events and group them into one single event, called a transaction (or sometimes, a session). Transactions can include: 
</p>
<ul><li> Different events from the same source and the same host.
</li><li> Different events from different sources from the same host.
</li><li> Similar events from different hosts and different sources.
</li></ul><p>Search for transactions using the <code><font size="2">transaction</font></code> search command either in Splunk Web or at the CLI. The <code><font size="2">transaction</font></code> command yields groupings of events which can be used in reports. To use <code><font size="2">transaction</font></code>, either call a transaction type (that you configured via transactiontypes.conf), or define transaction constraints in your search by setting the search options of the <code><font size="2">transaction</font></code> command.
</p>
<h3> <a name="identifyandgroupeventsintotransactions_transaction_search_options"><span class="mw-headline" id="Transaction_search_options"> Transaction search options </span></a></h3>
<p>Transactions returned at search time consist of the raw text of each event, the shared event types, and the field values. Transactions also have additional data that is stored in the fields: <code><font size="2">duration</font></code> and <code><font size="2">transactiontype</font></code>. 
</p>
<ul><li> <b><code><font size="2">duration</font></code></b> contains the duration of the transaction (the difference between the timestamps of the first and last events of the transaction). 
</li><li> <b><code><font size="2">transactiontype</font></code></b> is the name of the transaction (as defined in <code><font size="2">transactiontypes.conf</font></code> by the transaction's stanza name).
</li></ul><p>You can add <code><font size="2">transaction</font></code> to any search. For best search performance, craft your search and then pipe it to the transaction command. For more information see the topic on the <code><font size="2">transaction</font></code> command in the Search Reference manual.
</p><p>Follow the <code><font size="2">transaction</font></code> command with the following options.  <b>Note:</b> Some <code><font size="2">transaction</font></code> options do not work in conjunction with others.
</p><p><code><font size="2">name=&lt;transaction-name&gt;</font></code>
</p>
<ul><li> Specifies the name of a stanza from <code><font size="2">transactiontypes.conf</font></code>. Use this to invoke a <b>transaction type</b> that you have already configured for reuse. If other arguments are provided, they overule values specified for the same arguments in the transaction rule. For example, if <code><font size="2">web_purchase</font></code>, the transaction rule you're invoking, is configured with <code><font size="2">maxevents=10</font></code>, but you'd like to run it with a different value for <code><font size="2">maxevents</font></code>, add <code><font size="2">maxevents</font></code> to the search string with the value you want: 
</li></ul><div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_*  | transaction name=web_purchase maxevents=5</font></code><br></div>
<p><i>[field-list]</i>
</p>
<ul><li> This is a comma-separated list of fields, such as <code><font size="2">...|transaction host,cookie</font></code>	
</li><li> If set, each event must have the same field(s) to be considered part of the same transaction.
</li><li> Events with common field names and different values will not be grouped. 
<ul><li> For example, if you add <code><font size="2">...|transaction host</font></code>, then a search result that has <code><font size="2">host=mylaptop</font></code> can never be in the same transaction as a search result with <code><font size="2">host=myserver</font></code>. 
</li><li> A search result that has no <code><font size="2">host</font></code> value can be in a transaction with a result that has <code><font size="2">host=mylaptop</font></code>. 
</li></ul></li></ul><p><code><font size="2">match=closest</font></code>
</p>
<ul><li> Specify the matching type to use with a transaction definition. 
</li><li> The only value supported currently is closest.
</li></ul><p><code><font size="2">maxspan=[&lt;integer&gt; s|m|h|d]</font></code>
</p>
<ul><li> Set the maximum duration of one transaction.
</li><li> Can be in seconds, minutes, hours or days. 
<ul><li> For example:  5s, 6m, 12h or 30d.
</li></ul></li><li> Defaults to <code><font size="2">maxspan=-1</font></code>, for an "all time" timerange.
</li></ul><p><code><font size="2">maxpause=[&lt;integer&gt; s|m|h|d]</font></code>
</p>
<ul><li> Specifies the maximum pause between transactions. 
</li><li> Requires there be no pause between the events within the transaction greater than maxpause. 
</li><li> If the value is negative, the maxspause constraint is disabled. 
</li><li> Defaults to <code><font size="2">maxpause=-1</font></code>. 
</li></ul><p><code><font size="2">startswith=&lt;string&gt;</font></code>
</p>
<ul><li> A search or eval-filtering expression which, if satisfied by an event, marks the beginning of a new transaction. 
</li><li> For example:
<ul><li> <code><font size="2">startswith="login"</font></code>
</li><li> <code><font size="2">startswith=(username=foobar)</font></code>
</li><li> <code><font size="2">startswith=eval(speed_field &lt; max_speed_field)</font></code>
</li><li> <code><font size="2">startswith=eval(speed_field &lt; max_speed_field/12)</font></code>
</li></ul></li><li> Defaults to <code><font size="2">""</font></code>.
</li></ul><p><code><font size="2">endswith=&lt;transam-filter-string&gt;</font></code>
</p>
<ul><li> A search or eval-filtering expression which, if satisfied by an event, marks the end of a transaction. 
</li><li> For example:
<ul><li> <code><font size="2">endswith="logout"</font></code>
</li><li> <code><font size="2">endswith=(username=foobar)</font></code>
</li><li> <code><font size="2">endswith=eval(speed_field &lt; max_speed_field)</font></code>
</li><li> <code><font size="2">endswith=eval(speed_field &lt; max_speed_field/12)</font></code>
</li></ul></li><li> Defaults to <code><font size="2">""</font></code>.
</li></ul><p>For <code><font size="2">startswith</font></code> and <code><font size="2">endswith</font></code>, <code><font size="2">&lt;transam-filter-string&gt;</font></code> is defined with the following syntax:
<code><font size="2">"&lt;search-expression&gt;" | (&lt;quoted-search-expression&gt;) | eval(&lt;eval-expression&gt;</font></code>
</p>
<ul><li> <code><font size="2">&lt;search-expression&gt;</font></code> is a valid search expression that does not contain quotes.
</li><li> <code><font size="2">&lt;quoted-search-expression&gt;</font></code> is a valid search expression that contains quotes.
</li><li> <code><font size="2">&lt;eval-expression&gt;</font></code> is a valid eval expression that evaluates to a boolean.
</li></ul><p>Examples:
</p>
<ul><li> search expression: <code><font size="2">(name="foo bar")</font></code>
</li><li> search expression: <code><font size="2">"user=mildred"</font></code>
</li><li> search expression: <code><font size="2">("search literal")</font></code>
</li><li> eval bool expression: <code><font size="2">eval(distance/time &lt; max_speed)</font></code>
</li></ul><h3> <a name="identifyandgroupeventsintotransactions_example_transaction_search"><span class="mw-headline" id="Example_transaction_search"> Example transaction search </span></a></h3>
<p><b>Run a search that groups together all of the web pages a single user (or client IP address) looked at over a time range.</b> 
</p><p>This search takes events from the access logs, and creates a transaction from events that share the same <code><font size="2">clientip</font></code> value that occurred within 5 minutes of each other (within a 3 hour time span).   
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_combined  | transaction clientip maxpause=5m maxspan=3h</font></code><br></div>
<p>Refer to the transaction command topic in the Search Reference Manual for more examples.
</p>
<h1>Predict Future Events</h1><a name="aboutpredictiveanalytics"></a><h2> <a name="aboutpredictiveanalytics_about_predictive_analytics_with_splunk_enterprise"><span class="mw-headline" id="About_predictive_analytics_with_Splunk_Enterprise"> About predictive analytics with Splunk Enterprise </span></a></h2>
<p>Predictive analytics can be used in a number of ways. For example:
</p>
<ul><li> It aids in capacity planning by helping you to determine your hardware requirements for virtual environments and forecast energy consumption.
</li><li> It enables enhanced root cause analysis that can help detect abnormal patterns in events and prevent security attacks.
</li><li> It enables enhanced monitoring of key components which can detect system failures and prevent outages before they occur. 
</li></ul><p>Splunk enables you to use reports and dashboards to monitor activity as it is happening, then drill down into events and do a root-cause analysis to learn why something happened. If there are patterns and correlations to events that you monitor, you can use them to predict future activity. With this knowledge, you can proactively send alerts based on thresholds and perform "what-if" analyses to compare various scenarios.
</p>
<h3> <a name="aboutpredictiveanalytics_predictive_analytics_commands"><span class="mw-headline" id="Predictive_analytics_commands"> Predictive analytics commands </span></a></h3>
<p>The Splunk search language includes two forecasting commands: predict and x11. 
</p>
<ul><li> The predict command enables you to use different forecasting algorithms to predict future values of single and multivalue fields. 
</li><li> The x11 command, which is named after the X11 algorithm, removes seasonal fluctuations in fields to expose the real trend in your underlying data series.
</li></ul><h4><font size="3"><b><i> <a name="aboutpredictiveanalytics_forecasting_algorithms_for_predict"><span class="mw-headline" id="Forecasting_algorithms_for_predict"> Forecasting algorithms for predict </span></a></i></b></font></h4>
<p>You can select from the following algorithms with the predict command: LL, LLP, LLT, LLB, and LLP5. Each of these algorithms are variations based on the Kalman filter. 
</p>
<table cellpadding="5" cellspacing="0" border="1"><tr><th bgcolor="#C0C0C0">Algorithm option
</th><th bgcolor="#C0C0C0">Algorithm name
</th><th bgcolor="#C0C0C0">Description
</th></tr><tr><td valign="center" align="left"> LL
</td><td valign="center" align="left"> Local level
</td><td valign="center" align="left"> This is a univariate model with no trends and no seasonality. Requires a minimum of 2 data points.
</td></tr><tr><td valign="center" align="left"> LLP
</td><td valign="center" align="left"> Seasonal local level
</td><td valign="center" align="left"> This is a univariate model with seasonality. The periodicity of the time series is automatically computed. Requires the minimum number of data points to be twice the period.
</td></tr><tr><td valign="center" align="left"> LLT
</td><td valign="center" align="left"> Local level trend
</td><td valign="center" align="left"> This is a univariate model with trend but no seasonality. Requires a minimum of 3 data points.
</td></tr><tr><td valign="center" align="left"> LLB
</td><td valign="center" align="left"> Bivariate local level
</td><td valign="center" align="left"> This is a bivariate model with no trends and no seasonality. Requires a minimum of 2 data points. LLB uses one set of data to make predictions for another. For example, assume it uses dataset Y to make predictions for dataset X. If the holdback=10, the LLB algorithm uses the last 10 data points of Y to make predictions for the last 10 data points of X.
</td></tr><tr><td valign="center" align="left"> LLP5
</td><td valign="center" align="left">
</td><td valign="center" align="left"> Combines LLT and LLP models for its prediction.
</td></tr></table><p>See the predict command in the <i>Search Reference</i>.
</p>
<h4><font size="3"><b><i> <a name="aboutpredictiveanalytics_additive_and_multiplicative_seasonality_in_x11"><span class="mw-headline" id="Additive_and_multiplicative_seasonality_in_X11"> Additive and multiplicative seasonality in X11 </span></a></i></b></font></h4>
<p>The seasonal component of your time series data can be either additive or multiplicative. In Splunk Enterprise, this is defined as the two types of seasonality that you can calculate with x11, add() for additive and mult() for multiplicative.
</p><p>How do you know which type of seasonality to adjust from your data? The best way to describe the difference between an additive and a multiplicative seasonal component is with an example: The annual sales of flowers will peak on and around certain days of the year, including Valentine's Day and Mother's day.
</p><p>During Valentine's Day, the sale of roses may increase by X dollars every year. This dollar amount is independent of the normal level of the series, and you can add X dollars to your forecasts for Valentine's Day every year, making this time series a candidate for an additive seasonal adjustment. In an additive seasonal adjustment, each value of a time series is adjusted by adding or subtracting a quantity that represents the absolute amount by which that value differs from normal in that season.
</p><p>Alternatively, in a multiplicative seasonal component, the seasonal effect expresses itself in percentage terms, so the absolute magnitude of the seasonal variations increases as the series grows over time. For example, the number of roses sold during Valentine's Day may increase by 40% or a factor of 1.4. When the sales of roses generally weak, the absolute (dollar) increase in Valentine's Day sales will also be relatively weak&nbsp;; but the percentage will be constant. And, if the sales of roses are strong, then the absolute (dollar) increase will be proportionately greater. In a multiplicative seasonal adjustment, this pattern is removed by dividing each value of the time series by a quantity that represents the percentage from normal or factor that is typically observed in that season. 
</p><p>When plotted on a chart, these two types of seasonal components will show distinguishing characteristics:
</p>
<ul><li> The additive seasonal series shows steady seasonal fluctuations, regardless of the overall level of the series.
</li><li> The multiplicative seasonal series shows varying size of seasonal fluctuations that depend on the overall level of the series.
</li></ul><h1>More Ways to Search</h1><a name="usesearchmacros"></a><h2> <a name="usesearchmacros_create_and_use_search_macros"><span class="mw-headline" id="Create_and_use_search_macros"> Create and use search macros </span></a></h2>
<p><b>Search macros</b> are chunks of a search that you can reuse in multiple places, including saved and ad hoc searches. Search macros can be any part of a search, such as an eval statement or search term, and do not need to be a complete command. You can also specify whether or not the macro field takes any arguments. 
</p>
<h3> <a name="usesearchmacros_create_search_macros_in_splunk_web"><span class="mw-headline" id="Create_search_macros_in_Splunk_Web"> Create search macros in Splunk Web </span></a></h3>
<p>In <b>Settings &gt; Advanced Search &gt; Search macros</b>, click "New" to create a new search macro.
</p>
<h4><font size="3"><b><i> <a name="usesearchmacros_define_the_search_macro_and_its_arguments"><span class="mw-headline" id="Define_the_search_macro_and_its_arguments"> Define the search macro and its arguments </span></a></i></b></font></h4>
<p>Your search macro can be any chunk of your search string or search command pipeline that you want to re-use as part of another search.
</p><p><b>Destination app</b> is the name of the app you want to restrict your search macro to; by default, your search macros are restricted to the Search app.
</p><p><b>Name</b> is the name of your search macro, such as <code><font size="2">mymacro</font></code>. If your search macro takes an argument, you need to indicate this by appending the number of arguments to the name; for example, if <code><font size="2">mymacro</font></code> required two arguments, it should be named <code><font size="2">mymacro(2)</font></code>. You can create multiple search macros that have the same name but require different numbers of arguments: <code><font size="2">foo, foo(1), foo(2), etc</font></code>.
</p><p><b>Definition</b> is the string that your search macro expands to when referenced in another search. If the search macro requires the user to input arguments, they are tokenized and indicated by wrapping dollar signs around the arguments; for example, <code><font size="2">$arg1$</font></code>. The arguments values are then specified when the search macro is invoked.
</p>
<ul><li> If <b>Eval Generated Definition?</b> is checked, then the 'Definition' is expected to be an eval expression that returns a string that represents the expansion of this macro.
</li><li> <b>If a macro definition includes a leading pipe character ("|"), you may not use it as the first term in searches from the UI.</b> Example: "| metadata type=sources". The UI does not do the macro expansion and cannot correctly identify the initial pipe to differentiate it from a regular search term. The UI constructs the search as if the macro name were a search term, which after expansion would cause the metadata command to be incorrectly formed and therefore invalid.
</li></ul><p><b>Arguments</b> are a comma-delimited string of argument names. Argument names may only contain the characters: alphanumeric 'a-Z, A-Z, 0-9'; underscore '_'; and dash '-'. This list should not contain any repeated elements.
</p>
<ul><li> <b>If a macro argument includes quotes, you need to escape the quotes when you call the macro in your search.</b> For example, if you wanted to pass a quoted string as your macro's argument, you would use: <code><font size="2">`my-macro("He said \"hello!\"")`</font></code>.
</li></ul><h4><font size="3"><b><i> <a name="usesearchmacros_validate_your_argument_values"><span class="mw-headline" id="Validate_your_argument_values"> Validate your argument values </span></a></i></b></font></h4>
<p>You can verify that the argument values used to invoke the search macro are acceptable. How to invoke search macros are discussed in the following section, "Apply macros to saved and ad hoc searches".
</p>
<ul><li> <b>Validation Expression</b> is a string that is an 'eval' expression that evaluates to a boolean or a string.
</li><li> If the validation expression is a boolean expression, validation succeeds when it returns true.  If it returns false or is null, validation fails, and the <b>Validation Error Message</b> is returned.
</li></ul><p>If the validation expression is not a boolean expression, it is expected to return a string or NULL.  If it returns null, validation is considered a success. Otherwise, the string returned is rendered as the error string.
</p>
<h3> <a name="usesearchmacros_apply_macros_to_saved_and_ad_hoc_searches"><span class="mw-headline" id="Apply_macros_to_saved_and_ad_hoc_searches"> Apply macros to saved and ad hoc searches </span></a></h3>
<p>To include a search macro in your saved or ad hoc searches, use the left quote (also known as a grave accent) character; on most English-language keyboards, this character is located on the same key as the tilde (~). You can also reference a search macro within other search macros using this same syntax. 
</p><p><b>Note:</b> Do NOT use the straight quote character that appears in the same key as the double quote (").
</p>
<h3> <a name="usesearchmacros_example_-_combine_search_macros_and_transactions"><span class="mw-headline" id="Example_-_Combine_search_macros_and_transactions"> Example - Combine search macros and transactions </span></a></h3>
<p>Transactions and macro searches are a powerful combination that you can use to simplify your transaction searches and reports. This example demonstrates how you can use search macros to build reports based on a defined transaction.
</p><p>Here, a search macro, named "makesessions", defines a transaction session from events that share the same clientip value that occurred within 30 minutes of each other:
</p>
<code><font size="2"><br>transaction clientip maxpause=30m<br></font></code>
<p>This search takes web traffic events and breaks them into sessions, using the "makesessions" search macro:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | `makesessions`</font></code><br></div>
<p>This search returns a report of the number of pageviews per session for each day:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">sourcetype=access_* | `makesessions` | timechart span=1d sum(eventcount) as pageviews count as sessions</font></code><br></div>
<p>If you wanted to build the same report, but with varying span lengths, just save it as a search macro with an argument for the span length. Let's call this search macro, "pageviews_per_second(1)":
</p>
<code><font size="2"><br>sourcetype=access_* | `makesessions` | timechart $spanarg$ sum(eventcount) as pageviews count as sessions<br></font></code>
<p>Now, you can specify a span length when you run this search from the Search app or add it to a saved search:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2">`pageviews_per_second(span=1h)`</font></code><br></div>

<h1>Export search results</h1><a name="exportsearchresults"></a><h2> <a name="exportsearchresults_export_search_results"><span class="mw-headline" id="Export_search_results"> Export search results</span></a></h2>
<p>This topic provides a technical overview of Splunk Enterprise data export methods. You can export search results directly out of Splunk Enterprise. You can also forward data to third party systems.
</p>
<h3> <a name="exportsearchresults_what_are_the_available_export_methods.3f"><span class="mw-headline" id="What_are_the_available_export_methods.3F"> What are the available export methods?</span></a></h3>
<p>Splunk Enterprise provides several export methods:
</p>
<ul><li> Splunk Web
</li><li> The command line interface (CLI)
</li><li> Splunk Enterprise Software Development Kits (SDK)
</li><li> Representational State Transfer (REST)
</li><li> The dump search command
</li><li> Data forwarding
</li></ul><h3> <a name="exportsearchresults_overview_of_splunk_enterprise_export_options"><span class="mw-headline" id="Overview_of_Splunk_Enterprise_export_options">Overview of Splunk Enterprise export options</span></a></h3>
<p>Splunk Enterprise can export data in different ways. The export method you choose depends on the data volumes involved and your level of interactivity. For example, a single on-demand search export through Splunk Web may be appropriate for a low-volume export. Alternatively, if you want to set up a higher-volume, scheduled export, the SDK and REST options work best.
</p><p>For large exports, the most stable method of search data retrieval is the Command Line Interface (CLI). From the CLI, you can tailor your search to external applications using the various Splunk Enterprise SDKs. The REST API works from the CLI as well, but is recommended only for internal use.
</p><p>In terms of level of expertise, the Splunk Web and CLI methods are significantly more accessible than the SDKs and REST API, which require previous experience working with software development kits or REST API endpoints.
</p>
<table cellpadding="5" cellspacing="0" border="1" width="100%"><tr><th bgcolor="#C0C0C0">Method
</th><th bgcolor="#C0C0C0">Volume
</th><th bgcolor="#C0C0C0">Interactivity
</th><th bgcolor="#C0C0C0">Remarks
</th></tr><tr valign="top"><td width="20%" valign="center" align="left"> Splunk Web
</td><td width="20%" valign="center" align="left"> Low
</td><td width="30%" valign="center" align="left"> On-Demand, Interactive
</td><td width="30%" valign="center" align="left"> Easy to obtain on-demand exports
</td></tr><tr valign="top"><td valign="center" align="left"> CLI
</td><td valign="center" align="left"> Medium
</td><td valign="center" align="left"> On-Demand, Low Interactive
</td><td valign="center" align="left"> Easy to obtain on-demand exports
</td></tr><tr valign="top"><td valign="center" align="left"> REST
</td><td valign="center" align="left"> High
</td><td valign="center" align="left"> Automated, best for computer-to-computer
</td><td valign="center" align="left"> Works underneath SDK
</td></tr><tr valign="top"><td valign="center" align="left"> SDK
</td><td valign="center" align="left"> High
</td><td valign="center" align="left"> Automated, best for computer-to-computer
</td><td valign="center" align="left"> Best for automation
</td></tr></table><h3> <a name="exportsearchresults_choose_your_export_format"><span class="mw-headline" id="Choose_your_export_format">Choose your export format</span></a></h3>
<p>Splunk Enterprise lets you directly export your data into the following formats:
</p>
<ul><li> Raw Events
</li><li> CSV
</li><li> JSON
</li><li> XML
</li></ul><h3> <a name="exportsearchresults_export_data_using_splunk_web"><span class="mw-headline" id="Export_data_using_Splunk_Web"> Export data using Splunk Web</span></a></h3>
<p><b>1.</b> Run a search on your data. 
</p><p><b>2.</b> Click the export button, located directly below the timeline, and identifiable as <img alt="Splunk Export Button.jpg" src="images/a/a4/Splunk_Export_Button.jpg" width="24" height="28">.
</p><p><b>3.</b> Select the <b>Format</b> that you want the search results to be exported in. You can select <b>CSV</b>, <b>Raw Events</b>, <b>XML</b> or <b>JSON</b>).
</p><p><img alt="Export1.png" src="images/3/30/Export1.png" width="457" height="257"></p><p><b>4.</b> Choose the <b>Number of Results</b> you want ('<i>Limited</i> or <b>Unlimited</b>).
</p><p><img alt="Export2.png" src="images/5/5e/Export2.png" width="456" height="251"></p><p><b>5.</b> Click <b>Export</b> to confirm.
</p>
<h4><font size="3"><b><i> <a name="exportsearchresults_extend_the_session_timeout_when_exporting_large_amounts_of_data"><span class="mw-headline" id="Extend_the_session_timeout_when_exporting_large_amounts_of_data">Extend the session timeout when exporting large amounts of data</span></a></i></b></font></h4>
<p>When you try to export large amounts of data using the export button, you can run into session timeout issues. Follow this procedure to extend the session timeout limit.
</p><p><b>1.</b> Click <b>Settings</b> and select <b>System Settings</b>.
</p><p><b>2.</b> Under <b>Splunk Web</b>, increase the number in the Session timeout field.
</p><p><img alt="Timeout.png" src="images/8/87/Timeout.png" width="569" height="249"></p><p>Increasing the timeout settings allows Splunk Web more time for the connection between your browser and splunkweb.
</p>
<h4><font size="3"><b><i> <a name="exportsearchresults_archive_search_results"><span class="mw-headline" id="Archive_search_results">Archive search results</span></a></i></b></font></h4>
<p>If you need to archive your search results, Splunk Enterprise can export your job data into third-party charting applications. See "Export job data to a file" in the <i>Knowledge Manager Manual</i>.
</p>
<h4><font size="3"><b><i> <a name="exportsearchresults_schedule_reports_that_send_results_to_stakeholders"><span class="mw-headline" id="Schedule_reports_that_send_results_to_stakeholders"> Schedule reports that send results to stakeholders </span></a></i></b></font></h4>
<p>You can schedule reports to run on a regular interval and send their results to project stakeholders via email. The emails can present the report results in inline tables and CSV or PDF attachments. They can also include links to the report results in Splunk Enterprise.
</p><p>See "Schedule Reports" in the <i>Reporting Manual</i>.
</p>
<h3> <a name="exportsearchresults_export_data_using_the_cli"><span class="mw-headline" id="Export_data_using_the_CLI"> Export data using the CLI</span></a></h3>
<p>The Command Line Interface (CLI) is easy to script, can handle automation, and can process volumes of data faster and more efficiently than Splunk Web.  
</p><p>To access Splunk Enterprise through the CLI, you either need shell access to a Splunk Enterprise server, or permission to access the correct port on a remote Splunk server.  
</p><p>Splunk Enterprise CLI exports use the following command structure:
</p>
<div class="samplecode">
<code><font size="2"><br>&nbsp;splunk search [eventdata] -preview 0 -maxout 0 -output [rawdata|json|csv|xml] &gt; [myfilename.log] ... </font></code> </div>
<p>By default, CLI exports only export 100 events. To increase this number, use the <code><font size="2">-maxout</font></code> argument. For example, if you include <code><font size="2">-maxout 300000</font></code> you can export 300,000 events. Set <code><font size="2">-maxout</font></code> to 0 to export an unlimited number of events.
</p><p>To learn more about the Splunk Enterprise CLI, read  "About the CLI" in the <i>Admin Manual</i>.
</p>
<h4><font size="3"><b><i> <a name="exportsearchresults_cli_output_command_example"><span class="mw-headline" id="CLI_output_command_example"> CLI output command example</span></a></i></b></font></h4>
<p>This CLI example takes events from the <code><font size="2">_internal</font></code> index that occur within the time range specified by the search string and outputs 200,000 of them in raw data format to the file <code><font size="2">test123.dmp</font></code>.
</p>
<div class="samplecode">
<code><font size="2"><br>splunk search "index=_internal earliest=09/14/2014:23:59:00 latest=09/16/2014:01:00:00 " -output rawdata -maxout 200000 &gt; c:/test123.dmp <br></font></code> </div>
<h3> <a name="exportsearchresults_export_using_the_splunk_enterprise_rest_api"><span class="mw-headline" id="Export_using_the_Splunk_Enterprise_REST_API">Export using the Splunk Enterprise REST API </span></a></h3>
<p>You can bypass the Splunk Enterprise SDKs and gain access to Splunk Enterprise by directly using the REpresentational State Transfer (REST) model to make requests from a terminal or browser. The Splunk REST API lets you GET and POST data from a Splunk instance. 
</p><p>To export data using the REST API you need to GET your data from an endpoint. But before you can do that you need to run the search job.
</p><p><b>1.</b> Run a search job using the POST operation at <code><font size="2">/services/search/jobs/export</font></code>.
</p>
<dl><dd> Set your search as the POST payload. Remember to include the date range in the search, if you want to include one.
</dd></dl><div class="samplecode">
<code><font size="2"><br>curl -k -u admin:changeme \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://localhost:8089/services/search/jobs/export -d search="search sourcetype=access_* earliest=-7d"<br></font></code> </div>
<p><b>2.</b> Obtain the search job ID (SID) for the search.
</p>
<dl><dd> The search returns an XML response that includes the search job ID in <code><font size="2">&lt;sid&gt;</font></code> tags.
</dd></dl><div class="samplecode">
<code><font size="2"><br>&lt;?xml version='1.0' encoding='UTF-8'?&gt;<br>&lt;response&gt;<br>&nbsp;&nbsp;&lt;sid&gt;1423855196.339&lt;/sid&gt;<br>&lt;/response&gt;<br></font></code> </div>
<dl><dd> You can also get the search job ID by viewing the job in the <b>Search Job Inspector</b>. Navigate to <b>Activity &gt; Jobs</b> to open the Job Manager, locate the search job you just ran, and click <b>Inspect</b>. The Search Job Inspector opens in a separate window. 
</dd></dl><p><b>3.</b> Create a GET operation to export the results of the search to a file.
</p>
<dl><dd> The operation should:
</dd></dl><ul><li> Identify your object endpoints. Each endpoint gives you access to a different area of Splunk. To see a list of currently available object endpoints for your user, within your app, navigate to <code><font size="2">https://localhost:8089/servicesNS/&lt;user&gt;/&lt;app&gt;/</font></code>. For example, <code><font size="2">https://localhost:8089/servicesNS/admin/search/saved/searches/</font></code>.
</li></ul><ul><li> Identify the search job user and app. The following example defines <code><font size="2">&lt;user&gt;</font></code> as <code><font size="2">admin</font></code> and <code><font size="2">&lt;app&gt;</font></code> as <code><font size="2">search</font></code>.
</li></ul><ul><li> Use <code><font size="2">output_mode</font></code> to identify your output format. Possible values are <code><font size="2">JSON</font></code>, <code><font size="2">CSV</font></code>, or <code><font size="2">XML</font></code> The following example exports the search results to a JSON file.
</li></ul><div class="samplecode">
<code><font size="2"><br>curl -u admin:changeme \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-k https://localhost:8089/servicesNS/admin/search/jobs/1423855196.339/results/ \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--get -d output_mode=json count=5<br></font></code> </div>
<p>For more information about object endpoints in Splunk Enterprise, read "Search endpoint descriptions" in the <i>REST API Reference Manual</i>. 
</p><p>For more information about using the REST API to work with searches, see "Creating searches using the REST API" in <i>Rest API Tutorials</i>.
</p><p>For a detailed overview of the <code><font size="2">/services/search/jobs/export</font></code> endpoint, see "Search endpoint descriptions" in the <i>REST API Reference Manual</i>.
</p>
<h3> <a name="exportsearchresults_export_using_splunk_sdks"><span class="mw-headline" id="Export_using_Splunk_SDKs">Export using Splunk SDKs</span></a></h3>
<p>Splunk provides Software Development Kits (SDKs) that help software developers create Splunk apps using common programming languages. Splunk SDKs let you integrate Splunk Enterprise with third-party reporting tools and portals, include search results in your application, and extract high volumes of data for archival purposes. Use of Splunk SDKs require proficiency in SDK knowledge and development.
</p><p>Splunk offers SDKs for Python, Java, JavaScript, Ruby, and C#. Export searches in these SDKs run immediately, do not create a job for the search, and start streaming results immediately. 
</p><p>The Splunk SDKs are built on top of the Splunk Enterprise REST API. They provide a simpler interface for the REST API endpoints. With fewer lines of code, you can write applications that can: 
</p>
<ul><li> Create and run authenticated searches
</li><li> Add data
</li><li> Index data 
</li><li> Manage search jobs 
</li><li> Configure Splunk 
</li></ul><p>For more information about the Splunk SDKs, read "Overview of the Splunk SDKs" in the Splunk Developer Portal.
</p>
<h4><font size="3"><b><i> <a name="exportsearchresults_python_sdk"><span class="mw-headline" id="Python_SDK">Python SDK</span></a></i></b></font></h4>
<p>The Splunk SDK for Python lets you write Python applications that can interact with Splunk Enterprise. Export searches using the Python SDK can be run in historical mode and real-time mode. They start right away, and stream results instantly, letting you integrate them into your Python application. 
</p><p>Perform an export search using the Python SDK.
</p><p><b>1.</b> Set the parameters of what you wish to search. The following example sets the parameters as an export search of <code><font size="2">splunklib</font></code> in the last hour.
</p>
<div class="samplecode">
<code><font size="2"><br>import splunklib.client as client<br>import splunklib.results as results<br></font></code> </div>
<p><b>2.</b>  Run a normal-mode search. 
</p>
<div class="samplecode">
<code><font size="2"><br>service = client.connect(&acirc;&#128;&brvbar;)<br>rr = results.ResultsReader(service.jobs.export("search index=_internal | earliest= -1h))<br></font></code> </div>
<p><b>3.</b> Get the results and display them using the ResultsReader.
</p>
<div class="samplecode">
<code><font size="2"><br>&nbsp;if isinstance(result, results.Message):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Diagnostic messages may be returned in the results<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print '%s:&nbsp;%s'&nbsp;% (result.type, result.message)<br>&nbsp;&nbsp;&nbsp;&nbsp;elif isinstance(result, dict):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Normal events are returned as dicts<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print result<br>assert rr.is_preview == False<br></font></code> </div>
<h4><font size="3"><b><i> <a name="exportsearchresults_java_sdk"><span class="mw-headline" id="Java_SDK">Java SDK</span></a></i></b></font></h4>
<p>The Java SDK is able to conduct and export searches while using Java. 
</p><p>To perform an export search using the Java SDK, run the following example in the <code><font size="2">/splunk-sdk-java</font></code> directory using the CLI:
</p>
<div class="samplecode">
<code><font size="2"><br>java -jar dist/examples/export.jar main --username="admin" --password="changeme"<br></font></code> </div>
<p>The Export application exports the "main" index to <code><font size="2">export.out</font></code>, which is saved to the current working directory. If you want to run this application again, delete <code><font size="2">export.out</font></code> before you try again. If you do not do this, you will get an error.
</p><p>Here is a different CLI example of the Java SDK. It shows how to include a search query and change the output format to JSON.
</p>
<div class="samplecode">
<code><font size="2"><br>java -jar dist/examples/export.jar main --search="search sourcetype=access_*" json<br></font></code> </div>
<h4><font size="3"><b><i> <a name="exportsearchresults_javascript_export"><span class="mw-headline" id="JavaScript_Export">JavaScript Export</span></a></i></b></font></h4>
<p>The Javascript Export endpoint can export data out of Splunk Enterprise within the Javascript framework.  
</p><p>Splunk Enterprise does not currently support the Javascript Export endpoint in its Javascript SDK. However, you can use a node javascript (.js) application request to export data.
</p><p>To perform an export search using the Javascript Export endpoint:
</p><p><b>1.</b> Load the request module. Request is designed to be the simplest way to make an http/https call.
</p>
<div class="samplecode">
<code><font size="2"><br>var request = require('request');<br></font></code> </div>
<p><b>2.</b> Call <b>get</b> to issue a GET request. Enter the following parameters:
</p>
<ul><li> <code><font size="2">strictSSL</font></code> &acirc;&#128;&#147; When set to false, <code><font size="2">strictSSL</font></code> tells the request to not validate the server certificate returned by Splunk Enterprise, which by default is not a valid certificate.
</li><li> <code><font size="2">uri</font></code> &acirc;&#128;&#147; Provide the <code><font size="2">uri</font></code> of the Splunk Enterprise host along with the path for the export endpoint. A JSON response is specified in the query string.
</li><li> <code><font size="2">qs</font></code> &acirc;&#128;&#147; Set <code><font size="2">qs</font></code> to supply the search parameter. By passing it this way, you do not have to URI encode the search string.
</li></ul><div class="samplecode">
<code><font size="2"><br>request.get(<br>&nbsp;&nbsp;&nbsp;&nbsp;{<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;strictSSL: false,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uri: 'https://localhost:8089/servicesNS/admin/search/search/jobs/<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;export?output_mode=json',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;qs: {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;search: 'search index=_internal'<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>&nbsp;&nbsp;&nbsp;&nbsp;}<br>)<br><br></font></code> </div>
<p><b>3.</b> Call <code><font size="2">auth</font></code> to use HTTP Basic Auth and pass your Splunk Enterprise username and password.
</p>
<div class="samplecode">
<code><font size="2"><br>.auth('admin', 'changeme', false)<br></font></code> </div>
<p><b>4.</b> Pipe the results to <code><font size="2">stdout</font></code>.
</p>
<div class="samplecode">
<code><font size="2"><br>.pipe(process.stdout);<br></font></code> </div>
<h4><font size="3"><b><i> <a name="exportsearchresults_c.23_sdk"><span class="mw-headline" id="C.23_SDK">C# SDK</span></a></i></b></font></h4>
<p>An export search using the C# SDK runs asynchronously and immediately, does not create a job for the search, and starts streaming results right away. The C# SDK is useful when exporting large amounts of historical or real-time data. 
</p><p>To perform an export search using the C# SDK:
</p><p><b>1.</b> Create a preview search using StreamReader.
</p>
<div class="samplecode">
<code><font size="2"><br>SearchPreviewStream searchPreviewStream;<br></font></code> </div>
<p><b>2.</b> Export the search result previews.
</p>
<div class="samplecode">
<code><font size="2"><br>using (searchPreviewStream = service.ExportSearchPreviewsAsync("search index=_internal | head 100").Result)<br>{<br>&nbsp;&nbsp;&nbsp;&nbsp;int previewNumber = 0;<br></font></code> </div>
<p><b>3.</b> Enumerate through each search result preview.
</p>
<div class="samplecode">
<code><font size="2"><br><br>&nbsp;&nbsp;&nbsp;&nbsp;foreach (var searchPreview in searchPreviewStream.ToEnumerable())<br>&nbsp;&nbsp;&nbsp;&nbsp;{<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Console.WriteLine("Preview {0:D8}: {1}", ++previewNumber, searchPreview.IsFinal&nbsp;? "final"&nbsp;: "partial");<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int recordNumber = 0;<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;foreach (var result in searchPreview.Results)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Console.WriteLine(string.Format("{0:D8}: {1}", ++recordNumber, result));<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>&nbsp;&nbsp;&nbsp;&nbsp;}<br>}<br><br></font></code> </div>
<h4><font size="3"><b><i> <a name="exportsearchresults_ruby_sdk"><span class="mw-headline" id="Ruby_SDK">Ruby SDK</span></a></i></b></font></h4>
<p>The Ruby SDK helps developers build applications using Splunk Enterprise. The Splunk SDK for Ruby lets you write Ruby applications that can interact with the Splunk engine. The following instructions assume you have constructed your service class and connected to your Splunk server.
</p><p>To perform an export search using the Ruby SDK: 
</p><p><b>1.</b> Identify your search time parameters using the <code><font size="2">create_export</font></code> method. 
</p>
<dl><dd> The <code><font size="2">create_export</font></code> method starts a search query and returns the events found by the job before they are run through any transforming commands in the search string. This is equivalent to calling events on a job.
</dd></dl><dl><dd> This search example returns events that have taken place within the last hour (-1h, now).
</dd></dl><div class="samplecode">
<code><font size="2"><br>stream = service.create_export("search index=_internal | head 1",<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:earliest_time =&gt; "-1h",<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:latest_time =&gt; "now")<br></font></code> </div>
<p><b>2.</b> Identify the set of events that you want to export. 
</p>
<dl><dd> The following example is an export search of a streaming set of events that are output as raw data (<code><font size="2">_raw</font></code>). To speed up performance it returns events before processing them through the transforming search commands in the search string, if any exist. This means that previews are skipped until the export search returns.
</dd></dl><div class="samplecode">
<code><font size="2"><br>results = Splunk::ResultsReader.new(stream)<br>results.each do |result|<br>puts "#{result["_raw"]}"<br>end<br></font></code> </div>
<p><b>3.</b> Save your code to an <code><font size="2">.rb</font></code> file (<code><font size="2">example.rb</font></code>).
</p><p><b>4.</b> Run <code><font size="2">example.rb</font></code> on your terminal.
</p>
<h3> <a name="exportsearchresults_use_the_dump_search_command"><span class="mw-headline" id="Use_the_Dump_search_command"> Use the Dump search command </span></a></h3>
<p>The <code><font size="2">dump</font></code> search command allows large collections of events to be "dumped" onto a local disk. It can be used with the CLI, Splunk SDK and Splunk Web.
</p><p>The basic syntax of the <code><font size="2">dump</font></code> command is:
</p>
<div class="samplecode">
<code><font size="2"> dump basefilename=&lt;string&gt; [rollsize=&lt;number&gt;] [maxlocal=&lt;number&gt;] [compress=&lt;number&gt;] [format=&lt;string&gt;] [fields=&lt;comma-delimited-string&gt;] </font></code> </div>
<p>The <code><font size="2">&lt;format&gt;</font></code> is the data format of the dump file that you are creating. Your format options are <code><font size="2">raw</font></code>, <code><font size="2">csv</font></code>, <code><font size="2">tsv</font></code>,<code><font size="2">xml</font></code>, and <code><font size="2">json</font></code>.
</p><p><code><font size="2">maxlocal</font></code> is the maximum allowable disk usage in MB for this dump. The default is 1GB.
</p><p>See the topic on the <code><font size="2">dump</font></code> command in the <i>Search Reference</i> for search examples and full explanations of the <code><font size="2">dump</font></code> command required and optional arguments.
</p>
<h3> <a name="exportsearchresults_forward_data_to_third_party_systems"><span class="mw-headline" id="Forward_data_to_third_party_systems"> Forward data to third party systems </span></a></h3>
<p>Splunk Enterprise is able to forward data to third-party systems. It can send data:
</p>
<ul><li> Through a plain TCP socket
</li><li> Packaged in a standard syslog
</li></ul><p>You configure heavy forwarders by editing <code><font size="2">outputs.conf</font></code>, <code><font size="2">props.conf</font></code> and <code><font size="2">transforms.conf</font></code>. This export method is similar to routing your data to other Splunk Enterprise instances. You can filter the data by host, source, or source type. See "Forward data to third party systems" in the <i>Forwarding Data</i> manual.
</p>
<h1>Write Custom Search Commands</h1><a name="aboutcustomsearchcommands"></a><h2> <a name="aboutcustomsearchcommands_about_this_chapter"><span class="mw-headline" id="About_this_chapter"> About this chapter </span></a></h2>
<p>Splunk's search language includes a wide variety of commands that you can use to get what you want out of your data and even to display the results in different ways. You have commands to correlate events and calculate statistics on your results, evaluate fields and reorder results, reformat and enrich your data, build charts, and more. Still, Splunk enables yout to expand the search language to customize these commands to better meet your needs or to write your own search commands for custom processing or calculations.
</p><p>This chapter discusses:
</p>
<ul><li> Some style guidelines for naming your search command and its arguments.
</li><li> The outline for writing a search command and integrating it into Splunks set of search commands.
</li><li> How to set permissions and access control on your search commands.
</li><li> Custom search command examples.
</li></ul><a name="searchcommandstyleguide"></a><h2> <a name="searchcommandstyleguide_search_command_style_guide"><span class="mw-headline" id="Search_command_style_guide"> Search command style guide</span></a></h2>
<p>This topic discusses guidelines for the naming of custom search commands and their arguments and how they should handle arguments. You can find this style guide in <code><font size="2">searchproc_style.txt</font></code>.
</p>
<h3> <a name="searchcommandstyleguide_naming_conventions_for_custom_search_commands"><span class="mw-headline" id="Naming_conventions_for_custom_search_commands"> Naming conventions for custom search commands </span></a></h3>
<p>Search processor command names:
</p>
<ul><li> Should be alphanumeric and start with a letter.
</li><li> Should not contain any non-alphanumeric characters, such as dashes or underscores.
</li></ul><p>Argument option names:
</p>
<ul><li> Should be alphanumeric and start with a letter, but underscores are allowed.
</li><li> Boolean options should be specified positively, for example: use <code><font size="2">showfield=&lt;bool&gt;</font></code> instead of <code><font size="2">hidefield=&lt;bool&gt;</font></code>.
</li></ul><p>Case sensitivity:
</p>
<ul><li> Command names are case sensitive.
</li><li> Field names should be case sensitive.
</li><li> Keywords should not be case sensitive, for example: stopwords such as "by".
</li></ul><h3> <a name="searchcommandstyleguide_how_to_handle_and_check_arguments"><span class="mw-headline" id="How_to_handle_and_check_arguments"> How to handle and check arguments </span></a></h3>
<p>You can write search commands (or processors) to take a set of optional arguments with a set of options to the arguments.
</p><p>Simple processors that only take a set (can be empty set) of optional arguments:
</p>
<ul><li> in processArguments(), use the getOption() call to retrieve each option's value
</li><li> Examples: outputraw (takes no options), analyzefields (takes one optional arg)
</li></ul><p>Processors that take options and list(s) of fields or other arguments (most commands fall into this catagory):
</p>
<ul><li> List of fields should be specified not as an option but rather directly as part of the argument list. If multiple lists are necessary, use keywords to delimit the lists.
</li><li> in processArguments(), first use getOption() to consume any optional parameters. Then, use getNextArgs() to get a list of the renaming args. getNextArgs() can optionally take a "stopword" that indicates to stop consuming arguments if a certain word is seen.
<ul><li> For example, "mycommand myopt=optval field1 field2 field3 by otherval1 overval2" (where "by" is the stopword).
</li><li> An argument that is completely quoted will not be considered a keyword nor an option.
</li></ul></li></ul><p>Checking for extraneous arguments:
</p>
<ul><li> All processors should call the "ERRORIFUNUSEDARG" macro at the end of argument processing to ensure that extraneous arguments not consumed are flagged as an error.
</li><li> This is important because option names might easily be misspelled, causing misleading results.
</li></ul><h3> <a name="searchcommandstyleguide_how_to_handle_errors"><span class="mw-headline" id="How_to_handle_errors"> How to handle errors </span></a></h3>
<p>All argument parsing errors should throw a SearchProcessorException() at parse time.
</p><p>In general, execution time errors (e.g. a specified field not found in any event) should add an INFO/WARN/ERROR message to the SearchResultsInfo at execution time and should not stop execution.
</p><p>For custom <b>Python</b> search command scripts, stderr output is configurable from commands.conf, using 
</p>
<code><font size="2"><br>stderr_dest = log|message|none<br></font></code>
<p>By default, <code><font size="2">stderr_dest = log</font></code> which is the old behavior where the error output is forwarded to search.log. If <code><font size="2">stderr_dest = message</font></code>, each line of stderr output is treated as a search banner message. The message level is determined by how the message starts:
</p>
<ul><li> Info messages should start with "INFO "
</li><li> Warning messages with "WARN "
</li><li> Debug with "DEBUG "
</li><li> Error with "ERROR "
</li></ul><p>Messages that don't start with any of these patterns are treated as error messages.
</p>
<h3> <a name="searchcommandstyleguide_commands_that_take_a_subpipeline"><span class="mw-headline" id="Commands_that_take_a_subpipeline"> Commands that take a subpipeline </span></a></h3>
<p>These commands need to either override evalArgs() so that subpipelines aren't automatically executed, or they must override handleSearchResultsArgs() to return true.
</p><p>Commands that act on two or more pipeline should use the input to the command as one pipeline of events and any specified subpipelines are the other inputs. Example, "search A | join [search B]" instead of "join [search A] [search B]".
</p><p>Examples of these commands include join, append, and set (although, set violates the previous guideline).
</p>
<a name="writeasearchcommand"></a><h2> <a name="writeasearchcommand_write_a_search_command"><span class="mw-headline" id="Write_a_search_command"> Write a search command</span></a></h2>
<p>A custom search command is a Python script that reads data in and writes data out. This topic discusses how your Python script should handle inputs and arguments.
</p><p>The search command script should be:
</p>
<ul><li> Located in the appropriate <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/bin/</font></code> directory. Most of the scripts that ship with Splunk are associated with the Search app and are stored in <code><font size="2">$SPLUNK_HOME/etc/apps/search/bin</font></code>. (You can refer to scripts in this directory for examples.)
</li><li> Named <code><font size="2">&lt;command_name&gt;.py</font></code>. That is, the script filename should be the command name that you will invoke in your Splunk search. Search command names can consist only of alphanumeric (a-z, A-Z, and 0-9) characters. New commands should not have the same name of any existing commands. Read more about the naming conventions for custom commands in the <a href="#searchcommandstyleguide" class="external text">"Search command style guide"</a>.
</li></ul><h3> <a name="writeasearchcommand_types_of_commands"><span class="mw-headline" id="Types_of_commands"> Types of commands </span></a></h3>
<p>A search command can be a generating command, a streaming command, or one that generates events. 
</p>
<ul><li> A generating command is a command that retrieves (or generates) events from an index(es). These commands are used at the beginning of the search pipeline. They don't expect/require an input (whether it's events or search results) and instead are invoked with a leading pipeline. Examples of generating commands include search (when used at the beginning of the pipeline), inputcsv, inputlookup, and metadata. 
</li><li> A streaming command is one that applies a transformation to each event and writes out the results in a chunked manner instead of all at once. Examples of streaming commands include eval (which is used to add one or more fields to each event), where, and streamstats. A non-streaming command expects to have all the data available as an input before it operates or reduces that data into the output. Examples of non-streaming commands include stats, top, and timechart. 
</li><li> A command that generates events is one that returns data in a streaming manner. Examples of these commands include search, eval, and where. 
</li></ul><p>The default initial search operation generates events and the retrieved events will display in the events viewer tab in Splunk Web. Some generating commands (such as inputcsv, inputlookup, or metadata) don't generate events, and therefore the events viewer will not show anything. Certain operators (such as eval, sort, dedup, cluster, and where) preserves or retains events while other commands (such as stats, top, and timechart) do not. 
</p><p>You can describe what type of command your custom search command is with the parameters <code><font size="2">streaming</font></code> and <code><font size="2">generating</font></code> in commands.conf. You can also specify whether it retains or transforms events with the <code><font size="2">retainevents</font></code> parameter. Read <a href="#addthecustomcommandtosplunk" class="external text">"Add the custom command to Splunk"</a> for more information. Find all the configurable settings in the commands.conf reference in the Admin Manual.
</p>
<h3> <a name="writeasearchcommand_handling_inputs"><span class="mw-headline" id="Handling_inputs"> Handling inputs </span></a></h3>
<p>The input to the script should be formatted in pure CSV or in Intersplunk, which is a header section followed by a blank line followed by pure CSV body.
</p><p>The simplest way to interpret your script input is to use <code><font size="2">splunk.Intersplunk.readResults</font></code>, which takes 3 optional parameters and returns a list of dicts (which represents the list of input events).  The optional parameters are 'input_buf', 'settings', and 'has_header':  
</p>
<ul><li> 'inputbuf' is where to read input from, and if it is None (by default), it is assumed to be <code><font size="2">sys.stdin</font></code>.  
</li><li> 'settings' is expected to be a dict where we will store any information found in the input header (default = None, means don't record the settings). 
</li><li> 'has_header' indicates whether or not we expect an input header and is True by default.
</li></ul><p>To indicate whether or not your script expects a header, use the 'enableheader' key. The 'enableheader' key defaults to true, which means that the input will contain the header section and you are using the Intersplunk format. 
</p><p>If your script does not expect a header section in the input (<code><font size="2">enableheader</font></code> is false), you can directly use the Python csv module to read the input. For example:
</p>
<div class="samplecode">
<p>import csv <br></p><p>r = csv.reader(sys.stdin) <br>
for l in r: <br>
... <br></p>
</div>
<p>The advantage of this usage is that you can break at any time in the for loop, and only lines in the input that you had iterated to at that point will have been read into memory. This leads to much better performance for some usage cases.
</p>
<h3> <a name="writeasearchcommand_sending_output"><span class="mw-headline" id="Sending_output"> Sending output </span></a></h3>
<p>You can also use Intersplunk to construct your script's output.  <code><font size="2">splunk.Intersplunk.generateErrorResults</font></code> takes a string and writes the correct error output to <code><font size="2">sys.stdout</font></code>.  <code><font size="2">splunk.Intersplunk.outputResults</font></code> takes a list of dict objects and writes the appropriate CSV output to <code><font size="2">sys.stdout</font></code>.
</p><p>To output data, add:
</p>
<div class="samplecode">
<p>splunk.Intersplunk.outputResults(results)
</p>
</div>
<p>The output of your script is expected to be pure CSV.  For an error condition, simply return a CSV with a single "ERROR" column and a single row (besides the header row) with the contents of the message.
</p>
<h3> <a name="writeasearchcommand_handling_errors"><span class="mw-headline" id="Handling_errors"> Handling errors </span></a></h3>
<p>The arguments that are passed to your script (in sys.argv) will be the same arguments that are used to invoke your command in the search language unless your script has <code><font size="2">supports_getinfo = true</font></code>. The <code><font size="2">supports_getinfo</font></code> key indicates that the first argument to your script will either be <code><font size="2">__GETINFO__ or __EXECUTE__</font></code>. This allows you to call the script with the command arguments at parse time to check for syntax errors before any execution of the search. Errors at this time will short circuit any real execution of the search query. If called with <code><font size="2">__GETINFO__</font></code>, this also allows you to dynamically specify the properties of your script (such as streaming or not) depending on your arguments.
</p><p>If your script has <code><font size="2">supports_getinfo</font></code> set to 'true', you should first make a call like:
</p>
<div class="samplecode">
<p>(isgetinfo, sys.argv) = splunk.Intersplunk.isGetInfo(sys.argv)
</p>
</div>
<p>This call will strip the first argument from sys.argv and check if you are in GETINFO mode or EXECUTE mode.  If you are in GETINFO mode, your script should use <code><font size="2">splunk.Intersplunk.outputInfo()</font></code> to return the properties of your script or <code><font size="2">splunk.Intersplunk.parseError()</font></code> if the arguments are invalid.  
</p><p>The definition of <code><font size="2">outputInfo()</font></code> and its arguments is as follows:
</p>
<div class="samplecode">
<p>def outputInfo(streaming, generating, retevs, reqsop, preop, timeorder=False)
</p>
</div>
<p>You can also set these attributes in commands.conf.
</p>
<a name="addthecustomcommandtosplunk"></a><h2> <a name="addthecustomcommandtosplunk_add_the_custom_command_to_splunk_enterprise"><span class="mw-headline" id="Add_the_custom_command_to_Splunk_Enterprise"> Add the custom command to Splunk Enterprise</span></a></h2>
<p>After you <a href="#writeasearchcommand" class="external text">write your search command</a>, edit <code><font size="2">commands.conf</font></code> to create an entry for your command. Splunk Enterprise will not be aware of your custom command until you add it to <code><font size="2">commands.conf</font></code>. You can see the full list of configuration options for each command in <code><font size="2">commands.conf.spec</font></code> in the Admin Manual. This topic will only discuss a few of the parameters.
</p><p>If your custom command is app-specific, edit or create the configuration file in the app's local directory, <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/local</font></code>. If you want the command to be available system-wide instead, edit or create the commands.conf in system's local directory, <code><font size="2">$SPLUNK_HOME/etc/system/local</font></code> .
</p>
<h3> <a name="addthecustomcommandtosplunk_create_a_new_stanza"><span class="mw-headline" id="Create_a_new_stanza"> Create a new stanza </span></a></h3>
<p>Each stanza in <code><font size="2">commands.conf</font></code> represents the configuration for a search command. Here is an example of a stanza that just enables your custom script:
</p>
<div class="samplecode">
<p>[&lt;STANZA_NAME&gt;] <br>
filename = &lt;string&gt;
</p>
</div>
<p>The <code><font size="2">STANZA_NAME</font></code> is the keyword that will be specified in search phrases to invoke the command. Search command names can consist only of alphanumeric (a-z, A-Z, and 0-9) characters. New commands (in this case, new stanzas) should not have the same name of any existing commands. 
</p><p>The <code><font size="2">filename</font></code> attribute specifies the name of your custom script. Splunk expects this script to be in all appropriate <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/bin/</font></code> directories, otherwise it looks for this script in <code><font size="2">$SPLUNK_HOME/etc/apps/search/bin</font></code> (which is where most of the scripts that ship with Splunk are stored). In most cases, we recommend placing your script within an app namespace.
</p>
<h4><font size="3"><b><i> <a name="addthecustomcommandtosplunk_describe_the_command"><span class="mw-headline" id="Describe_the_command"> Describe the command </span></a></i></b></font></h4>
<p>The filename attribute merely tells the location of the search script. You can use other attributes to describe the type of command you are adding to Splunk Enterprise. For example, use <code><font size="2">generating</font></code> and <code><font size="2">streaming</font></code> to specify whether it is a generating command, a streaming command, or a command that generates events:
</p>
<div class="samplecode">
<p>generating = [true|false|stream] <br></p>
<ul><li> Specify whether your command generates new events. <br></li><li> If stream, then your command generates new events  (generating = true) and is streamable (streaming = true). <br></li><li> Defaults to false.
</li></ul><p><br>
streaming = [true|false] <br></p>
<ul><li> Specify whether the command is streamable. <br></li><li> Defaults to false. <br></li></ul></div>
<p>If the custom search command retains or transforms events with the <code><font size="2">retainevents</font></code> parameter: 
</p>
<div class="samplecode">
<p>retainsevents = [true|false]
</p>
<ul><li> Specify whether the command retains events (the way the sort/dedup/cluster commands do) or whether it transforms them (the way the stats command does). 
</li><li> Defaults to false.
</li></ul></div>
<h3> <a name="addthecustomcommandtosplunk_restart_splunk"><span class="mw-headline" id="Restart_Splunk"> Restart Splunk </span></a></h3>
<p>After adding your custom command to <code><font size="2">commands.conf</font></code>, you must restart Splunk Enterprise. Changes to your custom command script or to the parameters of an existing command in the <code><font size="2">commands.conf</font></code> file do not require a restart.
</p>
<a name="controlaccesstothecustomcommand"></a><h2> <a name="controlaccesstothecustomcommand_control_access_to_the_custom_command"><span class="mw-headline" id="Control_access_to_the_custom_command"> Control access to the custom command</span></a></h2>
<p>Once you have written the script and added it to <code><font size="2">commands.conf</font></code>, you're good to go.
</p><p>By default, all roles have read-access to <code><font size="2">commands.conf</font></code>, but only admins have write-access. This means that all roles can run the commands listed in <code><font size="2">commands.conf</font></code>, unless the access controls are explicitly changed for an individual command. If you want to restrict the usage of the command to certain roles or users, modify its access controls in Manager or edit <code><font size="2">default.meta.conf</font></code>. 
</p>
<h4><font size="3"><b><i> <a name="controlaccesstothecustomcommand_what_you_can_edit_in_splunk_web"><span class="mw-headline" id="What_you_can_edit_in_Splunk_Web"> What you can edit in Splunk Web </span></a></i></b></font></h4>
<p>You can use Splunk Manager to disable a search command that you don't want to run in an app: 
</p><p><b>1.</b> Navigate to <b>Manager &gt;&gt; Advanced search &gt;&gt; Search commands</b>. 
</p><p>This brings you to the table of search commands, which includes the following information: the command's name, the filename of the script that defines the command, the owner of the script, the app it belongs to, its sharing restrictions, and whether or not it is enabled.
</p><p><b>Note:</b> This table only lists the search commands that were written in Python.
</p><p><b>2.</b> Under the <b>Status</b> column for the search command, click <b>Disable</b>.
</p><p>Splunk will display a message banner saying that the command was disabled in the app.
</p><p>You can also use this Manager page to change the role's access controls for a command: 
</p><p><b>1.</b> Under the <b>Sharing</b> column for the search command, click <b>Permissions</b>. 
</p><p>This opens the <b>Permissions</b> view for the search command. Use this page to specify:
</p>
<ul><li> If this command should appear in the current app or all apps.
</li><li> Which roles are have read and write access to this command. 
</li></ul><p><b>2.</b> Don't forget to save your changes!
</p>
<h4><font size="3"><b><i> <a name="controlaccesstothecustomcommand_what_you_can_edit_in_conf_files"><span class="mw-headline" id="What_you_can_edit_in_conf_files"> What you can edit in conf files </span></a></i></b></font></h4>
<p>You can also change the access controls for a command using the <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/metadata/default.meta</font></code> file. For more information, see the default.meta.conf reference in the <i>Admin manual</i>. 
</p><p>The following example shows the default access for commands.conf and the input command, which you cannot run unless you are an admin.
</p>
<code><font size="2"><br>[commands]<br>access = read&nbsp;: [ * ], write&nbsp;: [ admin ]<br>export = system<br><br>[commands/input]<br>access = read&nbsp;: [ admin ], write&nbsp;: [ admin ]<br></font></code> 
<p>There is also an access control restriction on the search script files themselves. These controls are defined in the <code><font size="2">[searchscripts]</font></code> stanza. By default, the files are visible to all roles and apps, but only admins can edit them:
</p>
<code><font size="2"><br>[searchscripts]<br>access = read&nbsp;: [ * ], write&nbsp;: [ admin ]<br>export = system<br></font></code>
<p>Use the <code><font size="2">export = system</font></code> attribute to make files available to all apps in the system. In the examples above, access to <code><font size="2">commands.conf</font></code> and <code><font size="2">[searchscripts]</font></code> are global.  If the global export under <code><font size="2">[searchscripts]</font></code> was not present, the script configurations (<code><font size="2">commands.conf</font></code>) would be visible in all apps, but the script files themselves would not be. 
</p><p><b>Note:</b> Custom commands in apps that do not have a UI should also be exported to the system, since there is no way to run the command in a local context.
</p>
<a name="customsearchcommandexample"></a><h2> <a name="customsearchcommandexample_custom_event-generating_command_example"><span class="mw-headline" id="Custom_event-generating_command_example"> Custom event-generating command example</span></a></h2>
<p>This section gives you plug-and-play scripts so you can iterate from in order to make your own custom search command.
</p>
<h3> <a name="customsearchcommandexample_example_code"><span class="mw-headline" id="Example_code"> Example code </span></a></h3>
<p>You can go to our github repository to get a complex custom search command:
</p><p>Splunk github python SDK custom search command
</p>
<h3> <a name="customsearchcommandexample_winad"><span class="mw-headline" id="WinAD"> WinAD </span></a></h3>
<p>The following custom search command runs a python script, WinAD.py, to collect Active Directory information. This sample python script is available from Microsoft.
</p>
<h4><font size="3"><b><i> <a name="customsearchcommandexample_add_the_python_script"><span class="mw-headline" id="Add_the_python_script"> Add the python script </span></a></i></b></font></h4>
<p>Add this script, <code><font size="2">WinAD.py</font></code>, to an appropriate apps directory,  <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/bin/</font></code>&nbsp;:
</p>
<code><font size="2"><br>import win32com.client<br>strComputer = "."<br>objWMIService = win32com.client.Dispatch("WbemScripting.SWbemLocator")<br>objSWbemServices = objWMIService.ConnectServer(strComputer,"root\cimv2")<br>colItems = objSWbemServices.ExecQuery("Select * from Win32_NTDomain")<br>for objItem in colItems:<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Caption: ", objItem.Caption<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Client Site Name: ", objItem.ClientSiteName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Creation Class Name: ", objItem.CreationClassName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Dc Site Name: ", objItem.DcSiteName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Description: ", objItem.Description<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Dns Forest Name: ", objItem.DnsForestName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Domain Controller Address: ", objItem.DomainControllerAddress<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Domain Controller Address Type: ", objItem.DomainControllerAddressType<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Domain Controller Name: ", objItem.DomainControllerName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Domain Guid: ", objItem.DomainGuid<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Domain Name: ", objItem.DomainName<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Directory Service Flag: ", objItem.DSDirectoryServiceFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Dns Controller Flag: ", objItem.DSDnsControllerFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Dns Domain Flag: ", objItem.DSDnsDomainFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Dns Forest Flag: ", objItem.DSDnsForestFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Global Catalog Flag: ", objItem.DSGlobalCatalogFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Kerberos Distribution Center Flag: ", &nbsp;&nbsp;&nbsp;objItem.DSKerberosDistributionCenterFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Primary Domain Controller Flag: ", objItem.DSPrimaryDomainControllerFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Time Service Flag: ", objItem.DSTimeServiceFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "DS Writable Flag: ", objItem.DSWritableFlag<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Install Date: ", objItem.InstallDate<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Name: ", objItem.Name<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Name Format: ", objItem.NameFormat<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Primary Owner Contact: ", objItem.PrimaryOwnerContact<br>&nbsp;&nbsp;&nbsp;&nbsp;print "Primary Owner Name: ", objItem.PrimaryOwnerName<br>&nbsp;&nbsp;&nbsp;&nbsp;z = objItem.Roles<br>&nbsp;&nbsp;&nbsp;&nbsp;if z is None:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a = 1<br>&nbsp;&nbsp;&nbsp;&nbsp;else:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for x in z:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print "Roles: ", x<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print "Status: ", objItem.Status<br></font></code>
<h4><font size="3"><b><i> <a name="customsearchcommandexample_edit_configuration_files"><span class="mw-headline" id="Edit_configuration_files"> Edit configuration files </span></a></i></b></font></h4>
<p>Edit these configuration files in the app's local directory, <code><font size="2">$SPLUNK_HOME/etc/app/&lt;app_name&gt;/local</font></code>.
</p><p>In <code><font size="2">commands.conf</font></code>, add this stanza:
</p>
<code><font size="2"><br>[WinAD]<br>filename = WinAD.py<br></font></code>
<p>In <code><font size="2">authorize.conf</font></code>, add these two stanzas:
</p>
<code><font size="2"><br>[capability::run_script_WinAD]<br><br>[role_admin]<br>run_script_WinAD= enabled<br></font></code>
<p>Restart Splunk.
</p>
<h4><font size="3"><b><i> <a name="customsearchcommandexample_run_the_command_in_splunk_web"><span class="mw-headline" id="Run_the_command_in_Splunk_Web"> Run the command in Splunk Web </span></a></i></b></font></h4>
<p>In the app manager, modify the sharing for the search script so that it has Global Permissions.
</p><p>Restart Splunk.
</p><p>Now you can run the command from the search bar.  Also, it's an event-generating command, so it should start with a leading pipe.:
</p>
<div class="inlineQuery splunk_search_4_3"><code><font size="2"> | WinAD</font></code><br></div>

<a name="customsearchcommandshape"></a><h2> <a name="customsearchcommandshape_custom_search_command_shape"><span class="mw-headline" id="Custom_search_command_shape"> Custom search command shape</span></a></h2>
<p>This following is a new command called "shape" that categorizes events based on their line count (tall or short) and line length (thin, wide, and very_wide) and whether or not they are indented.
</p>
<h3> <a name="customsearchcommandshape_add_the_python_script"><span class="mw-headline" id="Add_the_Python_script"> Add the Python script </span></a></h3>
<p>Add this script, <code><font size="2">shape.py</font></code>, to an appropriate apps directory,  <code><font size="2">$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/bin/</font></code>&nbsp;:
</p>
<div class="samplecode">
<code><font size="2"> &nbsp;import splunk.Intersplunk <br></font></code>
<code><font size="2"> &nbsp;def getShape(text):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description = []<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;linecount = text.count("\n") + 1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if linecount &gt; 10:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("tall")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif linecount &gt; 1:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("short")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;avglinelen = len(text) / linecount<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if avglinelen &gt; 500:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("very_wide")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif avglinelen &gt; 200:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("wide")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif avglinelen &lt; 80:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("thin")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if text.find("\n ") &gt;= 0 or text.find("\n\t") &gt;= 0:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description.append("indented")<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if len(description) == 0:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "normal"<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "_".join(description) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br></font></code>
<code><font size="2"> &nbsp;# get the previous search results<br>&nbsp;&nbsp;results,unused1,unused2 = splunk.Intersplunk.getOrganizedResults()<br>&nbsp;&nbsp;# for each results, add a 'shape' attribute, calculated from the raw event text<br>&nbsp;&nbsp;for result in results:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result["shape"] = getShape(result["_raw"])<br>&nbsp;&nbsp;# output results<br>&nbsp;&nbsp;splunk.Intersplunk.outputResults(results)<br></font></code>
</div>
<h3> <a name="customsearchcommandshape_edit_the_configuration_files"><span class="mw-headline" id="Edit_the_configuration_files"> Edit the configuration files </span></a></h3>
<p>Edit these configuration files in the app's local directory, <code><font size="2">$SPLUNK_HOME/etc/app/&lt;app_name&gt;/local</font></code>.
</p><p>In <code><font size="2">commands.conf</font></code>, add this stanza:
</p>
<code><font size="2"><br>[shape]<br>filename = shape.py<br></font></code>
<p>In <code><font size="2">authorize.conf</font></code>, add these two stanzas:
</p>
<code><font size="2"><br>[capability::run_script_shape]<br><br>[role_admin]<br>run_script_shape= enabled<br></font></code>
<p>Restart Splunk.
</p>
<h3> <a name="customsearchcommandshape_run_the_command"><span class="mw-headline" id="Run_the_command"> Run the command </span></a></h3>
<p>This examples shows how to run the search from the CLI. You can also run it in Splunk Web.
</p><p>Show the top <i>shapes</i> for multi-line events:
</p>
<div class="samplecode">
<p>$ splunk search "linecount&gt;1 | shape | top shape"
</p>
</div>
<code><font size="2"><br>shape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count &nbsp;&nbsp;&nbsp;&nbsp;percent<br><br>tall_indented &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;43 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;43.000000 <br>short_indented &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29.000000<br>tall_thin_indented &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.000000<br>short_thin_indented &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10.000000<br>short_thin &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.000000 <br></font></code>

<a name="searcherrorstrings"></a><h2> <a name="searcherrorstrings_externalized_search_error_strings"><span class="mw-headline" id="Externalized_Search_Error_Strings"> Externalized Search Error Strings</span></a></h2>
<h2> <a name="searcherrorstrings_externalized_search_errors"><span class="mw-headline" id="Externalized_search_errors"> Externalized search errors </span></a></h2>
<p>All externalized strings in Splunk Enterprise, including error strings for search commands, are defined in the <code><font size="2">literals.conf</font></code> configuration file. A Splunk user and administrator should not need to edit this file. However a Splunk developer might want to overwrite existing strings or define custom configurations.
</p><p>The configuration file is located in <code><font size="2">$SPLUNK_HOME/etc/system/default/literals.conf</font></code>. <b>DO NOT edit this file.</b> Read the rest of this topic before proceeding. 
</p>
<h3> <a name="searcherrorstrings_search_error_strings"><span class="mw-headline" id="Search_error_strings"> Search error strings </span></a></h3>
<p>The part of the file dedicated to search error strings is indicated with: 
</p>
<code><font size="2"><br># String externalization starts here<br></font></code>
<p>This is followed with a stanza for each search command that has error strings associated with it. For example, the <code><font size="2">eval</font></code> command's stanza reads:
</p>
<code><font size="2"><br>[EVAL]<br>MISSING_ARGS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Missing arguments. usage: eval dest_key = expression<br>FAILED_PARSE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Failed to parse arguments. eval usage: eval dest_key = expression<br>INVALID_DEST&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Invalid destination key<br>BOOLEAN_RESULT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= The result of an expression cannot be boolean. Try if([bool expr], [expr], [expr])<br>BAD_DEST_BRACKETS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Invalid destination field. {} brackets must be closed<br>INVALID_OP__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Invalid operator at '%s'<br>TYPE_FAIL_CONCAT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Typechecking failed. '.' operator only takes strings and numbers<br>TYPE_FAIL_DIFF__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Typechecking failed. '%s' operator received different types<br>TYPE_FAIL_PLUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Typechecking failed. '+' only takes two strings or two numbers<br>TYPE_FAIL_NUM__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Typechecking failed. '%s' only takes numbers<br>TYPE_FAIL_BOOL__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Typechecking failed. '%s' only takes boolean arguments<br>MATCH_FAIL__C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression -&nbsp;%c expected<br>CONSUME_FAIL__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression -&nbsp;%s expected<br>INVALID_NUMBER__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Invalid number:&nbsp;%s<br>INVALID_UNARY_OP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Invalid unary op<br>UNEXPECTED_CHAR__C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Unexpected character hit in factor:&nbsp;%c<br>MISSING_FACTOR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Missing factor<br>MISSING_TERM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Missing term<br>MISSING_COMP_TERM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Missing comparison term<br>MISSING_AND&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Missing AND term<br>MISSING_OR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Malformed expression - Missing OR term<br>INVALID_FUNC_ARGS__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Invalid arguments to '%s' function<br>BAD_FUNC__S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Unsupported Function:&nbsp;%s<br></font></code>
<h3> <a name="searcherrorstrings_overwrite_or_define_error_strings"><span class="mw-headline" id="Overwrite_or_define_error_strings"> Overwrite or define error strings </span></a></h3>
<p><b>Before you edit literals.conf</b>, refer to the configuration specification and example files:
</p>
<ul><li> <code><font size="2">$SPLUNK_HOME/etc/system/README/literals.conf.spec</font></code>
</li><li> <code><font size="2">$SPLUNK_HOME/etc/system/README/literals.conf.example</font></code>
</li></ul><p>To overwrite existing error strings or define custom error strings, create a <code><font size="2">literals.conf</font></code> file in:
</p>
<code><font size="2"><br>$SPLUNK_HOME/etc/system/local/<br></font></code>
<p>Overwrite an existing string by copying the stanza name,  the attribute, and value pair from the default <code><font size="2">literals.conf</font></code> file into the local <code><font size="2">literals.conf</font></code> file. Then edit the value in the local copy <code><font size="2">literals.conf</font></code> file. 
</p><p>Define all new custom configurations in the local copy of the <code><font size="2">literals.conf</font></code> file.
</p><p><b>Important:</b> Editing the <code><font size="2">literals.conf</font></code> file incorrectly can seriously impact the performance of Splunk Enterprise. Use the following guidelines for any changes that you make to configurations in <code><font size="2">literals.conf</font></code> file.
</p>
<ul><li> Externalized strings are defined with attribute name and value pairs. You should need to edit only the attribute values. DO NOT edit the attribute names.
</li><li> When strings contain <code><font size="2">"%s"</font></code>, DO NOT add or remove instances of <code><font size="2">%s</font></code> or reorder their positions.
</li><li> When strings contain HTML tags and entities, make sure that all of the strings are properly escaped.
</li></ul><h1>Search Examples and Walkthroughs</h1><a name="searchwalkthroughs"></a><h2> <a name="searchwalkthroughs_what.27s_in_this_chapter.3f"><span class="mw-headline" id="What.27s_in_this_chapter.3F"> What's in this chapter? </span></a></h2>
<p><b>This page is currently a work in progress; expect frequent near-term updates.</b>
</p><p>This chapter contains walkthroughs of interesting search examples collected from Answers and the field. 
</p>
<ul><li> Report of multiple data series
</li><li> Compare hourly sums between different days
</li><li> Calculate sizes of dynamic fields
</li><li> Monitor and alert on Windows disk usage
</li></ul><a name="monitorandalertonwindowsdiskusage"></a><h2> <a name="monitorandalertonwindowsdiskusage_monitor_and_alert_on_windows_disk_usage"><span class="mw-headline" id="Monitor_and_alert_on_Windows_disk_usage"> Monitor and alert on Windows disk usage</span></a></h2>
<p><b>This page is currently a work in progress; expect frequent near-term updates.</b>
</p><p>This example walks you through setting up a <b>basic conditional alert</b> that sends an email when the disk usage falls below a certain percentage.
</p>
<a name="calculatesizesofdynamicfields"></a><h2> <a name="calculatesizesofdynamicfields_calculate_sizes_of_dynamic_fields"><span class="mw-headline" id="Calculate_sizes_of_dynamic_fields"> Calculate sizes of dynamic fields</span></a></h2>
<p><b>This page is currently a work in progress; expect frequent near-term updates.</b>
</p><p>This search determines which fields in your events, without any prior knowledge of field names and number of events, consume the most disk space.
</p>
<h3> <a name="calculatesizesofdynamicfields_scenario"><span class="mw-headline" id="Scenario">Scenario</span></a></h3>
<code><font size="2"><br>index=_internal earliest=-15m latest=now<br>| fieldsummary <br>| rex field=values max_match=0 "value\":\"(?&lt;values&gt;[^\"]*)\","<br>| mvexpand values <br>| eval bytes=len(values)<br>| rex field=field "^(?!date|punct|host|hostip|index|linecount|source|sourcetype|timeendpos|timestartpos|splunk_server)(?&lt;FieldName&gt;.*)"<br>| stats count sum(bytes) as SumOfBytesInField values(values) as Values max(bytes) as MaxFieldLengthInBytes by FieldName<br>| rename count as NumberOfValuesPerField<br>| eventstats sum(NumberOfValuesPerField) as TotalEvents sum(SumOfBytesInField) as TotalBytes<br>| eval PercentageOfTotalEvents=round(NumberOfValuesPerField/TotalEvents*100,2)<br>| eval PercentageOfTotalBytes=round(SumOfBytesInField/TotalBytes*100,2)<br>| eval ConsumedMB=SumOfBytesInField/1024/1024<br>| eval TotalMB=TotalBytes/1024/1024<br>| table FieldName NumberOfValuesPerField SumOfBytesInField ConsumedMB PercentageOfTotalBytes PercentageOfTotalEvents<br>| addcoltotals labelfield=FieldName label=Totals<br>| sort - PercentageOfTotalEvents<br></font></code>
<p><br><img alt="CalculateSizeofFields report.png" src="images/c/c2/CalculateSizeofFields_report.png" width="800" height="237"></p>
<h3> <a name="calculatesizesofdynamicfields_walkthough"><span class="mw-headline" id="Walkthough"> Walkthough </span></a></h3>
<p><b>1.</b> The example begins with a search to retrieve all events in <code><font size="2">index=_internal</font></code> within the last 15 minutes.
</p>
<code><font size="2"><br>index=_internal earliest=-15m latest=now<br></font></code>
<p><b>Note:</b> You can replace this with any search string and timerange.
</p><p><b>2.</b> Next, the fieldsummary command creates a summary of all the fields in previously retrieved events.
</p>
<code><font size="2"><br>... | fieldsummary<br></font></code>
<p>This looks something like this:
</p><p><img alt="Fieldsummary example1.png" src="images/e/e6/Fieldsummary_example1.png" width="800" height="235"></p><p><b>3.</b> The values of each field are extracted with a regex into a multivalue field, values, and then expanded. The length of each value is calculated in bytes. 
</p>
<code><font size="2"><br>| rex field=values max_match=0 "value\":\"(?&lt;values&gt;[^\"]*)\","<br>| mvexpand values <br>| eval bytes=len(values)<br></font></code>
<p><b>4.</b> The values of the field are extracted with another regex, with some exceptions.
</p>
<code><font size="2"><br>| rex field=field "^(?!date|punct|host|hostip|index|linecount|source|sourcetype|timeendpos|timestartpos|splunk_server)(?&lt;FieldName&gt;.*)"<br></font></code>
<p><b>5.</b>
</p>
<code><font size="2"><br>| stats count sum(bytes) as SumOfBytesInField values(values) as Values max(bytes) as MaxFieldLengthInBytes by FieldName<br>| rename count as NumberOfValuesPerField<br></font></code>
<p><b>6.</b>
</p>
<code><font size="2"><br>| eventstats sum(NumberOfValuesPerField) as TotalEvents sum(SumOfBytesInField) as TotalBytes<br></font></code>
<p><b>7.</b>
</p>
<code><font size="2"><br>| eval PercentageOfTotalEvents=round(NumberOfValuesPerField/TotalEvents*100,2)<br>| eval PercentageOfTotalBytes=round(SumOfBytesInField/TotalBytes*100,2)<br>| eval ConsumedMB=SumOfBytesInField/1024/1024<br>| eval TotalMB=TotalBytes/1024/1024<br></font></code>
<p><b>8.</b>
</p>
<code><font size="2"><br>| table FieldName NumberOfValuesPerField SumOfBytesInField ConsumedMB PercentageOfTotalBytes PercentageOfTotalEvents<br>| addcoltotals labelfield=FieldName label=Totals<br>| sort - PercentageOfTotalEvents<br></font></code>

</body><script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>

        <script src="js/index.js"></script></html>
