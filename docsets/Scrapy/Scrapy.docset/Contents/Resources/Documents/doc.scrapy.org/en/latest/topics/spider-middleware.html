

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->

<!-- Mirrored from doc.scrapy.org/en/latest/topics/spider-middleware.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:41 GMT -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spider Middleware &mdash; Scrapy 0.22.2 documentation</title>
  

  
  

  
  <link href='../../../../fonts.googleapis.com/css732b.css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  

  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.22.2 documentation" href="../index-2.html"/>
        <link rel="next" title="Extensions" href="extensions.html"/>
        <link rel="prev" title="Downloader Middleware" href="downloader-middleware.html"/>
 
<!-- RTD Extra Head -->



  
  <!-- 
  Always link to the latest version, as canonical.
  http://docs.readthedocs.org/en/latest/canonical.html
  -->
  <link rel="canonical" href="spider-middleware.html" />
  

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy",
    version: "latest",
    language: "en",
    page: "topics/spider-middleware",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org"
  }
  // Old variables
  var doc_version = "latest";
  var doc_slug = "scrapy";
  var page_name = "topics/spider-middleware";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);

  // User Analytics Code
  _gaq.push(['user._setAccount', 'UA-10231918-2']);
  _gaq.push(['user._trackPageview']);
  // End User Analytics Code


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="../../../../cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="../index-2.html" class="fa fa-home"> Scrapy</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="http://doc.scrapy.org/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#pick-a-website">Pick a website</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#define-the-data-you-want-to-scrape">Define the data you want to scrape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#write-a-spider-to-extract-the-data">Write a Spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#run-the-spider-to-extract-the-data">Run the spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#review-scraped-data">Review scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#what-s-next">What&#8217;s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#installing-scrapy">Installing Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#platform-specific-installation-notes">Platform specific installation notes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#creating-a-project">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#defining-our-item">Defining our Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#our-first-spider">Our first Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#storing-the-scraped-data">Storing the scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="commands.html#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#using-the-scrapy-tool">Using the <tt class="docutils literal"><span class="pre">scrapy</span></tt> tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#available-tool-commands">Available tool commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#custom-project-commands">Custom project commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="items.html#declaring-items">Declaring Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-fields">Item Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#working-with-items">Working with Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#extending-items">Extending Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-objects">Item objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#field-objects">Field objects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#spider-arguments">Spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#built-in-spiders-reference">Built-in spiders reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#using-selectors">Using selectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#module-scrapy.selector">Built-in Selectors reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="shell.html#launch-the-shell">Launch the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#using-the-shell">Using the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#example-of-shell-session">Example of shell session</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#invoking-the-shell-from-spiders-to-inspect-responses">Invoking the shell from spiders to inspect responses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#writing-your-own-item-pipeline">Writing your own item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#item-pipeline-example">Item pipeline example</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#activating-an-item-pipeline-component">Activating an Item Pipeline component</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#serialization-formats">Serialization formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storages">Storages</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-uri-parameters">Storage URI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-backends">Storage backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="link-extractors.html#module-scrapy.contrib.linkextractors">Built-in link extractors reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#how-to-set-the-log-level">How to set the log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#how-to-log-messages">How to log messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#logging-from-spiders">Logging from Spiders</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#module-scrapy.log">scrapy.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#logging-settings">Logging settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="stats.html#common-stats-collector-uses">Common Stats Collector uses</a></li>
<li class="toctree-l2"><a class="reference internal" href="stats.html#available-stats-collectors">Available Stats Collectors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a><ul>
<li class="toctree-l2"><a class="reference internal" href="email.html#quick-example">Quick example</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mailsender-class-reference">MailSender class reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mail-settings">Mail settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a><ul>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#how-to-access-the-telnet-console">How to access the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#available-variables-in-the-telnet-console">Available variables in the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-signals">Telnet Console signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-settings">Telnet settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-resources">Web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-settings">Web service settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#writing-a-web-service-resource">Writing a web service resource</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#examples-of-web-service-resources">Examples of web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-does-scrapy-compare-to-beautifulsoup-or-lxml">How does Scrapy compare to BeautifulSoup or lxml?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-python-versions-does-scrapy-support">What Python versions does Scrapy support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-python-3">Does Scrapy work with Python 3?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#did-scrapy-steal-x-from-django">Did Scrapy &#8220;steal&#8221; X from Django?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-http-proxies">Does Scrapy work with HTTP proxies?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-scrape-an-item-with-attributes-in-different-pages">How can I scrape an item with attributes in different pages?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-crashes-with-importerror-no-module-named-win32api">Scrapy crashes with: ImportError: No module named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-simulate-a-user-login-in-my-spider">How can I simulate a user login in my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-crawl-in-breadth-first-or-depth-first-order">Does Scrapy crawl in breadth-first or depth-first order?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#my-scrapy-crawler-has-memory-leaks-what-can-i-do">My Scrapy crawler has memory leaks. What can I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-make-scrapy-consume-less-memory">How can I make Scrapy consume less memory?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-basic-http-authentication-in-my-spiders">Can I use Basic HTTP Authentication in my spiders?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-does-scrapy-download-pages-in-english-instead-of-my-native-language">Why does Scrapy download pages in English instead of my native language?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-can-i-find-some-example-scrapy-projects">Where can I find some example Scrapy projects?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-run-a-spider-without-creating-a-project">Can I run a spider without creating a project?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-get-filtered-offsite-request-messages-how-can-i-fix-them">I get &#8220;Filtered offsite request&#8221; messages. How can I fix them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">What is the recommended way to deploy a Scrapy crawler in production?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-json-for-large-exports">Can I use JSON for large exports?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-return-twisted-deferreds-from-signal-handlers">Can I return (Twisted) deferreds from signal handlers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-does-the-response-status-code-999-means">What does the response status code 999 means?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">Can I call <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> from my spiders to debug them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">Simplest way to dump all my scraped items into a JSON/CSV/XML file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">What&#8217;s this huge cryptic <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> parameter used in some forms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-the-best-way-to-parse-big-xml-csv-data-feeds">What&#8217;s the best way to parse big XML/CSV data feeds?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-manage-cookies-automatically">Does Scrapy manage cookies automatically?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy">How can I see the cookies being sent and received from Scrapy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-instruct-a-spider-to-stop-itself">How can I instruct a spider to stop itself?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-prevent-my-scrapy-bot-from-getting-banned">How can I prevent my Scrapy bot from getting banned?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#should-i-use-spider-arguments-or-settings-to-configure-my-spider">Should I use spider arguments or settings to configure my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items">I&#8217;m scraping a XML document and my XPath selector doesn&#8217;t return any items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-getting-an-error-cannot-import-name-crawler">I&#8217;m getting an error: &#8220;cannot import name crawler&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debug.html#parse-command">Parse Command</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#scrapy-shell">Scrapy Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#open-in-browser">Open in browser</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contracts.html#custom-contracts">Custom Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="practices.html#run-scrapy-from-a-script">Run Scrapy from a script</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#running-multiple-spiders-in-the-same-process">Running multiple spiders in the same process</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#distributed-crawls">Distributed crawls</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#avoiding-getting-banned">Avoiding getting banned</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#dynamic-creation-of-item-classes">Dynamic Creation of Item Classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#increase-concurrency">Increase concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#reduce-log-level">Reduce log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-cookies">Disable cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-retries">Disable retries</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#reduce-download-timeout">Reduce download timeout</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-redirects">Disable redirects</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#enable-crawling-of-ajax-crawlable-pages">Enable crawling of &#8220;Ajax Crawlable Pages&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#caveats-with-inspecting-the-live-browser-dom">Caveats with inspecting the live browser DOM</a></li>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#useful-firefox-add-ons-for-scraping">Useful Firefox add-ons for scraping</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#getting-links-to-follow">Getting links to follow</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#extracting-the-data">Extracting the data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#common-causes-of-memory-leaks">Common causes of memory leaks</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#debugging-memory-leaks-with-trackref">Debugging memory leaks with <tt class="docutils literal"><span class="pre">trackref</span></tt></a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#debugging-memory-leaks-with-guppy">Debugging memory leaks with Guppy</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="images.html">Downloading Item Images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="images.html#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#enabling-your-images-pipeline">Enabling your Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#images-storage">Images Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#additional-features">Additional features</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#module-scrapy.contrib.pipeline.images">Implementing your custom Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#design-goals">Design goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#how-it-works">How it works</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#throttling-algorithm">Throttling algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#job-directory">Job directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#how-to-use-it">How to use it</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#keeping-persistent-state-between-batches">Keeping persistent state between batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#persistence-gotchas">Persistence gotchas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#using-djangoitem">Using DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#djangoitem-caveats">DjangoItem caveats</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#django-settings-set-up">Django settings set up</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#components">Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#data-flow">Data flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#event-driven-networking">Event-driven networking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#activating-a-downloader-middleware">Activating a downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#writing-your-own-downloader-middleware">Writing your own downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#built-in-downloader-middleware-reference">Built-in downloader middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spider Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#activating-a-spider-middleware">Activating a spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#writing-your-own-spider-middleware">Writing your own spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-spider-middleware-reference">Built-in spider middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#extension-settings">Extension settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#loading-activating-extensions">Loading &amp; activating extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#available-enabled-and-disabled-extensions">Available, enabled and disabled extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#disabling-an-extension">Disabling an extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#writing-your-own-extension">Writing your own extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#built-in-extensions-reference">Built-in extensions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.settings">Settings API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.signalmanager">Signals API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#stats-collector-api">Stats Collector API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="settings.html#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#populating-the-settings">Populating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#built-in-settings-reference">Built-in settings reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="signals.html#deferred-signal-handlers">Deferred signal handlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="signals.html#module-scrapy.signals">Built-in signals reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exceptions.html#built-in-exceptions-reference">Built-in Exceptions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#using-item-exporters">Using Item Exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#serialization-of-item-fields">Serialization of item fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#built-in-item-exporters-reference">Built-in Item Exporters reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-01-17">0.22.0 (released 2014-01-17)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id2">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id3">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id4">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id5">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id6">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id7">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id8">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id11">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id14">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id15">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">Experimental features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental/index.html#add-commands-using-external-libraries">Add commands using external libraries</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index-2.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index-2.html">Docs</a> &raquo;</li>
      
    <li>Spider Middleware</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/scrapy/scrapy/blob/0.22/docs/topics/spider-middleware.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="spider-middleware">
<span id="topics-spider-middleware"></span><h1>Spider Middleware<a class="headerlink" href="#spider-middleware" title="Permalink to this headline">¶</a></h1>
<p>The spider middleware is a framework of hooks into Scrapy&#8217;s spider processing
mechanism where you can plug custom functionality to process the requests that
are sent to <a class="reference internal" href="spiders.html#topics-spiders"><em>Spiders</em></a> for processing and to process the responses
and items that are generated from spiders.</p>
<div class="section" id="activating-a-spider-middleware">
<span id="topics-spider-middleware-setting"></span><h2>Activating a spider middleware<a class="headerlink" href="#activating-a-spider-middleware" title="Permalink to this headline">¶</a></h2>
<p>To activate a spider middleware component, add it to the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></tt></a> setting, which is a dict whose keys are the
middleware class path and their values are the middleware orders.</p>
<p>Here&#8217;s an example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">SPIDER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;myproject.middlewares.CustomSpiderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></tt></a> setting is merged with the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></tt></a> setting defined in Scrapy (and not meant to
be overridden) and then sorted by order to get the final sorted list of enabled
middlewares: the first middleware is the one closer to the engine and the last
is the one closer to the spider.</p>
<p>To decide which order to assign to your middleware see the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></tt></a> setting and pick a value according to where
you want to insert the middleware. The order does matter because each
middleware performs a different action and your middleware could depend on some
previous (or subsequent) middleware being applied.</p>
<p>If you want to disable a builtin middleware (the ones defined in
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></tt></a>, and enabled by default) you must define it
in your project <a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></tt></a> setting and assign <cite>None</cite> as its
value.  For example, if you want to disable the off-site middleware:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">SPIDER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;myproject.middlewares.CustomSpiderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware&#39;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, keep in mind that some middlewares may need to be enabled through a
particular setting. See each middleware documentation for more info.</p>
</div>
<div class="section" id="writing-your-own-spider-middleware">
<h2>Writing your own spider middleware<a class="headerlink" href="#writing-your-own-spider-middleware" title="Permalink to this headline">¶</a></h2>
<p>Writing your own spider middleware is easy. Each middleware component is a
single Python class that defines one or more of the following methods:</p>
<span class="target" id="module-scrapy.contrib.spidermiddleware"></span><dl class="class">
<dt id="scrapy.contrib.spidermiddleware.SpiderMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.</tt><tt class="descname">SpiderMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input">
<tt class="descname">process_spider_input</tt><big>(</big><em>response</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called for each response that goes through the spider
middleware and into the spider, for processing.</p>
<p><a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_input()</span></tt></a> should return <tt class="docutils literal"><span class="pre">None</span></tt> or raise an
exception.</p>
<p>If it returns <tt class="docutils literal"><span class="pre">None</span></tt>, Scrapy will continue processing this response,
executing all other middlewares until, finally, the response is handed
to the spider for processing.</p>
<p>If it raises an exception, Scrapy won&#8217;t bother calling any other spider
middleware <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_input()</span></tt></a> and will call the request
errback.  The output of the errback is chained back in the other
direction for <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_output()</span></tt></a> to process it, or
<a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_exception()</span></tt></a> if it raised an exception.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> object) &#8211; the response being processed</li>
<li><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt></a> object) &#8211; the spider for which this response is intended</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output">
<tt class="descname">process_spider_output</tt><big>(</big><em>response</em>, <em>result</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called with the results returned from the Spider, after
it has processed the response.</p>
<p><a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_output()</span></tt></a> must return an iterable of
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> or <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> objects.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>response</strong> (class:<cite>~scrapy.http.Response</cite> object) &#8211; the response which generated this output from the
spider</li>
<li><strong>result</strong> (an iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> or
<a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> objects) &#8211; the result returned by the spider</li>
<li><strong>spider</strong> (<tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt> object) &#8211; the spider whose result is being processed</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception">
<tt class="descname">process_spider_exception</tt><big>(</big><em>response</em>, <em>exception</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called when when a spider or <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_input"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_input()</span></tt></a>
method (from other spider middleware) raises an exception.</p>
<p><a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_exception()</span></tt></a> should return either <tt class="docutils literal"><span class="pre">None</span></tt> or an
iterable of <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> or
<a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> objects.</p>
<p>If it returns <tt class="docutils literal"><span class="pre">None</span></tt>, Scrapy will continue processing this exception,
executing any other <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_exception()</span></tt></a> in the following
middleware components, until no middleware components are left and the
exception reaches the engine (where it&#8217;s logged and discarded).</p>
<p>If it returns an iterable the <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_output()</span></tt></a> pipeline
kicks in, and no other <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_exception()</span></tt></a> will be called.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> object) &#8211; the response being processed when the exception was
raised</li>
<li><strong>exception</strong> (<a class="reference external" href="http://docs.python.org/library/exceptions.html#exceptions.Exception">Exception</a> object) &#8211; the exception raised</li>
<li><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.spider.Spider</span></tt></a> object) &#8211; the spider which raised the exception</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests">
<tt class="descname">process_start_requests</tt><big>(</big><em>start_requests</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests" title="Permalink to this definition">¶</a></dt>
<dd><div class="versionadded">
<p><span class="versionmodified">New in version 0.15.</span></p>
</div>
<p>This method is called with the start requests of the spider, and works
similarly to the <a class="reference internal" href="#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_spider_output"><tt class="xref py py-meth docutils literal"><span class="pre">process_spider_output()</span></tt></a> method, except that it
doesn&#8217;t have a response associated and must return only requests (not
items).</p>
<p>It receives an iterable (in the <tt class="docutils literal"><span class="pre">start_requests</span></tt> parameter) and must
return another iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> objects.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When implementing this method in your spider middleware, you
should always return an iterable (that follows the input one) and
not consume all <tt class="docutils literal"><span class="pre">start_requests</span></tt> iterator because it can be very
large (or even unbounded) and cause a memory overflow. The Scrapy
engine is designed to pull start requests while it has capacity to
process them, so the start requests iterator can be effectively
endless where there is some other condition for stopping the spider
(like a time limit or item/page count).</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start_requests</strong> (an iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a>) &#8211; the start requests</li>
<li><strong>spider</strong> (<tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt> object) &#8211; the spider to whom the start requests belong</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="built-in-spider-middleware-reference">
<span id="topics-spider-middleware-ref"></span><h2>Built-in spider middleware reference<a class="headerlink" href="#built-in-spider-middleware-reference" title="Permalink to this headline">¶</a></h2>
<p>This page describes all spider middleware components that come with Scrapy. For
information on how to use them and how to write your own spider middleware, see
the <a class="reference internal" href="#topics-spider-middleware"><em>spider middleware usage guide</em></a>.</p>
<p>For a list of the components enabled by default (and their orders) see the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></tt></a> setting.</p>
<div class="section" id="module-scrapy.contrib.spidermiddleware.depth">
<span id="depthmiddleware"></span><h3>DepthMiddleware<a class="headerlink" href="#module-scrapy.contrib.spidermiddleware.depth" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spidermiddleware.depth.DepthMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.depth.</tt><tt class="descname">DepthMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.depth.DepthMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>DepthMiddleware is a scrape middleware used for tracking the depth of each
Request inside the site being scraped. It can be used to limit the maximum
depth to scrape or things like that.</p>
<p>The <a class="reference internal" href="#scrapy.contrib.spidermiddleware.depth.DepthMiddleware" title="scrapy.contrib.spidermiddleware.depth.DepthMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">DepthMiddleware</span></tt></a> can be configured through the following
settings (see the settings documentation for more info):</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="settings.html#std:setting-DEPTH_LIMIT"><tt class="xref std std-setting docutils literal"><span class="pre">DEPTH_LIMIT</span></tt></a> - The maximum depth that will be allowed to
crawl for any site. If zero, no limit will be imposed.</li>
<li><a class="reference internal" href="settings.html#std:setting-DEPTH_STATS"><tt class="xref std std-setting docutils literal"><span class="pre">DEPTH_STATS</span></tt></a> - Whether to collect depth stats.</li>
<li><a class="reference internal" href="settings.html#std:setting-DEPTH_PRIORITY"><tt class="xref std std-setting docutils literal"><span class="pre">DEPTH_PRIORITY</span></tt></a> - Whether to prioritize the requests based on
their depth.</li>
</ul>
</div></blockquote>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.spidermiddleware.httperror">
<span id="httperrormiddleware"></span><h3>HttpErrorMiddleware<a class="headerlink" href="#module-scrapy.contrib.spidermiddleware.httperror" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.httperror.</tt><tt class="descname">HttpErrorMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter out unsuccessful (erroneous) HTTP responses so that spiders don&#8217;t
have to deal with them, which (most of the time) imposes an overhead,
consumes more resources, and makes the spider logic more complex.</p>
</dd></dl>

<p>According to the <a class="reference external" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP standard</a>, successful responses are those whose
status codes are in the 200-300 range.</p>
<p>If you still want to process response codes outside that range, you can
specify which response codes the spider is able to handle using the
<tt class="docutils literal"><span class="pre">handle_httpstatus_list</span></tt> spider attribute or
<a class="reference internal" href="#std:setting-HTTPERROR_ALLOWED_CODES"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPERROR_ALLOWED_CODES</span></tt></a> setting.</p>
<p>For example, if you want your spider to handle 404 responses you can do
this:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">handle_httpstatus_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">404</span><span class="p">]</span>
</pre></div>
</div>
<p id="std:reqmeta-handle_httpstatus_list">The <tt class="docutils literal"><span class="pre">handle_httpstatus_list</span></tt> key of <a class="reference internal" href="request-response.html#scrapy.http.Request.meta" title="scrapy.http.Request.meta"><tt class="xref py py-attr docutils literal"><span class="pre">Request.meta</span></tt></a> can also be used to specify which response codes to
allow on a per-request basis.</p>
<p>Keep in mind, however, that it&#8217;s usually a bad idea to handle non-200
responses, unless you really know what you&#8217;re doing.</p>
<p>For more information see: <a class="reference external" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP Status Code Definitions</a>.</p>
<div class="section" id="httperrormiddleware-settings">
<h4>HttpErrorMiddleware settings<a class="headerlink" href="#httperrormiddleware-settings" title="Permalink to this headline">¶</a></h4>
<div class="section" id="httperror-allowed-codes">
<span id="std:setting-HTTPERROR_ALLOWED_CODES"></span><h5>HTTPERROR_ALLOWED_CODES<a class="headerlink" href="#httperror-allowed-codes" title="Permalink to this headline">¶</a></h5>
<p>Default: <tt class="docutils literal"><span class="pre">[]</span></tt></p>
<p>Pass all responses with non-200 status codes contained in this list.</p>
</div>
<div class="section" id="httperror-allow-all">
<span id="std:setting-HTTPERROR_ALLOW_ALL"></span><h5>HTTPERROR_ALLOW_ALL<a class="headerlink" href="#httperror-allow-all" title="Permalink to this headline">¶</a></h5>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Pass all responses, regardless of its status code.</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.spidermiddleware.offsite">
<span id="offsitemiddleware"></span><h3>OffsiteMiddleware<a class="headerlink" href="#module-scrapy.contrib.spidermiddleware.offsite" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.offsite.</tt><tt class="descname">OffsiteMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters out Requests for URLs outside the domains covered by the spider.</p>
<p>This middleware filters out every request whose host names aren&#8217;t in the
spider&#8217;s <a class="reference internal" href="spiders.html#scrapy.spider.Spider.allowed_domains" title="scrapy.spider.Spider.allowed_domains"><tt class="xref py py-attr docutils literal"><span class="pre">allowed_domains</span></tt></a> attribute.</p>
<p>When your spider returns a request for a domain not belonging to those
covered by the spider, this middleware will log a debug message similar to
this one:</p>
<div class="highlight-python"><div class="highlight"><pre>DEBUG: Filtered offsite request to &#39;www.othersite.com&#39;: &lt;GET http://www.othersite.com/some/page.html&gt;
</pre></div>
</div>
<p>To avoid filling the log with too much noise, it will only print one of
these messages for each new domain filtered. So, for example, if another
request for <tt class="docutils literal"><span class="pre">www.othersite.com</span></tt> is filtered, no log message will be
printed. But if a request for <tt class="docutils literal"><span class="pre">someothersite.com</span></tt> is filtered, a message
will be printed (but only for the first request filtered).</p>
<p>If the spider doesn&#8217;t define an
<a class="reference internal" href="spiders.html#scrapy.spider.Spider.allowed_domains" title="scrapy.spider.Spider.allowed_domains"><tt class="xref py py-attr docutils literal"><span class="pre">allowed_domains</span></tt></a> attribute, or the
attribute is empty, the offsite middleware will allow all requests.</p>
<p>If the request has the <tt class="xref py py-attr docutils literal"><span class="pre">dont_filter</span></tt> attribute
set, the offsite middleware will allow the request even if its domain is not
listed in allowed domains.</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.spidermiddleware.referer">
<span id="referermiddleware"></span><h3>RefererMiddleware<a class="headerlink" href="#module-scrapy.contrib.spidermiddleware.referer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spidermiddleware.referer.RefererMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.referer.</tt><tt class="descname">RefererMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.referer.RefererMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Populates Request <tt class="docutils literal"><span class="pre">Referer</span></tt> header, based on the URL of the Response which
generated it.</p>
</dd></dl>

<div class="section" id="referermiddleware-settings">
<h4>RefererMiddleware settings<a class="headerlink" href="#referermiddleware-settings" title="Permalink to this headline">¶</a></h4>
<div class="section" id="referer-enabled">
<span id="std:setting-REFERER_ENABLED"></span><h5>REFERER_ENABLED<a class="headerlink" href="#referer-enabled" title="Permalink to this headline">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.15.</span></p>
</div>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Whether to enable referer middleware.</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.spidermiddleware.urllength">
<span id="urllengthmiddleware"></span><h3>UrlLengthMiddleware<a class="headerlink" href="#module-scrapy.contrib.spidermiddleware.urllength" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spidermiddleware.urllength.</tt><tt class="descname">UrlLengthMiddleware</tt><a class="headerlink" href="#scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters out requests with URLs longer than URLLENGTH_LIMIT</p>
<p>The <a class="reference internal" href="#scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware" title="scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">UrlLengthMiddleware</span></tt></a> can be configured through the following
settings (see the settings documentation for more info):</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="settings.html#std:setting-URLLENGTH_LIMIT"><tt class="xref std std-setting docutils literal"><span class="pre">URLLENGTH_LIMIT</span></tt></a> - The maximum URL length to allow for crawled URLs.</li>
</ul>
</div></blockquote>
</dd></dl>

</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="extensions.html" class="btn btn-neutral float-right" title="Extensions">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="downloader-middleware.html" class="btn btn-neutral" title="Downloader Middleware"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008-2013, Scrapy developers.
      Last updated on Apr 17, 2014.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org/">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="http://doc.scrapy.org/en/master/">master</a></dd>
        
          <dd><a href="../index.html">latest</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.20/">0.20</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.18/">0.18</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.16/">0.16</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.14/">0.14</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.12/">0.12</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.9/">0.9</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.8/">0.8</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.7/">0.7</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="https://media.readthedocs.org/pdf/scrapy/latest/scrapy.pdf">PDF</a></dd>
        
          <dd><a href="https://media.readthedocs.org/htmlzip/scrapy/latest/scrapy.zip">HTML</a></dd>
        
          <dd><a href="https://media.readthedocs.org/epub/scrapy/latest/scrapy.epub">Epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="http://readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="http://readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org/">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.22.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>

<!-- Mirrored from doc.scrapy.org/en/latest/topics/spider-middleware.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:41 GMT -->
</html>