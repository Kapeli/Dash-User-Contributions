

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->

<!-- Mirrored from doc.scrapy.org/en/latest/news.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:41 GMT -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Release notes &mdash; Scrapy 0.22.2 documentation</title>
  

  
  

  
  <link href='../../../fonts.googleapis.com/css732b.css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  

  
    <link rel="stylesheet" href="../../../media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.22.2 documentation" href="index-2.html"/>
        <link rel="next" title="Contributing to Scrapy" href="contributing.html"/>
        <link rel="prev" title="Item Exporters" href="topics/exporters.html"/>
 
<!-- RTD Extra Head -->



  
  <!-- 
  Always link to the latest version, as canonical.
  http://docs.readthedocs.org/en/latest/canonical.html
  -->
  <link rel="canonical" href="news.html" />
  

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy",
    version: "latest",
    language: "en",
    page: "news",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org"
  }
  // Old variables
  var doc_version = "latest";
  var doc_slug = "scrapy";
  var page_name = "news";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);

  // User Analytics Code
  _gaq.push(['user._setAccount', 'UA-10231918-2']);
  _gaq.push(['user._trackPageview']);
  // End User Analytics Code


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="../../../cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="index-2.html" class="fa fa-home"> Scrapy</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="http://doc.scrapy.org/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="intro/overview.html">Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#pick-a-website">Pick a website</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#define-the-data-you-want-to-scrape">Define the data you want to scrape</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#write-a-spider-to-extract-the-data">Write a Spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#run-the-spider-to-extract-the-data">Run the spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#review-scraped-data">Review scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#what-s-next">What&#8217;s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/install.html">Installation guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/install.html#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/install.html#installing-scrapy">Installing Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/install.html#platform-specific-installation-notes">Platform specific installation notes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/tutorial.html">Scrapy Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#creating-a-project">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#defining-our-item">Defining our Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#our-first-spider">Our first Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#storing-the-scraped-data">Storing the scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/commands.html">Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#using-the-scrapy-tool">Using the <tt class="docutils literal"><span class="pre">scrapy</span></tt> tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#available-tool-commands">Available tool commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#custom-project-commands">Custom project commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#declaring-items">Declaring Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#item-fields">Item Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#working-with-items">Working with Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#extending-items">Extending Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#item-objects">Item objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#field-objects">Field objects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/spiders.html">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/spiders.html#spider-arguments">Spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spiders.html#built-in-spiders-reference">Built-in spiders reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/selectors.html">Selectors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/selectors.html#using-selectors">Using selectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/selectors.html#module-scrapy.selector">Built-in Selectors reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/shell.html">Scrapy shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#launch-the-shell">Launch the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#using-the-shell">Using the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#example-of-shell-session">Example of shell session</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#invoking-the-shell-from-spiders-to-inspect-responses">Invoking the shell from spiders to inspect responses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#writing-your-own-item-pipeline">Writing your own item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#item-pipeline-example">Item pipeline example</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#activating-an-item-pipeline-component">Activating an Item Pipeline component</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#serialization-formats">Serialization formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#storages">Storages</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#storage-uri-parameters">Storage URI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#storage-backends">Storage backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/link-extractors.html#module-scrapy.contrib.linkextractors">Built-in link extractors reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#how-to-set-the-log-level">How to set the log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#how-to-log-messages">How to log messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#logging-from-spiders">Logging from Spiders</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#module-scrapy.log">scrapy.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#logging-settings">Logging settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/stats.html">Stats Collection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/stats.html#common-stats-collector-uses">Common Stats Collector uses</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/stats.html#available-stats-collectors">Available Stats Collectors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/email.html">Sending e-mail</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#quick-example">Quick example</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#mailsender-class-reference">MailSender class reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#mail-settings">Mail settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/telnetconsole.html">Telnet Console</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#how-to-access-the-telnet-console">How to access the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#available-variables-in-the-telnet-console">Available variables in the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#telnet-console-signals">Telnet Console signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#telnet-settings">Telnet settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#web-service-resources">Web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#web-service-settings">Web service settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#writing-a-web-service-resource">Writing a web service resource</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#examples-of-web-service-resources">Examples of web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-does-scrapy-compare-to-beautifulsoup-or-lxml">How does Scrapy compare to BeautifulSoup or lxml?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-python-versions-does-scrapy-support">What Python versions does Scrapy support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#does-scrapy-work-with-python-3">Does Scrapy work with Python 3?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#did-scrapy-steal-x-from-django">Did Scrapy &#8220;steal&#8221; X from Django?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#does-scrapy-work-with-http-proxies">Does Scrapy work with HTTP proxies?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-scrape-an-item-with-attributes-in-different-pages">How can I scrape an item with attributes in different pages?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapy-crashes-with-importerror-no-module-named-win32api">Scrapy crashes with: ImportError: No module named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-simulate-a-user-login-in-my-spider">How can I simulate a user login in my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#does-scrapy-crawl-in-breadth-first-or-depth-first-order">Does Scrapy crawl in breadth-first or depth-first order?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#my-scrapy-crawler-has-memory-leaks-what-can-i-do">My Scrapy crawler has memory leaks. What can I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-make-scrapy-consume-less-memory">How can I make Scrapy consume less memory?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-use-basic-http-authentication-in-my-spiders">Can I use Basic HTTP Authentication in my spiders?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#why-does-scrapy-download-pages-in-english-instead-of-my-native-language">Why does Scrapy download pages in English instead of my native language?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#where-can-i-find-some-example-scrapy-projects">Where can I find some example Scrapy projects?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-run-a-spider-without-creating-a-project">Can I run a spider without creating a project?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#i-get-filtered-offsite-request-messages-how-can-i-fix-them">I get &#8220;Filtered offsite request&#8221; messages. How can I fix them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">What is the recommended way to deploy a Scrapy crawler in production?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-use-json-for-large-exports">Can I use JSON for large exports?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-return-twisted-deferreds-from-signal-handlers">Can I return (Twisted) deferreds from signal handlers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-does-the-response-status-code-999-means">What does the response status code 999 means?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">Can I call <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> from my spiders to debug them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">Simplest way to dump all my scraped items into a JSON/CSV/XML file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">What&#8217;s this huge cryptic <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> parameter used in some forms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-s-the-best-way-to-parse-big-xml-csv-data-feeds">What&#8217;s the best way to parse big XML/CSV data feeds?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#does-scrapy-manage-cookies-automatically">Does Scrapy manage cookies automatically?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy">How can I see the cookies being sent and received from Scrapy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-instruct-a-spider-to-stop-itself">How can I instruct a spider to stop itself?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-can-i-prevent-my-scrapy-bot-from-getting-banned">How can I prevent my Scrapy bot from getting banned?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#should-i-use-spider-arguments-or-settings-to-configure-my-spider">Should I use spider arguments or settings to configure my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items">I&#8217;m scraping a XML document and my XPath selector doesn&#8217;t return any items</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#i-m-getting-an-error-cannot-import-name-crawler">I&#8217;m getting an error: &#8220;cannot import name crawler&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/debug.html">Debugging Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#parse-command">Parse Command</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#scrapy-shell">Scrapy Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#open-in-browser">Open in browser</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/contracts.html#custom-contracts">Custom Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/practices.html">Common Practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#run-scrapy-from-a-script">Run Scrapy from a script</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#running-multiple-spiders-in-the-same-process">Running multiple spiders in the same process</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#distributed-crawls">Distributed crawls</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#avoiding-getting-banned">Avoiding getting banned</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#dynamic-creation-of-item-classes">Dynamic Creation of Item Classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/broad-crawls.html">Broad Crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#increase-concurrency">Increase concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#reduce-log-level">Reduce log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#disable-cookies">Disable cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#disable-retries">Disable retries</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#reduce-download-timeout">Reduce download timeout</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#disable-redirects">Disable redirects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#enable-crawling-of-ajax-crawlable-pages">Enable crawling of &#8220;Ajax Crawlable Pages&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/firefox.html">Using Firefox for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/firefox.html#caveats-with-inspecting-the-live-browser-dom">Caveats with inspecting the live browser DOM</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firefox.html#useful-firefox-add-ons-for-scraping">Useful Firefox add-ons for scraping</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/firebug.html">Using Firebug for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#getting-links-to-follow">Getting links to follow</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#extracting-the-data">Extracting the data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/leaks.html">Debugging memory leaks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#common-causes-of-memory-leaks">Common causes of memory leaks</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#debugging-memory-leaks-with-trackref">Debugging memory leaks with <tt class="docutils literal"><span class="pre">trackref</span></tt></a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#debugging-memory-leaks-with-guppy">Debugging memory leaks with Guppy</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/images.html">Downloading Item Images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#enabling-your-images-pipeline">Enabling your Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#images-storage">Images Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#additional-features">Additional features</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#module-scrapy.contrib.pipeline.images">Implementing your custom Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/autothrottle.html">AutoThrottle extension</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#design-goals">Design goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#how-it-works">How it works</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#throttling-algorithm">Throttling algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/jobs.html">Jobs: pausing and resuming crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#job-directory">Job directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#how-to-use-it">How to use it</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#keeping-persistent-state-between-batches">Keeping persistent state between batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#persistence-gotchas">Persistence gotchas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#using-djangoitem">Using DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#djangoitem-caveats">DjangoItem caveats</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#django-settings-set-up">Django settings set up</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/architecture.html">Architecture overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#components">Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#data-flow">Data flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#event-driven-networking">Event-driven networking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/downloader-middleware.html">Downloader Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#activating-a-downloader-middleware">Activating a downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#writing-your-own-downloader-middleware">Writing your own downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#built-in-downloader-middleware-reference">Built-in downloader middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/spider-middleware.html">Spider Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#activating-a-spider-middleware">Activating a spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#writing-your-own-spider-middleware">Writing your own spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#built-in-spider-middleware-reference">Built-in spider middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/extensions.html">Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#extension-settings">Extension settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#loading-activating-extensions">Loading &amp; activating extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#available-enabled-and-disabled-extensions">Available, enabled and disabled extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#disabling-an-extension">Disabling an extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#writing-your-own-extension">Writing your own extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#built-in-extensions-reference">Built-in extensions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/api.html">Core API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#module-scrapy.settings">Settings API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#module-scrapy.signalmanager">Signals API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#stats-collector-api">Stats Collector API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/settings.html">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#populating-the-settings">Populating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#built-in-settings-reference">Built-in settings reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/signals.html">Signals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/signals.html#deferred-signal-handlers">Deferred signal handlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/signals.html#module-scrapy.signals">Built-in signals reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/exceptions.html">Exceptions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/exceptions.html#built-in-exceptions-reference">Built-in Exceptions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/exporters.html#using-item-exporters">Using Item Exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/exporters.html#serialization-of-item-fields">Serialization of item fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/exporters.html#built-in-item-exporters-reference">Built-in Item Exporters reference</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-01-17">0.22.0 (released 2014-01-17)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id11">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id14">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id15">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experimental/index.html">Experimental features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="experimental/index.html#add-commands-using-external-libraries">Add commands using external libraries</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index-2.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index-2.html">Docs</a> &raquo;</li>
      
    <li>Release notes</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/scrapy/scrapy/blob/0.22/docs/news.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="release-notes">
<span id="news"></span><h1>Release notes<a class="headerlink" href="#release-notes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="released-2014-02-14">
<h2>0.22.2 (released 2014-02-14)<a class="headerlink" href="#released-2014-02-14" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fix a reference to unexistent engine.slots. closes #593 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c099a">commit 13c099a</a>)</li>
<li>downloaderMW doc typo (spiderMW doc copy remnant) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8ae11bf">commit 8ae11bf</a>)</li>
<li>Correct typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1346037">commit 1346037</a>)</li>
</ul>
</div>
<div class="section" id="released-2014-02-08">
<h2>0.22.1 (released 2014-02-08)<a class="headerlink" href="#released-2014-02-08" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>localhost666 can resolve under certain circumstances (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2ec2279">commit 2ec2279</a>)</li>
<li>test inspect.stack failure (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc3eda3">commit cc3eda3</a>)</li>
<li>Handle cases when inspect.stack() fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8cb44f9">commit 8cb44f9</a>)</li>
<li>Fix wrong checks on subclassing of deprecated classes. closes #581 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/46d98d6">commit 46d98d6</a>)</li>
<li>Docs: 4-space indent for final spider example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13846de">commit 13846de</a>)</li>
<li>Fix HtmlParserLinkExtractor and tests after #485 merge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/368a946">commit 368a946</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed the missing space when the link has an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b566388">commit b566388</a>)</li>
<li>BaseSgmlLinkExtractor: Added unit test of a link with an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c1cb418">commit c1cb418</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed unknown_endtag() so that it only set current_link=None when the end tag match the opening tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7e4d627">commit 7e4d627</a>)</li>
<li>Fix tests for Travis-CI build (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/76c7e20">commit 76c7e20</a>)</li>
<li>replace unencodeable codepoints with html entities. fixes #562 and #285 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f87b17">commit 5f87b17</a>)</li>
<li>RegexLinkExtractor: encode URL unicode value when creating Links (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0ee545">commit d0ee545</a>)</li>
<li>Updated the tutorial crawl output with latest output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8da65de">commit 8da65de</a>)</li>
<li>Updated shell docs with the crawler reference and fixed the actual shell output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/875b9ab">commit 875b9ab</a>)</li>
<li>PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f89efaf">commit f89efaf</a>)</li>
<li>Expose current crawler in the scrapy shell. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5349cec">commit 5349cec</a>)</li>
<li>Unused re import and PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/387f414">commit 387f414</a>)</li>
<li>Ignore None&#8217;s values when using the ItemLoader. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0632546">commit 0632546</a>)</li>
<li>DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Filesystem instead Dbm. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cde9a8c">commit cde9a8c</a>)</li>
<li>show ubuntu setup instructions as literal code (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fb5c9c5">commit fb5c9c5</a>)</li>
<li>Update Ubuntu installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/70fb105">commit 70fb105</a>)</li>
<li>Merge pull request #550 from stray-leone/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f70b6a">commit 6f70b6a</a>)</li>
<li>modify the version of scrapy ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/725900d">commit 725900d</a>)</li>
<li>fix 0.22.0 release date (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/af0219a">commit af0219a</a>)</li>
<li>fix typos in news.rst and remove (not released yet) header (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7f58f4">commit b7f58f4</a>)</li>
</ul>
</div>
<div class="section" id="released-2014-01-17">
<h2>0.22.0 (released 2014-01-17)<a class="headerlink" href="#released-2014-01-17" title="Permalink to this headline">¶</a></h2>
<div class="section" id="enhancements">
<h3>Enhancements<a class="headerlink" href="#enhancements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>[<strong>Backwards incompatible</strong>] Switched HTTPCacheMiddleware backend to filesystem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>)
To restore old backend set <cite>HTTPCACHE_STORAGE</cite> to <cite>scrapy.contrib.httpcache.DbmCacheStorage</cite></li>
<li>Proxy <a class="reference external" href="https:///">https://</a> urls using CONNECT method (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/392">issue 392</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/397">issue 397</a>)</li>
<li>Add a middleware to crawl ajax crawleable pages as defined by google (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/343">issue 343</a>)</li>
<li>Rename scrapy.spider.BaseSpider to scrapy.spider.Spider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/510">issue 510</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/519">issue 519</a>)</li>
<li>Selectors register EXSLT namespaces by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/472">issue 472</a>)</li>
<li>Unify item loaders similar to selectors renaming (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/461">issue 461</a>)</li>
<li>Make <cite>RFPDupeFilter</cite> class easily subclassable (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/533">issue 533</a>)</li>
<li>Improve test coverage and forthcoming Python 3 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/525">issue 525</a>)</li>
<li>Promote startup info on settings and middleware to INFO level (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/520">issue 520</a>)</li>
<li>Support partials in <cite>get_func_args</cite> util (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/506">issue 506</a>, issue:<cite>504</cite>)</li>
<li>Allow running indiviual tests via tox (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/503">issue 503</a>)</li>
<li>Update extensions ignored by link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/498">issue 498</a>)</li>
<li>Add middleware methods to get files/images/thumbs paths (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/490">issue 490</a>)</li>
<li>Improve offsite middleware tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/478">issue 478</a>)</li>
<li>Add a way to skip default Referer header set by RefererMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/475">issue 475</a>)</li>
<li>Do not send <cite>x-gzip</cite> in default <cite>Accept-Encoding</cite> header (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/469">issue 469</a>)</li>
<li>Support defining http error handling using settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/466">issue 466</a>)</li>
<li>Use moderm python idioms wherever you find legacies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/497">issue 497</a>)</li>
<li>Improve and correct documentation
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/527">issue 527</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/524">issue 524</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/521">issue 521</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/517">issue 517</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/512">issue 512</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/505">issue 505</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/502">issue 502</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/489">issue 489</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/465">issue 465</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/460">issue 460</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/425">issue 425</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/536">issue 536</a>)</li>
</ul>
</div>
<div class="section" id="fixes">
<h3>Fixes<a class="headerlink" href="#fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Update Selector class imports in CrawlSpider template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/484">issue 484</a>)</li>
<li>Fix unexistent reference to <cite>engine.slots</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/464">issue 464</a>)</li>
<li>Do not try to call <cite>body_as_unicode()</cite> on a non-TextResponse instance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/462">issue 462</a>)</li>
<li>Warn when subclassing XPathItemLoader, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/523">issue 523</a>)</li>
<li>Warn when subclassing XPathSelector, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/537">issue 537</a>)</li>
<li>Multiple fixes to memory stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/531">issue 531</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/530">issue 530</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/529">issue 529</a>)</li>
<li>Fix overriding url in <cite>FormRequest.from_response()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/507">issue 507</a>)</li>
<li>Fix tests runner under pip 1.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/513">issue 513</a>)</li>
<li>Fix logging error when spider name is unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/479">issue 479</a>)</li>
</ul>
</div>
</div>
<div class="section" id="released-2013-12-09">
<h2>0.20.2 (released 2013-12-09)<a class="headerlink" href="#released-2013-12-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Update CrawlSpider Template with Selector changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d1457d">commit 6d1457d</a>)</li>
<li>fix method name in tutorial. closes GH-480 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4fc359">commit b4fc359</a></li>
</ul>
</div>
<div class="section" id="released-2013-11-28">
<h2>0.20.1 (released 2013-11-28)<a class="headerlink" href="#released-2013-11-28" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>include_package_data is required to build wheels from published sources (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ba1ad5">commit 5ba1ad5</a>)</li>
<li>process_parallel was leaking the failures on its internal deferreds.  closes #458 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/419a780">commit 419a780</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-11-08">
<h2>0.20.0 (released 2013-11-08)<a class="headerlink" href="#released-2013-11-08" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Enhancements<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New Selector&#8217;s API including CSS selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/395">issue 395</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/426">issue 426</a>),</li>
<li>Request/Response url/body attributes are now immutable
(modifying them had been deprecated for a long time)</li>
<li><a class="reference internal" href="topics/settings.html#std:setting-ITEM_PIPELINES"><tt class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></tt></a> is now defined as a dict (instead of a list)</li>
<li>Sitemap spider can fetch alternate URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/360">issue 360</a>)</li>
<li><cite>Selector.remove_namespaces()</cite> now remove namespaces from element&#8217;s attributes. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/416">issue 416</a>)</li>
<li>Paved the road for Python 3.3+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/435">issue 435</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/436">issue 436</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/431">issue 431</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/452">issue 452</a>)</li>
<li>New item exporter using native python types with nesting support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/366">issue 366</a>)</li>
<li>Tune HTTP1.1 pool size so it matches concurrency defined by settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b43b5f575">commit b43b5f575</a>)</li>
<li>scrapy.mail.MailSender now can connect over TLS or upgrade using STARTTLS (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/327">issue 327</a>)</li>
<li>New FilesPipeline with functionality factored out from ImagesPipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/370">issue 370</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/409">issue 409</a>)</li>
<li>Recommend Pillow instead of PIL for image handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/317">issue 317</a>)</li>
<li>Added debian packages for Ubuntu quantal and raring (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86230c0">commit 86230c0</a>)</li>
<li>Mock server (used for tests) can listen for HTTPS requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/410">issue 410</a>)</li>
<li>Remove multi spider support from multiple core components
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/422">issue 422</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/421">issue 421</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/420">issue 420</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/419">issue 419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/423">issue 423</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>)</li>
<li>Travis-CI now tests Scrapy changes against development versions of <cite>w3lib</cite> and <cite>queuelib</cite> python packages.</li>
<li>Add pypy 2.1 to continous integration tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ecfa7431">commit ecfa7431</a>)</li>
<li>Pylinted, pep8 and removed old-style exceptions from source (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/430">issue 430</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/432">issue 432</a>)</li>
<li>Use importlib for parametric imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/445">issue 445</a>)</li>
<li>Handle a regression introduced in Python 2.7.5 that affects XmlItemExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/372">issue 372</a>)</li>
<li>Bugfix crawling shutdown on SIGINT (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/450">issue 450</a>)</li>
<li>Do not submit <cite>reset</cite> type inputs in FormRequest.from_response (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b326b87">commit b326b87</a>)</li>
<li>Do not silence download errors when request errback raises an exception (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/684cfc0">commit 684cfc0</a>)</li>
</ul>
</div>
<div class="section" id="bugfixes">
<h3>Bugfixes<a class="headerlink" href="#bugfixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Fix tests under Django 1.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b6bed44c">commit b6bed44c</a>)</li>
<li>Lot of bugfixes to retry middleware under disconnections using HTTP 1.1 download handler</li>
<li>Fix inconsistencies among Twisted releases (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/406">issue 406</a>)</li>
<li>Fix scrapy shell bugs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/407">issue 407</a>)</li>
<li>Fix invalid variable name in setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/429">issue 429</a>)</li>
<li>Fix tutorial references (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/387">issue 387</a>)</li>
<li>Improve request-response docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/391">issue 391</a>)</li>
<li>Improve best practices docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/399">issue 399</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/400">issue 400</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/401">issue 401</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/402">issue 402</a>)</li>
<li>Improve django integration docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/404">issue 404</a>)</li>
<li>Document <cite>bindaddress</cite> request meta (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/37c24e01d7">commit 37c24e01d7</a>)</li>
<li>Improve <cite>Request</cite> class documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/226">issue 226</a>)</li>
</ul>
</div>
<div class="section" id="other">
<h3>Other<a class="headerlink" href="#other" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Dropped Python 2.6 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/448">issue 448</a>)</li>
<li>Add <a class="reference external" href="https://github.com/SimonSapin/cssselect">cssselect</a> python package as install dependency</li>
<li>Drop libxml2 and multi selector&#8217;s backend support, <a class="reference external" href="http://lxml.de/">lxml</a> is required from now on.</li>
<li>Minimum Twisted version increased to 10.0.0, dropped Twisted 8.0 support.</li>
<li>Running test suite now requires <cite>mock</cite> python library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/390">issue 390</a>)</li>
</ul>
</div>
<div class="section" id="thanks">
<h3>Thanks<a class="headerlink" href="#thanks" title="Permalink to this headline">¶</a></h3>
<p>Thanks to everyone who contribute to this release!</p>
<p>List of contributors sorted by number of commits:</p>
<div class="highlight-python"><div class="highlight"><pre>69 Daniel Graña &lt;dangra@...&gt;
37 Pablo Hoffman &lt;pablo@...&gt;
13 Mikhail Korobov &lt;kmike84@...&gt;
 9 Alex Cepoi &lt;alex.cepoi@...&gt;
 9 alexanderlukanin13 &lt;alexander.lukanin.13@...&gt;
 8 Rolando Espinoza La fuente &lt;darkrho@...&gt;
 8 Lukasz Biedrycki &lt;lukasz.biedrycki@...&gt;
 6 Nicolas Ramirez &lt;nramirez.uy@...&gt;
 3 Paul Tremberth &lt;paul.tremberth@...&gt;
 2 Martin Olveyra &lt;molveyra@...&gt;
 2 Stefan &lt;misc@...&gt;
 2 Rolando Espinoza &lt;darkrho@...&gt;
 2 Loren Davie &lt;loren@...&gt;
 2 irgmedeiros &lt;irgmedeiros@...&gt;
 1 Stefan Koch &lt;taikano@...&gt;
 1 Stefan &lt;cct@...&gt;
 1 scraperdragon &lt;dragon@...&gt;
 1 Kumara Tharmalingam &lt;ktharmal@...&gt;
 1 Francesco Piccinno &lt;stack.box@...&gt;
 1 Marcos Campal &lt;duendex@...&gt;
 1 Dragon Dave &lt;dragon@...&gt;
 1 Capi Etheriel &lt;barraponto@...&gt;
 1 cacovsky &lt;amarquesferraz@...&gt;
 1 Berend Iwema &lt;berend@...&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="released-2013-10-10">
<h2>0.18.4 (released 2013-10-10)<a class="headerlink" href="#released-2013-10-10" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>IPython refuses to update the namespace. fix #396 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3d32c4f">commit 3d32c4f</a>)</li>
<li>Fix AlreadyCalledError replacing a request in shell command. closes #407 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b1d8919">commit b1d8919</a>)</li>
<li>Fix start_requests lazyness and early hangs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/89faf52">commit 89faf52</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-10-03">
<h2>0.18.3 (released 2013-10-03)<a class="headerlink" href="#released-2013-10-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fix regression on lazy evaluation of start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/12693a5">commit 12693a5</a>)</li>
<li>forms: do not submit reset inputs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e429f63">commit e429f63</a>)</li>
<li>increase unittest timeouts to decrease travis false positive failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/912202e">commit 912202e</a>)</li>
<li>backport master fixes to json exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cfc2d46">commit cfc2d46</a>)</li>
<li>Fix permission and set umask before generating sdist tarball (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/06149e0">commit 06149e0</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-09-03">
<h2>0.18.2 (released 2013-09-03)<a class="headerlink" href="#released-2013-09-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Backport <cite>scrapy check</cite> command fixes and backward compatible multi
crawler process(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/339">issue 339</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-08-27">
<h2>0.18.1 (released 2013-08-27)<a class="headerlink" href="#released-2013-08-27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>remove extra import added by cherry picked changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d20304e">commit d20304e</a>)</li>
<li>fix crawling tests under twisted pre 11.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1994f38">commit 1994f38</a>)</li>
<li>py26 can not format zero length fields {} (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/abf756f">commit abf756f</a>)</li>
<li>test PotentiaDataLoss errors on unbound responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b15470d">commit b15470d</a>)</li>
<li>Treat responses without content-length or Transfer-Encoding as good responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4bf324">commit c4bf324</a>)</li>
<li>do no include ResponseFailed if http11 handler is not enabled (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cbe684">commit 6cbe684</a>)</li>
<li>New HTTP client wraps connection losts in ResponseFailed exception. fix #373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1a20bba">commit 1a20bba</a>)</li>
<li>limit travis-ci build matrix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3b01bb8">commit 3b01bb8</a>)</li>
<li>Merge pull request #375 from peterarenot/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa766d7">commit fa766d7</a>)</li>
<li>Fixed so it refers to the correct folder (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3283809">commit 3283809</a>)</li>
<li>added quantal &amp; raring to support ubuntu releases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1411923">commit 1411923</a>)</li>
<li>fix retry middleware which didn&#8217;t retry certain connection errors after the upgrade to http1 client, closes GH-373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb35ed0">commit bb35ed0</a>)</li>
<li>fix XmlItemExporter in Python 2.7.4 and 2.7.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de3e451">commit de3e451</a>)</li>
<li>minor updates to 0.18 release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c45e5f1">commit c45e5f1</a>)</li>
<li>fix contributters list format (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0b60031">commit 0b60031</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-08-09">
<h2>0.18.0 (released 2013-08-09)<a class="headerlink" href="#released-2013-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Lot of improvements to testsuite run using Tox, including a way to test on pypi</li>
<li>Handle GET parameters for AJAX crawleable urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3fe2a32">commit 3fe2a32</a>)</li>
<li>Use lxml recover option to parse sitemaps (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/347">issue 347</a>)</li>
<li>Bugfix cookie merging by hostname and not by netloc (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/352">issue 352</a>)</li>
<li>Support disabling <cite>HttpCompressionMiddleware</cite> using a flag setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/359">issue 359</a>)</li>
<li>Support xml namespaces using <cite>iternodes</cite> parser in <cite>XMLFeedSpider</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/12">issue 12</a>)</li>
<li>Support <cite>dont_cache</cite> request meta flag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/19">issue 19</a>)</li>
<li>Bugfix <cite>scrapy.utils.gz.gunzip</cite> broken by changes in python 2.7.4 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4dc76e">commit 4dc76e</a>)</li>
<li>Bugfix url encoding on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/24">issue 24</a>)</li>
<li>Bugfix <cite>TakeFirst</cite> processor shouldn&#8217;t discard zero (0) value (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/59">issue 59</a>)</li>
<li>Support nested items in xml exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/66">issue 66</a>)</li>
<li>Improve cookies handling performance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/77">issue 77</a>)</li>
<li>Log dupe filtered requests once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/105">issue 105</a>)</li>
<li>Split redirection middleware into status and meta based middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/78">issue 78</a>)</li>
<li>Use HTTP1.1 as default downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/109">issue 109</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/318">issue 318</a>)</li>
<li>Support xpath form selection on <cite>FormRequest.from_response</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/185">issue 185</a>)</li>
<li>Bugfix unicode decoding error on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/199">issue 199</a>)</li>
<li>Bugfix signal dispatching on pypi interpreter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/205">issue 205</a>)</li>
<li>Improve request delay and concurrency handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/206">issue 206</a>)</li>
<li>Add RFC2616 cache policy to <cite>HttpCacheMiddleware</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/212">issue 212</a>)</li>
<li>Allow customization of messages logged by engine (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/214">issue 214</a>)</li>
<li>Multiples improvements to <cite>DjangoItem</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/217">issue 217</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/218">issue 218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/221">issue 221</a>)</li>
<li>Extend Scrapy commands using setuptools entry points (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Allow spider <cite>allowed_domains</cite> value to be set/tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/261">issue 261</a>)</li>
<li>Support <cite>settings.getdict</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/269">issue 269</a>)</li>
<li>Simplify internal <cite>scrapy.core.scraper</cite> slot handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/271">issue 271</a>)</li>
<li>Added <cite>Item.copy</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/290">issue 290</a>)</li>
<li>Collect idle downloader slots (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/297">issue 297</a>)</li>
<li>Add <cite>ftp://</cite> scheme downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/329">issue 329</a>)</li>
<li>Added downloader benchmark webserver and spider tools <a class="reference internal" href="topics/benchmarking.html#benchmarking"><em>Benchmarking</em></a></li>
<li>Moved persistent (on disk) queues to a separate project (<a class="reference external" href="https://github.com/scrapy/queuelib">queuelib</a>) which scrapy now depends on</li>
<li>Add scrapy commands using external libraries (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Added <tt class="docutils literal"><span class="pre">--pdb</span></tt> option to <tt class="docutils literal"><span class="pre">scrapy</span></tt> command line tool</li>
<li>Added <tt class="xref py py-meth docutils literal"><span class="pre">XPathSelector.remove_namespaces()</span></tt> which allows to remove all namespaces from XML documents for convenience (to work with namespace-less XPaths). Documented in <a class="reference internal" href="topics/selectors.html#topics-selectors"><em>Selectors</em></a>.</li>
<li>Several improvements to spider contracts</li>
<li>New default middleware named MetaRefreshMiddldeware that handles meta-refresh html tag redirections,</li>
<li>MetaRefreshMiddldeware and RedirectMiddleware have different priorities to address #62</li>
<li>added from_crawler method to spiders</li>
<li>added system tests with mock server</li>
<li>more improvements to Mac OS compatibility (thanks Alex Cepoi)</li>
<li>several more cleanups to singletons and multi-spider support (thanks Nicolas Ramirez)</li>
<li>support custom download slots</li>
<li>added &#8211;spider option to &#8220;shell&#8221; command.</li>
<li>log overridden settings when scrapy starts</li>
</ul>
<p>Thanks to everyone who contribute to this release. Here is a list of
contributors sorted by number of commits:</p>
<div class="highlight-python"><div class="highlight"><pre>130 Pablo Hoffman &lt;pablo@...&gt;
 97 Daniel Graña &lt;dangra@...&gt;
 20 Nicolás Ramírez &lt;nramirez.uy@...&gt;
 13 Mikhail Korobov &lt;kmike84@...&gt;
 12 Pedro Faustino &lt;pedrobandim@...&gt;
 11 Steven Almeroth &lt;sroth77@...&gt;
  5 Rolando Espinoza La fuente &lt;darkrho@...&gt;
  4 Michal Danilak &lt;mimino.coder@...&gt;
  4 Alex Cepoi &lt;alex.cepoi@...&gt;
  4 Alexandr N Zamaraev (aka tonal) &lt;tonal@...&gt;
  3 paul &lt;paul.tremberth@...&gt;
  3 Martin Olveyra &lt;molveyra@...&gt;
  3 Jordi Llonch &lt;llonchj@...&gt;
  3 arijitchakraborty &lt;myself.arijit@...&gt;
  2 Shane Evans &lt;shane.evans@...&gt;
  2 joehillen &lt;joehillen@...&gt;
  2 Hart &lt;HartSimha@...&gt;
  2 Dan &lt;ellisd23@...&gt;
  1 Zuhao Wan &lt;wanzuhao@...&gt;
  1 whodatninja &lt;blake@...&gt;
  1 vkrest &lt;v.krestiannykov@...&gt;
  1 tpeng &lt;pengtaoo@...&gt;
  1 Tom Mortimer-Jones &lt;tom@...&gt;
  1 Rocio Aramberri &lt;roschegel@...&gt;
  1 Pedro &lt;pedro@...&gt;
  1 notsobad &lt;wangxiaohugg@...&gt;
  1 Natan L &lt;kuyanatan.nlao@...&gt;
  1 Mark Grey &lt;mark.grey@...&gt;
  1 Luan &lt;luanpab@...&gt;
  1 Libor Nenadál &lt;libor.nenadal@...&gt;
  1 Juan M Uys &lt;opyate@...&gt;
  1 Jonas Brunsgaard &lt;jonas.brunsgaard@...&gt;
  1 Ilya Baryshev &lt;baryshev@...&gt;
  1 Hasnain Lakhani &lt;m.hasnain.lakhani@...&gt;
  1 Emanuel Schorsch &lt;emschorsch@...&gt;
  1 Chris Tilden &lt;chris.tilden@...&gt;
  1 Capi Etheriel &lt;barraponto@...&gt;
  1 cacovsky &lt;amarquesferraz@...&gt;
  1 Berend Iwema &lt;berend@...&gt;
</pre></div>
</div>
</div>
<div class="section" id="released-2013-05-30">
<h2>0.16.5 (released 2013-05-30)<a class="headerlink" href="#released-2013-05-30" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>obey request method when scrapy deploy is redirected to a new endpoint (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c4fcee">commit 8c4fcee</a>)</li>
<li>fix inaccurate downloader middleware documentation. refs #280 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/40667cb">commit 40667cb</a>)</li>
<li>doc: remove links to diveintopython.org, which is no longer available. closes #246 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bd58bfa">commit bd58bfa</a>)</li>
<li>Find form nodes in invalid html5 documents (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3d6945">commit e3d6945</a>)</li>
<li>Fix typo labeling attrs type bool instead of list (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274276">commit a274276</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-01-23">
<h2>0.16.4 (released 2013-01-23)<a class="headerlink" href="#released-2013-01-23" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fixes spelling errors in documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d2b3aa">commit 6d2b3aa</a>)</li>
<li>add doc about disabling an extension. refs #132 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c90de33">commit c90de33</a>)</li>
<li>Fixed error message formatting. log.err() doesn&#8217;t support cool formatting and when error occured, the message was:    &#8220;ERROR: Error processing %(item)s&#8221; (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c16150c">commit c16150c</a>)</li>
<li>lint and improve images pipeline error logging (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/56b45fc">commit 56b45fc</a>)</li>
<li>fixed doc typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/243be84">commit 243be84</a>)</li>
<li>add documentation topics: Broad Crawls &amp; Common Practies (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1fbb715">commit 1fbb715</a>)</li>
<li>fix bug in scrapy parse command when spider is not specified explicitly. closes #209 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c72e682">commit c72e682</a>)</li>
<li>Update docs/topics/commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/28eac7a">commit 28eac7a</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-12-07">
<h2>0.16.3 (released 2012-12-07)<a class="headerlink" href="#released-2012-12-07" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Remove concurrency limitation when using download delays and still ensure inter-request delays are enforced (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/487b9b5">commit 487b9b5</a>)</li>
<li>add error details when image pipeline fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8232569">commit 8232569</a>)</li>
<li>improve mac os compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8dcf8aa">commit 8dcf8aa</a>)</li>
<li>setup.py: use README.rst to populate long_description (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7b5310d">commit 7b5310d</a>)</li>
<li>doc: removed obsolete references to ClientForm (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/80f9bb6">commit 80f9bb6</a>)</li>
<li>correct docs for default storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2aa491b">commit 2aa491b</a>)</li>
<li>doc: removed broken proxyhub link from FAQ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bdf61c4">commit bdf61c4</a>)</li>
<li>Fixed docs typo in SpiderOpenCloseLogging example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7184094">commit 7184094</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-11-09">
<h2>0.16.2 (released 2012-11-09)<a class="headerlink" href="#released-2012-11-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>scrapy contracts: python2.6 compat (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a4a9199">commit a4a9199</a>)</li>
<li>scrapy contracts verbose option (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ec41673">commit ec41673</a>)</li>
<li>proper unittest-like output for scrapy contracts (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86635e4">commit 86635e4</a>)</li>
<li>added open_in_browser to debugging doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c9b690d">commit c9b690d</a>)</li>
<li>removed reference to global scrapy stats from settings doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/dd55067">commit dd55067</a>)</li>
<li>Fix SpiderState bug in Windows platforms (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/58998f4">commit 58998f4</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-10-26">
<h2>0.16.1 (released 2012-10-26)<a class="headerlink" href="#released-2012-10-26" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fixed LogStats extension, which got broken after a wrong merge before the 0.16 release (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c780fd">commit 8c780fd</a>)</li>
<li>better backwards compatibility for scrapy.conf.settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3403089">commit 3403089</a>)</li>
<li>extended documentation on how to access crawler stats from extensions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4da0b5">commit c4da0b5</a>)</li>
<li>removed .hgtags (no longer needed now that scrapy uses git) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d52c188">commit d52c188</a>)</li>
<li>fix dashes under rst headers (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa4f7f9">commit fa4f7f9</a>)</li>
<li>set release date for 0.16.0 in news (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e292246">commit e292246</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-10-18">
<h2>0.16.0 (released 2012-10-18)<a class="headerlink" href="#released-2012-10-18" title="Permalink to this headline">¶</a></h2>
<p>Scrapy changes:</p>
<ul class="simple">
<li>added <a class="reference internal" href="topics/contracts.html#topics-contracts"><em>Spiders Contracts</em></a>, a mechanism for testing spiders in a formal/reproducible way</li>
<li>added options <tt class="docutils literal"><span class="pre">-o</span></tt> and <tt class="docutils literal"><span class="pre">-t</span></tt> to the <a class="reference internal" href="topics/commands.html#std:command-runspider"><tt class="xref std std-command docutils literal"><span class="pre">runspider</span></tt></a> command</li>
<li>documented <a class="reference internal" href="topics/autothrottle.html"><em>AutoThrottle extension</em></a> and added to extensions installed by default. You still need to enable it with <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">AUTOTHROTTLE_ENABLED</span></tt></a></li>
<li>major Stats Collection refactoring: removed separation of global/per-spider stats, removed stats-related signals (<tt class="docutils literal"><span class="pre">stats_spider_opened</span></tt>, etc). Stats are much simpler now, backwards compatibility is kept on the Stats Collector API and signals.</li>
<li>added <a class="reference internal" href="topics/spider-middleware.html#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests"><tt class="xref py py-meth docutils literal"><span class="pre">process_start_requests()</span></tt></a> method to spider middlewares</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Stats Collector singleton. Stats can now be accessed through the Crawler.stats attribute. See the stats collection documentation for more info.</li>
<li>documented <a class="reference internal" href="topics/api.html#topics-api"><em>Core API</em></a></li>
<li><cite>lxml</cite> is now the default selectors backend instead of <cite>libxml2</cite></li>
<li>ported FormRequest.from_response() to use <a class="reference external" href="http://lxml.de/">lxml</a> instead of <a class="reference external" href="http://wwwsearch.sourceforge.net/old/ClientForm/">ClientForm</a></li>
<li>removed modules: <tt class="docutils literal"><span class="pre">scrapy.xlib.BeautifulSoup</span></tt> and <tt class="docutils literal"><span class="pre">scrapy.xlib.ClientForm</span></tt></li>
<li>SitemapSpider: added support for sitemap urls ending in .xml and .xml.gz, even if they advertise a wrong content type (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10ed28b">commit 10ed28b</a>)</li>
<li>StackTraceDump extension: also dump trackref live references (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fe2ce93">commit fe2ce93</a>)</li>
<li>nested items now fully supported in JSON and JSONLines exporters</li>
<li>added <a class="reference internal" href="topics/downloader-middleware.html#std:reqmeta-cookiejar"><tt class="xref std std-reqmeta docutils literal"><span class="pre">cookiejar</span></tt></a> Request meta key to support multiple cookie sessions per spider</li>
<li>decoupled encoding detection code to <a class="reference external" href="https://github.com/scrapy/w3lib/blob/master/w3lib/encoding.py">w3lib.encoding</a>, and ported Scrapy code to use that mdule</li>
<li>dropped support for Python 2.5. See <a class="reference external" href="http://blog.scrapy.org/scrapy-dropping-support-for-python-25">http://blog.scrapy.org/scrapy-dropping-support-for-python-25</a></li>
<li>dropped support for Twisted 2.5</li>
<li>added <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERER_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">REFERER_ENABLED</span></tt></a> setting, to control referer middleware</li>
<li>changed default user agent to: <tt class="docutils literal"><span class="pre">Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)</span></tt></li>
<li>removed (undocumented) <tt class="docutils literal"><span class="pre">HTMLImageLinkExtractor</span></tt> class from <tt class="docutils literal"><span class="pre">scrapy.contrib.linkextractors.image</span></tt></li>
<li>removed per-spider settings (to be replaced by instantiating multiple crawler objects)</li>
<li><tt class="docutils literal"><span class="pre">USER_AGENT</span></tt> spider attribute will no longer work, use <tt class="docutils literal"><span class="pre">user_agent</span></tt> attribute instead</li>
<li><tt class="docutils literal"><span class="pre">DOWNLOAD_TIMEOUT</span></tt> spider attribute will no longer work, use <tt class="docutils literal"><span class="pre">download_timeout</span></tt> attribute instead</li>
<li>removed <tt class="docutils literal"><span class="pre">ENCODING_ALIASES</span></tt> setting, as encoding auto-detection has been moved to the <a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> library</li>
<li>promoted <a class="reference internal" href="topics/djangoitem.html#topics-djangoitem"><em>DjangoItem</em></a> to main contrib</li>
<li>LogFormatter method now return dicts(instead of strings) to support lazy formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/164">issue 164</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/dcef7b0">commit dcef7b0</a>)</li>
<li>downloader handlers (<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_HANDLERS"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></tt></a> setting) now receive settings as the first argument of the constructor</li>
<li>replaced memory usage acounting with (more portable) <a class="reference external" href="http://docs.python.org/library/resource.html">resource</a> module, removed <tt class="docutils literal"><span class="pre">scrapy.utils.memory</span></tt> module</li>
<li>removed signal: <tt class="docutils literal"><span class="pre">scrapy.mail.mail_sent</span></tt></li>
<li>removed <tt class="docutils literal"><span class="pre">TRACK_REFS</span></tt> setting, now <a class="reference internal" href="topics/leaks.html#topics-leaks-trackrefs"><em>trackrefs</em></a> is always enabled</li>
<li>DBM is now the default storage backend for HTTP cache middleware</li>
<li>number of log messages (per level) are now tracked through Scrapy stats (stat name: <tt class="docutils literal"><span class="pre">log_count/LEVEL</span></tt>)</li>
<li>number received responses are now tracked through Scrapy stats (stat name: <tt class="docutils literal"><span class="pre">response_received_count</span></tt>)</li>
<li>removed <tt class="docutils literal"><span class="pre">scrapy.log.started</span></tt> attribute</li>
</ul>
</div>
<div class="section" id="id2">
<h2>0.14.4<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>added precise to supported ubuntu distros (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7e46df">commit b7e46df</a>)</li>
<li>fixed bug in json-rpc webservice reported in <a class="reference external" href="https://groups.google.com/d/topic/scrapy-users/qgVBmFybNAQ/discussion">https://groups.google.com/d/topic/scrapy-users/qgVBmFybNAQ/discussion</a>. also removed no longer supported &#8216;run&#8217; command from extras/scrapy-ws.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/340fbdb">commit 340fbdb</a>)</li>
<li>meta tag attributes for content-type http equiv can be in any order. #123 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0cb68af">commit 0cb68af</a>)</li>
<li>replace &#8220;import Image&#8221; by more standard &#8220;from PIL import Image&#8221;. closes #88 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4d17048">commit 4d17048</a>)</li>
<li>return trial status as bin/runtests.sh exit value. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7b2e7f">commit b7b2e7f</a>)</li>
</ul>
</div>
<div class="section" id="id3">
<h2>0.14.3<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>forgot to include pydispatch license. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fd85f9c">commit fd85f9c</a>)</li>
<li>include egg files used by testsuite in source distribution. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c897793">commit c897793</a>)</li>
<li>update docstring in project template to avoid confusion with genspider command, which may be considered as an advanced feature. refs #107 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2548dcc">commit 2548dcc</a>)</li>
<li>added note to docs/topics/firebug.rst about google directory being shut down (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/668e352">commit 668e352</a>)</li>
<li>dont discard slot when empty, just save in another dict in order to recycle if needed again. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e9f607">commit 8e9f607</a>)</li>
<li>do not fail handling unicode xpaths in libxml2 backed selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b830e95">commit b830e95</a>)</li>
<li>fixed minor mistake in Request objects documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bf3c9ee">commit bf3c9ee</a>)</li>
<li>fixed minor defect in link extractors documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ba14f38">commit ba14f38</a>)</li>
<li>removed some obsolete remaining code related to sqlite support in scrapy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0665175">commit 0665175</a>)</li>
</ul>
</div>
<div class="section" id="id4">
<h2>0.14.2<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>move buffer pointing to start of file before computing checksum. refs #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6a5bef2">commit 6a5bef2</a>)</li>
<li>Compute image checksum before persisting images. closes #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9817df1">commit 9817df1</a>)</li>
<li>remove leaking references in cached failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/673a120">commit 673a120</a>)</li>
<li>fixed bug in MemoryUsage extension: get_engine_status() takes exactly 1 argument (0 given) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/11133e9">commit 11133e9</a>)</li>
<li>fixed struct.error on http compression middleware. closes #87 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1423140">commit 1423140</a>)</li>
<li>ajax crawling wasn&#8217;t expanding for unicode urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0de3fb4">commit 0de3fb4</a>)</li>
<li>Catch start_requests iterator errors. refs #83 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/454a21d">commit 454a21d</a>)</li>
<li>Speed-up libxml2 XPathSelector (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2fbd662">commit 2fbd662</a>)</li>
<li>updated versioning doc according to recent changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a070f5">commit 0a070f5</a>)</li>
<li>scrapyd: fixed documentation link (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2b4e4c3">commit 2b4e4c3</a>)</li>
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
</ul>
</div>
<div class="section" id="id5">
<h2>0.14.1<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
<li>bumped version to 0.14.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cb9e1c">commit 6cb9e1c</a>)</li>
<li>fixed reference to tutorial directory (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4b86bd6">commit 4b86bd6</a>)</li>
<li>doc: removed duplicated callback argument from Request.replace() (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1aeccdd">commit 1aeccdd</a>)</li>
<li>fixed formatting of scrapyd doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8bf19e6">commit 8bf19e6</a>)</li>
<li>Dump stacks for all running threads and fix engine status dumped by StackTraceDump extension (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/14a8e6e">commit 14a8e6e</a>)</li>
<li>added comment about why we disable ssl on boto images upload (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5223575">commit 5223575</a>)</li>
<li>SSL handshaking hangs when doing too many parallel connections to S3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/63d583d">commit 63d583d</a>)</li>
<li>change tutorial to follow changes on dmoz site (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bcb3198">commit bcb3198</a>)</li>
<li>Avoid _disconnectedDeferred AttributeError exception in Twisted&gt;=11.1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98f3f87">commit 98f3f87</a>)</li>
<li>allow spider to set autothrottle max concurrency (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/175a4b5">commit 175a4b5</a>)</li>
</ul>
</div>
<div class="section" id="id6">
<h2>0.14<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="new-features-and-settings">
<h3>New features and settings<a class="headerlink" href="#new-features-and-settings" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first">Support for <a class="reference external" href="http://code.google.com/web/ajaxcrawling/docs/getting-started.html">AJAX crawleable urls</a></p>
</li>
<li><p class="first">New persistent scheduler that stores requests on disk, allowing to suspend and resume crawls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2737">r2737</a>)</p>
</li>
<li><p class="first">added <tt class="docutils literal"><span class="pre">-o</span></tt> option to <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></tt>, a shortcut for dumping scraped items into a file (or standard output using <tt class="docutils literal"><span class="pre">-</span></tt>)</p>
</li>
<li><p class="first">Added support for passing custom settings to Scrapyd <tt class="docutils literal"><span class="pre">schedule.json</span></tt> api (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2779">r2779</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2783">r2783</a>)</p>
</li>
<li><p class="first">New <tt class="docutils literal"><span class="pre">ChunkedTransferMiddleware</span></tt> (enabled by default) to support <a class="reference external" href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">chunked transfer encoding</a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2769">r2769</a>)</p>
</li>
<li><p class="first">Add boto 2.0 support for S3 downloader handler (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2763">r2763</a>)</p>
</li>
<li><p class="first">Added <a class="reference external" href="http://docs.python.org/library/marshal.html">marshal</a> to formats supported by feed exports (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2744">r2744</a>)</p>
</li>
<li><p class="first">In request errbacks, offending requests are now received in <cite>failure.request</cite> attribute (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2738">r2738</a>)</p>
</li>
<li><dl class="first docutils">
<dt>Big downloader refactoring to support per domain/ip concurrency limits (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2732">r2732</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></tt> setting has been deprecated and replaced by:</dt>
<dd><ul class="first last simple">
<li><a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS</span></tt></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></tt></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></tt></a></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">check the documentation for more details</p>
</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Added builtin caching DNS resolver (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2728">r2728</a>)</p>
</li>
<li><p class="first">Moved Amazon AWS-related components/extensions (SQS spider queue, SimpleDB stats collector) to a separate project: [scaws](<a class="reference external" href="https://github.com/scrapinghub/scaws">https://github.com/scrapinghub/scaws</a>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2706">r2706</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2714">r2714</a>)</p>
</li>
<li><p class="first">Moved spider queues to scrapyd: <cite>scrapy.spiderqueue</cite> -&gt; <cite>scrapyd.spiderqueue</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2708">r2708</a>)</p>
</li>
<li><p class="first">Moved sqlite utils to scrapyd: <cite>scrapy.utils.sqlite</cite> -&gt; <cite>scrapyd.sqlite</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2781">r2781</a>)</p>
</li>
<li><p class="first">Real support for returning iterators on <cite>start_requests()</cite> method. The iterator is now consumed during the crawl when the spider is getting idle (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-REDIRECT_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">REDIRECT_ENABLED</span></tt></a> setting to quickly enable/disable the redirect middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2697">r2697</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">RETRY_ENABLED</span></tt></a> setting to quickly enable/disable the retry middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2694">r2694</a>)</p>
</li>
<li><p class="first">Added <tt class="docutils literal"><span class="pre">CloseSpider</span></tt> exception to manually close spiders (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2691">r2691</a>)</p>
</li>
<li><p class="first">Improved encoding detection by adding support for HTML5 meta charset declaration (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2690">r2690</a>)</p>
</li>
<li><p class="first">Refactored close spider behavior to wait for all downloads to finish and be processed by spiders, before closing the spider (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2688">r2688</a>)</p>
</li>
<li><p class="first">Added <tt class="docutils literal"><span class="pre">SitemapSpider</span></tt> (see documentation in Spiders page) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2658">r2658</a>)</p>
</li>
<li><p class="first">Added <tt class="docutils literal"><span class="pre">LogStats</span></tt> extension for periodically logging basic stats (like crawled pages and scraped items) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2657">r2657</a>)</p>
</li>
<li><p class="first">Make handling of gzipped responses more robust (#319, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2643">r2643</a>). Now Scrapy will try and decompress as much as possible from a gzipped response, instead of failing with an <cite>IOError</cite>.</p>
</li>
<li><p class="first">Simplified !MemoryDebugger extension to use stats for dumping memory debugging info (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2639">r2639</a>)</p>
</li>
<li><p class="first">Added new command to edit spiders: <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">edit</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2636">r2636</a>) and <cite>-e</cite> flag to <cite>genspider</cite> command that uses it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2653">r2653</a>)</p>
</li>
<li><p class="first">Changed default representation of items to pretty-printed dicts. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2631">r2631</a>). This improves default logging by making log more readable in the default case, for both Scraped and Dropped lines.</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/signals.html#std:signal-spider_error"><tt class="xref std std-signal docutils literal"><span class="pre">spider_error</span></tt></a> signal (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2628">r2628</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-COOKIES_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">COOKIES_ENABLED</span></tt></a> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2625">r2625</a>)</p>
</li>
<li><p class="first">Stats are now dumped to Scrapy log (default value of <a class="reference internal" href="topics/settings.html#std:setting-STATS_DUMP"><tt class="xref std std-setting docutils literal"><span class="pre">STATS_DUMP</span></tt></a> setting has been changed to <cite>True</cite>). This is to make Scrapy users more aware of Scrapy stats and the data that is collected there.</p>
</li>
<li><p class="first">Added support for dynamically adjusting download delay and maximum concurrent requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2599">r2599</a>)</p>
</li>
<li><p class="first">Added new DBM HTTP cache storage backend (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2576">r2576</a>)</p>
</li>
<li><p class="first">Added <tt class="docutils literal"><span class="pre">listjobs.json</span></tt> API to Scrapyd (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2571">r2571</a>)</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">CsvItemExporter</span></tt>: added <tt class="docutils literal"><span class="pre">join_multivalued</span></tt> parameter (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2578">r2578</a>)</p>
</li>
<li><p class="first">Added namespace support to <tt class="docutils literal"><span class="pre">xmliter_lxml</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2552">r2552</a>)</p>
</li>
<li><p class="first">Improved cookies middleware by making <cite>COOKIES_DEBUG</cite> nicer and documenting it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2579">r2579</a>)</p>
</li>
<li><p class="first">Several improvements to Scrapyd and Link extractors</p>
</li>
</ul>
</div>
<div class="section" id="code-rearranged-and-removed">
<h3>Code rearranged and removed<a class="headerlink" href="#code-rearranged-and-removed" title="Permalink to this headline">¶</a></h3>
<ul>
<li><dl class="first docutils">
<dt>Merged item passed and item scraped concepts, as they have often proved confusing in the past. This means: (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2630">r2630</a>)</dt>
<dd><ul class="first last simple">
<li>original item_scraped signal was removed</li>
<li>original item_passed signal was renamed to item_scraped</li>
<li>old log lines <tt class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></tt> were removed</li>
<li>old log lines <tt class="docutils literal"><span class="pre">Passed</span> <span class="pre">Item...</span></tt> were renamed to <tt class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></tt> lines and downgraded to <tt class="docutils literal"><span class="pre">DEBUG</span></tt> level</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Reduced Scrapy codebase by striping part of Scrapy code into two new libraries:</dt>
<dd><ul class="first last simple">
<li><a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> (several functions from <tt class="docutils literal"><span class="pre">scrapy.utils.{http,markup,multipart,response,url}</span></tt>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2584">r2584</a>)</li>
<li><a class="reference external" href="https://github.com/scrapy/scrapely">scrapely</a> (was <tt class="docutils literal"><span class="pre">scrapy.contrib.ibl</span></tt>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2586">r2586</a>)</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Removed unused function: <cite>scrapy.utils.request.request_info()</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2577">r2577</a>)</p>
</li>
<li><p class="first">Removed googledir project from <cite>examples/googledir</cite>. There&#8217;s now a new example project called <cite>dirbot</cite> available on github: <a class="reference external" href="https://github.com/scrapy/dirbot">https://github.com/scrapy/dirbot</a></p>
</li>
<li><p class="first">Removed support for default field values in Scrapy items (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2616">r2616</a>)</p>
</li>
<li><p class="first">Removed experimental crawlspider v2 (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2632">r2632</a>)</p>
</li>
<li><p class="first">Removed scheduler middleware to simplify architecture. Duplicates filter is now done in the scheduler itself, using the same dupe fltering class as before (<cite>DUPEFILTER_CLASS</cite> setting) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2640">r2640</a>)</p>
</li>
<li><p class="first">Removed support for passing urls to <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></tt> command (use <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">parse</span></tt> instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Removed deprecated Execution Queue (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Removed (undocumented) spider context extension (from scrapy.contrib.spidercontext) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2780">r2780</a>)</p>
</li>
<li><p class="first">removed <tt class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></tt> setting (use scrapyd maxproc instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2789">r2789</a>)</p>
</li>
<li><p class="first">Renamed attributes of core components: downloader.sites -&gt; downloader.slots, scraper.sites -&gt; scraper.slots (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2717">r2717</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2718">r2718</a>)</p>
</li>
<li><p class="first">Renamed setting <tt class="docutils literal"><span class="pre">CLOSESPIDER_ITEMPASSED</span></tt> to <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT"><tt class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></tt></a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2655">r2655</a>). Backwards compatibility kept.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="id7">
<h2>0.12<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features-and-improvements">
<h3>New features and improvements<a class="headerlink" href="#new-features-and-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Passed item is now sent in the <tt class="docutils literal"><span class="pre">item</span></tt> argument of the <tt class="xref std std-signal docutils literal"><span class="pre">item_passed</span></tt> (#273)</li>
<li>Added verbose option to <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">version</span></tt> command, useful for bug reports (#298)</li>
<li>HTTP cache now stored by default in the project data dir (#279)</li>
<li>Added project data storage directory (#276, #277)</li>
<li>Documented file structure of Scrapy projects (see command-line tool doc)</li>
<li>New lxml backend for XPath selectors (#147)</li>
<li>Per-spider settings (#245)</li>
<li>Support exit codes to signal errors in Scrapy commands (#248)</li>
<li>Added <tt class="docutils literal"><span class="pre">-c</span></tt> argument to <tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span></tt> command</li>
<li>Made <tt class="docutils literal"><span class="pre">libxml2</span></tt> optional (#260)</li>
<li>New <tt class="docutils literal"><span class="pre">deploy</span></tt> command (#261)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_PAGECOUNT"><tt class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_PAGECOUNT</span></tt></a> setting (#253)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT"><tt class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ERRORCOUNT</span></tt></a> setting (#254)</li>
</ul>
</div>
<div class="section" id="scrapyd-changes">
<h3>Scrapyd changes<a class="headerlink" href="#scrapyd-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Scrapyd now uses one process per spider</li>
<li>It stores one log file per spider run, and rotate them keeping the lastest 5 logs per spider (by default)</li>
<li>A minimal web ui was added, available at <a class="reference external" href="http://localhost:6800/">http://localhost:6800</a> by default</li>
<li>There is now a <cite>scrapy server</cite> command to start a Scrapyd server of the current project</li>
</ul>
</div>
<div class="section" id="changes-to-settings">
<h3>Changes to settings<a class="headerlink" href="#changes-to-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>added <cite>HTTPCACHE_ENABLED</cite> setting (False by default) to enable HTTP cache middleware</li>
<li>changed <cite>HTTPCACHE_EXPIRATION_SECS</cite> semantics: now zero means &#8220;never expire&#8221;.</li>
</ul>
</div>
<div class="section" id="deprecated-obsoleted-functionality">
<h3>Deprecated/obsoleted functionality<a class="headerlink" href="#deprecated-obsoleted-functionality" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Deprecated <tt class="docutils literal"><span class="pre">runserver</span></tt> command in favor of <tt class="docutils literal"><span class="pre">server</span></tt> command which starts a Scrapyd server. See also: Scrapyd changes</li>
<li>Deprecated <tt class="docutils literal"><span class="pre">queue</span></tt> command in favor of using Scrapyd <tt class="docutils literal"><span class="pre">schedule.json</span></tt> API. See also: Scrapyd changes</li>
<li>Removed the !LxmlItemLoader (experimental contrib which never graduated to main contrib)</li>
</ul>
</div>
</div>
<div class="section" id="id8">
<h2>0.10<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id9">
<h3>New features and improvements<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New Scrapy service called <tt class="docutils literal"><span class="pre">scrapyd</span></tt> for deploying Scrapy crawlers in production (#218) (documentation available)</li>
<li>Simplified Images pipeline usage which doesn&#8217;t require subclassing your own images pipeline now (#217)</li>
<li>Scrapy shell now shows the Scrapy log by default (#206)</li>
<li>Refactored execution queue in a common base code and pluggable backends called &#8220;spider queues&#8221; (#220)</li>
<li>New persistent spider queue (based on SQLite) (#198), available by default, which allows to start Scrapy in server mode and then schedule spiders to run.</li>
<li>Added documentation for Scrapy command-line tool and all its available sub-commands. (documentation available)</li>
<li>Feed exporters with pluggable backends (#197) (documentation available)</li>
<li>Deferred signals (#193)</li>
<li>Added two new methods to item pipeline open_spider(), close_spider() with deferred support (#195)</li>
<li>Support for overriding default request headers per spider (#181)</li>
<li>Replaced default Spider Manager with one with similar functionality but not depending on Twisted Plugins (#186)</li>
<li>Splitted Debian package into two packages - the library and the service (#187)</li>
<li>Scrapy log refactoring (#188)</li>
<li>New extension for keeping persistent spider contexts among different runs (#203)</li>
<li>Added <cite>dont_redirect</cite> request.meta key for avoiding redirects (#233)</li>
<li>Added <cite>dont_retry</cite> request.meta key for avoiding retries (#234)</li>
</ul>
</div>
<div class="section" id="command-line-tool-changes">
<h3>Command-line tool changes<a class="headerlink" href="#command-line-tool-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New <cite>scrapy</cite> command which replaces the old <cite>scrapy-ctl.py</cite> (#199)
- there is only one global <cite>scrapy</cite> command now, instead of one <cite>scrapy-ctl.py</cite> per project
- Added <cite>scrapy.bat</cite> script for running more conveniently from Windows</li>
<li>Added bash completion to command-line tool (#210)</li>
<li>Renamed command <cite>start</cite> to <cite>runserver</cite> (#209)</li>
</ul>
</div>
<div class="section" id="api-changes">
<h3>API changes<a class="headerlink" href="#api-changes" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first"><tt class="docutils literal"><span class="pre">url</span></tt> and <tt class="docutils literal"><span class="pre">body</span></tt> attributes of Request objects are now read-only (#230)</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">Request.copy()</span></tt> and <tt class="docutils literal"><span class="pre">Request.replace()</span></tt> now also copies their <tt class="docutils literal"><span class="pre">callback</span></tt> and <tt class="docutils literal"><span class="pre">errback</span></tt> attributes (#231)</p>
</li>
<li><p class="first">Removed <tt class="docutils literal"><span class="pre">UrlFilterMiddleware</span></tt> from <tt class="docutils literal"><span class="pre">scrapy.contrib</span></tt> (already disabled by default)</p>
</li>
<li><p class="first">Offsite middelware doesn&#8217;t filter out any request coming from a spider that doesn&#8217;t have a allowed_domains attribute (#225)</p>
</li>
<li><p class="first">Removed Spider Manager <tt class="docutils literal"><span class="pre">load()</span></tt> method. Now spiders are loaded in the constructor itself.</p>
</li>
<li><dl class="first docutils">
<dt>Changes to Scrapy Manager (now called &#8220;Crawler&#8221;):</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">scrapy.core.manager.ScrapyManager</span></tt> class renamed to <tt class="docutils literal"><span class="pre">scrapy.crawler.Crawler</span></tt></li>
<li><tt class="docutils literal"><span class="pre">scrapy.core.manager.scrapymanager</span></tt> singleton moved to <tt class="docutils literal"><span class="pre">scrapy.project.crawler</span></tt></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Moved module: <tt class="docutils literal"><span class="pre">scrapy.contrib.spidermanager</span></tt> to <tt class="docutils literal"><span class="pre">scrapy.spidermanager</span></tt></p>
</li>
<li><p class="first">Spider Manager singleton moved from <tt class="docutils literal"><span class="pre">scrapy.spider.spiders</span></tt> to the <tt class="docutils literal"><span class="pre">spiders`</span> <span class="pre">attribute</span> <span class="pre">of</span> <span class="pre">``scrapy.project.crawler</span></tt> singleton.</p>
</li>
<li><dl class="first docutils">
<dt>moved Stats Collector classes: (#204)</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">scrapy.stats.collector.StatsCollector</span></tt> to <tt class="docutils literal"><span class="pre">scrapy.statscol.StatsCollector</span></tt></li>
<li><tt class="docutils literal"><span class="pre">scrapy.stats.collector.SimpledbStatsCollector</span></tt> to <tt class="docutils literal"><span class="pre">scrapy.contrib.statscol.SimpledbStatsCollector</span></tt></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">default per-command settings are now specified in the <tt class="docutils literal"><span class="pre">default_settings</span></tt> attribute of command object class (#201)</p>
</li>
<li><dl class="first docutils">
<dt>changed arguments of Item pipeline <tt class="docutils literal"><span class="pre">process_item()</span></tt> method from <tt class="docutils literal"><span class="pre">(spider,</span> <span class="pre">item)</span></tt> to <tt class="docutils literal"><span class="pre">(item,</span> <span class="pre">spider)</span></tt></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <tt class="docutils literal"><span class="pre">scrapy.core.signals</span></tt> module to <tt class="docutils literal"><span class="pre">scrapy.signals</span></tt></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <tt class="docutils literal"><span class="pre">scrapy.core.exceptions</span></tt> module to <tt class="docutils literal"><span class="pre">scrapy.exceptions</span></tt></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">added <tt class="docutils literal"><span class="pre">handles_request()</span></tt> class method to <tt class="docutils literal"><span class="pre">BaseSpider</span></tt></p>
</li>
<li><p class="first">dropped <tt class="docutils literal"><span class="pre">scrapy.log.exc()</span></tt> function (use <tt class="docutils literal"><span class="pre">scrapy.log.err()</span></tt> instead)</p>
</li>
<li><p class="first">dropped <tt class="docutils literal"><span class="pre">component</span></tt> argument of <tt class="docutils literal"><span class="pre">scrapy.log.msg()</span></tt> function</p>
</li>
<li><p class="first">dropped <tt class="docutils literal"><span class="pre">scrapy.log.log_level</span></tt> attribute</p>
</li>
<li><p class="first">Added <tt class="docutils literal"><span class="pre">from_settings()</span></tt> class methods to Spider Manager, and Item Pipeline Manager</p>
</li>
</ul>
</div>
<div class="section" id="id10">
<h3>Changes to settings<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added <tt class="docutils literal"><span class="pre">HTTPCACHE_IGNORE_SCHEMES</span></tt> setting to ignore certain schemes on !HttpCacheMiddleware (#225)</li>
<li>Added <tt class="docutils literal"><span class="pre">SPIDER_QUEUE_CLASS</span></tt> setting which defines the spider queue to use (#220)</li>
<li>Added <tt class="docutils literal"><span class="pre">KEEP_ALIVE</span></tt> setting (#220)</li>
<li>Removed <tt class="docutils literal"><span class="pre">SERVICE_QUEUE</span></tt> setting (#220)</li>
<li>Removed <tt class="docutils literal"><span class="pre">COMMANDS_SETTINGS_MODULE</span></tt> setting (#201)</li>
<li>Renamed <tt class="docutils literal"><span class="pre">REQUEST_HANDLERS</span></tt> to <tt class="docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></tt> and make download handlers classes (instead of functions)</li>
</ul>
</div>
</div>
<div class="section" id="id11">
<h2>0.9<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id12">
<h3>New features and improvements<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added SMTP-AUTH support to scrapy.mail</li>
<li>New settings added: <tt class="docutils literal"><span class="pre">MAIL_USER</span></tt>, <tt class="docutils literal"><span class="pre">MAIL_PASS</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2065">r2065</a> | #149)</li>
<li>Added new scrapy-ctl view command - To view URL in the browser, as seen by Scrapy (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Added web service for controlling Scrapy process (this also deprecates the web console. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2053">r2053</a> | #167)</li>
<li>Support for running Scrapy as a service, for production systems (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1988">r1988</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2054">r2054</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2055">r2055</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2056">r2056</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2057">r2057</a> | #168)</li>
<li>Added wrapper induction library (documentation only available in source code for now). (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2011">r2011</a>)</li>
<li>Simplified and improved response encoding support (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1969">r1969</a>)</li>
<li>Added <tt class="docutils literal"><span class="pre">LOG_ENCODING</span></tt> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1956">r1956</a>, documentation available)</li>
<li>Added <tt class="docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></tt> setting (enabled by default) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1923">r1923</a>, doc available)</li>
<li><tt class="docutils literal"><span class="pre">MailSender</span></tt> is no longer IO-blocking (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1955">r1955</a> | #146)</li>
<li>Linkextractors and new Crawlspider now handle relative base tag urls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1960">r1960</a> | #148)</li>
<li>Several improvements to Item Loaders and processors (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2022">r2022</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2023">r2023</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2024">r2024</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2025">r2025</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2026">r2026</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2027">r2027</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2028">r2028</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2029">r2029</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2030">r2030</a>)</li>
<li>Added support for adding variables to telnet console (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a> | #165)</li>
<li>Support for requests without callbacks (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2050">r2050</a> | #166)</li>
</ul>
</div>
<div class="section" id="id13">
<h3>API changes<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Change <tt class="docutils literal"><span class="pre">Spider.domain_name</span></tt> to <tt class="docutils literal"><span class="pre">Spider.name</span></tt> (SEP-012, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1975">r1975</a>)</li>
<li><tt class="docutils literal"><span class="pre">Response.encoding</span></tt> is now the detected encoding (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>)</li>
<li><tt class="docutils literal"><span class="pre">HttpErrorMiddleware</span></tt> now returns None or raises an exception (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2006">r2006</a> | #157)</li>
<li><tt class="docutils literal"><span class="pre">scrapy.command</span></tt> modules relocation (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2035">r2035</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2036">r2036</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2037">r2037</a>)</li>
<li>Added <tt class="docutils literal"><span class="pre">ExecutionQueue</span></tt> for feeding spiders to scrape (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2034">r2034</a>)</li>
<li>Removed <tt class="docutils literal"><span class="pre">ExecutionEngine</span></tt> singleton (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Ported <tt class="docutils literal"><span class="pre">S3ImagesStore</span></tt> (images pipeline) to use boto and threads (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2033">r2033</a>)</li>
<li>Moved module: <tt class="docutils literal"><span class="pre">scrapy.management.telnet</span></tt> to <tt class="docutils literal"><span class="pre">scrapy.telnet</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a>)</li>
</ul>
</div>
<div class="section" id="changes-to-default-settings">
<h3>Changes to default settings<a class="headerlink" href="#changes-to-default-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Changed default <tt class="docutils literal"><span class="pre">SCHEDULER_ORDER</span></tt> to <tt class="docutils literal"><span class="pre">DFO</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1939">r1939</a>)</li>
</ul>
</div>
</div>
<div class="section" id="id14">
<h2>0.8<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features">
<h3>New features<a class="headerlink" href="#new-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added DEFAULT_RESPONSE_ENCODING setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1809">r1809</a>)</li>
<li>Added <tt class="docutils literal"><span class="pre">dont_click</span></tt> argument to <tt class="docutils literal"><span class="pre">FormRequest.from_response()</span></tt> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1813">r1813</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1816">r1816</a>)</li>
<li>Added <tt class="docutils literal"><span class="pre">clickdata</span></tt> argument to <tt class="docutils literal"><span class="pre">FormRequest.from_response()</span></tt> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1802">r1802</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1803">r1803</a>)</li>
<li>Added support for HTTP proxies (<tt class="docutils literal"><span class="pre">HttpProxyMiddleware</span></tt>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1781">r1781</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1785">r1785</a>)</li>
<li>Offiste spider middleware now logs messages when filtering out requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1841">r1841</a>)</li>
</ul>
</div>
<div class="section" id="backwards-incompatible-changes">
<h3>Backwards-incompatible changes<a class="headerlink" href="#backwards-incompatible-changes" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first">Changed <tt class="docutils literal"><span class="pre">scrapy.utils.response.get_meta_refresh()</span></tt> signature (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1804">r1804</a>)</p>
</li>
<li><p class="first">Removed deprecated <tt class="docutils literal"><span class="pre">scrapy.item.ScrapedItem</span></tt> class - use <tt class="docutils literal"><span class="pre">scrapy.item.Item</span> <span class="pre">instead</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1838">r1838</a>)</p>
</li>
<li><p class="first">Removed deprecated <tt class="docutils literal"><span class="pre">scrapy.xpath</span></tt> module - use <tt class="docutils literal"><span class="pre">scrapy.selector</span></tt> instead. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1836">r1836</a>)</p>
</li>
<li><p class="first">Removed deprecated <tt class="docutils literal"><span class="pre">core.signals.domain_open</span></tt> signal - use <tt class="docutils literal"><span class="pre">core.signals.domain_opened</span></tt> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</p>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">log.msg()</span></tt> now receives a <tt class="docutils literal"><span class="pre">spider</span></tt> argument (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</dt>
<dd><ul class="first last simple">
<li>Old domain argument has been deprecated and will be removed in 0.9. For spiders, you should always use the <tt class="docutils literal"><span class="pre">spider</span></tt> argument and pass spider references. If you really want to pass a string, use the <tt class="docutils literal"><span class="pre">component</span></tt> argument instead.</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Changed core signals <tt class="docutils literal"><span class="pre">domain_opened</span></tt>, <tt class="docutils literal"><span class="pre">domain_closed</span></tt>, <tt class="docutils literal"><span class="pre">domain_idle</span></tt></p>
</li>
<li><dl class="first docutils">
<dt>Changed Item pipeline to use spiders instead of domains</dt>
<dd><ul class="first last simple">
<li>The <tt class="docutils literal"><span class="pre">domain</span></tt> argument of  <tt class="docutils literal"><span class="pre">process_item()</span></tt> item pipeline method was changed to  <tt class="docutils literal"><span class="pre">spider</span></tt>, the new signature is: <tt class="docutils literal"><span class="pre">process_item(spider,</span> <span class="pre">item)</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1827">r1827</a> | #105)</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <tt class="docutils literal"><span class="pre">spider.domain_name</span></tt> where you previously used <tt class="docutils literal"><span class="pre">domain</span></tt>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Changed Stats API to use spiders instead of domains (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1849">r1849</a> | #113)</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">StatsCollector</span></tt> was changed to receive spider references (instead of domains) in its methods (<tt class="docutils literal"><span class="pre">set_value</span></tt>, <tt class="docutils literal"><span class="pre">inc_value</span></tt>, etc).</li>
<li>added <tt class="docutils literal"><span class="pre">StatsCollector.iter_spider_stats()</span></tt> method</li>
<li>removed <tt class="docutils literal"><span class="pre">StatsCollector.list_domains()</span></tt> method</li>
<li>Also, Stats signals were renamed and now pass around spider references (instead of domains). Here&#8217;s a summary of the changes:</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <tt class="docutils literal"><span class="pre">spider.domain_name</span></tt> where you previously used <tt class="docutils literal"><span class="pre">domain</span></tt>. <tt class="docutils literal"><span class="pre">spider_stats</span></tt> contains exactly the same data as <tt class="docutils literal"><span class="pre">domain_stats</span></tt>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><tt class="docutils literal"><span class="pre">CloseDomain</span></tt> extension moved to <tt class="docutils literal"><span class="pre">scrapy.contrib.closespider.CloseSpider</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1833">r1833</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt>Its settings were also renamed:</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">CLOSEDOMAIN_TIMEOUT</span></tt> to <tt class="docutils literal"><span class="pre">CLOSESPIDER_TIMEOUT</span></tt></li>
<li><tt class="docutils literal"><span class="pre">CLOSEDOMAIN_ITEMCOUNT</span></tt> to <tt class="docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></tt></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Removed deprecated <tt class="docutils literal"><span class="pre">SCRAPYSETTINGS_MODULE</span></tt> environment variable - use <tt class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></tt> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1840">r1840</a>)</p>
</li>
<li><p class="first">Renamed setting: <tt class="docutils literal"><span class="pre">REQUESTS_PER_DOMAIN</span></tt> to <tt class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1844">r1844</a>)</p>
</li>
<li><p class="first">Renamed setting: <tt class="docutils literal"><span class="pre">CONCURRENT_DOMAINS</span></tt> to <tt class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>)</p>
</li>
<li><p class="first">Refactored HTTP Cache middleware</p>
</li>
<li><p class="first">HTTP Cache middleware has been heavilty refactored, retaining the same functionality except for the domain sectorization which was removed. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1843">r1843</a> )</p>
</li>
<li><p class="first">Renamed exception: <tt class="docutils literal"><span class="pre">DontCloseDomain</span></tt> to <tt class="docutils literal"><span class="pre">DontCloseSpider</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1859">r1859</a> | #120)</p>
</li>
<li><p class="first">Renamed extension: <tt class="docutils literal"><span class="pre">DelayedCloseDomain</span></tt> to <tt class="docutils literal"><span class="pre">SpiderCloseDelay</span></tt> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1861">r1861</a> | #121)</p>
</li>
<li><p class="first">Removed obsolete <tt class="docutils literal"><span class="pre">scrapy.utils.markup.remove_escape_chars</span></tt> function - use <tt class="docutils literal"><span class="pre">scrapy.utils.markup.replace_escape_chars</span></tt> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1865">r1865</a>)</p>
</li>
</ul>
</div>
</div>
<div class="section" id="id15">
<h2>0.7<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<p>First release of Scrapy.</p>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contributing.html" class="btn btn-neutral float-right" title="Contributing to Scrapy">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="topics/exporters.html" class="btn btn-neutral" title="Item Exporters"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008-2013, Scrapy developers.
      Last updated on Apr 17, 2014.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org/">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="http://doc.scrapy.org/en/master/">master</a></dd>
        
          <dd><a href="index.html">latest</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.20/">0.20</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.18/">0.18</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.16/">0.16</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.14/">0.14</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.12/">0.12</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.9/">0.9</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.8/">0.8</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.7/">0.7</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="https://media.readthedocs.org/pdf/scrapy/latest/scrapy.pdf">PDF</a></dd>
        
          <dd><a href="https://media.readthedocs.org/htmlzip/scrapy/latest/scrapy.zip">HTML</a></dd>
        
          <dd><a href="https://media.readthedocs.org/epub/scrapy/latest/scrapy.epub">Epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="http://readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="http://readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org/">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.22.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="../../../media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="../../../media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="../../../media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../../../media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>

<!-- Mirrored from doc.scrapy.org/en/latest/news.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:42 GMT -->
</html>