

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->

<!-- Mirrored from doc.scrapy.org/en/latest/topics/settings.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:41 GMT -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Settings &mdash; Scrapy 0.22.2 documentation</title>
  

  
  

  
  <link href='../../../../fonts.googleapis.com/css732b.css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  

  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.22.2 documentation" href="../index-2.html"/>
        <link rel="next" title="Signals" href="signals.html"/>
        <link rel="prev" title="Requests and Responses" href="request-response.html"/>
 
<!-- RTD Extra Head -->



  
  <!-- 
  Always link to the latest version, as canonical.
  http://docs.readthedocs.org/en/latest/canonical.html
  -->
  <link rel="canonical" href="settings.html" />
  

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy",
    version: "latest",
    language: "en",
    page: "topics/settings",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org"
  }
  // Old variables
  var doc_version = "latest";
  var doc_slug = "scrapy";
  var page_name = "topics/settings";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);

  // User Analytics Code
  _gaq.push(['user._setAccount', 'UA-10231918-2']);
  _gaq.push(['user._trackPageview']);
  // End User Analytics Code


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="../../../../cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="../index-2.html" class="fa fa-home"> Scrapy</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="http://doc.scrapy.org/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#pick-a-website">Pick a website</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#define-the-data-you-want-to-scrape">Define the data you want to scrape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#write-a-spider-to-extract-the-data">Write a Spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#run-the-spider-to-extract-the-data">Run the spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#review-scraped-data">Review scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#what-s-next">What&#8217;s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#installing-scrapy">Installing Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#platform-specific-installation-notes">Platform specific installation notes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#creating-a-project">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#defining-our-item">Defining our Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#our-first-spider">Our first Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#storing-the-scraped-data">Storing the scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="commands.html#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#using-the-scrapy-tool">Using the <tt class="docutils literal"><span class="pre">scrapy</span></tt> tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#available-tool-commands">Available tool commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#custom-project-commands">Custom project commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="items.html#declaring-items">Declaring Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-fields">Item Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#working-with-items">Working with Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#extending-items">Extending Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-objects">Item objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#field-objects">Field objects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#spider-arguments">Spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#built-in-spiders-reference">Built-in spiders reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#using-selectors">Using selectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#module-scrapy.selector">Built-in Selectors reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="shell.html#launch-the-shell">Launch the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#using-the-shell">Using the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#example-of-shell-session">Example of shell session</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#invoking-the-shell-from-spiders-to-inspect-responses">Invoking the shell from spiders to inspect responses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#writing-your-own-item-pipeline">Writing your own item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#item-pipeline-example">Item pipeline example</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#activating-an-item-pipeline-component">Activating an Item Pipeline component</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#serialization-formats">Serialization formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storages">Storages</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-uri-parameters">Storage URI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-backends">Storage backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="link-extractors.html#module-scrapy.contrib.linkextractors">Built-in link extractors reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#how-to-set-the-log-level">How to set the log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#how-to-log-messages">How to log messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#logging-from-spiders">Logging from Spiders</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#module-scrapy.log">scrapy.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#logging-settings">Logging settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="stats.html#common-stats-collector-uses">Common Stats Collector uses</a></li>
<li class="toctree-l2"><a class="reference internal" href="stats.html#available-stats-collectors">Available Stats Collectors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a><ul>
<li class="toctree-l2"><a class="reference internal" href="email.html#quick-example">Quick example</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mailsender-class-reference">MailSender class reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mail-settings">Mail settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a><ul>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#how-to-access-the-telnet-console">How to access the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#available-variables-in-the-telnet-console">Available variables in the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-signals">Telnet Console signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-settings">Telnet settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-resources">Web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-settings">Web service settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#writing-a-web-service-resource">Writing a web service resource</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#examples-of-web-service-resources">Examples of web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-does-scrapy-compare-to-beautifulsoup-or-lxml">How does Scrapy compare to BeautifulSoup or lxml?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-python-versions-does-scrapy-support">What Python versions does Scrapy support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-python-3">Does Scrapy work with Python 3?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#did-scrapy-steal-x-from-django">Did Scrapy &#8220;steal&#8221; X from Django?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-http-proxies">Does Scrapy work with HTTP proxies?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-scrape-an-item-with-attributes-in-different-pages">How can I scrape an item with attributes in different pages?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-crashes-with-importerror-no-module-named-win32api">Scrapy crashes with: ImportError: No module named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-simulate-a-user-login-in-my-spider">How can I simulate a user login in my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-crawl-in-breadth-first-or-depth-first-order">Does Scrapy crawl in breadth-first or depth-first order?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#my-scrapy-crawler-has-memory-leaks-what-can-i-do">My Scrapy crawler has memory leaks. What can I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-make-scrapy-consume-less-memory">How can I make Scrapy consume less memory?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-basic-http-authentication-in-my-spiders">Can I use Basic HTTP Authentication in my spiders?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-does-scrapy-download-pages-in-english-instead-of-my-native-language">Why does Scrapy download pages in English instead of my native language?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-can-i-find-some-example-scrapy-projects">Where can I find some example Scrapy projects?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-run-a-spider-without-creating-a-project">Can I run a spider without creating a project?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-get-filtered-offsite-request-messages-how-can-i-fix-them">I get &#8220;Filtered offsite request&#8221; messages. How can I fix them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">What is the recommended way to deploy a Scrapy crawler in production?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-json-for-large-exports">Can I use JSON for large exports?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-return-twisted-deferreds-from-signal-handlers">Can I return (Twisted) deferreds from signal handlers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-does-the-response-status-code-999-means">What does the response status code 999 means?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">Can I call <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> from my spiders to debug them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">Simplest way to dump all my scraped items into a JSON/CSV/XML file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">What&#8217;s this huge cryptic <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> parameter used in some forms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-the-best-way-to-parse-big-xml-csv-data-feeds">What&#8217;s the best way to parse big XML/CSV data feeds?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-manage-cookies-automatically">Does Scrapy manage cookies automatically?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy">How can I see the cookies being sent and received from Scrapy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-instruct-a-spider-to-stop-itself">How can I instruct a spider to stop itself?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-prevent-my-scrapy-bot-from-getting-banned">How can I prevent my Scrapy bot from getting banned?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#should-i-use-spider-arguments-or-settings-to-configure-my-spider">Should I use spider arguments or settings to configure my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items">I&#8217;m scraping a XML document and my XPath selector doesn&#8217;t return any items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-getting-an-error-cannot-import-name-crawler">I&#8217;m getting an error: &#8220;cannot import name crawler&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debug.html#parse-command">Parse Command</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#scrapy-shell">Scrapy Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#open-in-browser">Open in browser</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contracts.html#custom-contracts">Custom Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="practices.html#run-scrapy-from-a-script">Run Scrapy from a script</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#running-multiple-spiders-in-the-same-process">Running multiple spiders in the same process</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#distributed-crawls">Distributed crawls</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#avoiding-getting-banned">Avoiding getting banned</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#dynamic-creation-of-item-classes">Dynamic Creation of Item Classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#increase-concurrency">Increase concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#reduce-log-level">Reduce log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-cookies">Disable cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-retries">Disable retries</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#reduce-download-timeout">Reduce download timeout</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#disable-redirects">Disable redirects</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#enable-crawling-of-ajax-crawlable-pages">Enable crawling of &#8220;Ajax Crawlable Pages&#8221;</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#caveats-with-inspecting-the-live-browser-dom">Caveats with inspecting the live browser DOM</a></li>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#useful-firefox-add-ons-for-scraping">Useful Firefox add-ons for scraping</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#getting-links-to-follow">Getting links to follow</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#extracting-the-data">Extracting the data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#common-causes-of-memory-leaks">Common causes of memory leaks</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#debugging-memory-leaks-with-trackref">Debugging memory leaks with <tt class="docutils literal"><span class="pre">trackref</span></tt></a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#debugging-memory-leaks-with-guppy">Debugging memory leaks with Guppy</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="images.html">Downloading Item Images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="images.html#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#enabling-your-images-pipeline">Enabling your Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#images-storage">Images Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#additional-features">Additional features</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#module-scrapy.contrib.pipeline.images">Implementing your custom Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#design-goals">Design goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#how-it-works">How it works</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#throttling-algorithm">Throttling algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#job-directory">Job directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#how-to-use-it">How to use it</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#keeping-persistent-state-between-batches">Keeping persistent state between batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#persistence-gotchas">Persistence gotchas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#using-djangoitem">Using DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#djangoitem-caveats">DjangoItem caveats</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#django-settings-set-up">Django settings set up</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#components">Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#data-flow">Data flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#event-driven-networking">Event-driven networking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#activating-a-downloader-middleware">Activating a downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#writing-your-own-downloader-middleware">Writing your own downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#built-in-downloader-middleware-reference">Built-in downloader middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#activating-a-spider-middleware">Activating a spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#writing-your-own-spider-middleware">Writing your own spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#built-in-spider-middleware-reference">Built-in spider middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#extension-settings">Extension settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#loading-activating-extensions">Loading &amp; activating extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#available-enabled-and-disabled-extensions">Available, enabled and disabled extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#disabling-an-extension">Disabling an extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#writing-your-own-extension">Writing your own extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#built-in-extensions-reference">Built-in extensions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.settings">Settings API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.signalmanager">Signals API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#stats-collector-api">Stats Collector API</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#populating-the-settings">Populating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-settings-reference">Built-in settings reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="signals.html#deferred-signal-handlers">Deferred signal handlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="signals.html#module-scrapy.signals">Built-in signals reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exceptions.html#built-in-exceptions-reference">Built-in Exceptions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#using-item-exporters">Using Item Exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#serialization-of-item-fields">Serialization of item fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#built-in-item-exporters-reference">Built-in Item Exporters reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-01-17">0.22.0 (released 2014-01-17)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id2">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id3">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id4">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id5">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id6">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id7">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id8">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id11">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id14">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id15">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">Experimental features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental/index.html#add-commands-using-external-libraries">Add commands using external libraries</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index-2.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index-2.html">Docs</a> &raquo;</li>
      
    <li>Settings</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/scrapy/scrapy/blob/0.22/docs/topics/settings.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="settings">
<span id="topics-settings"></span><h1>Settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h1>
<p>The Scrapy settings allows you to customize the behaviour of all Scrapy
components, including the core, extensions, pipelines and spiders themselves.</p>
<p>The infrastructure of the settings provides a global namespace of key-value mappings
that the code can use to pull configuration values from. The settings can be
populated through different mechanisms, which are described below.</p>
<p>The settings are also the mechanism for selecting the currently active Scrapy
project (in case you have many).</p>
<p>For a list of available built-in settings see: <a class="reference internal" href="#topics-settings-ref"><em>Built-in settings reference</em></a>.</p>
<div class="section" id="designating-the-settings">
<h2>Designating the settings<a class="headerlink" href="#designating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>When you use Scrapy, you have to tell it which settings you&#8217;re using. You can
do this by using an environment variable, <tt class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></tt>.</p>
<p>The value of <tt class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></tt> should be in Python path syntax, e.g.
<tt class="docutils literal"><span class="pre">myproject.settings</span></tt>. Note that the settings module should be on the
Python <a class="reference external" href="http://docs.python.org/2/tutorial/modules.html#the-module-search-path">import search path</a>.</p>
</div>
<div class="section" id="populating-the-settings">
<h2>Populating the settings<a class="headerlink" href="#populating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>Settings can be populated using different mechanisms, each of which having a
different precedence. Here is the list of them in decreasing order of
precedence:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Global overrides (most precedence)</li>
<li>Project settings module</li>
<li>Default settings per-command</li>
<li>Default global settings (less precedence)</li>
</ol>
</div></blockquote>
<p>These mechanisms are described in more detail below.</p>
<div class="section" id="global-overrides">
<h3>1. Global overrides<a class="headerlink" href="#global-overrides" title="Permalink to this headline">¶</a></h3>
<p>Global overrides are the ones that take most precedence, and are usually
populated by command-line options. You can also override one (or more) settings
from command line using the <tt class="docutils literal"><span class="pre">-s</span></tt> (or <tt class="docutils literal"><span class="pre">--set</span></tt>) command line option.</p>
<p>For more information see the <a class="reference internal" href="api.html#scrapy.settings.Settings.overrides" title="scrapy.settings.Settings.overrides"><tt class="xref py py-attr docutils literal"><span class="pre">overrides</span></tt></a>
Settings attribute.</p>
<p>Example:</p>
<div class="highlight-sh"><div class="highlight"><pre>scrapy crawl myspider -s <span class="nv">LOG_FILE</span><span class="o">=</span>scrapy.log
</pre></div>
</div>
</div>
<div class="section" id="project-settings-module">
<h3>2. Project settings module<a class="headerlink" href="#project-settings-module" title="Permalink to this headline">¶</a></h3>
<p>The project settings module is the standard configuration file for your Scrapy
project.  It&#8217;s where most of your custom settings will be populated. For
example:: <tt class="docutils literal"><span class="pre">myproject.settings</span></tt>.</p>
</div>
<div class="section" id="default-settings-per-command">
<h3>3. Default settings per-command<a class="headerlink" href="#default-settings-per-command" title="Permalink to this headline">¶</a></h3>
<p>Each <a class="reference internal" href="commands.html"><em>Scrapy tool</em></a> command can have its own default
settings, which override the global default settings. Those custom command
settings are specified in the <tt class="docutils literal"><span class="pre">default_settings</span></tt> attribute of the command
class.</p>
</div>
<div class="section" id="default-global-settings">
<h3>4. Default global settings<a class="headerlink" href="#default-global-settings" title="Permalink to this headline">¶</a></h3>
<p>The global defaults are located in the <tt class="docutils literal"><span class="pre">scrapy.settings.default_settings</span></tt>
module and documented in the <a class="reference internal" href="#topics-settings-ref"><em>Built-in settings reference</em></a> section.</p>
</div>
</div>
<div class="section" id="how-to-access-settings">
<h2>How to access settings<a class="headerlink" href="#how-to-access-settings" title="Permalink to this headline">¶</a></h2>
<p>Settings can be accessed through the <a class="reference internal" href="api.html#scrapy.crawler.Crawler.settings" title="scrapy.crawler.Crawler.settings"><tt class="xref py py-attr docutils literal"><span class="pre">scrapy.crawler.Crawler.settings</span></tt></a>
attribute of the Crawler that is passed to <tt class="docutils literal"><span class="pre">from_crawler</span></tt> method in
extensions and middlewares:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">MyExtension</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">settings</span>
        <span class="k">if</span> <span class="n">settings</span><span class="p">[</span><span class="s">&#39;LOG_ENABLED&#39;</span><span class="p">]:</span>
            <span class="k">print</span> <span class="s">&quot;log is enabled!&quot;</span>
</pre></div>
</div>
<p>In other words, settings can be accessed like a dict, but it&#8217;s usually preferred
to extract the setting in the format you need it to avoid type errors. In order
to do that you&#8217;ll have to use one of the methods provided the
<a class="reference internal" href="api.html#scrapy.settings.Settings" title="scrapy.settings.Settings"><tt class="xref py py-class docutils literal"><span class="pre">Settings</span></tt></a> API.</p>
</div>
<div class="section" id="rationale-for-setting-names">
<h2>Rationale for setting names<a class="headerlink" href="#rationale-for-setting-names" title="Permalink to this headline">¶</a></h2>
<p>Setting names are usually prefixed with the component that they configure. For
example, proper setting names for a fictional robots.txt extension would be
<tt class="docutils literal"><span class="pre">ROBOTSTXT_ENABLED</span></tt>, <tt class="docutils literal"><span class="pre">ROBOTSTXT_OBEY</span></tt>, <tt class="docutils literal"><span class="pre">ROBOTSTXT_CACHEDIR</span></tt>, etc.</p>
</div>
<div class="section" id="built-in-settings-reference">
<span id="topics-settings-ref"></span><h2>Built-in settings reference<a class="headerlink" href="#built-in-settings-reference" title="Permalink to this headline">¶</a></h2>
<p>Here&#8217;s a list of all available Scrapy settings, in alphabetical order, along
with their default values and the scope where they apply.</p>
<p>The scope, where available, shows where the setting is being used, if it&#8217;s tied
to any particular component. In that case the module of that component will be
shown, typically an extension, middleware or pipeline. It also means that the
component must be enabled in order for the setting to have any effect.</p>
<div class="section" id="aws-access-key-id">
<span id="std:setting-AWS_ACCESS_KEY_ID"></span><h3>AWS_ACCESS_KEY_ID<a class="headerlink" href="#aws-access-key-id" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">None</span></tt></p>
<p>The AWS access key used by code that requires access to <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><em>S3 feed storage backend</em></a>.</p>
</div>
<div class="section" id="aws-secret-access-key">
<span id="std:setting-AWS_SECRET_ACCESS_KEY"></span><h3>AWS_SECRET_ACCESS_KEY<a class="headerlink" href="#aws-secret-access-key" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">None</span></tt></p>
<p>The AWS secret key used by code that requires access to <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><em>S3 feed storage backend</em></a>.</p>
</div>
<div class="section" id="bot-name">
<span id="std:setting-BOT_NAME"></span><h3>BOT_NAME<a class="headerlink" href="#bot-name" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'scrapybot'</span></tt></p>
<p>The name of the bot implemented by this Scrapy project (also known as the
project name). This will be used to construct the User-Agent by default, and
also for logging.</p>
<p>It&#8217;s automatically populated with your project name when you create your
project with the <a class="reference internal" href="commands.html#std:command-startproject"><tt class="xref std std-command docutils literal"><span class="pre">startproject</span></tt></a> command.</p>
</div>
<div class="section" id="concurrent-items">
<span id="std:setting-CONCURRENT_ITEMS"></span><h3>CONCURRENT_ITEMS<a class="headerlink" href="#concurrent-items" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">100</span></tt></p>
<p>Maximum number of concurrent items (per response) to process in parallel in the
Item Processor (also known as the <a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><em>Item Pipeline</em></a>).</p>
</div>
<div class="section" id="concurrent-requests">
<span id="std:setting-CONCURRENT_REQUESTS"></span><h3>CONCURRENT_REQUESTS<a class="headerlink" href="#concurrent-requests" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">16</span></tt></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed by the Scrapy downloader.</p>
</div>
<div class="section" id="concurrent-requests-per-domain">
<span id="std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"></span><h3>CONCURRENT_REQUESTS_PER_DOMAIN<a class="headerlink" href="#concurrent-requests-per-domain" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">8</span></tt></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed to any single domain.</p>
</div>
<div class="section" id="concurrent-requests-per-ip">
<span id="std:setting-CONCURRENT_REQUESTS_PER_IP"></span><h3>CONCURRENT_REQUESTS_PER_IP<a class="headerlink" href="#concurrent-requests-per-ip" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed to any single IP. If non-zero, the
<a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></tt></a> setting is ignored, and this one is
used instead. In other words, concurrency limits will be applied per IP, not
per domain.</p>
<p>This setting also affects <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></tt></a>:
if <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></tt></a> is non-zero, download delay is
enforced per IP, not per domain.</p>
</div>
<div class="section" id="default-item-class">
<span id="std:setting-DEFAULT_ITEM_CLASS"></span><h3>DEFAULT_ITEM_CLASS<a class="headerlink" href="#default-item-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'scrapy.item.Item'</span></tt></p>
<p>The default class that will be used for instantiating items in the <a class="reference internal" href="shell.html#topics-shell"><em>the
Scrapy shell</em></a>.</p>
</div>
<div class="section" id="default-request-headers">
<span id="std:setting-DEFAULT_REQUEST_HEADERS"></span><h3>DEFAULT_REQUEST_HEADERS<a class="headerlink" href="#default-request-headers" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;Accept&#39;</span><span class="p">:</span> <span class="s">&#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;</span><span class="p">,</span>
    <span class="s">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s">&#39;en&#39;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The default headers used for Scrapy HTTP Requests. They&#8217;re populated in the
<a class="reference internal" href="downloader-middleware.html#scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware" title="scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">DefaultHeadersMiddleware</span></tt></a>.</p>
</div>
<div class="section" id="depth-limit">
<span id="std:setting-DEPTH_LIMIT"></span><h3>DEPTH_LIMIT<a class="headerlink" href="#depth-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>The maximum depth that will be allowed to crawl for any site. If zero, no limit
will be imposed.</p>
</div>
<div class="section" id="depth-priority">
<span id="std:setting-DEPTH_PRIORITY"></span><h3>DEPTH_PRIORITY<a class="headerlink" href="#depth-priority" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>An integer that is used to adjust the request priority based on its depth.</p>
<p>If zero, no priority adjustment is made from depth.</p>
</div>
<div class="section" id="depth-stats">
<span id="std:setting-DEPTH_STATS"></span><h3>DEPTH_STATS<a class="headerlink" href="#depth-stats" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Whether to collect maximum depth stats.</p>
</div>
<div class="section" id="depth-stats-verbose">
<span id="std:setting-DEPTH_STATS_VERBOSE"></span><h3>DEPTH_STATS_VERBOSE<a class="headerlink" href="#depth-stats-verbose" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Whether to collect verbose depth stats. If this is enabled, the number of
requests for each depth is collected in the stats.</p>
</div>
<div class="section" id="dnscache-enabled">
<span id="std:setting-DNSCACHE_ENABLED"></span><h3>DNSCACHE_ENABLED<a class="headerlink" href="#dnscache-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Whether to enable DNS in-memory cache.</p>
</div>
<div class="section" id="downloader-debug">
<span id="std:setting-DOWNLOADER_DEBUG"></span><h3>DOWNLOADER_DEBUG<a class="headerlink" href="#downloader-debug" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Whether to enable the Downloader debugging mode.</p>
</div>
<div class="section" id="downloader-middlewares">
<span id="std:setting-DOWNLOADER_MIDDLEWARES"></span><h3>DOWNLOADER_MIDDLEWARES<a class="headerlink" href="#downloader-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the downloader middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><em>Activating a downloader middleware</em></a>.</p>
</div>
<div class="section" id="downloader-middlewares-base">
<span id="std:setting-DOWNLOADER_MIDDLEWARES_BASE"></span><h3>DOWNLOADER_MIDDLEWARES_BASE<a class="headerlink" href="#downloader-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.robotstxt.RobotsTxtMiddleware&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.downloadtimeout.DownloadTimeoutMiddleware&#39;</span><span class="p">:</span> <span class="mi">350</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware&#39;</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.retry.RetryMiddleware&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware&#39;</span><span class="p">:</span> <span class="mi">550</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware&#39;</span><span class="p">:</span> <span class="mi">580</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.httpcompression.HttpCompressionMiddleware&#39;</span><span class="p">:</span> <span class="mi">590</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware&#39;</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.cookies.CookiesMiddleware&#39;</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware&#39;</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.chunked.ChunkedTransferMiddleware&#39;</span><span class="p">:</span> <span class="mi">830</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.stats.DownloaderStats&#39;</span><span class="p">:</span> <span class="mi">850</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware&#39;</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the downloader middlewares enabled by default in Scrapy. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOADER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></tt></a> instead.  For more info see
<a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><em>Activating a downloader middleware</em></a>.</p>
</div>
<div class="section" id="downloader-stats">
<span id="std:setting-DOWNLOADER_STATS"></span><h3>DOWNLOADER_STATS<a class="headerlink" href="#downloader-stats" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Whether to enable downloader stats collection.</p>
</div>
<div class="section" id="download-delay">
<span id="std:setting-DOWNLOAD_DELAY"></span><h3>DOWNLOAD_DELAY<a class="headerlink" href="#download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>The amount of time (in secs) that the downloader should wait before downloading
consecutive pages from the same website. This can be used to throttle the
crawling speed to avoid hitting servers too hard. Decimal numbers are
supported.  Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mf">0.25</span>    <span class="c"># 250 ms of delay</span>
</pre></div>
</div>
<p>This setting is also affected by the <a class="reference internal" href="#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><tt class="xref std std-setting docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></tt></a>
setting (which is enabled by default). By default, Scrapy doesn&#8217;t wait a fixed
amount of time between requests, but uses a random interval between 0.5 and 1.5
* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></tt></a>.</p>
<p>When <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><tt class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></tt></a> is non-zero, delays are enforced
per ip address instead of per domain.</p>
<p>You can also change this setting per spider by setting <tt class="docutils literal"><span class="pre">download_delay</span></tt>
spider attribute.</p>
</div>
<div class="section" id="download-handlers">
<span id="std:setting-DOWNLOAD_HANDLERS"></span><h3>DOWNLOAD_HANDLERS<a class="headerlink" href="#download-handlers" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the request downloader handlers enabled in your project.
See <cite>DOWNLOAD_HANDLERS_BASE</cite> for example format.</p>
</div>
<div class="section" id="download-handlers-base">
<span id="std:setting-DOWNLOAD_HANDLERS_BASE"></span><h3>DOWNLOAD_HANDLERS_BASE<a class="headerlink" href="#download-handlers-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;file&#39;</span><span class="p">:</span> <span class="s">&#39;scrapy.core.downloader.handlers.file.FileDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s">&#39;http&#39;</span><span class="p">:</span> <span class="s">&#39;scrapy.core.downloader.handlers.http.HttpDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s">&#39;https&#39;</span><span class="p">:</span> <span class="s">&#39;scrapy.core.downloader.handlers.http.HttpDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s">&#39;s3&#39;</span><span class="p">:</span> <span class="s">&#39;scrapy.core.downloader.handlers.s3.S3DownloadHandler&#39;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the request download handlers enabled by default in Scrapy.
You should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></tt></a> instead.</p>
</div>
<div class="section" id="download-timeout">
<span id="std:setting-DOWNLOAD_TIMEOUT"></span><h3>DOWNLOAD_TIMEOUT<a class="headerlink" href="#download-timeout" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">180</span></tt></p>
<p>The amount of time (in secs) that the downloader will wait before timing out.</p>
</div>
<div class="section" id="dupefilter-class">
<span id="std:setting-DUPEFILTER_CLASS"></span><h3>DUPEFILTER_CLASS<a class="headerlink" href="#dupefilter-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'scrapy.dupefilter.RFPDupeFilter'</span></tt></p>
<p>The class used to detect and filter duplicate requests.</p>
<p>The default (<tt class="docutils literal"><span class="pre">RFPDupeFilter</span></tt>) filters based on request fingerprint using
the <tt class="docutils literal"><span class="pre">scrapy.utils.request.request_fingerprint</span></tt> function.</p>
</div>
<div class="section" id="editor">
<span id="std:setting-jDITOR"></span><h3>EDITOR<a class="headerlink" href="#editor" title="Permalink to this headline">¶</a></h3>
<p>Default: <cite>depends on the environment</cite></p>
<p>The editor to use for editing spiders with the <a class="reference internal" href="commands.html#std:command-edit"><tt class="xref std std-command docutils literal"><span class="pre">edit</span></tt></a> command. It
defaults to the <tt class="docutils literal"><span class="pre">EDITOR</span></tt> environment variable, if set. Otherwise, it defaults
to <tt class="docutils literal"><span class="pre">vi</span></tt> (on Unix systems) or the IDLE editor (on Windows).</p>
</div>
<div class="section" id="extensions">
<span id="std:setting-EXTENSIONS"></span><h3>EXTENSIONS<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h3>
<p>Default:: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the extensions enabled in your project, and their orders.</p>
</div>
<div class="section" id="extensions-base">
<span id="std:setting-EXTENSIONS_BASE"></span><h3>EXTENSIONS_BASE<a class="headerlink" href="#extensions-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;scrapy.contrib.corestats.CoreStats&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.webservice.WebService&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.telnet.TelnetConsole&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.memusage.MemoryUsage&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.memdebug.MemoryDebugger&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.closespider.CloseSpider&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.feedexport.FeedExporter&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.logstats.LogStats&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spiderstate.SpiderState&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.throttle.AutoThrottle&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The list of available extensions. Keep in mind that some of them need to
be enabled through a setting. By default, this setting contains all stable
built-in extensions.</p>
<p>For more information See the <a class="reference internal" href="extensions.html#topics-extensions"><em>extensions user guide</em></a>
and the <a class="reference internal" href="extensions.html#topics-extensions-ref"><em>list of available extensions</em></a>.</p>
</div>
<div class="section" id="item-pipelines">
<span id="std:setting-ITEM_PIPELINES"></span><h3>ITEM_PIPELINES<a class="headerlink" href="#item-pipelines" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the item pipelines to use, and their orders. The dict is
empty by default order values are arbitrary but it&#8217;s customary to define them
in the 0-1000 range.</p>
<p>Lists are supported in <a class="reference internal" href="#std:setting-ITEM_PIPELINES"><tt class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></tt></a> for backwards compatibility,
but they are deprecated.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;mybot.pipeline.validate.ValidateMyItem&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s">&#39;mybot.pipeline.validate.StoreMyItem&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="item-pipelines-base">
<span id="std:setting-ITEM_PIPELINES_BASE"></span><h3>ITEM_PIPELINES_BASE<a class="headerlink" href="#item-pipelines-base" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the pipelines enabled by default in Scrapy. You should never
modify this setting in your project, modify <a class="reference internal" href="#std:setting-ITEM_PIPELINES"><tt class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></tt></a> instead.</p>
</div>
<div class="section" id="log-enabled">
<span id="std:setting-LOG_ENABLED"></span><h3>LOG_ENABLED<a class="headerlink" href="#log-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Whether to enable logging.</p>
</div>
<div class="section" id="log-encoding">
<span id="std:setting-LOG_ENCODING"></span><h3>LOG_ENCODING<a class="headerlink" href="#log-encoding" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'utf-8'</span></tt></p>
<p>The encoding to use for logging.</p>
</div>
<div class="section" id="log-file">
<span id="std:setting-LOG_FILE"></span><h3>LOG_FILE<a class="headerlink" href="#log-file" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">None</span></tt></p>
<p>File name to use for logging output. If None, standard error will be used.</p>
</div>
<div class="section" id="log-level">
<span id="std:setting-LOG_LEVEL"></span><h3>LOG_LEVEL<a class="headerlink" href="#log-level" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'DEBUG'</span></tt></p>
<p>Minimum level to log. Available levels are: CRITICAL, ERROR, WARNING,
INFO, DEBUG. For more info see <a class="reference internal" href="logging.html#topics-logging"><em>Logging</em></a>.</p>
</div>
<div class="section" id="log-stdout">
<span id="std:setting-LOG_STDOUT"></span><h3>LOG_STDOUT<a class="headerlink" href="#log-stdout" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>If <tt class="docutils literal"><span class="pre">True</span></tt>, all standard output (and error) of your process will be redirected
to the log. For example if you <tt class="docutils literal"><span class="pre">print</span> <span class="pre">'hello'</span></tt> it will appear in the Scrapy
log.</p>
</div>
<div class="section" id="memdebug-enabled">
<span id="std:setting-MEMDEBUG_ENABLED"></span><h3>MEMDEBUG_ENABLED<a class="headerlink" href="#memdebug-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Whether to enable memory debugging.</p>
</div>
<div class="section" id="memdebug-notify">
<span id="std:setting-MEMDEBUG_NOTIFY"></span><h3>MEMDEBUG_NOTIFY<a class="headerlink" href="#memdebug-notify" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">[]</span></tt></p>
<p>When memory debugging is enabled a memory report will be sent to the specified
addresses if this setting is not empty, otherwise the report will be written to
the log.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">MEMDEBUG_NOTIFY</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user@example.com&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="memusage-enabled">
<span id="std:setting-MEMUSAGE_ENABLED"></span><h3>MEMUSAGE_ENABLED<a class="headerlink" href="#memusage-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></tt></p>
<p>Whether to enable the memory usage extension that will shutdown the Scrapy
process when it exceeds a memory limit, and also notify by email when that
happened.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><em>Memory usage extension</em></a>.</p>
</div>
<div class="section" id="memusage-limit-mb">
<span id="std:setting-MEMUSAGE_LIMIT_MB"></span><h3>MEMUSAGE_LIMIT_MB<a class="headerlink" href="#memusage-limit-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></tt></p>
<p>The maximum amount of memory to allow (in megabytes) before shutting down
Scrapy  (if MEMUSAGE_ENABLED is True). If zero, no check will be performed.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><em>Memory usage extension</em></a>.</p>
</div>
<div class="section" id="memusage-notify-mail">
<span id="std:setting-MEMUSAGE_NOTIFY_MAIL"></span><h3>MEMUSAGE_NOTIFY_MAIL<a class="headerlink" href="#memusage-notify-mail" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></tt></p>
<p>A list of emails to notify if the memory limit has been reached.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">MEMUSAGE_NOTIFY_MAIL</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user@example.com&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><em>Memory usage extension</em></a>.</p>
</div>
<div class="section" id="memusage-report">
<span id="std:setting-MEMUSAGE_REPORT"></span><h3>MEMUSAGE_REPORT<a class="headerlink" href="#memusage-report" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></tt></p>
<p>Whether to send a memory usage report after each spider has been closed.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><em>Memory usage extension</em></a>.</p>
</div>
<div class="section" id="memusage-warning-mb">
<span id="std:setting-MEMUSAGE_WARNING_MB"></span><h3>MEMUSAGE_WARNING_MB<a class="headerlink" href="#memusage-warning-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></tt></p>
<p>The maximum amount of memory to allow (in megabytes) before sending a warning
email notifying about it. If zero, no warning will be produced.</p>
</div>
<div class="section" id="newspider-module">
<span id="std:setting-NEWSPIDER_MODULE"></span><h3>NEWSPIDER_MODULE<a class="headerlink" href="#newspider-module" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">''</span></tt></p>
<p>Module where to create new spiders using the <a class="reference internal" href="commands.html#std:command-genspider"><tt class="xref std std-command docutils literal"><span class="pre">genspider</span></tt></a> command.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s">&#39;mybot.spiders_dev&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="randomize-download-delay">
<span id="std:setting-RANDOMIZE_DOWNLOAD_DELAY"></span><h3>RANDOMIZE_DOWNLOAD_DELAY<a class="headerlink" href="#randomize-download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>If enabled, Scrapy will wait a random amount of time (between 0.5 and 1.5
* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></tt></a>) while fetching requests from the same
website.</p>
<p>This randomization decreases the chance of the crawler being detected (and
subsequently blocked) by sites which analyze requests looking for statistically
significant similarities in the time between their requests.</p>
<p>The randomization policy is the same used by <a class="reference external" href="http://www.gnu.org/software/wget/manual/wget.html">wget</a> <tt class="docutils literal"><span class="pre">--random-wait</span></tt> option.</p>
<p>If <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></tt></a> is zero (default) this option has no effect.</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h3>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">20</span></tt></p>
<p>Defines the maximum times a request can be redirected. After this maximum the
request&#8217;s response is returned as is. We used Firefox default value for the
same task.</p>
</div>
<div class="section" id="redirect-max-metarefresh-delay">
<span id="std:setting-REDIRECT_MAX_METAREFRESH_DELAY"></span><h3>REDIRECT_MAX_METAREFRESH_DELAY<a class="headerlink" href="#redirect-max-metarefresh-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">100</span></tt></p>
<p>Some sites use meta-refresh for redirecting to a session expired page, so we
restrict automatic redirection to a maximum delay (in seconds)</p>
</div>
<div class="section" id="redirect-priority-adjust">
<span id="std:setting-REDIRECT_PRIORITY_ADJUST"></span><h3>REDIRECT_PRIORITY_ADJUST<a class="headerlink" href="#redirect-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">+2</span></tt></p>
<p>Adjust redirect request priority relative to original request.
A negative priority adjust means more priority.</p>
</div>
<div class="section" id="robotstxt-obey">
<span id="std:setting-ROBOTSTXT_OBEY"></span><h3>ROBOTSTXT_OBEY<a class="headerlink" href="#robotstxt-obey" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">scrapy.contrib.downloadermiddleware.robotstxt</span></tt></p>
<p>If enabled, Scrapy will respect robots.txt policies. For more information see
<a class="reference internal" href="downloader-middleware.html#topics-dlmw-robots"><em>RobotsTxtMiddleware</em></a></p>
</div>
<div class="section" id="scheduler">
<span id="std:setting-SCHEDULER"></span><h3>SCHEDULER<a class="headerlink" href="#scheduler" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'scrapy.core.scheduler.Scheduler'</span></tt></p>
<p>The scheduler to use for crawling.</p>
</div>
<div class="section" id="spider-contracts">
<span id="std:setting-SPIDER_CONTRACTS"></span><h3>SPIDER_CONTRACTS<a class="headerlink" href="#spider-contracts" title="Permalink to this headline">¶</a></h3>
<p>Default:: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the scrapy contracts enabled in your project, used for
testing spiders. For more info see <a class="reference internal" href="contracts.html#topics-contracts"><em>Spiders Contracts</em></a>.</p>
</div>
<div class="section" id="spider-contracts-base">
<span id="std:setting-SPIDER_CONTRACTS_BASE"></span><h3>SPIDER_CONTRACTS_BASE<a class="headerlink" href="#spider-contracts-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;scrapy.contracts.default.UrlContract&#39;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contracts.default.ReturnsContract&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contracts.default.ScrapesContract&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the scrapy contracts enabled by default in Scrapy. You should
never modify this setting in your project, modify <a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_CONTRACTS</span></tt></a>
instead. For more info see <a class="reference internal" href="contracts.html#topics-contracts"><em>Spiders Contracts</em></a>.</p>
</div>
<div class="section" id="spider-middlewares">
<span id="std:setting-SPIDER_MIDDLEWARES"></span><h3>SPIDER_MIDDLEWARES<a class="headerlink" href="#spider-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <tt class="docutils literal"><span class="pre">{}</span></tt></p>
<p>A dict containing the spider middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><em>Activating a spider middleware</em></a>.</p>
</div>
<div class="section" id="spider-middlewares-base">
<span id="std:setting-SPIDER_MIDDLEWARES_BASE"></span><h3>SPIDER_MIDDLEWARES_BASE<a class="headerlink" href="#spider-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.referer.RefererMiddleware&#39;</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.spidermiddleware.depth.DepthMiddleware&#39;</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the spider middlewares enabled by default in Scrapy. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-SPIDER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></tt></a> instead. For more info see
<a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><em>Activating a spider middleware</em></a>.</p>
</div>
<div class="section" id="spider-modules">
<span id="std:setting-SPIDER_MODULES"></span><h3>SPIDER_MODULES<a class="headerlink" href="#spider-modules" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">[]</span></tt></p>
<p>A list of modules where Scrapy will look for spiders.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;mybot.spiders_prod&#39;</span><span class="p">,</span> <span class="s">&#39;mybot.spiders_dev&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="stats-class">
<span id="std:setting-STATS_CLASS"></span><h3>STATS_CLASS<a class="headerlink" href="#stats-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">'scrapy.statscol.MemoryStatsCollector'</span></tt></p>
<p>The class to use for collecting stats, who must implement the
<a class="reference internal" href="api.html#topics-api-stats"><em>Stats Collector API</em></a>.</p>
</div>
<div class="section" id="stats-dump">
<span id="std:setting-STATS_DUMP"></span><h3>STATS_DUMP<a class="headerlink" href="#stats-dump" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Dump the <a class="reference internal" href="stats.html#topics-stats"><em>Scrapy stats</em></a> (to the Scrapy log) once the spider
finishes.</p>
<p>For more info see: <a class="reference internal" href="stats.html#topics-stats"><em>Stats Collection</em></a>.</p>
</div>
<div class="section" id="statsmailer-rcpts">
<span id="std:setting-STATSMAILER_RCPTS"></span><h3>STATSMAILER_RCPTS<a class="headerlink" href="#statsmailer-rcpts" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">[]</span></tt> (empty list)</p>
<p>Send Scrapy stats after spiders finish scraping. See
<tt class="xref py py-class docutils literal"><span class="pre">StatsMailer</span></tt> for more info.</p>
</div>
<div class="section" id="telnetconsole-enabled">
<span id="std:setting-TELNETCONSOLE_ENABLED"></span><h3>TELNETCONSOLE_ENABLED<a class="headerlink" href="#telnetconsole-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>A boolean which specifies if the <a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><em>telnet console</em></a>
will be enabled (provided its extension is also enabled).</p>
</div>
<div class="section" id="telnetconsole-port">
<span id="std:setting-TELNETCONSOLE_PORT"></span><h3>TELNETCONSOLE_PORT<a class="headerlink" href="#telnetconsole-port" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">[6023,</span> <span class="pre">6073]</span></tt></p>
<p>The port range to use for the telnet console. If set to <tt class="docutils literal"><span class="pre">None</span></tt> or <tt class="docutils literal"><span class="pre">0</span></tt>, a
dynamically assigned port is used. For more info see
<a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><em>Telnet Console</em></a>.</p>
</div>
<div class="section" id="templates-dir">
<span id="std:setting-TEMPLATES_DIR"></span><h3>TEMPLATES_DIR<a class="headerlink" href="#templates-dir" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">templates</span></tt> dir inside scrapy module</p>
<p>The directory where to look for templates when creating new projects with
<a class="reference internal" href="commands.html#std:command-startproject"><tt class="xref std std-command docutils literal"><span class="pre">startproject</span></tt></a> command.</p>
</div>
<div class="section" id="urllength-limit">
<span id="std:setting-URLLENGTH_LIMIT"></span><h3>URLLENGTH_LIMIT<a class="headerlink" href="#urllength-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">2083</span></tt></p>
<p>Scope: <tt class="docutils literal"><span class="pre">contrib.spidermiddleware.urllength</span></tt></p>
<p>The maximum URL length to allow for crawled URLs. For more information about
the default value for this setting see: <a class="reference external" href="http://www.boutell.com/newfaq/misc/urllength.html">http://www.boutell.com/newfaq/misc/urllength.html</a></p>
</div>
<div class="section" id="user-agent">
<span id="std:setting-USER_AGENT"></span><h3>USER_AGENT<a class="headerlink" href="#user-agent" title="Permalink to this headline">¶</a></h3>
<p>Default: <tt class="docutils literal"><span class="pre">&quot;Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)&quot;</span></tt></p>
<p>The default User-Agent to use when crawling, unless overridden.</p>
</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="signals.html" class="btn btn-neutral float-right" title="Signals">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="request-response.html" class="btn btn-neutral" title="Requests and Responses"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008-2013, Scrapy developers.
      Last updated on Apr 17, 2014.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org/">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="http://doc.scrapy.org/en/master/">master</a></dd>
        
          <dd><a href="../index.html">latest</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.20/">0.20</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.18/">0.18</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.16/">0.16</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.14/">0.14</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.12/">0.12</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.9/">0.9</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.8/">0.8</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.7/">0.7</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="https://media.readthedocs.org/pdf/scrapy/latest/scrapy.pdf">PDF</a></dd>
        
          <dd><a href="https://media.readthedocs.org/htmlzip/scrapy/latest/scrapy.zip">HTML</a></dd>
        
          <dd><a href="https://media.readthedocs.org/epub/scrapy/latest/scrapy.epub">Epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="http://readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="http://readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org/">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.22.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>

<!-- Mirrored from doc.scrapy.org/en/latest/topics/settings.html by HTTrack Website Copier/3.x [XR&CO'2013], Wed, 23 Apr 2014 03:06:41 GMT -->
</html>