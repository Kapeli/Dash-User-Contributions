
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Training a Simple Neural Network, with tensorflow/datasets Data Loading ‚Äî JAX  documentation</title>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" rel="stylesheet" type="text/css">
<link href="../_static/plot_directive.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/style.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<link href="../_static/favicon.png" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="Custom_derivative_rules_for_Python_code.html" rel="next" title="Custom derivative rules for JAX-transformable Python functions"/>
<link href="vmapped_log_probs.html" rel="prev" title="Autobatching log-densities example"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../_static/jax_logo_250px.png"/>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search the docs ..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../installation.html">
   Installing JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="quickstart.html">
   JAX Quickstart
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="thinking_in_jax.html">
   How to Think in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Common_Gotchas_in_JAX.html">
   üî™ JAX - The Sharp Bits üî™
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jax-101/index.html">
   Tutorial: JAX 101
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/01-jax-basics.html">
     JAX As Accelerated NumPy
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/02-jitting.html">
     Just In Time Compilation with JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/03-vectorization.html">
     Automatic Vectorization in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/04-advanced-autodiff.html">
     Advanced Automatic Differentiation in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/05-random-numbers.html">
     Pseudo Random Numbers in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/05.1-pytrees.html">
     Working with Pytrees
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/06-parallelism.html">
     Parallel Evaluation in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/07-state.html">
     Stateful Computations in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/08-pjit.html">
     Introduction to pjit
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../debugging/index.html">
   Runtime value debugging in JAX
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/print_breakpoint.html">
<code class="docutils literal notranslate">
<span class="pre">
       jax.debug.print
      </span>
</code>
     and
     <code class="docutils literal notranslate">
<span class="pre">
       jax.debug.breakpoint
      </span>
</code>
</a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/checkify_guide.html">
     The
     <code class="docutils literal notranslate">
<span class="pre">
       checkify
      </span>
</code>
     transformation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/flags.html">
     JAX debugging flags
    </a>
</li>
</ul>
</input></li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Reference Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../faq.html">
   JAX Frequently Asked Questions (FAQ)
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../async_dispatch.html">
   Asynchronous dispatch
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../aot.html">
   Ahead-of-time lowering and compilation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../jaxpr.html">
   Understanding Jaxprs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="convolutions.html">
   Convolutions in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../pytrees.html">
   Pytrees
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../type_promotion.html">
   Type promotion semantics
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../errors.html">
   JAX Errors
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../transfer_guard.html">
   Transfer guard
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../glossary.html">
   JAX Glossary of Terms
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../changelog.html">
   Change log
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Advanced JAX Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="autodiff_cookbook.html">
   The Autodiff Cookbook
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="vmapped_log_probs.html">
   Autobatching log-densities example
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   Training a Simple Neural Network, with tensorflow/datasets Data Loading
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Custom_derivative_rules_for_Python_code.html">
   Custom derivative rules for JAX-transformable Python functions
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="How_JAX_primitives_work.html">
   How JAX primitives work
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Writing_custom_interpreters_in_Jax.html">
   Writing custom Jaxpr interpreters in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Neural_Network_and_Data_Loading.html">
   Training a Simple Neural Network, with PyTorch Data Loading
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="xmap_tutorial.html">
   Named axes and easy-to-revise parallelism
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../multi_process.html">
   Using JAX in multi-host and multi-process environments
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Notes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../api_compatibility.html">
   API compatibility
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../deprecation.html">
   Python and NumPy version support policy
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../concurrency.html">
   Concurrency
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../gpu_memory_allocation.html">
   GPU memory allocation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../profiling.html">
   Profiling JAX programs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../device_memory_profiling.html">
   Device Memory Profiling
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../rank_promotion_warning.html">
   Rank promotion warning
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Developer documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../contributing.html">
   Contributing to JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../developer.html">
   Building from source
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../jax_internal_api.html">
   Internal APIs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../autodidax.html">
   Autodidax: JAX core from scratch
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jep/index.html">
   JAX Enhancement Proposals (JEPs)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jep/263-prng.html">
     263: JAX PRNG Design
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/2026-custom-derivatives.html">
     2026: Custom JVP/VJP rules for JAX-transformable functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/4008-custom-vjp-update.html">
     4008: Custom VJP and `nondiff_argnums` update
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/4410-omnistaging.html">
     4410: Omnistaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/9407-type-promotion.html">
     9407: Design of Type Promotion Semantics for JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/9419-jax-versioning.html">
     9419: Jax and Jaxlib versioning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/10657-sequencing-effects.html">
     10657: Sequencing side-effects in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/11830-new-remat-checkpoint.html">
     11830: `jax.remat` / `jax.checkpoint` new implementation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/12049-type-annotations.html">
     12049: Type Annotation Roadmap for JAX
    </a>
</li>
</ul>
</input></li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  API documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jax.html">
   Public API: jax package
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jax.numpy.html">
     jax.numpy package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.scipy.html">
     jax.scipy package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.config.html">
     JAX configuration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.debug.html">
     jax.debug package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.dlpack.html">
     jax.dlpack module
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.distributed.html">
     jax.distributed module
    </a>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.example_libraries.html">
     jax.example_libraries package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.example_libraries.optimizers.html">
       jax.example_libraries.optimizers module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.example_libraries.stax.html">
       jax.example_libraries.stax module
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.experimental.html">
     jax.experimental package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.checkify.html">
       jax.experimental.checkify module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.global_device_array.html">
       jax.experimental.global_device_array module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.host_callback.html">
       jax.experimental.host_callback module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.maps.html">
       jax.experimental.maps module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.pjit.html">
       jax.experimental.pjit module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.sparse.html">
       jax.experimental.sparse module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.jet.html">
       jax.experimental.jet module
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.flatten_util.html">
     jax.flatten_util package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.image.html">
     jax.image package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.lax.html">
     jax.lax package
    </a>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.nn.html">
     jax.nn package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.nn.initializers.html">
       jax.nn.initializers package
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.ops.html">
     jax.ops package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.profiler.html">
     jax.profiler module
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.random.html">
     jax.random package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.stages.html">
     jax.stages package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.tree_util.html">
     jax.tree_util package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.lib.html">
     jax.lib package
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<a class="headerbtn" data-placement="bottom" data-toggle="tooltip" href="https://github.com/google/jax" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
</a>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../_sources/notebooks/neural_network_with_tfds_data.ipynb.txt" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#hyperparameters">
   Hyperparameters
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#auto-batching-predictions">
   Auto-batching predictions
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#utility-and-loss-functions">
   Utility and loss functions
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-loading-with-tensorflow-datasets">
   Data Loading with
   <code class="docutils literal notranslate">
<span class="pre">
     tensorflow/datasets
    </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#training-loop">
   Training Loop
  </a>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Training a Simple Neural Network, with tensorflow/datasets Data Loading</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#hyperparameters">
   Hyperparameters
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#auto-batching-predictions">
   Auto-batching predictions
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#utility-and-loss-functions">
   Utility and loss functions
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-loading-with-tensorflow-datasets">
   Data Loading with
   <code class="docutils literal notranslate">
<span class="pre">
     tensorflow/datasets
    </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#training-loop">
   Training Loop
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><strong>Copyright 2018 The JAX Authors.</strong></p>
<p>Licensed under the Apache License, Version 2.0 (the ‚ÄúLicense‚Äù);</p>
<p>Licensed under the Apache License, Version 2.0 (the ‚ÄúLicense‚Äù);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<p>https://www.apache.org/licenses/LICENSE-2.0</p>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ‚ÄúAS IS‚Äù BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Training a Simple Neural Network, with tensorflow/datasets Data Loading"></a><section class="tex2jax_ignore mathjax_ignore" id="training-a-simple-neural-network-with-tensorflow-datasets-data-loading">
<h1>Training a Simple Neural Network, with tensorflow/datasets Data Loading<a class="headerlink" href="#training-a-simple-neural-network-with-tensorflow-datasets-data-loading" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<p><em>Forked from</em> <code class="docutils literal notranslate"><span class="pre">neural_network_and_data_loading.ipynb</span></code></p>
<p><img alt="JAX" src="https://raw.githubusercontent.com/google/jax/main/images/jax_logo_250px.png"/></p>
<p>Let‚Äôs combine everything we showed in the <a class="reference external" href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">quickstart notebook</a> to train a simple neural network. We will first specify and train a simple MLP on MNIST using JAX for the computation. We will use <code class="docutils literal notranslate"><span class="pre">tensorflow/datasets</span></code> data loading API to load images and labels (because it‚Äôs pretty great, and the world doesn‚Äôt need yet another data loading library :P).</p>
<p>Of course, you can use JAX with any API that is compatible with NumPy to make specifying the model a bit more plug-and-play. Here, just for explanatory purposes, we won‚Äôt use any neural network libraries or special APIs for building our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>
</pre></div>
</div>
</div>
</div>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Hyperparameters"></a><section id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">#</a></h2>
<p>Let‚Äôs get a few bookkeeping items out of the way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A helper function to randomly initialize weights and biases</span>
<span class="c1"># for a dense neural network layer</span>
<span class="k">def</span> <span class="nf">random_layer_params</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">):</span>
  <span class="n">w_key</span><span class="p">,</span> <span class="n">b_key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">w_key</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)),</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">b_key</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,))</span>

<span class="c1"># Initialize all layers for a fully-connected neural network with sizes "sizes"</span>
<span class="k">def</span> <span class="nf">init_network_params</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
  <span class="n">keys</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">))</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">random_layer_params</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">keys</span><span class="p">)]</span>

<span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">784</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">n_targets</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">init_network_params</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Auto-batching predictions"></a><section id="auto-batching-predictions">
<h2>Auto-batching predictions<a class="headerlink" href="#auto-batching-predictions" title="Permalink to this headline">#</a></h2>
<p>Let us first define our prediction function. Note that we‚Äôre defining this for a <em>single</em> image example. We‚Äôre going to use JAX‚Äôs <code class="docutils literal notranslate"><span class="pre">vmap</span></code> function to automatically handle mini-batches, with no performance penalty.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.scipy.special</span> <span class="kn">import</span> <span class="n">logsumexp</span>

<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
  <span class="c1"># per-example predictions</span>
  <span class="n">activations</span> <span class="o">=</span> <span class="n">image</span>
  <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activations</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
  
  <span class="n">final_w</span><span class="p">,</span> <span class="n">final_b</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">final_w</span><span class="p">,</span> <span class="n">activations</span><span class="p">)</span> <span class="o">+</span> <span class="n">final_b</span>
  <span class="k">return</span> <span class="n">logits</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs check that our prediction function only works on single images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This works on single examples</span>
<span class="n">random_flattened_image</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,))</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">random_flattened_image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Doesn't work with a batch</span>
<span class="n">random_flattened_images</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="k">try</span><span class="p">:</span>
  <span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">random_flattened_images</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Invalid shapes!'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Invalid shapes!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let's upgrade it to handle batches using `vmap`</span>

<span class="c1"># Make a batched version of the `predict` function</span>
<span class="n">batched_predict</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="c1"># `batched_predict` has the same call signature as `predict`</span>
<span class="n">batched_preds</span> <span class="o">=</span> <span class="n">batched_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">random_flattened_images</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batched_preds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10, 10)
</pre></div>
</div>
</div>
</div>
<p>At this point, we have all the ingredients we need to define our neural network and train it. We‚Äôve built an auto-batched version of <code class="docutils literal notranslate"><span class="pre">predict</span></code>, which we should be able to use in a loss function. We should be able to use <code class="docutils literal notranslate"><span class="pre">grad</span></code> to take the derivative of the loss with respect to the neural network parameters. Last, we should be able to use <code class="docutils literal notranslate"><span class="pre">jit</span></code> to speed up everything.</p>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Utility and loss functions"></a><section id="utility-and-loss-functions">
<h2>Utility and loss functions<a class="headerlink" href="#utility-and-loss-functions" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
  <span class="sd">"""Create a one-hot encoding of x of size k."""</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">==</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
  
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
  <span class="n">target_class</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">batched_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_class</span> <span class="o">==</span> <span class="n">target_class</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
  <span class="n">preds</span> <span class="o">=</span> <span class="n">batched_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
  <span class="k">return</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds</span> <span class="o">*</span> <span class="n">targets</span><span class="p">)</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">grads</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[(</span><span class="n">w</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">dw</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">db</span><span class="p">)</span>
          <span class="k">for</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="p">(</span><span class="n">dw</span><span class="p">,</span> <span class="n">db</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Data Loading with tensorflow/datasets"></a><section id="data-loading-with-tensorflow-datasets">
<h2>Data Loading with <code class="docutils literal notranslate"><span class="pre">tensorflow/datasets</span></code><a class="headerlink" href="#data-loading-with-tensorflow-datasets" title="Permalink to this headline">#</a></h2>
<p>JAX is laser-focused on program transformations and accelerator-backed NumPy, so we don‚Äôt include data loading or munging in the JAX library. There are already a lot of great data loaders out there, so let‚Äôs just use them instead of reinventing anything. We‚Äôll use the <code class="docutils literal notranslate"><span class="pre">tensorflow/datasets</span></code> data loader.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># Ensure TF does not see GPU and grab all GPU memory.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">([],</span> <span class="n">device_type</span><span class="o">=</span><span class="s1">'GPU'</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">'/tmp/tfds'</span>

<span class="c1"># Fetch full datasets for evaluation</span>
<span class="c1"># tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)</span>
<span class="c1"># You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy</span>
<span class="n">mnist_data</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"mnist"</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnist_data</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">mnist_data</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">mnist_data</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span> <span class="n">mnist_data</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span>
<span class="n">num_labels</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]</span><span class="o">.</span><span class="n">num_classes</span>
<span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">'image'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">num_pixels</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">c</span>

<span class="c1"># Full train set</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">'image'</span><span class="p">],</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">),</span> <span class="n">num_pixels</span><span class="p">))</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

<span class="c1"># Full test set</span>
<span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">'image'</span><span class="p">],</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">),</span> <span class="n">num_pixels</span><span class="p">))</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Train:'</span><span class="p">,</span> <span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Test:'</span><span class="p">,</span> <span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train: (60000, 784) (60000, 10)
Test: (10000, 784) (10000, 10)
</pre></div>
</div>
</div>
</div>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Training Loop"></a><section id="training-loop">
<h2>Training Loop<a class="headerlink" href="#training-loop" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">get_train_batches</span><span class="p">():</span>
  <span class="c1"># as_supervised=True gives us the (image, label) as a tuple instead of a dict</span>
  <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'mnist'</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">)</span>
  <span class="c1"># You can build up an arbitrary tf.data input pipeline</span>
  <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="c1"># tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays</span>
  <span class="k">return</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">get_train_batches</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">num_pixels</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">epoch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

  <span class="n">train_acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
  <span class="n">test_acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Epoch </span><span class="si">{}</span><span class="s2"> in </span><span class="si">{:0.2f}</span><span class="s2"> sec"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_time</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Training set accuracy </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_acc</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Test set accuracy </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0 in 28.30 sec
Training set accuracy 0.8400499820709229
Test set accuracy 0.8469000458717346
Epoch 1 in 14.74 sec
Training set accuracy 0.8743667006492615
Test set accuracy 0.8803000450134277
Epoch 2 in 14.57 sec
Training set accuracy 0.8901500105857849
Test set accuracy 0.8957000374794006
Epoch 3 in 14.36 sec
Training set accuracy 0.8991333246231079
Test set accuracy 0.903700053691864
Epoch 4 in 14.20 sec
Training set accuracy 0.9061833620071411
Test set accuracy 0.9087000489234924
Epoch 5 in 14.89 sec
Training set accuracy 0.9113333225250244
Test set accuracy 0.912600040435791
Epoch 6 in 13.95 sec
Training set accuracy 0.9156833291053772
Test set accuracy 0.9176000356674194
Epoch 7 in 13.32 sec
Training set accuracy 0.9192000031471252
Test set accuracy 0.9214000701904297
Epoch 8 in 13.55 sec
Training set accuracy 0.9222500324249268
Test set accuracy 0.9241000413894653
Epoch 9 in 13.40 sec
Training set accuracy 0.9253666996955872
Test set accuracy 0.9269000291824341
</pre></div>
</div>
</div>
</div>
<p>We‚Äôve now used the whole of the JAX API: <code class="docutils literal notranslate"><span class="pre">grad</span></code> for derivatives, <code class="docutils literal notranslate"><span class="pre">jit</span></code> for speedups and <code class="docutils literal notranslate"><span class="pre">vmap</span></code> for auto-vectorization.
We used NumPy to specify all of our computation, and borrowed the great data loaders from <code class="docutils literal notranslate"><span class="pre">tensorflow/datasets</span></code>, and ran the whole thing on the GPU.</p>
</section>
</section>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="vmapped_log_probs.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Autobatching log-densities example</p>
</div>
</a>
<a class="right-next" href="Custom_derivative_rules_for_Python_code.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Custom derivative rules for JAX-transformable Python functions</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By The JAX authors<br/>
  
      ¬© Copyright 2020, The JAX Authors. NumPy and SciPy documentation are copyright the respective authors..<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>