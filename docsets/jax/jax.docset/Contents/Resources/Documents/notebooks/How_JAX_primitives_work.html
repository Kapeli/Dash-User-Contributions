
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>
<title>How JAX primitives work ‚Äî JAX  documentation</title>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" rel="stylesheet" type="text/css">
<link href="../_static/plot_directive.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/style.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<link href="../_static/favicon.png" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="Writing_custom_interpreters_in_Jax.html" rel="next" title="Writing custom Jaxpr interpreters in JAX"/>
<link href="Custom_derivative_rules_for_Python_code.html" rel="prev" title="Custom derivative rules for JAX-transformable Python functions"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../_static/jax_logo_250px.png"/>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search the docs ..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../installation.html">
   Installing JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="quickstart.html">
   JAX Quickstart
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="thinking_in_jax.html">
   How to Think in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Common_Gotchas_in_JAX.html">
   üî™ JAX - The Sharp Bits üî™
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jax-101/index.html">
   Tutorial: JAX 101
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/01-jax-basics.html">
     JAX As Accelerated NumPy
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/02-jitting.html">
     Just In Time Compilation with JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/03-vectorization.html">
     Automatic Vectorization in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/04-advanced-autodiff.html">
     Advanced Automatic Differentiation in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/05-random-numbers.html">
     Pseudo Random Numbers in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/05.1-pytrees.html">
     Working with Pytrees
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/06-parallelism.html">
     Parallel Evaluation in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/07-state.html">
     Stateful Computations in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax-101/08-pjit.html">
     Introduction to pjit
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../debugging/index.html">
   Runtime value debugging in JAX
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/print_breakpoint.html">
<code class="docutils literal notranslate">
<span class="pre">
       jax.debug.print
      </span>
</code>
     and
     <code class="docutils literal notranslate">
<span class="pre">
       jax.debug.breakpoint
      </span>
</code>
</a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/checkify_guide.html">
     The
     <code class="docutils literal notranslate">
<span class="pre">
       checkify
      </span>
</code>
     transformation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../debugging/flags.html">
     JAX debugging flags
    </a>
</li>
</ul>
</input></li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Reference Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../faq.html">
   JAX Frequently Asked Questions (FAQ)
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../async_dispatch.html">
   Asynchronous dispatch
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../aot.html">
   Ahead-of-time lowering and compilation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../jaxpr.html">
   Understanding Jaxprs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="convolutions.html">
   Convolutions in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../pytrees.html">
   Pytrees
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../type_promotion.html">
   Type promotion semantics
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../errors.html">
   JAX Errors
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../transfer_guard.html">
   Transfer guard
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../glossary.html">
   JAX Glossary of Terms
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../changelog.html">
   Change log
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Advanced JAX Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="autodiff_cookbook.html">
   The Autodiff Cookbook
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="vmapped_log_probs.html">
   Autobatching log-densities example
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="neural_network_with_tfds_data.html">
   Training a Simple Neural Network, with tensorflow/datasets Data Loading
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Custom_derivative_rules_for_Python_code.html">
   Custom derivative rules for JAX-transformable Python functions
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   How JAX primitives work
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Writing_custom_interpreters_in_Jax.html">
   Writing custom Jaxpr interpreters in JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="Neural_Network_and_Data_Loading.html">
   Training a Simple Neural Network, with PyTorch Data Loading
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="xmap_tutorial.html">
   Named axes and easy-to-revise parallelism
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../multi_process.html">
   Using JAX in multi-host and multi-process environments
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Notes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../api_compatibility.html">
   API compatibility
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../deprecation.html">
   Python and NumPy version support policy
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../concurrency.html">
   Concurrency
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../gpu_memory_allocation.html">
   GPU memory allocation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../profiling.html">
   Profiling JAX programs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../device_memory_profiling.html">
   Device Memory Profiling
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../rank_promotion_warning.html">
   Rank promotion warning
  </a>
</li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  Developer documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../contributing.html">
   Contributing to JAX
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../developer.html">
   Building from source
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../jax_internal_api.html">
   Internal APIs
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../autodidax.html">
   Autodidax: JAX core from scratch
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jep/index.html">
   JAX Enhancement Proposals (JEPs)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jep/263-prng.html">
     263: JAX PRNG Design
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/2026-custom-derivatives.html">
     2026: Custom JVP/VJP rules for JAX-transformable functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/4008-custom-vjp-update.html">
     4008: Custom VJP and `nondiff_argnums` update
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/4410-omnistaging.html">
     4410: Omnistaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/9407-type-promotion.html">
     9407: Design of Type Promotion Semantics for JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/9419-jax-versioning.html">
     9419: Jax and Jaxlib versioning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/10657-sequencing-effects.html">
     10657: Sequencing side-effects in JAX
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/11830-new-remat-checkpoint.html">
     11830: `jax.remat` / `jax.checkpoint` new implementation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jep/12049-type-annotations.html">
     12049: Type Annotation Roadmap for JAX
    </a>
</li>
</ul>
</input></li>
</ul>
<p aria-level="2" class="caption" role="heading">
<span class="caption-text">
  API documentation
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../jax.html">
   Public API: jax package
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../jax.numpy.html">
     jax.numpy package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.scipy.html">
     jax.scipy package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.config.html">
     JAX configuration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.debug.html">
     jax.debug package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.dlpack.html">
     jax.dlpack module
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.distributed.html">
     jax.distributed module
    </a>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.example_libraries.html">
     jax.example_libraries package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.example_libraries.optimizers.html">
       jax.example_libraries.optimizers module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.example_libraries.stax.html">
       jax.example_libraries.stax module
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.experimental.html">
     jax.experimental package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.checkify.html">
       jax.experimental.checkify module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.global_device_array.html">
       jax.experimental.global_device_array module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.host_callback.html">
       jax.experimental.host_callback module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.maps.html">
       jax.experimental.maps module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.pjit.html">
       jax.experimental.pjit module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.sparse.html">
       jax.experimental.sparse module
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../jax.experimental.jet.html">
       jax.experimental.jet module
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.flatten_util.html">
     jax.flatten_util package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.image.html">
     jax.image package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.lax.html">
     jax.lax package
    </a>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../jax.nn.html">
     jax.nn package
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../jax.nn.initializers.html">
       jax.nn.initializers package
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.ops.html">
     jax.ops package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.profiler.html">
     jax.profiler module
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.random.html">
     jax.random package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.stages.html">
     jax.stages package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.tree_util.html">
     jax.tree_util package
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../jax.lib.html">
     jax.lib package
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<a class="headerbtn" data-placement="bottom" data-toggle="tooltip" href="https://github.com/google/jax" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
</a>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../_sources/notebooks/How_JAX_primitives_work.ipynb.txt" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#using-existing-primitives">
   Using existing primitives
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#defining-new-jax-primitives">
   Defining new JAX primitives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#primal-evaluation-rules">
     Primal evaluation rules
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit">
     JIT
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#abstract-evaluation-rules">
       Abstract evaluation rules
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#xla-compilation-rules">
       XLA Compilation rules
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#forward-differentiation">
     Forward differentiation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-forward-differentiation">
       JIT of forward differentiation
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#reverse-differentiation">
     Reverse differentiation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#transposition">
       Transposition
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-reverse-differentiation">
       JIT of reverse differentiation
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#batching">
     Batching
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-batching">
       JIT of batching
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>How JAX primitives work</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#using-existing-primitives">
   Using existing primitives
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#defining-new-jax-primitives">
   Defining new JAX primitives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#primal-evaluation-rules">
     Primal evaluation rules
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit">
     JIT
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#abstract-evaluation-rules">
       Abstract evaluation rules
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#xla-compilation-rules">
       XLA Compilation rules
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#forward-differentiation">
     Forward differentiation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-forward-differentiation">
       JIT of forward differentiation
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#reverse-differentiation">
     Reverse differentiation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#transposition">
       Transposition
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-reverse-differentiation">
       JIT of reverse differentiation
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#batching">
     Batching
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#jit-of-batching">
       JIT of batching
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<a class="dashAnchor" name="//apple_ref/cpp/Section/How JAX primitives work"></a><section class="tex2jax_ignore mathjax_ignore" id="how-jax-primitives-work">
<h1>How JAX primitives work<a class="headerlink" href="#how-jax-primitives-work" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/How_JAX_primitives_work.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<p><em>necula@google.com</em>, October 2019.</p>
<p>JAX implements certain transformations of Python functions, e.g., <code class="docutils literal notranslate"><span class="pre">jit</span></code>, <code class="docutils literal notranslate"><span class="pre">grad</span></code>,
<code class="docutils literal notranslate"><span class="pre">vmap</span></code>, or <code class="docutils literal notranslate"><span class="pre">pmap</span></code>. The Python functions to be transformed must be JAX-traceable,
which means that as the Python function executes
the only operations it applies to the data are either inspections of data
attributes such as shape or type, or special operations called JAX primitives.
In particular, a JAX-traceable function is sometimes invoked by JAX with
abstract arguments. An example of a JAX abstract value is <code class="docutils literal notranslate"><span class="pre">ShapedArray(float32[2,2])</span></code>,
which captures the type and the shape of values, but not the concrete data values.
JAX primitives know how to operate on both concrete data
values and on the JAX abstract values.</p>
<p>The JAX-transformed functions must themselves be JAX-traceable functions,
to ensure that these transformations
can be composed, e.g., <code class="docutils literal notranslate"><span class="pre">jit(jacfwd(grad(f)))</span></code>.</p>
<p>There are pre-defined JAX primitives corresponding to most XLA operations,
e.g., add, matmul, sin, cos, indexing.
JAX comes with an implementation of numpy functions in terms of JAX primitives, which means that Python programs
using JAX‚Äôs implementation of numpy are JAX-traceable and therefore transformable.
Other libraries can be made JAX-traceable by implementing them in terms of JAX primitives.</p>
<p>The set of JAX primitives is extensible. Instead of reimplementing a function in terms of pre-defined JAX primitives,
one can define a new primitive that encapsulates the behavior of the function.</p>
<p><strong>The goal of this document is to explain the interface that a JAX primitive must support in order to allow JAX to perform all its transformations.</strong></p>
<p>Consider that we want to add to JAX support for a multiply-add function with three arguments, defined mathematically
as ‚Äúmultiply_add(x, y, z) = x * y + z‚Äù.
This function operates on 3 identically-shaped tensors of floating point
values and performs the operations pointwise.</p>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Using existing primitives"></a><section id="using-existing-primitives">
<h2>Using existing primitives<a class="headerlink" href="#using-existing-primitives" title="Permalink to this headline">#</a></h2>
<p>The easiest way to define new functions is to write them in terms of JAX primitives, or in terms of other
functions that are themselves written using JAX primitives, e.g., those
defined in the <code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">api</span>

<span class="k">def</span> <span class="nf">multiply_add_lax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
  <span class="sd">"""Implementation of multiply-add using the jax.lax primitives."""</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">lax</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">square_add_lax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">"""A square-add function using the newly defined multiply-add."""</span>
  <span class="k">return</span> <span class="n">multiply_add_lax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"square_add_lax = "</span><span class="p">,</span> <span class="n">square_add_lax</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
<span class="c1"># Differentiate w.r.t. the first argument</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"grad(square_add_lax) = "</span><span class="p">,</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_lax</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>square_add_lax =  14.0
grad(square_add_lax) =  4.0
</pre></div>
</div>
</div>
</div>
<p>In order to understand how JAX is internally using the primitives,
we add some helpers for tracing function calls.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions (execute this cell)</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="n">_indentation</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">def</span> <span class="nf">_trace</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Print a message at current indentation."""</span>
    <span class="k">if</span> <span class="n">msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"  "</span> <span class="o">*</span> <span class="n">_indentation</span> <span class="o">+</span> <span class="n">msg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_trace_indent</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Print a message and then indent the rest."""</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_trace</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_indentation</span>

<span class="k">def</span> <span class="nf">_trace_unindent</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Unindent then print a message."""</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="n">_indentation</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">_trace</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="sd">"""A decorator for functions to trace arguments and results."""</span>

  <span class="k">def</span> <span class="nf">trace_func</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>  <span class="c1"># pylint: disable=missing-docstring</span>
    <span class="k">def</span> <span class="nf">pp</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="sd">"""Print certain values more succinctly"""</span>
        <span class="n">vtype</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="s2">"jax._src.lib.xla_bridge._JaxComputationBuilder"</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">"&lt;JaxComputationBuilder&gt;"</span>
        <span class="k">elif</span> <span class="s2">"jaxlib.xla_extension.XlaOp"</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">"&lt;XlaOp at 0x</span><span class="si">{:x}</span><span class="s2">&gt;"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">elif</span> <span class="p">(</span><span class="s2">"partial_eval.JaxprTracer"</span> <span class="ow">in</span> <span class="n">vtype</span> <span class="ow">or</span>
              <span class="s2">"batching.BatchTracer"</span> <span class="ow">in</span> <span class="n">vtype</span> <span class="ow">or</span>
              <span class="s2">"ad.JVPTracer"</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">"Traced&lt;</span><span class="si">{}</span><span class="s2">&gt;"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">"(</span><span class="si">{}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pp_values</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">pp_values</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">", "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">pp</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">])</span>
    
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">func_wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
      <span class="n">_trace_indent</span><span class="p">(</span><span class="s2">"call </span><span class="si">{}</span><span class="s2">(</span><span class="si">{}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pp_values</span><span class="p">(</span><span class="n">args</span><span class="p">)))</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
      <span class="n">_trace_unindent</span><span class="p">(</span><span class="s2">"|&lt;- </span><span class="si">{}</span><span class="s2"> = </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pp</span><span class="p">(</span><span class="n">res</span><span class="p">)))</span>
      <span class="k">return</span> <span class="n">res</span>

    <span class="k">return</span> <span class="n">func_wrapper</span>

  <span class="k">return</span> <span class="n">trace_func</span>

<span class="k">class</span> <span class="nc">expectNotImplementedError</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">"""Context manager to check for NotImplementedError."""</span>
  <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
  <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">tb</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="nb">type</span> <span class="ow">is</span> <span class="ne">NotImplementedError</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Found expected exception:"</span><span class="p">)</span>
      <span class="n">traceback</span><span class="o">.</span><span class="n">print_exc</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
      <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="nb">type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># No exception</span>
      <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">"Expected NotImplementedError"</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<p>Instead of using <code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> primitives directly, we can use other functions
that are already written in terms of those primitives, such as those in <code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_numpy"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">"square_add_numpy"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">square_add_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">multiply_add_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Normal evaluation:"</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">"square_add_numpy = "</span><span class="p">,</span> <span class="n">square_add_numpy</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Gradient evaluation:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"grad(square_add_numpy) = "</span><span class="p">,</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_numpy</span><span class="p">)(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal evaluation:
call square_add_numpy(2.0, 10.0)
  call multiply_add_numpy(2.0, 2.0, 10.0)
  |&lt;- multiply_add_numpy = 14.0
|&lt;- square_add_numpy = 14.0
square_add_numpy =  14.0

Gradient evaluation:
call square_add_numpy(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
  call multiply_add_numpy(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
  |&lt;- multiply_add_numpy = Traced&lt;ConcreteArray(14.0, dtype=float32, weak_type=True)&gt;
|&lt;- square_add_numpy = Traced&lt;ConcreteArray(14.0, dtype=float32, weak_type=True)&gt;
grad(square_add_numpy) =  4.0
</pre></div>
</div>
</div>
</div>
<p>Notice that in the process of computing <code class="docutils literal notranslate"><span class="pre">grad</span></code>, JAX invokes <code class="docutils literal notranslate"><span class="pre">square_add_numpy</span></code> and
<code class="docutils literal notranslate"><span class="pre">multiply_add_numpy</span></code> with special arguments <code class="docutils literal notranslate"><span class="pre">ConcreteArray(...)</span></code> (described further
below in this colab).
It is important to remember that a JAX-traceable function must be able to
operate not only on concrete arguments but also on special abstract arguments
that JAX may use to abstract the function execution.</p>
<p>The JAX traceability property is satisfied as long as the function is written
in terms of JAX primitives.</p>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Defining new JAX primitives"></a><section id="defining-new-jax-primitives">
<h2>Defining new JAX primitives<a class="headerlink" href="#defining-new-jax-primitives" title="Permalink to this headline">#</a></h2>
<p>The right way to add support for multiply-add is in terms of existing
JAX primitives, as shown above. However, in order to demonstrate how JAX
primitives work let us pretend that we want to add a new primitive to
JAX for the multiply-add functionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">core</span>
<span class="n">multiply_add_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Primitive</span><span class="p">(</span><span class="s2">"multiply_add"</span><span class="p">)</span>  <span class="c1"># Create the primitive</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_prim"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
  <span class="sd">"""The JAX-traceable way to use the JAX primitive.</span>
<span class="sd">  </span>
<span class="sd">  Note that the traced arguments must be passed as positional arguments</span>
<span class="sd">  to `bind`. </span>
<span class="sd">  """</span>
  <span class="k">return</span> <span class="n">multiply_add_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">"square_add_prim"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">square_add_prim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">"""A square-add function implemented using the new JAX-primitive."""</span>
  <span class="k">return</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we try to call the newly defined functions we get an error, because
we have not yet told JAX anything about the semantics of the new primitive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">square_add_prim</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(2.0, 10.0)
  call multiply_add_prim(2.0, 2.0, 10.0)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/2844449444.py", line 2, in &lt;module&gt;
    square_add_prim(2., 10.)
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/2936509082.py", line 48, in func_wrapper
    res = func(*args)
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/1308506715.py", line 16, in square_add_prim
    return multiply_add_prim(a, a, b)
NotImplementedError: Evaluation rule for 'multiply_add' not implemented
</pre></div>
</div>
</div>
</div>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Primal evaluation rules"></a><section id="primal-evaluation-rules">
<h3>Primal evaluation rules<a class="headerlink" href="#primal-evaluation-rules" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_impl"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_impl</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
  <span class="sd">"""Concrete implementation of the primitive.</span>

<span class="sd">  This function does not need to be JAX traceable.</span>
<span class="sd">  Args:</span>
<span class="sd">    x, y, z: the concrete arguments of the primitive. Will only be called with </span>
<span class="sd">      concrete values.</span>
<span class="sd">  Returns:</span>
<span class="sd">    the concrete result of the primitive.</span>
<span class="sd">  """</span>
  <span class="c1"># Note that we can use the original numpy, which is not JAX traceable</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>

<span class="c1"># Now we register the primal implementation with JAX</span>
<span class="n">multiply_add_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">multiply_add_impl</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.multiply_add_impl(x, y, z)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(2.0, 10.0)
  call multiply_add_prim(2.0, 2.0, 10.0)
    call multiply_add_impl(2.0, 2.0, 10.0)
    |&lt;- multiply_add_impl = 14.0
  |&lt;- multiply_add_prim = 14.0
|&lt;- square_add_prim = 14.0
</pre></div>
</div>
</div>
</div>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/JIT"></a><section id="jit">
<h3>JIT<a class="headerlink" href="#jit" title="Permalink to this headline">#</a></h3>
<p>If we now try to use <code class="docutils literal notranslate"><span class="pre">jit</span></code> we get a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/1813425700.py", line 2, in &lt;module&gt;
    api.jit(square_add_prim)(2., 10.)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 605, in cache_miss
    out_flat = xla.xla_call(
NotImplementedError: Abstract evaluation for 'multiply_add' not implemented
</pre></div>
</div>
</div>
</div>
<section id="abstract-evaluation-rules">
<h4>Abstract evaluation rules<a class="headerlink" href="#abstract-evaluation-rules" title="Permalink to this headline">#</a></h4>
<p>In order to JIT the function, and for other transformations as well,
JAX first evaluates it abstractly using only the
shape and type of the arguments. This abstract evaluation serves multiple
purposes:</p>
<ul class="simple">
<li><p>Gets the sequence of JAX primitives that are used in the computation. This
sequence will be compiled.</p></li>
<li><p>Computes the shape and type of all vectors and operations used in the computation.</p></li>
</ul>
<p>For example, the abstraction of a vector with 3 elements may be <code class="docutils literal notranslate"><span class="pre">ShapedArray(float32[3])</span></code>, or <code class="docutils literal notranslate"><span class="pre">ConcreteArray([1.,</span> <span class="pre">2.,</span> <span class="pre">3.])</span></code>.
In the latter case, JAX uses the actual concrete value wrapped as an abstract value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">abstract_arrays</span>
<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_abstract_eval"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_abstract_eval</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
  <span class="sd">"""Abstract evaluation of the primitive.</span>

<span class="sd">  This function does not need to be JAX traceable. It will be invoked with</span>
<span class="sd">  abstractions of the actual arguments. </span>
<span class="sd">  Args:</span>
<span class="sd">    xs, ys, zs: abstractions of the arguments.</span>
<span class="sd">  Result:</span>
<span class="sd">    a ShapedArray for the result of the primitive.</span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span>
  <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">zs</span><span class="o">.</span><span class="n">shape</span>
  <span class="k">return</span> <span class="n">abstract_arrays</span><span class="o">.</span><span class="n">ShapedArray</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Now we register the abstract evaluation with JAX</span>
<span class="n">multiply_add_p</span><span class="o">.</span><span class="n">def_abstract_eval</span><span class="p">(</span><span class="n">multiply_add_abstract_eval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.multiply_add_abstract_eval(xs, ys, zs)&gt;
</pre></div>
</div>
</div>
</div>
<p>If we re-attempt to JIT, we see how the abstract evaluation proceeds, but
we get another error, about missing the actual XLA compilation rule:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
    call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
    |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/Users/bosr/.pyenv/versions/3.10.5/lib/python3.10/runpy.py", line 191, in _run_module_as_main
    msg = "%s: %s" % (sys.executable, exc)
  File "/Users/bosr/.pyenv/versions/3.10.5/lib/python3.10/runpy.py", line 75, in _run_code
    fname = mod_spec.origin
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/ipykernel_launcher.py", line 12, in &lt;module&gt;
    if sys.path[0] == "":
jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform cpu

The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/1813425700.py", line 2, in &lt;module&gt;
    api.jit(square_add_prim)(2., 10.)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 605, in cache_miss
    out_flat = xla.xla_call(
NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform cpu
</pre></div>
</div>
</div>
</div>
</section>
<section id="xla-compilation-rules">
<h4>XLA Compilation rules<a class="headerlink" href="#xla-compilation-rules" title="Permalink to this headline">#</a></h4>
<p>JAX compilation works by compiling each primitive into a graph of XLA operations.</p>
<p>This is the biggest hurdle to adding new functionality to JAX, because the
set of XLA operations is limited, and JAX already has pre-defined primitives
for most of them. However, XLA includes a <code class="docutils literal notranslate"><span class="pre">CustomCall</span></code> operation that can be used to encapsulate arbitrary functionality defined using C++.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax._src.lib</span> <span class="kn">import</span> <span class="n">xla_client</span>
<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_xla_translation"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_xla_translation</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">avals_in</span><span class="p">,</span> <span class="n">avals_out</span><span class="p">,</span> <span class="n">xc</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">zc</span><span class="p">):</span>
  <span class="sd">"""The compilation to XLA of the primitive.</span>

<span class="sd">  Given an XlaBuilder and XlaOps for each argument, return the XlaOp for the</span>
<span class="sd">  result of the function.</span>

<span class="sd">  Does not need to be a JAX-traceable function.</span>
<span class="sd">  """</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">xla_client</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">xla_client</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="n">yc</span><span class="p">),</span> <span class="n">zc</span><span class="p">)]</span>

<span class="c1"># Now we register the XLA compilation rule with JAX</span>
<span class="c1"># TODO: for GPU? and TPU?</span>
<span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">xla</span>
<span class="n">xla</span><span class="o">.</span><span class="n">register_translation</span><span class="p">(</span><span class="n">multiply_add_p</span><span class="p">,</span> <span class="n">multiply_add_xla_translation</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we succeed to JIT. Notice below that JAX first evaluates the function
abstractly, which triggers the <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> function, and
then compiles the set of primitives it has encountered, including <code class="docutils literal notranslate"><span class="pre">multiply_add</span></code>.
At this point JAX invokes <code class="docutils literal notranslate"><span class="pre">multiply_add_xla_translation</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
    call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
    |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fb900b0&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], &lt;XlaOp at 0x12f13fc30&gt;, &lt;XlaOp at 0x107a17af0&gt;, &lt;XlaOp at 0x12fb90170&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12f06dbf0&gt;]
</pre></div>
</div>
</div>
</div>
<p>Below is another use of <code class="docutils literal notranslate"><span class="pre">jit</span></code> where we compile only
with respect to the first argument. Notice how the second argument to <code class="docutils literal notranslate"><span class="pre">square_add_prim</span></code> is concrete, which leads
in the third argument to <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> being
<code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>. We see that <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> may be used with
both <code class="docutils literal notranslate"><span class="pre">ShapedArray</span></code> and <code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> 
               <span class="n">static_argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, 10.0)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, 10.0)
    call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
    |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fb91930&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], &lt;XlaOp at 0x12fb91b30&gt;, &lt;XlaOp at 0x12fb91af0&gt;, &lt;XlaOp at 0x12fb91b70&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fb91830&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Forward differentiation"></a><section id="forward-differentiation">
<h3>Forward differentiation<a class="headerlink" href="#forward-differentiation" title="Permalink to this headline">#</a></h3>
<p>JAX implements forward differentiation in the form of
a Jacobian-vector product (see the <a class="reference external" href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#Jacobian-Matrix-and-Matrix-Jacobian-products">JAX autodiff cookbook</a>).</p>
<p>If we attempt now to compute the <code class="docutils literal notranslate"><span class="pre">jvp</span></code> function we get an
error because we have not yet told JAX how to differentiate
the <code class="docutils literal notranslate"><span class="pre">multiply_add</span></code> primitive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The second argument `(2., 10.)` are the argument values</span>
<span class="c1"># where we evaluate the Jacobian, and the third `(1., 1.)`</span>
<span class="c1"># are the values of the tangents for the arguments.</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(10.0, dtype=float32, weak_type=True)&gt;)
  call multiply_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(10.0, dtype=float32, weak_type=True)&gt;)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/800067577.py", line 5, in &lt;module&gt;
    api.jvp(square_add_prim, (2., 10.), (1., 1.))
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 2370, in jvp
    return _jvp(lu.wrap_init(fun), primals, tangents, has_aux=has_aux)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 2399, in _jvp
    out_primals, out_tangents = ad.jvp(flat_fun).call_wrapped(ps_flat, ts_flat)
NotImplementedError: Differentiation rule for 'multiply_add' not implemented
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">ad</span>


<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_value_and_jvp"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_value_and_jvp</span><span class="p">(</span><span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">):</span>
  <span class="sd">"""Evaluates the primal output and the tangents (Jacobian-vector product).</span>

<span class="sd">  Given values of the arguments and perturbation of the arguments (tangents), </span>
<span class="sd">  compute the output of the primitive and the perturbation of the output.</span>

<span class="sd">  This method must be JAX-traceable. JAX may invoke it with abstract values </span>
<span class="sd">  for the arguments and tangents.</span>

<span class="sd">  Args:</span>
<span class="sd">    arg_values: a tuple of arguments</span>
<span class="sd">    arg_tangents: a tuple with the tangents of the arguments. The tuple has </span>
<span class="sd">      the same length as the arg_values. Some of the tangents may also be the </span>
<span class="sd">      special value ad.Zero to specify a zero tangent.</span>
<span class="sd">  Returns:</span>
<span class="sd">     a pair of the primal output and the tangent.</span>
<span class="sd">  """</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">arg_values</span>
  <span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">zt</span> <span class="o">=</span> <span class="n">arg_tangents</span>
  <span class="n">_trace</span><span class="p">(</span><span class="s2">"Primal evaluation:"</span><span class="p">)</span>
  <span class="c1"># Now we have a JAX-traceable computation of the output. </span>
  <span class="c1"># Normally, we can use the ma primtive itself to compute the primal output. </span>
  <span class="n">primal_out</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
  
  <span class="n">_trace</span><span class="p">(</span><span class="s2">"Tangent evaluation:"</span><span class="p">)</span>
  <span class="c1"># We must use a JAX-traceable way to compute the tangent. It turns out that </span>
  <span class="c1"># the output tangent can be computed as (xt * y + x * yt + zt),</span>
  <span class="c1"># which we can implement in a JAX-traceable way using the same "multiply_add_prim" primitive.</span>
  
  <span class="c1"># We do need to deal specially with Zero. Here we just turn it into a </span>
  <span class="c1"># proper tensor of 0s (of the same shape as 'x'). </span>
  <span class="c1"># An alternative would be to check for Zero and perform algebraic </span>
  <span class="c1"># simplification of the output tangent computation.</span>
  <span class="k">def</span> <span class="nf">make_zero</span><span class="p">(</span><span class="n">tan</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">tan</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">tan</span>  
  
  <span class="n">output_tangent</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">make_zero</span><span class="p">(</span><span class="n">xt</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">make_zero</span><span class="p">(</span><span class="n">yt</span><span class="p">),</span> <span class="n">make_zero</span><span class="p">(</span><span class="n">zt</span><span class="p">)))</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">primal_out</span><span class="p">,</span> <span class="n">output_tangent</span><span class="p">)</span>

<span class="c1"># Register the forward differentiation rule with JAX </span>
<span class="n">ad</span><span class="o">.</span><span class="n">primitive_jvps</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_value_and_jvp</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tangent is: xt*y + x*yt + zt = 1.*2. + 2.*1. + 1. = 5.</span>
<span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(10.0, dtype=float32, weak_type=True)&gt;)
  call multiply_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(10.0, dtype=float32, weak_type=True)&gt;)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (1.0, 1.0, 1.0))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, 1.0, 1.0)
        call multiply_add_impl(2.0, 1.0, 1.0)
        |&lt;- multiply_add_impl = 3.0
      |&lt;- multiply_add_prim = 3.0
      call multiply_add_prim(1.0, 2.0, 3.0)
        call multiply_add_impl(1.0, 2.0, 3.0)
        |&lt;- multiply_add_impl = 5.0
      |&lt;- multiply_add_prim = 5.0
    |&lt;- multiply_add_value_and_jvp = (14.0, 5.0)
  |&lt;- multiply_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;
|&lt;- square_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>TO EXPLAIN:</p>
<ul class="simple">
<li><p>Why is JAX using ConcreteArray in square_add_prim? There is no abstract evaluation going on here.</p></li>
<li><p>Not sure how to explain that multiply_add_prim is invoked with ConcreteValue, yet
we do not call the multiply_add_abstract_eval.</p></li>
<li><p>I think it would be useful to show the jaxpr here</p></li>
</ul>
<section id="jit-of-forward-differentiation">
<h4>JIT of forward differentiation<a class="headerlink" href="#jit-of-forward-differentiation" title="Permalink to this headline">#</a></h4>
<p>We can apply JIT to the forward differentiation function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">:</span> 
                   <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">))(</span>
         <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;)
    call multiply_add_value_and_jvp((Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;), (Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;))
      Primal evaluation:
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
      Tangent evaluation:
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[]))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
    |&lt;- multiply_add_value_and_jvp = (Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fba0c70&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], &lt;XlaOp at 0x12fb696f0&gt;, &lt;XlaOp at 0x12fba0db0&gt;, &lt;XlaOp at 0x12fba0df0&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fba0c30&gt;]
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fba1170&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[])], [ShapedArray(float32[])], &lt;XlaOp at 0x12fba12f0&gt;, &lt;XlaOp at 0x12fba12b0&gt;, &lt;XlaOp at 0x12fba1330&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fba1130&gt;]
</pre></div>
</div>
</div>
</div>
<p>Notice that first we evaluate <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> abstractly, which in turn
evaluates abstractly both the primal and the tangent evaluation (a total of
3 invocations of the <code class="docutils literal notranslate"><span class="pre">ma</span></code> primitive). Then we compile the 3 occurrences
of the primitive.</p>
</section>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Reverse differentiation"></a><section id="reverse-differentiation">
<h3>Reverse differentiation<a class="headerlink" href="#reverse-differentiation" title="Permalink to this headline">#</a></h3>
<p>If we attempt now to use reverse differentiation we
see that JAX starts by using the <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> to
compute the forward differentiation for abstract values, but then runs
into a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>.</p>
<p>When computing the reverse differentiation JAX first does abstract evaluation
of the forward differentiation code <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> to obtain a
trace of primitives that compute the output tangent.
Observe that JAX performs this abstract evaluation with concrete values
for the differentiation point, and abstract values for the tangents.
Observe also that JAX uses the special abstract tangent value <code class="docutils literal notranslate"><span class="pre">Zero</span></code> for
the tangent corresponding to the 3rd argument of <code class="docutils literal notranslate"><span class="pre">ma</span></code>. This reflects the
fact that we do not differentiate w.r.t. the 2nd argument to <code class="docutils literal notranslate"><span class="pre">square_add_prim</span></code>,
which flows to the 3rd argument to <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code>.</p>
<p>Observe also that during the abstract evaluation of the tangent we pass the
value 0.0 as the tangent for the 3rd argument. This is due to the use
of the <code class="docutils literal notranslate"><span class="pre">make_zero</span></code> function in the definition of <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is reverse differentiation w.r.t. the first argument of square_add_prim</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
  call multiply_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Zero(ShapedArray(float32[], weak_type=True))))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, 0.0)
        call multiply_add_abstract_eval(ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[], weak_type=True), ConcreteArray(0.0, dtype=float32, weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, 2.0, Traced&lt;ShapedArray(float32[])&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[]))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
    |&lt;- multiply_add_value_and_jvp = (14.0, Traced&lt;ShapedArray(float32[])&gt;)
  |&lt;- multiply_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;
|&lt;- square_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/interpreters/ad.py", line 277, in get_primitive_transpose
    return primitive_transposes[p]
KeyError: multiply_add

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/bosr/.pyenv/versions/3.10.5/lib/python3.10/runpy.py", line 191, in _run_module_as_main
    msg = "%s: %s" % (sys.executable, exc)
  File "/Users/bosr/.pyenv/versions/3.10.5/lib/python3.10/runpy.py", line 75, in _run_code
    fname = mod_spec.origin
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/ipykernel_launcher.py", line 12, in &lt;module&gt;
    if sys.path[0] == "":
jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented

The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/339076514.py", line 3, in &lt;module&gt;
    api.grad(square_add_prim)(2., 10.)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 1073, in grad_f
    _, g = value_and_grad_f(*args, **kwargs)
NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented
</pre></div>
</div>
</div>
</div>
<p>The above error is because there is a missing piece for JAX to be able
to use the forward differentiation code to compute reverse differentiation.</p>
<section id="transposition">
<h4>Transposition<a class="headerlink" href="#transposition" title="Permalink to this headline">#</a></h4>
<p>As explained above, when computing reverse differentiation JAX obtains
a trace of primitives that compute the tangent using forward differentiation.
Then, <strong>JAX interprets this trace abstractly backwards</strong> and for each
primitive it applies a <strong>transposition</strong> rule.</p>
<p>To understand what is going on, consider for now a simpler example of the function ‚Äúf(x, y) = x * y + y‚Äù. Assume we need to differentiate at the point <code class="docutils literal notranslate"><span class="pre">(2.,</span> <span class="pre">4.)</span></code>. JAX will produce the following JVP tangent calculation of <code class="docutils literal notranslate"><span class="pre">ft</span></code> from the tangents of the input <code class="docutils literal notranslate"><span class="pre">xt</span></code> and <code class="docutils literal notranslate"><span class="pre">yt</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="n">a</span> <span class="o">=</span> <span class="n">xt</span> <span class="o">*</span> <span class="mf">4.</span>
   <span class="n">b</span> <span class="o">=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">yt</span>
   <span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
   <span class="n">ft</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">yt</span>
</pre></div>
</div>
<p>By construction, the tangent calculation is always linear in the input tangents.
The only non-linear operator that may arise in the tangent calculation is multiplication,
but then one of the operands is constant.</p>
<p>JAX will produce the reverse differentiation computation by processing the
JVP computation backwards. For each operation in the tangent computation,
it accumulates the cotangents
of the variables used by the operation, using the cotangent of the result
of the operation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="c1"># Initialize cotangents of inputs and intermediate vars</span>
  <span class="n">xct</span> <span class="o">=</span> <span class="n">yct</span> <span class="o">=</span> <span class="n">act</span> <span class="o">=</span> <span class="n">bct</span> <span class="o">=</span> <span class="n">cct</span> <span class="o">=</span> <span class="mf">0.</span>
  <span class="c1"># Initialize cotangent of the output</span>
  <span class="n">fct</span> <span class="o">=</span> <span class="mf">1.</span>
  <span class="c1"># Process "ft = c + yt"</span>
  <span class="n">cct</span> <span class="o">+=</span> <span class="n">fct</span>
  <span class="n">yct</span> <span class="o">+=</span> <span class="n">fct</span>
  <span class="c1"># Process "c = a + b"</span>
  <span class="n">act</span> <span class="o">+=</span> <span class="n">cct</span>
  <span class="n">bct</span> <span class="o">+=</span> <span class="n">cct</span>
  <span class="c1"># Process "b = 2. * yt"</span>
  <span class="n">yct</span> <span class="o">+=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">bct</span>
  <span class="c1"># Process "a = xt * 4."</span>
  <span class="n">xct</span> <span class="o">+=</span> <span class="n">act</span> <span class="o">*</span> <span class="mf">4.</span>
</pre></div>
</div>
<p>One can verify that this computation produces <code class="docutils literal notranslate"><span class="pre">xct</span> <span class="pre">=</span> <span class="pre">4.</span></code> and <code class="docutils literal notranslate"><span class="pre">yct</span> <span class="pre">=</span> <span class="pre">3.</span></code>, which
are the partial derivatives of the function <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p>
<p>JAX knows for each primitive that may appear in a JVP calculation how to transpose it. Conceptually, if the primitive <code class="docutils literal notranslate"><span class="pre">p(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code> is linear in the arguments <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">z</span></code> for a constant value of <code class="docutils literal notranslate"><span class="pre">x</span></code>, e.g., <code class="docutils literal notranslate"><span class="pre">p(x,</span> <span class="pre">y,</span> <span class="pre">z)</span> <span class="pre">=</span> <span class="pre">y*cy</span> <span class="pre">+</span> <span class="pre">z*cz</span></code>, then the transposition of the primitive is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_ct</span><span class="o">*</span><span class="n">cy</span><span class="p">,</span> <span class="n">out_ct</span><span class="o">*</span><span class="n">cz</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">p_transpose</span></code> takes the cotangent of the output of the primitive and a value corresponding to each argument of the primitive. For the linear arguments, the transposition gets an undefined <code class="docutils literal notranslate"><span class="pre">_</span></code> value, and for the other
arguments it gets the actual constants. The transposition returns a cotangent value for each argument of the primitive, with the value <code class="docutils literal notranslate"><span class="pre">None</span></code> returned
for the constant arguments.</p>
<p>In particular,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">add_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">out_ct</span><span class="p">)</span>
 <span class="n">mult_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">out_ct</span><span class="p">)</span>
 <span class="n">mult_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_ct</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_transpose"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_transpose</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
  <span class="sd">"""Evaluates the transpose of a linear primitive.</span>

<span class="sd">  This method is only used when computing the backward gradient following </span>
<span class="sd">  value_and_jvp, and is only needed for primitives that are used in the JVP </span>
<span class="sd">  calculation for some other primitive. We need transposition for multiply_add_prim, </span>
<span class="sd">  because we have used multiply_add_prim in the computation of the output_tangent in </span>
<span class="sd">  multiply_add_value_and_jvp.</span>

<span class="sd">  In our case, multiply_add is not a linear primitive. However, it is used linearly </span>
<span class="sd">  w.r.t. tangents in multiply_add_value_and_jvp:</span>
<span class="sd">       output_tangent(xt, yt, zt) = multiply_add_prim(xt, y, multiply_add_prim(x, yt, zt))</span>
<span class="sd">  </span>
<span class="sd">  Always one of the first two multiplicative arguments is a constant.</span>

<span class="sd">  Args:</span>
<span class="sd">      ct: the cotangent of the output of the primitive.</span>
<span class="sd">      x, y, z: values of the arguments. The arguments that are used linearly</span>
<span class="sd">        get an ad.UndefinedPrimal value. The other arguments get a constant</span>
<span class="sd">        value.</span>
<span class="sd">  Returns:</span>
<span class="sd">      a tuple with the cotangent of the inputs, with the value None</span>
<span class="sd">      corresponding to the constant arguments.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># This use of multiply_add is with a constant "x"</span>
    <span class="k">assert</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">ct_y</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ct</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ct_y</span><span class="p">,</span> <span class="n">ct</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># This use of multiply_add is with a constant "y"</span>
    <span class="k">assert</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ct_x</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">ct_x</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ct</span>
  <span class="k">return</span> <span class="n">res</span>


<span class="n">ad</span><span class="o">.</span><span class="n">primitive_transposes</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_transpose</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can complete the run of the <code class="docutils literal notranslate"><span class="pre">grad</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">4.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
  call multiply_add_prim(Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, Traced&lt;ConcreteArray(2.0, dtype=float32, weak_type=True)&gt;, 10.0)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Zero(ShapedArray(float32[], weak_type=True))))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, 0.0)
        call multiply_add_abstract_eval(ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[], weak_type=True), ConcreteArray(0.0, dtype=float32, weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, 2.0, Traced&lt;ShapedArray(float32[])&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[]))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
    |&lt;- multiply_add_value_and_jvp = (14.0, Traced&lt;ShapedArray(float32[])&gt;)
  |&lt;- multiply_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;
|&lt;- square_add_prim = Traced&lt;ConcreteArray(14.0, dtype=float32)&gt;
call multiply_add_transpose(1.0, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), 2.0, UndefinedPrimal(ShapedArray(float32[])))
  call multiply_add_prim(1.0, 2.0, 0.0)
    call multiply_add_impl(1.0, 2.0, 0.0)
    |&lt;- multiply_add_impl = 2.0
  |&lt;- multiply_add_prim = 2.0
|&lt;- multiply_add_transpose = (2.0, None, 1.0)
call multiply_add_transpose(1.0, 2.0, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), 0.0)
  call multiply_add_prim(2.0, 1.0, 0.0)
    call multiply_add_impl(2.0, 1.0, 0.0)
    |&lt;- multiply_add_impl = 2.0
  |&lt;- multiply_add_prim = 2.0
|&lt;- multiply_add_transpose = (None, 2.0, 1.0)
</pre></div>
</div>
</div>
</div>
<p>Notice the two calls to <code class="docutils literal notranslate"><span class="pre">multiply_add_transpose</span></code>. They correspond to the two
uses of <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> in the computation of the <code class="docutils literal notranslate"><span class="pre">output_tangent</span></code> in <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code>. The first call to transpose corresponds to the
last use of <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code>: <code class="docutils literal notranslate"><span class="pre">multiply_add_prim(xt,</span> <span class="pre">y,</span> <span class="pre">...)</span></code> where <code class="docutils literal notranslate"><span class="pre">y</span></code> is the constant 2.0.</p>
</section>
<section id="jit-of-reverse-differentiation">
<h4>JIT of reverse differentiation<a class="headerlink" href="#jit-of-reverse-differentiation" title="Permalink to this headline">#</a></h4>
<p>Notice that the abstract evaluation of the <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> is using only
abstract values, while in the absence of JIT we used <code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">))(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">4.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
    call multiply_add_value_and_jvp((Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;), (Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Zero(ShapedArray(float32[], weak_type=True))))
      Primal evaluation:
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
      Tangent evaluation:
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
      call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[]))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
    |&lt;- multiply_add_value_and_jvp = (Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;)
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;
call multiply_add_transpose(Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, UndefinedPrimal(ShapedArray(float32[])))
  call multiply_add_prim(Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
    call multiply_add_abstract_eval(ShapedArray(float32[]), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))
    |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
|&lt;- multiply_add_transpose = (Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, None, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
call multiply_add_transpose(Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[], weak_type=True)&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
    call multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[]), ShapedArray(float32[], weak_type=True))
    |&lt;- multiply_add_abstract_eval = ShapedArray(float32[])
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
|&lt;- multiply_add_transpose = (None, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12f06d5b0&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[]), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], &lt;XlaOp at 0x12fbaa130&gt;, &lt;XlaOp at 0x12fbaa270&gt;, &lt;XlaOp at 0x12f06ffb0&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fbabab0&gt;]
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fbaad30&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[]), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], &lt;XlaOp at 0x12fbab6f0&gt;, &lt;XlaOp at 0x12fbab830&gt;, &lt;XlaOp at 0x12fbab570&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fba9c30&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<a class="dashAnchor" name="//apple_ref/cpp/Section/Batching"></a><section id="batching">
<h3>Batching<a class="headerlink" href="#batching" title="Permalink to this headline">#</a></h3>
<p>The batching transformation takes a point-wise computation and turns it
into a computation on vectors. If we try it right now, we get a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The arguments are two vectors instead of two scalars</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
                                               <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/folders/hb/9_9_kvm96fb7w3zrqwzp3kkh0000gn/T/ipykernel_60944/2641678767.py", line 3, in &lt;module&gt;
    api.vmap(square_add_prim, in_axes=0, out_axes=0)(np.array([2., 3.]),
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/Users/bosr/.pyenv/versions/3.10.5/envs/dash/lib/python3.10/site-packages/jax/_src/api.py", line 1665, in vmap_f
    out_flat = batching.batch(
NotImplementedError: Batching rule for 'multiply_add' not implemented
</pre></div>
</div>
</div>
</div>
<p>We need to tell JAX how to evaluate the batched version of the primitive. In this particular case, the <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> already operates pointwise for any dimension of input vectors. So the batched version can use the same <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">batching</span>


<span class="nd">@trace</span><span class="p">(</span><span class="s2">"multiply_add_batch"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_batch</span><span class="p">(</span><span class="n">vector_arg_values</span><span class="p">,</span> <span class="n">batch_axes</span><span class="p">):</span>
  <span class="sd">"""Computes the batched version of the primitive.</span>
<span class="sd">  </span>
<span class="sd">  This must be a JAX-traceable function.</span>
<span class="sd">  </span>
<span class="sd">  Since the multiply_add primitive already operates pointwise on arbitrary</span>
<span class="sd">  dimension tensors, to batch it we can use the primitive itself. This works as</span>
<span class="sd">  long as both the inputs have the same dimensions and are batched along the</span>
<span class="sd">  same axes. The result is batched along the axis that the inputs are batched.</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    vector_arg_values: a tuple of two arguments, each being a tensor of matching</span>
<span class="sd">      shape.</span>
<span class="sd">    batch_axes: the axes that are being batched. See vmap documentation.</span>
<span class="sd">  Returns:</span>
<span class="sd">    a tuple of the result, and the result axis that was batched. </span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">assert</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
  <span class="n">_trace</span><span class="p">(</span><span class="s2">"Using multiply_add to compute the batch:"</span><span class="p">)</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="o">*</span><span class="n">vector_arg_values</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span>
  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">])),</span>
  <span class="p">[</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">29.</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)
    call multiply_add_batch(([2. 3.], [2. 3.], [10. 20.]), (0, 0, 0))
      Using multiply_add to compute the batch:
      call multiply_add_prim([2. 3.], [2. 3.], [10. 20.])
        call multiply_add_impl([2. 3.], [2. 3.], [10. 20.])
        |&lt;- multiply_add_impl = [14. 29.]
      |&lt;- multiply_add_prim = [14. 29.]
    |&lt;- multiply_add_batch = ([14. 29.], 0)
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;
</pre></div>
</div>
</div>
</div>
<section id="jit-of-batching">
<h4>JIT of batching<a class="headerlink" href="#jit-of-batching" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
                    <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">])),</span>
                    <span class="p">[</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">29.</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)
  call multiply_add_prim(Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;, Traced&lt;ShapedArray(float32[])&gt;)
    call multiply_add_batch((Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;), (0, 0, 0))
      Using multiply_add to compute the batch:
      call multiply_add_prim(Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;)
        call multiply_add_abstract_eval(ShapedArray(float32[2]), ShapedArray(float32[2]), ShapedArray(float32[2]))
        |&lt;- multiply_add_abstract_eval = ShapedArray(float32[2])
      |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;
    |&lt;- multiply_add_batch = (Traced&lt;ShapedArray(float32[2])&gt;with&lt;DynamicJaxprTrace(level=0/1)&gt;, 0)
  |&lt;- multiply_add_prim = Traced&lt;ShapedArray(float32[])&gt;
|&lt;- square_add_prim = Traced&lt;ShapedArray(float32[])&gt;
call multiply_add_xla_translation(TranslationContext(builder=&lt;jaxlib.xla_extension.XlaBuilder object at 0x12fbd8430&gt;, platform='cpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=NameStack(stack=())), [ShapedArray(float32[2]), ShapedArray(float32[2]), ShapedArray(float32[2])], [ShapedArray(float32[2])], &lt;XlaOp at 0x12fbd8570&gt;, &lt;XlaOp at 0x12f5efc30&gt;, &lt;XlaOp at 0x12fba3f70&gt;)
|&lt;- multiply_add_xla_translation = [&lt;jaxlib.xla_extension.XlaOp object at 0x12fbd83f0&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="Custom_derivative_rules_for_Python_code.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Custom derivative rules for JAX-transformable Python functions</p>
</div>
</a>
<a class="right-next" href="Writing_custom_interpreters_in_Jax.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Writing custom Jaxpr interpreters in JAX</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By The JAX authors<br/>
  
      ¬© Copyright 2020, The JAX Authors. NumPy and SciPy documentation are copyright the respective authors..<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>