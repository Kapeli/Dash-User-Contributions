
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>RAG — transformers 4.2.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/huggingface.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/code-snippets.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/hidesidebar.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/js/custom.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="reformer.html" rel="next" title="Reformer"/>
<link href="prophetnet.html" rel="prev" title="ProphetNet"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html"> transformers
          

          
          </a>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<div aria-label="main navigation" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using 🤗 Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">🤗 Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragconfig">RagConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragtokenizer">RagTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rag-specific-outputs">Rag specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragretriever">RagRetriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragmodel">RagModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragsequenceforgeneration">RagSequenceForGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ragtokenforgeneration">RagTokenForGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/generation_utils.html">Utilities for Generation</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="top navigation" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">transformers</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a class="icon icon-home" href="../index.html"></a> »</li>
<li>RAG</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/model_doc/rag.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="rag">
<h1>RAG<a class="headerlink" href="#rag" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Retrieval-augmented generation (“RAG”) models combine the powers of pretrained dense retrieval (DPR) and
sequence-to-sequence models. RAG models retrieve documents, pass them to a seq2seq model, then marginalize to generate
outputs. The retriever and seq2seq modules are initialized from pretrained models, and fine-tuned jointly, allowing
both retrieval and generation to adapt to downstream tasks.</p>
<p>It is based on the paper <a class="reference external" href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a> by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela.</p>
<p>The abstract from the paper is the following:</p>
<p><em>Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve
state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely
manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind
task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge
remain open research problems. Pre-trained models with a differentiable access mechanism to explicit nonparametric
memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a
general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained
parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a
pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a
pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages
across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our
models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks,
outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation
tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art
parametric-only seq2seq baseline.</em></p>
</div>
<div class="section" id="ragconfig">
<h2>RagConfig<a class="headerlink" href="#ragconfig" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagConfig"><a name="//apple_ref/cpp/Class/transformers.RagConfig"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">is_encoder_decoder</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">prefix</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">bos_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_start_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">title_sep</span><span class="o">=</span><span class="default_value">' / '</span></em>, <em class="sig-param"><span class="n">doc_sep</span><span class="o">=</span><span class="default_value">' // '</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">max_combined_length</span><span class="o">=</span><span class="default_value">300</span></em>, <em class="sig-param"><span class="n">retrieval_vector_size</span><span class="o">=</span><span class="default_value">768</span></em>, <em class="sig-param"><span class="n">retrieval_batch_size</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">dataset</span><span class="o">=</span><span class="default_value">'wiki_dpr'</span></em>, <em class="sig-param"><span class="n">dataset_split</span><span class="o">=</span><span class="default_value">'train'</span></em>, <em class="sig-param"><span class="n">index_name</span><span class="o">=</span><span class="default_value">'compressed'</span></em>, <em class="sig-param"><span class="n">index_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">passages_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_dummy_dataset</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">reduce_loss</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">label_smoothing</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">do_deduplication</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">exclude_bos_score</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_marginalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">output_retrieved</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/configuration_rag.html#RagConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagConfig" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a> stores the configuration of a <cite>RagModel</cite>. Configuration objects inherit from
<a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> and can be used to control the model outputs. Read the documentation from
<a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>title_sep</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>, defaults to  <code class="docutils literal notranslate"><span class="pre">"</span> <span class="pre">/</span> <span class="pre">"</span></code>) – Separator inserted between the title and the text of the retrieved document when calling
<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>.</p></li>
<li><p><strong>doc_sep</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>, defaults to  <code class="docutils literal notranslate"><span class="pre">"</span> <span class="pre">//</span> <span class="pre">"</span></code>) – Separator inserted between the the text of the retrieved document and the original input when calling
<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 5) – Number of documents to retrieve.</p></li>
<li><p><strong>max_combined_length</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 300) – Max length of contextualized input returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p></li>
<li><p><strong>retrieval_vector_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 768) – Dimensionality of the document embeddings indexed by <a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>.</p></li>
<li><p><strong>retrieval_batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 8) – Retrieval batch size, defined as the number of queries issues concurrently to the faiss index encapsulated
<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>.</p></li>
<li><p><strong>dataset</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">"wiki_dpr"</span></code>) – A dataset identifier of the indexed dataset in HuggingFace Datasets (list all available datasets and ids
using <code class="xref py py-obj docutils literal notranslate"><span class="pre">datasets.list_datasets()</span></code>).</p></li>
<li><p><strong>dataset_split</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">"train"</span></code>) – Which split of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">dataset</span></code> to load.</p></li>
<li><p><strong>index_name</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">"compressed"</span></code>) – The index name of the index associated with the <code class="xref py py-obj docutils literal notranslate"><span class="pre">dataset</span></code>. One can choose between <code class="xref py py-obj docutils literal notranslate"><span class="pre">"legacy"</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">"exact"</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">"compressed"</span></code>.</p></li>
<li><p><strong>index_path</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>) – The path to the serialized faiss index on disk.</p></li>
<li><p><strong>passages_path</strong> – (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <cite>optional</cite>):
A path to text passages compatible with the faiss index. Required if using
<code class="xref py py-class docutils literal notranslate"><span class="pre">LegacyIndex</span></code></p></li>
<li><p><strong>use_dummy_dataset</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) – Whether to load a “dummy” variant of the dataset specified by <code class="xref py py-obj docutils literal notranslate"><span class="pre">dataset</span></code>.</p></li>
<li><p><strong>label_smoothing</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0) – Only relevant if <code class="docutils literal notranslate"><span class="pre">return_loss</span></code> is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>. Controls the <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> parameter value for label
smoothing in the loss calculation. If set to 0, no label smoothing is performed.</p></li>
<li><p><strong>do_marginalize</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the logits are marginalized over all documents by making use of
<code class="docutils literal notranslate"><span class="pre">torch.nn.functional.log_softmax</span></code>.</p></li>
<li><p><strong>reduce_loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Whether or not to reduce the NLL loss using the <code class="docutils literal notranslate"><span class="pre">torch.Tensor.sum</span></code> operation.</p></li>
<li><p><strong>do_deduplication</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – Whether or not to deduplicate the generations from different context documents for a given input. Has to be
set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code> if used while training with distributed backend.</p></li>
<li><p><strong>exclude_bos_score</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Whether or not to disregard the BOS token when computing the loss.</p></li>
<li><p><strong>output_retrieved</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_ids</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> are returned. See returned tensors for more detail.</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – Whether or not the model should return the last key/values attentions (not used by all models).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.RagConfig.from_question_encoder_generator_configs"><a name="//apple_ref/cpp/Method/transformers.RagConfig.from_question_encoder_generator_configs"></a>
<em class="property">classmethod </em><code class="sig-name descname">from_question_encoder_generator_configs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">question_encoder_config</span><span class="p">:</span> <span class="n">transformers.configuration_utils.PretrainedConfig</span></em>, <em class="sig-param"><span class="n">generator_config</span><span class="p">:</span> <span class="n">transformers.configuration_utils.PretrainedConfig</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> → transformers.configuration_utils.PretrainedConfig<a class="reference internal" href="../_modules/transformers/models/rag/configuration_rag.html#RagConfig.from_question_encoder_generator_configs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagConfig.from_question_encoder_generator_configs" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate a <a class="reference internal" href="encoderdecoder.html#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a> (or a derived class) from a pre-trained encoder model
configuration and decoder model configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of a configuration object</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="encoderdecoder.html#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.RagConfig.to_dict"><a name="//apple_ref/cpp/Method/transformers.RagConfig.to_dict"></a>
<code class="sig-name descname">to_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/configuration_rag.html#RagConfig.to_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagConfig.to_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Serializes this instance to a Python dictionary. Override the default
<a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig.to_dict" title="transformers.PretrainedConfig.to_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_dict()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of all the attributes that make up this configuration instance,</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">any]</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="ragtokenizer">
<h2>RagTokenizer<a class="headerlink" href="#ragtokenizer" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagTokenizer"><a name="//apple_ref/cpp/Class/transformers.RagTokenizer"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">question_encoder</span></em>, <em class="sig-param"><span class="n">generator</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/tokenization_rag.html#RagTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagTokenizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="rag-specific-outputs">
<h2>Rag specific outputs<a class="headerlink" href="#rag-specific-outputs" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"><a name="//apple_ref/cpp/Class/transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.models.rag.modeling_rag.</code><code class="sig-name descname">RetrievAugLMMarginOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">logits</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retrieved_doc_embeds</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retrieved_doc_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_encoder_last_hidden_state</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_enc_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_enc_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_last_hidden_state</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_dec_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_dec_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RetrievAugLMMarginOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for retriever augmented marginalized models outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) – Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head. The score is possibly marginalized over all documents for
each vocabulary token.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[torch.FloatTensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – <p>List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span>
<span class="pre">batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used
(see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</p></li>
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Embedded documents retrieved by the retriever. Is used with <code class="docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> to
compute the <code class="docutils literal notranslate"><span class="pre">doc_scores</span></code>.</p></li>
<li><p><strong>retrieved_doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – The indexes of the embedded documents retrieved by the retriever.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p></li>
<li><p><strong>question_encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden states at the output of the last layer of the question encoder pooled output of the
model.</p></li>
<li><p><strong>question_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the question encoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>question_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the question encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
<li><p><strong>generator_enc_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the generator encoder of the model.</p></li>
<li><p><strong>generator_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>generator_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
<li><p><strong>generator_dec_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>generator_dec_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator decoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.models.rag.modeling_rag.RetrievAugLMOutput"><a name="//apple_ref/cpp/Class/transformers.models.rag.modeling_rag.RetrievAugLMOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.models.rag.modeling_rag.</code><code class="sig-name descname">RetrievAugLMOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">logits</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retrieved_doc_embeds</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retrieved_doc_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_encoder_last_hidden_state</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_enc_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_enc_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_last_hidden_state</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_enc_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_dec_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator_dec_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RetrievAugLMOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.models.rag.modeling_rag.RetrievAugLMOutput" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head. The score is possibly marginalized over all documents for
each vocabulary token.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[torch.FloatTensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – <p>List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span>
<span class="pre">batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used
(see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</p></li>
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Embedded documents retrieved by the retriever. Is used with <code class="docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> to
compute the <code class="docutils literal notranslate"><span class="pre">doc_scores</span></code>.</p></li>
<li><p><strong>retrieved_doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – The indexes of the embedded documents retrieved by the retriever.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p></li>
<li><p><strong>question_encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden states at the output of the last layer of the question encoder pooled output of the
model.</p></li>
<li><p><strong>question_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the question encoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>question_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the question encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
<li><p><strong>generator_enc_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the generator encoder of the model.</p></li>
<li><p><strong>generator_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>generator_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
<li><p><strong>generator_dec_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs.</p>
</p></li>
<li><p><strong>generator_dec_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – <p>Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator decoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="ragretriever">
<h2>RagRetriever<a class="headerlink" href="#ragretriever" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagRetriever"><a name="//apple_ref/cpp/Class/transformers.RagRetriever"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagRetriever</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em>, <em class="sig-param"><span class="n">question_encoder_tokenizer</span></em>, <em class="sig-param"><span class="n">generator_tokenizer</span></em>, <em class="sig-param"><span class="n">index</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">init_retrieval</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/retrieval_rag.html#RagRetriever"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagRetriever" title="Permalink to this definition">¶</a></dt>
<dd><p>Retriever used to get documents from vector queries. It retrieves the documents embeddings as well as the documents
contents, and it formats them to be used with a RagModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) – The configuration of the RAG model this Retriever is used with. Contains parameters indicating which
<code class="docutils literal notranslate"><span class="pre">Index</span></code> to build. You can load your own custom dataset with <code class="docutils literal notranslate"><span class="pre">config.index_name="custom"</span></code> or use a
canonical one (default) from the datasets library with <code class="docutils literal notranslate"><span class="pre">config.index_name="wiki_dpr"</span></code> for example.</p></li>
<li><p><strong>question_encoder_tokenizer</strong> (<a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer" title="transformers.PreTrainedTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedTokenizer</span></code></a>) – The tokenizer that was used to tokenize the question. It is used to decode the question and then use the
generator_tokenizer.</p></li>
<li><p><strong>generator_tokenizer</strong> (<a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer" title="transformers.PreTrainedTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedTokenizer</span></code></a>) – The tokenizer used for the generator part of the RagModel.</p></li>
<li><p><strong>index</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Index</span></code>, optional, defaults to the one defined by the configuration) – If specified, use this index instead of the one built using the configuration</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To load the default "wiki_dpr" dataset with 21M passages from wikipedia (index name is 'compressed' or 'exact')</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagRetriever</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'facebook/dpr-ctx_encoder-single-nq-base'</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s2">"wiki_dpr"</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s1">'compressed'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To load your own indexed dataset built with the datasets library. More info on how to build the indexed dataset in examples/rag/use_own_knowledge_dataset.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagRetriever</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># dataset must be a datasets.Datasets object with columns "title", "text" and "embeddings", and it must have a faiss index</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'facebook/dpr-ctx_encoder-single-nq-base'</span><span class="p">,</span> <span class="n">indexed_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To load your own indexed dataset built with the datasets library that was saved on disk. More info in examples/rag/use_own_knowledge_dataset.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagRetriever</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_path</span> <span class="o">=</span> <span class="s2">"path/to/my/dataset"</span>  <span class="c1"># dataset saved via `dataset.save_to_disk(...)`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index_path</span> <span class="o">=</span> <span class="s2">"path/to/my/index.faiss"</span>  <span class="c1"># faiss index saved via `dataset.get_index("embeddings").save(...)`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'facebook/dpr-ctx_encoder-single-nq-base'</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s1">'custom'</span><span class="p">,</span> <span class="n">passages_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">index_path</span><span class="o">=</span><span class="n">index_path</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To load the legacy index built originally for Rag's paper</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagRetriever</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'facebook/dpr-ctx_encoder-single-nq-base'</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s1">'legacy'</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="transformers.RagRetriever.init_retrieval"><a name="//apple_ref/cpp/Method/transformers.RagRetriever.init_retrieval"></a>
<code class="sig-name descname">init_retrieval</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/retrieval_rag.html#RagRetriever.init_retrieval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagRetriever.init_retrieval" title="Permalink to this definition">¶</a></dt>
<dd><p>Retriever initalization function. It loads the index into memory.</p>
</dd></dl>
<dl class="py method">
<dt id="transformers.RagRetriever.postprocess_docs"><a name="//apple_ref/cpp/Method/transformers.RagRetriever.postprocess_docs"></a>
<code class="sig-name descname">postprocess_docs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">docs</span></em>, <em class="sig-param"><span class="n">input_strings</span></em>, <em class="sig-param"><span class="n">prefix</span></em>, <em class="sig-param"><span class="n">n_docs</span></em>, <em class="sig-param"><span class="n">return_tensors</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/retrieval_rag.html#RagRetriever.postprocess_docs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagRetriever.postprocess_docs" title="Permalink to this definition">¶</a></dt>
<dd><p>Postprocessing retrieved <code class="docutils literal notranslate"><span class="pre">docs</span></code> and combining them with <code class="docutils literal notranslate"><span class="pre">input_strings</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>) – Retrieved documents.</p></li>
<li><p><strong>input_strings</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>) – Input strings decoded by <code class="docutils literal notranslate"><span class="pre">preprocess_query</span></code>.</p></li>
<li><p><strong>prefix</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>) – Prefix added at the beginning of each input, typically used with T5-based models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tuple consisting of two elements: contextualized <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> and a compatible
<code class="docutils literal notranslate"><span class="pre">attention_mask</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tensors)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.RagRetriever.retrieve"><a name="//apple_ref/cpp/Method/transformers.RagRetriever.retrieve"></a>
<code class="sig-name descname">retrieve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">question_hidden_states</span><span class="p">:</span> <span class="n">numpy.ndarray</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> → Tuple<span class="p">[</span>numpy.ndarray<span class="p">, </span>List<span class="p">[</span>dict<span class="p">]</span><span class="p">]</span><a class="reference internal" href="../_modules/transformers/models/rag/retrieval_rag.html#RagRetriever.retrieve"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagRetriever.retrieve" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves documents for specified <code class="docutils literal notranslate"><span class="pre">question_hidden_states</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">vector_size)</span></code>) – A batch of query vectors to retrieve with.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The number of docs retrieved per query.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A tuple with the following objects:</p>
<ul class="simple">
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_docs,</span> <span class="pre">dim)</span></code>) – The retrieval
embeddings of the retrieved docs per query.</p></li>
<li><p><strong>doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_docs)</span></code>) – The ids of the documents in the
index</p></li>
<li><p><strong>doc_dicts</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[dict]</span></code>): The <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code> examples per query.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[np.ndarray,</span> <span class="pre">np.ndarray,</span> <span class="pre">List[dict]]</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="ragmodel">
<h2>RagModel<a class="headerlink" href="#ragmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagModel"><a name="//apple_ref/cpp/Class/transformers.RagModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.configuration_utils.PretrainedConfig<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_encoder</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retriever</span><span class="p">:</span> <span class="n">Optional</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagModel" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagModel" title="transformers.RagModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<p>RAG is a seq2seq model which encapsulates two core components: a question encoder and a generator. During a forward
pass, we encode the input with the question encoder and pass it to the retriever to extract relevant context
documents. The documents are then prepended to the input. Such contextualized inputs is passed to the generator.</p>
<p>The question encoder can be any <cite>autoencoding</cite> model, preferably <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a>, and the
generator can be any <cite>seq2seq</cite> model, preferably <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a>.</p>
<p>The model can be initialized with a <a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a> for end-to-end generation or used in
combination with the outputs of a retriever in multiple steps—see examples for more details. The model is
compatible any <cite>autoencoding</cite> model as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code> and any <cite>seq2seq</cite> model with language model head as
the <code class="docutils literal notranslate"><span class="pre">generator</span></code>. It has been tested with <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a> as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code>
and <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a> or <a class="reference internal" href="t5.html#transformers.T5ForConditionalGeneration" title="transformers.T5ForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">T5ForConditionalGeneration</span></code></a> as the
<code class="docutils literal notranslate"><span class="pre">generator</span></code>.</p>
<p>This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) – Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model weights.</p></li>
<li><p><strong>question_encoder</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – An encoder model compatible with the faiss index encapsulated by the <code class="docutils literal notranslate"><span class="pre">retriever</span></code>.</p></li>
<li><p><strong>generator</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – A seq2seq model used as the generator in the RAG architecture.</p></li>
<li><p><strong>retriever</strong> (<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>) – A retriever class encapsulating a faiss index queried to obtain context documents for current inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.RagModel.forward"><a name="//apple_ref/cpp/Method/transformers.RagModel.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_retrieved</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagModel" title="transformers.RagModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – Indices of input sequence tokens in the vocabulary. <a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>, used to initialize
the model, specifies which generator to use, it also specifies a compatible generator tokenizer. Use that
tokenizer class to obtain the indices.</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) – <p>Tuple consists of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_hidden_states</span></code>,
<cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_attentions</span></code>). <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_docs</span> <span class="pre">*</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code> is a sequence of hidden-states at the output of
the last layer of the generator’s encoder.</p>
<p>Used by the (<a class="reference internal" href="#transformers.RagModel" title="transformers.RagModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagModel</span></code></a>) model during decoding.</p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Provide for generation tasks. <cite>None</cite> by default, construct as per instructions for the generator model
you’re using with your RAG instance.</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.BoolTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>  <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>) – Tuple consists of two elements: <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code> of the RAG model (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> of the underlying generator. Can be used to speed up decoding.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used in the (<a class="reference internal" href="#transformers.RagTokenForGeneration" title="transformers.RagTokenForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagTokenForGeneration</span></code></a>) model during
decoding.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>. If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> has to be provided to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> can be computed via
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, see examples for more
information.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Input IDs post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided to the
forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>output_retrieved</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_ids</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code>. See returned tensors for more detail.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_docs</span></code>) – Number of documents to retrieve and/or number of documents for which to generate an answer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head. The score is possibly marginalized over all documents for
each vocabulary token.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[torch.FloatTensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span>
<span class="pre">batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used
(see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Embedded documents retrieved by the retriever. Is used with <code class="docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> to
compute the <code class="docutils literal notranslate"><span class="pre">doc_scores</span></code>.</p></li>
<li><p><strong>retrieved_doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – The indexes of the embedded documents retrieved by the retriever.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p></li>
<li><p><strong>question_encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden states at the output of the last layer of the question encoder pooled output of the
model.</p></li>
<li><p><strong>question_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the question encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>question_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the question encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_enc_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the generator encoder of the model.</p></li>
<li><p><strong>generator_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_dec_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_dec_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator decoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagTokenizer</span><span class="p">,</span> <span class="n">RagRetriever</span><span class="p">,</span> <span class="n">RagModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RagTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-base"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-base"</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span> <span class="n">use_dummy_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize with RagRetriever to do everything in one forward call</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RagModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-base"</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="s2">"How many people live in Paris?"</span><span class="p">,</span> <span class="s2">"In Paris, there are 10 million people."</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="ragsequenceforgeneration">
<h2>RagSequenceForGeneration<a class="headerlink" href="#ragsequenceforgeneration" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagSequenceForGeneration"><a name="//apple_ref/cpp/Class/transformers.RagSequenceForGeneration"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagSequenceForGeneration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.configuration_utils.PretrainedConfig<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_encoder</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retriever</span><span class="p">:</span> <span class="n">Optional</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagSequenceForGeneration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagSequenceForGeneration" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagSequenceForGeneration" title="transformers.RagSequenceForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagSequenceForGeneration</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<p>A RAG-sequence model implementation. It performs RAG-sequence specific marginalization in the forward pass.</p>
<p>RAG is a seq2seq model which encapsulates two core components: a question encoder and a generator. During a forward
pass, we encode the input with the question encoder and pass it to the retriever to extract relevant context
documents. The documents are then prepended to the input. Such contextualized inputs is passed to the generator.</p>
<p>The question encoder can be any <cite>autoencoding</cite> model, preferably <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a>, and the
generator can be any <cite>seq2seq</cite> model, preferably <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a>.</p>
<p>The model can be initialized with a <a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a> for end-to-end generation or used in
combination with the outputs of a retriever in multiple steps—see examples for more details. The model is
compatible any <cite>autoencoding</cite> model as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code> and any <cite>seq2seq</cite> model with language model head as
the <code class="docutils literal notranslate"><span class="pre">generator</span></code>. It has been tested with <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a> as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code>
and <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a> or <a class="reference internal" href="t5.html#transformers.T5ForConditionalGeneration" title="transformers.T5ForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">T5ForConditionalGeneration</span></code></a> as the
<code class="docutils literal notranslate"><span class="pre">generator</span></code>.</p>
<p>This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) – Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model weights.</p></li>
<li><p><strong>question_encoder</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – An encoder model compatible with the faiss index encapsulated by the <code class="docutils literal notranslate"><span class="pre">retriever</span></code>.</p></li>
<li><p><strong>generator</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – A seq2seq model used as the generator in the RAG architecture.</p></li>
<li><p><strong>retriever</strong> (<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>) – A retriever class encapsulating a faiss index queried to obtain context documents for current inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.RagSequenceForGeneration.forward"><a name="//apple_ref/cpp/Method/transformers.RagSequenceForGeneration.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_retrieved</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">exclude_bos_score</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reduce_loss</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagSequenceForGeneration.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagSequenceForGeneration.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagSequenceForGeneration" title="transformers.RagSequenceForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagSequenceForGeneration</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – Indices of input sequence tokens in the vocabulary. <a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>, used to initialize
the model, specifies which generator to use, it also specifies a compatible generator tokenizer. Use that
tokenizer class to obtain the indices.</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) – <p>Tuple consists of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_hidden_states</span></code>,
<cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_attentions</span></code>). <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_docs</span> <span class="pre">*</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code> is a sequence of hidden-states at the output of
the last layer of the generator’s encoder.</p>
<p>Used by the (<a class="reference internal" href="#transformers.RagModel" title="transformers.RagModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagModel</span></code></a>) model during decoding.</p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Provide for generation tasks. <cite>None</cite> by default, construct as per instructions for the generator model
you’re using with your RAG instance.</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.BoolTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>  <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>) – Tuple consists of two elements: <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code> of the RAG model (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> of the underlying generator. Can be used to speed up decoding.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used in the (<a class="reference internal" href="#transformers.RagTokenForGeneration" title="transformers.RagTokenForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagTokenForGeneration</span></code></a>) model during
decoding.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>. If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> has to be provided to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> can be computed via
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, see examples for more
information.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Input IDs post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided to the
forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>output_retrieved</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_ids</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code>. See returned tensors for more detail.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_docs</span></code>) – Number of documents to retrieve and/or number of documents for which to generate an answer.</p></li>
<li><p><strong>exclude_bos_score</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Only relevant if <code class="docutils literal notranslate"><span class="pre">labels</span></code> is passed. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the score of the BOS token is disregarded when
computing the loss.</p></li>
<li><p><strong>reduce_loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Only relevant if <code class="docutils literal notranslate"><span class="pre">labels</span></code> is passed. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the NLL loss is reduced using the
<code class="docutils literal notranslate"><span class="pre">torch.Tensor.sum</span></code> operation.</p></li>
<li><p><strong>kwargs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">any]</span></code>, optional, defaults to <cite>{}</cite>) – Legacy dictionary, which is required so that model can use <cite>generate()</cite> function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMMarginOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) – Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head. The score is possibly marginalized over all documents for
each vocabulary token.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[torch.FloatTensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span>
<span class="pre">batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used
(see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Embedded documents retrieved by the retriever. Is used with <code class="docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> to
compute the <code class="docutils literal notranslate"><span class="pre">doc_scores</span></code>.</p></li>
<li><p><strong>retrieved_doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – The indexes of the embedded documents retrieved by the retriever.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p></li>
<li><p><strong>question_encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden states at the output of the last layer of the question encoder pooled output of the
model.</p></li>
<li><p><strong>question_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the question encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>question_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the question encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_enc_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the generator encoder of the model.</p></li>
<li><p><strong>generator_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_dec_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_dec_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator decoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagTokenizer</span><span class="p">,</span> <span class="n">RagRetriever</span><span class="p">,</span> <span class="n">RagSequenceForGeneration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RagTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-sequence-nq"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-sequence-nq"</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span> <span class="n">use_dummy_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize with RagRetriever to do everything in one forward call</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RagSequenceForGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-nq"</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="s2">"How many people live in Paris?"</span><span class="p">,</span> <span class="s2">"In Paris, there are 10 million people."</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">"labels"</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># or use retriever separately</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RagSequenceForGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-sequence-nq"</span><span class="p">,</span> <span class="n">use_dummy_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1. Encode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">question_hidden_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">question_encoder</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2. Retrieve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">docs_dict</span> <span class="o">=</span> <span class="n">retriever</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">question_hidden_states</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doc_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">question_hidden_states</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">docs_dict</span><span class="p">[</span><span class="s2">"retrieved_doc_embeds"</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3. Forward to generator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">context_input_ids</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_input_ids"</span><span class="p">],</span> <span class="n">context_attention_mask</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_attention_mask"</span><span class="p">],</span> <span class="n">doc_scores</span><span class="o">=</span><span class="n">doc_scores</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">"labels"</span><span class="p">])</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMMarginOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.RagSequenceForGeneration.generate"><a name="//apple_ref/cpp/Method/transformers.RagSequenceForGeneration.generate"></a>
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">do_deduplication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_return_sequences</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_beams</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">model_kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagSequenceForGeneration.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagSequenceForGeneration.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements RAG sequence “thorough” decoding. Read the <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate`()</span></code>
documentation for more information on how to set other generate input parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – The sequence used as a prompt for the generation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> is not passed, then
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided.</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input IDs post-processed from the retrieved documents and the question encoder input_ids by the
retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by
the retriever.</p>
<p>If the model is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> or <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> is not given,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> have to be provided to the forward pass.
They are returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – <p>Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p>
<p>If the model is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> or <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> is not given, <code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code>
has to be provided to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>do_deduplication</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to deduplicate the generations from different context documents for a given input. Has
to be set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code> if used while training with distributed backend.</p></li>
<li><p><strong>num_return_sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) – The number of independently computed returned sequences for each element in the batch. Note that this
is not the value we pass to the <code class="docutils literal notranslate"><span class="pre">generator</span></code>’s <cite>:func:`~transformers.PreTrainedModel.generate`</cite>
function, where we set <code class="docutils literal notranslate"><span class="pre">num_return_sequences</span></code> to <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_beams</span></code>.</p></li>
<li><p><strong>num_beams</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) – Number of beams for beam search. 1 means no beam search.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_docs</span></code>) – Number of documents to retrieve and/or number of documents for which to generate an answer.</p></li>
<li><p><strong>kwargs</strong> – Additional kwargs will be passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The generated
sequences. The second dimension (sequence length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or shorter if all
batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequences,</span> <span class="pre">sequence_length)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="ragtokenforgeneration">
<h2>RagTokenForGeneration<a class="headerlink" href="#ragtokenforgeneration" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.RagTokenForGeneration"><a name="//apple_ref/cpp/Class/transformers.RagTokenForGeneration"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RagTokenForGeneration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.configuration_utils.PretrainedConfig<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">question_encoder</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">generator</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">retriever</span><span class="p">:</span> <span class="n">Optional</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagTokenForGeneration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagTokenForGeneration" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagTokenForGeneration" title="transformers.RagTokenForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagTokenForGeneration</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<p>A RAG-token model implementation. It performs RAG-token specific marginalization in the forward pass.</p>
<p>RAG is a seq2seq model which encapsulates two core components: a question encoder and a generator. During a forward
pass, we encode the input with the question encoder and pass it to the retriever to extract relevant context
documents. The documents are then prepended to the input. Such contextualized inputs is passed to the generator.</p>
<p>The question encoder can be any <cite>autoencoding</cite> model, preferably <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a>, and the
generator can be any <cite>seq2seq</cite> model, preferably <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a>.</p>
<p>The model can be initialized with a <a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a> for end-to-end generation or used in
combination with the outputs of a retriever in multiple steps—see examples for more details. The model is
compatible any <cite>autoencoding</cite> model as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code> and any <cite>seq2seq</cite> model with language model head as
the <code class="docutils literal notranslate"><span class="pre">generator</span></code>. It has been tested with <a class="reference internal" href="dpr.html#transformers.DPRQuestionEncoder" title="transformers.DPRQuestionEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPRQuestionEncoder</span></code></a> as the <code class="docutils literal notranslate"><span class="pre">question_encoder</span></code>
and <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a> or <a class="reference internal" href="t5.html#transformers.T5ForConditionalGeneration" title="transformers.T5ForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">T5ForConditionalGeneration</span></code></a> as the
<code class="docutils literal notranslate"><span class="pre">generator</span></code>.</p>
<p>This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) – Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model weights.</p></li>
<li><p><strong>question_encoder</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – An encoder model compatible with the faiss index encapsulated by the <code class="docutils literal notranslate"><span class="pre">retriever</span></code>.</p></li>
<li><p><strong>generator</strong> (<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.PreTrainedModel</span></code></a>) – A seq2seq model used as the generator in the RAG architecture.</p></li>
<li><p><strong>retriever</strong> (<a class="reference internal" href="#transformers.RagRetriever" title="transformers.RagRetriever"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagRetriever</span></code></a>) – A retriever class encapsulating a faiss index queried to obtain context documents for current inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.RagTokenForGeneration.forward"><a name="//apple_ref/cpp/Method/transformers.RagTokenForGeneration.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_retrieved</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">do_marginalize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reduce_loss</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagTokenForGeneration.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagTokenForGeneration.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.RagTokenForGeneration" title="transformers.RagTokenForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagTokenForGeneration</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – Indices of input sequence tokens in the vocabulary. <a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>, used to initialize
the model, specifies which generator to use, it also specifies a compatible generator tokenizer. Use that
tokenizer class to obtain the indices.</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) – <p>Tuple consists of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_hidden_states</span></code>,
<cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_attentions</span></code>). <code class="xref py py-obj docutils literal notranslate"><span class="pre">generator_enc_last_hidden_state</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_docs</span> <span class="pre">*</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code> is a sequence of hidden-states at the output of
the last layer of the generator’s encoder.</p>
<p>Used by the (<a class="reference internal" href="#transformers.RagModel" title="transformers.RagModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagModel</span></code></a>) model during decoding.</p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Provide for generation tasks. <cite>None</cite> by default, construct as per instructions for the generator model
you’re using with your RAG instance.</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.BoolTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>  <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>) – Tuple consists of two elements: <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code> of the RAG model (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_outputs</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> of the underlying generator. Can be used to speed up decoding.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used in the (<a class="reference internal" href="#transformers.RagTokenForGeneration" title="transformers.RagTokenForGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagTokenForGeneration</span></code></a>) model during
decoding.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>. If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> has to be provided to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">doc_scores</span></code> can be computed via
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, see examples for more
information.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Input IDs post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided to the
forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by <code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>output_retrieved</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_ids</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_attention_mask</span></code>. See returned tensors for more detail.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_docs</span></code>) – Number of documents to retrieve and/or number of documents for which to generate an answer.</p></li>
<li><p><strong>do_marginalize</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the logits are marginalized over all documents by making use of
<code class="docutils literal notranslate"><span class="pre">torch.nn.functional.log_softmax</span></code>.</p></li>
<li><p><strong>reduce_loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Only relevant if <code class="docutils literal notranslate"><span class="pre">labels</span></code> is passed. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the NLL loss is reduced using the
<code class="docutils literal notranslate"><span class="pre">torch.Tensor.sum</span></code> operation.</p></li>
<li><p><strong>kwargs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">any]</span></code>, optional, defaults to <cite>{}</cite>) – Legacy dictionary, which is required so that model can use <cite>generate()</cite> function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMMarginOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.RagConfig" title="transformers.RagConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">RagConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) – Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head. The score is possibly marginalized over all documents for
each vocabulary token.</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[torch.FloatTensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span>
<span class="pre">batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used
(see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>retrieved_doc_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Embedded documents retrieved by the retriever. Is used with <code class="docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code> to
compute the <code class="docutils literal notranslate"><span class="pre">doc_scores</span></code>.</p></li>
<li><p><strong>retrieved_doc_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – The indexes of the embedded documents retrieved by the retriever.</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever.</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p></li>
<li><p><strong>question_encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden states at the output of the last layer of the question encoder pooled output of the
model.</p></li>
<li><p><strong>question_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the question encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>question_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the question encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_enc_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the generator encoder of the model.</p></li>
<li><p><strong>generator_enc_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_enc_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator encoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
<li><p><strong>generator_dec_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings and one for the output of each
layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>generator_dec_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the generator decoder, after the attention softmax, used to compute the weighted
average in the self-attention heads.</p>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RagTokenizer</span><span class="p">,</span> <span class="n">RagRetriever</span><span class="p">,</span> <span class="n">RagTokenForGeneration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RagTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-nq"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">retriever</span> <span class="o">=</span> <span class="n">RagRetriever</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-nq"</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span> <span class="n">use_dummy_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize with RagRetriever to do everything in one forward call</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RagTokenForGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-nq"</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="s2">"How many people live in Paris?"</span><span class="p">,</span> <span class="s2">"In Paris, there are 10 million people."</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">"labels"</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># or use retriever separately</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RagTokenForGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"facebook/rag-token-nq"</span><span class="p">,</span> <span class="n">use_dummy_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1. Encode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">question_hidden_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">question_encoder</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2. Retrieve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">docs_dict</span> <span class="o">=</span> <span class="n">retriever</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">question_hidden_states</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doc_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">question_hidden_states</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">docs_dict</span><span class="p">[</span><span class="s2">"retrieved_doc_embeds"</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3. Forward to generator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">context_input_ids</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_input_ids"</span><span class="p">],</span> <span class="n">context_attention_mask</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_attention_mask"</span><span class="p">],</span> <span class="n">doc_scores</span><span class="o">=</span><span class="n">doc_scores</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">"labels"</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># or directly generate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">context_input_ids</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_input_ids"</span><span class="p">],</span> <span class="n">context_attention_mask</span><span class="o">=</span><span class="n">docs_dict</span><span class="p">[</span><span class="s2">"context_attention_mask"</span><span class="p">],</span> <span class="n">doc_scores</span><span class="o">=</span><span class="n">doc_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">generated_string</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput" title="transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetrievAugLMMarginOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.RagTokenForGeneration.generate"><a name="//apple_ref/cpp/Method/transformers.RagTokenForGeneration.generate"></a>
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">context_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">doc_scores</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_length</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">min_length</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">early_stopping</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_beams</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_beam_groups</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">diversity_penalty</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">bos_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">length_penalty</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">repetition_penalty</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">bad_words_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_return_sequences</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_start_token_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_docs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">prefix_allowed_tokens_fn</span><span class="p">:</span> <span class="n">Callable<span class="p">[</span><span class="p">[</span>int<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>List<span class="p">[</span>int<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">model_kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/rag/modeling_rag.html#RagTokenForGeneration.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RagTokenForGeneration.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements RAG token decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – The sequence used as a prompt for the generation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> is not passed, then
<code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided.</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>context_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Input IDs post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by the
retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>context_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">config.n_docs,</span> <span class="pre">config.max_combined_length)</span></code>, <cite>optional</cite>, returned when <cite>output_retrieved=True</cite>) – <p>Attention mask post-processed from the retrieved documents and the question encoder <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> by
the retriever.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>doc_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.n_docs)</span></code>) – <p>Score between each retrieved document embeddings (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieved_doc_embeds</span></code>) and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">question_encoder_last_hidden_state</span></code>.</p>
<p>If the model has is not initialized with a <code class="docutils literal notranslate"><span class="pre">retriever</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> has to be provided
to the forward pass. <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_input_ids</span></code> are returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code>.</p>
</p></li>
<li><p><strong>max_length</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 20) – The maximum length of the sequence to be generated.</p></li>
<li><p><strong>min_length</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 10) – The minimum length of the sequence to be generated.</p></li>
<li><p><strong>early_stopping</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Whether or not to stop the beam search when at least <code class="docutils literal notranslate"><span class="pre">num_beams</span></code> sentences are finished per batch or
not.</p></li>
<li><p><strong>use_cache</strong> – (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>):
Whether or not the model should use the past last key/values attentions (if applicable to the model) to
speed up decoding.</p></li>
<li><p><strong>pad_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) – The id of the <cite>padding</cite> token.</p></li>
<li><p><strong>bos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) – The id of the <cite>beginning-of-sequence</cite> token.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) – The id of the <cite>end-of-sequence</cite> token.</p></li>
<li><p><strong>length_penalty</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 1.0) – <p>Exponential penalty to the length. 1.0 means no penalty.</p>
<p>Set to values &lt; 1.0 in order to encourage the model to generate shorter sequences, to a value &gt; 1.0 in
order to encourage the model to produce longer sequences.</p>
</p></li>
<li><p><strong>no_repeat_ngram_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 0) – If set to int &gt; 0, all ngrams of that size can only occur once.</p></li>
<li><p><strong>bad_words_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[int]</span></code>, <cite>optional</cite>) – List of token ids that are not allowed to be generated. In order to get the tokens of the words that
should not appear in the generated text, use <code class="xref py py-obj docutils literal notranslate"><span class="pre">tokenizer.encode(bad_word,</span> <span class="pre">add_prefix_space=True)</span></code>.</p></li>
<li><p><strong>num_beams</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) – Number of beams for beam search. 1 means no beam search.</p></li>
<li><p><strong>num_beam_groups</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) – Number of groups to divide <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_beams</span></code> into in order to ensure diversity among different groups of
beams. <a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">this paper</a> for more details.</p></li>
<li><p><strong>diversity_penalty</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0) – This value is subtracted from a beam’s score if it generates a token same as any beam from other group
at a particular time. Note that <code class="xref py py-obj docutils literal notranslate"><span class="pre">diversity_penalty</span></code> is only effective if <code class="docutils literal notranslate"><span class="pre">group</span> <span class="pre">beam</span> <span class="pre">search</span></code> is
enabled.</p></li>
<li><p><strong>num_return_sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) – The number of independently computed returned sequences for each element in the batch. Note that this
is not the value we pass to the <code class="docutils literal notranslate"><span class="pre">generator</span></code>’s <cite>:func:`~transformers.PreTrainedModel.generate</cite>
function, where we set <code class="docutils literal notranslate"><span class="pre">num_return_sequences</span></code> to <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_beams</span></code>.</p></li>
<li><p><strong>decoder_start_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) – If an encoder-decoder model starts decoding with a different token than <cite>bos</cite>, the id of that token.</p></li>
<li><p><strong>n_docs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_docs</span></code>) – Number of documents to retrieve and/or number of documents for which to generate an answer.</p></li>
<li><p><strong>prefix_allowed_tokens_fn</strong> – (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Callable[[int,</span> <span class="pre">torch.Tensor],</span> <span class="pre">List[int]]</span></code>, <cite>optional</cite>):
If provided, this function constraints the beam search to allowed tokens only at each step. If not
provided no constraint is applied. This function takes 2 arguments <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_ids</span></code> and the batch ID
<code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_id</span></code>. It has to return a list with the allowed tokens for the next generation step
conditioned on the previously generated tokens <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_ids</span></code> and the batch ID <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_id</span></code>. This
argument is useful for constrained generation conditioned on the prefix, as described in
<a class="reference external" href="https://arxiv.org/abs/2010.00904">Autoregressive Entity Retrieval</a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The generated
sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or shorter if all
batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequences,</span> <span class="pre">sequence_length)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="reformer.html" rel="next" title="Reformer">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
<a accesskey="p" class="btn btn-neutral float-left" href="prophetnet.html" rel="prev" title="ProphetNet"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
</div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
</section>
</div>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Theme Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>
</body>
</html>