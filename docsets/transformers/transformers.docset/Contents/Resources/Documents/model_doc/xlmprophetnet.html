
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>XLM-ProphetNet — transformers 4.2.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/huggingface.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/code-snippets.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/hidesidebar.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/js/custom.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="xlmroberta.html" rel="next" title="XLM-RoBERTa"/>
<link href="xlm.html" rel="prev" title="XLM"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html"> transformers
          

          
          </a>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<div aria-label="main navigation" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using 🤗 Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">🤗 Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlm.html">XLM</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">XLM-ProphetNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetconfig">XLMProphetNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnettokenizer">XLMProphetNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetmodel">XLMProphetNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetencoder">XLMProphetNetEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetdecoder">XLMProphetNetDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetforconditionalgeneration">XLMProphetNetForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xlmprophetnetforcausallm">XLMProphetNetForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/generation_utils.html">Utilities for Generation</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="top navigation" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">transformers</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a class="icon icon-home" href="../index.html"></a> »</li>
<li>XLM-ProphetNet</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/model_doc/xlmprophetnet.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="xlm-prophetnet">
<h1>XLM-ProphetNet<a class="headerlink" href="#xlm-prophetnet" title="Permalink to this headline">¶</a></h1>
<p><strong>DISCLAIMER:</strong> If you see something strange, file a <a class="reference external" href="https://github.com/huggingface/transformers/issues/new?assignees=&amp;labels=&amp;template=bug-report.md&amp;title">Github Issue</a> and assign
@patrickvonplaten</p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The XLM-ProphetNet model was proposed in <a class="reference external" href="https://arxiv.org/abs/2001.04063">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training,</a> by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, Ming Zhou on 13 Jan, 2020.</p>
<p>XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for “ngram” language modeling instead of
just the next token. Its architecture is identical to ProhpetNet, but the model was trained on the multi-lingual
“wiki100” Wikipedia dump.</p>
<p>The abstract from the paper is the following:</p>
<p><em>In this paper, we present a new sequence-to-sequence pretraining model called ProphetNet, which introduces a novel
self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism. Instead of
the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by
n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent
overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale
dataset (160GB) respectively. Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the same scale pretraining corpus.</em></p>
<p>The Authors’ code can be found <a class="reference external" href="https://github.com/microsoft/ProphetNet">here</a>.</p>
</div>
<div class="section" id="xlmprophetnetconfig">
<h2>XLMProphetNetConfig<a class="headerlink" href="#xlmprophetnetconfig" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetConfig"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetConfig"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">activation_dropout</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">activation_function</span><span class="o">=</span><span class="default_value">'gelu'</span></em>, <em class="sig-param"><span class="n">vocab_size</span><span class="o">=</span><span class="default_value">30522</span></em>, <em class="sig-param"><span class="n">hidden_size</span><span class="o">=</span><span class="default_value">1024</span></em>, <em class="sig-param"><span class="n">encoder_ffn_dim</span><span class="o">=</span><span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">num_encoder_layers</span><span class="o">=</span><span class="default_value">12</span></em>, <em class="sig-param"><span class="n">num_encoder_attention_heads</span><span class="o">=</span><span class="default_value">16</span></em>, <em class="sig-param"><span class="n">decoder_ffn_dim</span><span class="o">=</span><span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">num_decoder_layers</span><span class="o">=</span><span class="default_value">12</span></em>, <em class="sig-param"><span class="n">num_decoder_attention_heads</span><span class="o">=</span><span class="default_value">16</span></em>, <em class="sig-param"><span class="n">attention_dropout</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">max_position_embeddings</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">init_std</span><span class="o">=</span><span class="default_value">0.02</span></em>, <em class="sig-param"><span class="n">is_encoder_decoder</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">add_cross_attention</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">decoder_start_token_id</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">ngram</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">num_buckets</span><span class="o">=</span><span class="default_value">32</span></em>, <em class="sig-param"><span class="n">relative_max_distance</span><span class="o">=</span><span class="default_value">128</span></em>, <em class="sig-param"><span class="n">disable_ngram_loss</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">bos_token_id</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.html#XLMProphetNetConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetConfig" title="transformers.ProphetNetConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetConfig</span></code></a>. Please check the superclass for the appropriate
documentation alongside usage examples.</p>
</dd></dl>
</div>
<div class="section" id="xlmprophetnettokenizer">
<h2>XLMProphetNetTokenizer<a class="headerlink" href="#xlmprophetnettokenizer" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetTokenizer"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetTokenizer"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/utils/dummy_sentencepiece_objects.html#XLMProphetNetTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetTokenizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="xlmprophetnetmodel">
<h2>XLMProphetNetModel<a class="headerlink" href="#xlmprophetnetmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetModel"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.html#XLMProphetNetModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetModel" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetModel" title="transformers.ProphetNetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetModel</span></code></a>. Please check the superclass for the appropriate
documentation alongside usage examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMProphetNetModel</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">XLMProphetNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies have been shown that owning a dog is good for you"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies show that"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>  <span class="c1"># main stream hidden states</span>
<span class="go">    &gt;&gt;&gt; last_hidden_states_ngram = outputs.last_hidden_state_ngram  # predict hidden states</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="xlmprophetnetencoder">
<h2>XLMProphetNetEncoder<a class="headerlink" href="#xlmprophetnetencoder" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetEncoder"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetEncoder"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetEncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">transformers.models.prophetnet.configuration_prophetnet.ProphetNetConfig</span></em>, <em class="sig-param"><span class="n">word_embeddings</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.nn.modules.sparse.Embedding<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.html#XLMProphetNetEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetEncoder" title="transformers.ProphetNetEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetEncoder</span></code></a>. Please check the superclass for the appropriate
documentation alongside usage examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMProphetNetEncoder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">XLMProphetNetEncoder</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'patrickvonplaten/xprophetnet-large-uncased-standalone'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_decoder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> has to be configured as a decoder."</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Hello, my dog is cute"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="xlmprophetnetdecoder">
<h2>XLMProphetNetDecoder<a class="headerlink" href="#xlmprophetnetdecoder" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetDecoder"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetDecoder"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetDecoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">transformers.models.prophetnet.configuration_prophetnet.ProphetNetConfig</span></em>, <em class="sig-param"><span class="n">word_embeddings</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.nn.modules.sparse.Embedding<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.html#XLMProphetNetDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetDecoder" title="transformers.ProphetNetDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetDecoder</span></code></a>. Please check the superclass for the appropriate
documentation alongside usage examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMProphetNetDecoder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">XLMProphetNetDecoder</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'patrickvonplaten/xprophetnet-large-uncased-standalone'</span><span class="p">,</span> <span class="n">add_cross_attention</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_decoder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> has to be configured as a decoder."</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Hello, my dog is cute"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="xlmprophetnetforconditionalgeneration">
<h2>XLMProphetNetForConditionalGeneration<a class="headerlink" href="#xlmprophetnetforconditionalgeneration" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetForConditionalGeneration"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetForConditionalGeneration"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetForConditionalGeneration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">transformers.models.prophetnet.configuration_prophetnet.ProphetNetConfig</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.html#XLMProphetNetForConditionalGeneration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetForConditionalGeneration" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetForConditionalGeneration" title="transformers.ProphetNetForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetForConditionalGeneration</span></code></a>. Please check the superclass for the
appropriate documentation alongside usage examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMProphetNetForConditionalGeneration</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span>  <span class="n">XLMProphetNetForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies have been shown that owning a dog is good for you"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies show that"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_next_token</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>  <span class="c1"># logits to predict next token as usual</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_ngram_next_tokens</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits_ngram</span>  <span class="c1"># logits to predict 2nd, 3rd, ... next tokens</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="xlmprophetnetforcausallm">
<h2>XLMProphetNetForCausalLM<a class="headerlink" href="#xlmprophetnetforcausallm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.XLMProphetNetForCausalLM"><a name="//apple_ref/cpp/Class/transformers.XLMProphetNetForCausalLM"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">XLMProphetNetForCausalLM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.html#XLMProphetNetForCausalLM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.XLMProphetNetForCausalLM" title="Permalink to this definition">¶</a></dt>
<dd><p>This class overrides <a class="reference internal" href="prophetnet.html#transformers.ProphetNetForCausalLM" title="transformers.ProphetNetForCausalLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProphetNetForCausalLM</span></code></a>. Please check the superclass for the appropriate
documentation alongside usage examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMProphetNetForCausalLM</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">XLMProphetNetForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_decoder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> has to be configured as a decoder."</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Hello, my dog is cute"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Model can also be used with EncoderDecoder framework</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">EncoderDecoderModel</span><span class="p">,</span> <span class="n">XLMProphetNetTokenizer</span><span class="p">,</span> <span class="n">XLMRobertaTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_enc</span> <span class="o">=</span> <span class="n">XLMRobertaTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'xlm-roberta-large'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_dec</span> <span class="o">=</span> <span class="n">XLMProphetNetTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_encoder_decoder_pretrained</span><span class="p">(</span><span class="s2">"xlm-roberta-large"</span><span class="p">,</span> <span class="s1">'microsoft/xprophetnet-large-wiki100-cased'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">ARTICLE</span> <span class="o">=</span> <span class="p">(</span>
<span class="gp">... </span><span class="s2">"the us state department said wednesday it had received no "</span>
<span class="gp">... </span><span class="s2">"formal word from bolivia that it was expelling the us ambassador there "</span>
<span class="gp">... </span><span class="s2">"but said the charges made against him are `` baseless ."</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_enc</span><span class="p">(</span><span class="n">ARTICLE</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer_dec</span><span class="p">(</span><span class="s2">"us rejects charges against its ambassador in bolivia"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">labels</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
</pre></div>
</div>
</dd></dl>
</div>
</div>
</div>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="xlmroberta.html" rel="next" title="XLM-RoBERTa">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
<a accesskey="p" class="btn btn-neutral float-left" href="xlm.html" rel="prev" title="XLM"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
</div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
</section>
</div>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Theme Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>
</body>
</html>