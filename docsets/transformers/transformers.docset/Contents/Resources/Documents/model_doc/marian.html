
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>MarianMT — transformers 4.2.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/huggingface.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/code-snippets.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/hidesidebar.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/js/custom.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="mbart.html" rel="next" title="MBart"/>
<link href="lxmert.html" rel="prev" title="LXMERT"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html"> transformers
          

          
          </a>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<div aria-label="main navigation" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using 🤗 Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">🤗 Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lxmert.html">LXMERT</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MarianMT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#naming">Naming</a></li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multilingual-models">Multilingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#old-style-multi-lingual-models">Old Style Multi-Lingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#marianconfig">MarianConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mariantokenizer">MarianTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#marianmodel">MarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#marianmtmodel">MarianMTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tfmarianmodel">TFMarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tfmarianmtmodel">TFMarianMTModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/generation_utils.html">Utilities for Generation</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="top navigation" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">transformers</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a class="icon icon-home" href="../index.html"></a> »</li>
<li>MarianMT</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/model_doc/marian.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="marianmt">
<h1>MarianMT<a class="headerlink" href="#marianmt" title="Permalink to this headline">¶</a></h1>
<p><strong>Bugs:</strong> If you see something strange, file a <a class="reference external" href="https://github.com/huggingface/transformers/issues/new?assignees=sshleifer&amp;labels=&amp;template=bug-report.md&amp;title">Github Issue</a>
and assign @patrickvonplaten.</p>
<p>Translations should be similar, but not identical to output in the test set linked to in each model card.</p>
<div class="section" id="implementation-notes">
<h2>Implementation Notes<a class="headerlink" href="#implementation-notes" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>Each model is about 298 MB on disk, there are more than 1,000 models.</p></li>
<li><p>The list of supported language pairs can be found <a class="reference external" href="https://huggingface.co/Helsinki-NLP">here</a>.</p></li>
<li><p>Models were originally trained by <a class="reference external" href="https://researchportal.helsinki.fi/en/persons/j%C3%B6rg-tiedemann">Jörg Tiedemann</a> using the <a class="reference external" href="https://marian-nmt.github.io/">Marian</a> C++ library, which supports fast training and translation.</p></li>
<li><p>All models are transformer encoder-decoders with 6 layers in each component. Each model’s performance is documented
in a model card.</p></li>
<li><p>The 80 opus models that require BPE preprocessing are not supported.</p></li>
<li><p>The modeling code is the same as <a class="reference internal" href="bart.html#transformers.BartForConditionalGeneration" title="transformers.BartForConditionalGeneration"><code class="xref py py-class docutils literal notranslate"><span class="pre">BartForConditionalGeneration</span></code></a> with a few minor modifications:</p>
<blockquote>
<div><ul class="simple">
<li><p>static (sinusoid) positional embeddings (<code class="xref py py-obj docutils literal notranslate"><span class="pre">MarianConfig.static_position_embeddings=True</span></code>)</p></li>
<li><p>no layernorm_embedding (<code class="xref py py-obj docutils literal notranslate"><span class="pre">MarianConfig.normalize_embedding=False</span></code>)</p></li>
<li><p>the model starts generating with <code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_token_id</span></code> (which has 0 as a token_embedding) as the prefix (Bart uses
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&lt;s/&gt;</span></code>),</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Code to bulk convert models can be found in <code class="docutils literal notranslate"><span class="pre">convert_marian_to_pytorch.py</span></code>.</p></li>
</ul>
</div>
<div class="section" id="naming">
<h2>Naming<a class="headerlink" href="#naming" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>All model names use the following format: <code class="xref py py-obj docutils literal notranslate"><span class="pre">Helsinki-NLP/opus-mt-{src}-{tgt}</span></code></p></li>
<li><p>The language codes used to name models are inconsistent. Two digit codes can usually be found <a class="reference external" href="https://developers.google.com/admin-sdk/directory/v1/languages">here</a>, three digit codes require googling “language
code {code}”.</p></li>
<li><p>Codes formatted like <code class="xref py py-obj docutils literal notranslate"><span class="pre">es_AR</span></code> are usually <code class="xref py py-obj docutils literal notranslate"><span class="pre">code_{region}</span></code>. That one is Spanish from Argentina.</p></li>
<li><p>The models were converted in two stages. The first 1000 models use ISO-639-2 codes to identify languages, the second
group use a combination of ISO-639-5 codes and ISO-639-2 codes.</p></li>
</ul>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Since Marian models are smaller than many other translation models available in the library, they can be useful for
fine-tuning experiments and integration tests.</p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/transformers/blob/master/examples/research_projects/seq2seq-distillation/train_distil_marian_enro_teacher.sh">Fine-tune on GPU</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/transformers/blob/master/examples/research_projects/seq2seq-distillation/train_distil_marian_no_teacher.sh">Fine-tune on GPU with pytorch-lightning</a></p></li>
</ul>
</div>
<div class="section" id="multilingual-models">
<h2>Multilingual Models<a class="headerlink" href="#multilingual-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>All model names use the following format: <code class="xref py py-obj docutils literal notranslate"><span class="pre">Helsinki-NLP/opus-mt-{src}-{tgt}</span></code>:</p></li>
<li><p>If a model can output multiple languages, and you should specify a language code by prepending the desired output
language to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">src_text</span></code>.</p></li>
<li><p>You can see a models’s supported language codes in its model card, under target constituents, like in <a class="reference external" href="https://huggingface.co/Helsinki-NLP/opus-mt-en-roa">opus-mt-en-roa</a>.</p></li>
<li><p>Note that if a model is only multilingual on the source side, like <code class="xref py py-obj docutils literal notranslate"><span class="pre">Helsinki-NLP/opus-mt-roa-en</span></code>, no language
codes are required.</p></li>
</ul>
<p>New multi-lingual models from the <a class="reference external" href="https://github.com/Helsinki-NLP/Tatoeba-Challenge">Tatoeba-Challenge repo</a>
require 3 character language codes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianMTModel</span><span class="p">,</span> <span class="n">MarianTokenizer</span>
<span class="n">src_text</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'&gt;&gt;fra&lt;&lt; this is a sentence in english that we want to translate to french'</span><span class="p">,</span>
    <span class="s1">'&gt;&gt;por&lt;&lt; This should go to portuguese'</span><span class="p">,</span>
    <span class="s1">'&gt;&gt;esp&lt;&lt; And this to Spanish'</span>
<span class="p">]</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s1">'Helsinki-NLP/opus-mt-en-roa'</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">supported_language_codes</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">translated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="n">src_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">))</span>
<span class="n">tgt_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">translated</span><span class="p">]</span>
<span class="c1"># ["c'est une phrase en anglais que nous voulons traduire en français",</span>
<span class="c1"># 'Isto deve ir para o português.',</span>
<span class="c1"># 'Y esto al español']</span>
</pre></div>
</div>
<p>Code to see available pretrained models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers.hf_api</span> <span class="kn">import</span> <span class="n">HfApi</span>
<span class="n">model_list</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">()</span><span class="o">.</span><span class="n">model_list</span><span class="p">()</span>
<span class="n">org</span> <span class="o">=</span> <span class="s2">"Helsinki-NLP"</span>
<span class="n">model_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">modelId</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model_list</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">modelId</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">org</span><span class="p">)]</span>
<span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'/'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model_ids</span><span class="p">]</span>
<span class="n">old_style_multi_models</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">org</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">suffix</span> <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="section" id="old-style-multi-lingual-models">
<h2>Old Style Multi-Lingual Models<a class="headerlink" href="#old-style-multi-lingual-models" title="Permalink to this headline">¶</a></h2>
<p>These are the old style multi-lingual models ported from the OPUS-MT-Train repo: and the members of each language
group:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">'Helsinki-NLP/opus-mt-NORTH_EU-NORTH_EU'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-ROMANCE-en'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-SCANDINAVIA-SCANDINAVIA'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-de-ZH'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-en-CELTIC'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-en-ROMANCE'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-es-NORWAY'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-fi-NORWAY'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-fi-ZH'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-fi_nb_no_nn_ru_sv_en-SAMI'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-sv-NORWAY'</span><span class="p">,</span>
 <span class="s1">'Helsinki-NLP/opus-mt-sv-ZH'</span><span class="p">]</span>
<span class="n">GROUP_MEMBERS</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">'ZH'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'cmn'</span><span class="p">,</span> <span class="s1">'cn'</span><span class="p">,</span> <span class="s1">'yue'</span><span class="p">,</span> <span class="s1">'ze_zh'</span><span class="p">,</span> <span class="s1">'zh_cn'</span><span class="p">,</span> <span class="s1">'zh_CN'</span><span class="p">,</span> <span class="s1">'zh_HK'</span><span class="p">,</span> <span class="s1">'zh_tw'</span><span class="p">,</span> <span class="s1">'zh_TW'</span><span class="p">,</span> <span class="s1">'zh_yue'</span><span class="p">,</span> <span class="s1">'zhs'</span><span class="p">,</span> <span class="s1">'zht'</span><span class="p">,</span> <span class="s1">'zh'</span><span class="p">],</span>
 <span class="s1">'ROMANCE'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'fr'</span><span class="p">,</span> <span class="s1">'fr_BE'</span><span class="p">,</span> <span class="s1">'fr_CA'</span><span class="p">,</span> <span class="s1">'fr_FR'</span><span class="p">,</span> <span class="s1">'wa'</span><span class="p">,</span> <span class="s1">'frp'</span><span class="p">,</span> <span class="s1">'oc'</span><span class="p">,</span> <span class="s1">'ca'</span><span class="p">,</span> <span class="s1">'rm'</span><span class="p">,</span> <span class="s1">'lld'</span><span class="p">,</span> <span class="s1">'fur'</span><span class="p">,</span> <span class="s1">'lij'</span><span class="p">,</span> <span class="s1">'lmo'</span><span class="p">,</span> <span class="s1">'es'</span><span class="p">,</span> <span class="s1">'es_AR'</span><span class="p">,</span> <span class="s1">'es_CL'</span><span class="p">,</span> <span class="s1">'es_CO'</span><span class="p">,</span> <span class="s1">'es_CR'</span><span class="p">,</span> <span class="s1">'es_DO'</span><span class="p">,</span> <span class="s1">'es_EC'</span><span class="p">,</span> <span class="s1">'es_ES'</span><span class="p">,</span> <span class="s1">'es_GT'</span><span class="p">,</span> <span class="s1">'es_HN'</span><span class="p">,</span> <span class="s1">'es_MX'</span><span class="p">,</span> <span class="s1">'es_NI'</span><span class="p">,</span> <span class="s1">'es_PA'</span><span class="p">,</span> <span class="s1">'es_PE'</span><span class="p">,</span> <span class="s1">'es_PR'</span><span class="p">,</span> <span class="s1">'es_SV'</span><span class="p">,</span> <span class="s1">'es_UY'</span><span class="p">,</span> <span class="s1">'es_VE'</span><span class="p">,</span> <span class="s1">'pt'</span><span class="p">,</span> <span class="s1">'pt_br'</span><span class="p">,</span> <span class="s1">'pt_BR'</span><span class="p">,</span> <span class="s1">'pt_PT'</span><span class="p">,</span> <span class="s1">'gl'</span><span class="p">,</span> <span class="s1">'lad'</span><span class="p">,</span> <span class="s1">'an'</span><span class="p">,</span> <span class="s1">'mwl'</span><span class="p">,</span> <span class="s1">'it'</span><span class="p">,</span> <span class="s1">'it_IT'</span><span class="p">,</span> <span class="s1">'co'</span><span class="p">,</span> <span class="s1">'nap'</span><span class="p">,</span> <span class="s1">'scn'</span><span class="p">,</span> <span class="s1">'vec'</span><span class="p">,</span> <span class="s1">'sc'</span><span class="p">,</span> <span class="s1">'ro'</span><span class="p">,</span> <span class="s1">'la'</span><span class="p">],</span>
 <span class="s1">'NORTH_EU'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'de'</span><span class="p">,</span> <span class="s1">'nl'</span><span class="p">,</span> <span class="s1">'fy'</span><span class="p">,</span> <span class="s1">'af'</span><span class="p">,</span> <span class="s1">'da'</span><span class="p">,</span> <span class="s1">'fo'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'no'</span><span class="p">,</span> <span class="s1">'nb'</span><span class="p">,</span> <span class="s1">'nn'</span><span class="p">,</span> <span class="s1">'sv'</span><span class="p">],</span>
 <span class="s1">'SCANDINAVIA'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'da'</span><span class="p">,</span> <span class="s1">'fo'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'no'</span><span class="p">,</span> <span class="s1">'nb'</span><span class="p">,</span> <span class="s1">'nn'</span><span class="p">,</span> <span class="s1">'sv'</span><span class="p">],</span>
 <span class="s1">'SAMI'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'se'</span><span class="p">,</span> <span class="s1">'sma'</span><span class="p">,</span> <span class="s1">'smj'</span><span class="p">,</span> <span class="s1">'smn'</span><span class="p">,</span> <span class="s1">'sms'</span><span class="p">],</span>
 <span class="s1">'NORWAY'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'nb_NO'</span><span class="p">,</span> <span class="s1">'nb'</span><span class="p">,</span> <span class="s1">'nn_NO'</span><span class="p">,</span> <span class="s1">'nn'</span><span class="p">,</span> <span class="s1">'nog'</span><span class="p">,</span> <span class="s1">'no_nb'</span><span class="p">,</span> <span class="s1">'no'</span><span class="p">],</span>
 <span class="s1">'CELTIC'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'ga'</span><span class="p">,</span> <span class="s1">'cy'</span><span class="p">,</span> <span class="s1">'br'</span><span class="p">,</span> <span class="s1">'gd'</span><span class="p">,</span> <span class="s1">'kw'</span><span class="p">,</span> <span class="s1">'gv'</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Example of translating english to many romance languages, using old-style 2 character language codes</p>
</div>
<div class="section" id="marianconfig">
<h2>MarianConfig<a class="headerlink" href="#marianconfig" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.MarianConfig"><a name="//apple_ref/cpp/Class/transformers.MarianConfig"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">MarianConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vocab_size</span><span class="o">=</span><span class="default_value">50265</span></em>, <em class="sig-param"><span class="n">max_position_embeddings</span><span class="o">=</span><span class="default_value">1024</span></em>, <em class="sig-param"><span class="n">encoder_layers</span><span class="o">=</span><span class="default_value">12</span></em>, <em class="sig-param"><span class="n">encoder_ffn_dim</span><span class="o">=</span><span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">encoder_attention_heads</span><span class="o">=</span><span class="default_value">16</span></em>, <em class="sig-param"><span class="n">decoder_layers</span><span class="o">=</span><span class="default_value">12</span></em>, <em class="sig-param"><span class="n">decoder_ffn_dim</span><span class="o">=</span><span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">decoder_attention_heads</span><span class="o">=</span><span class="default_value">16</span></em>, <em class="sig-param"><span class="n">encoder_layerdrop</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">decoder_layerdrop</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">is_encoder_decoder</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">activation_function</span><span class="o">=</span><span class="default_value">'gelu'</span></em>, <em class="sig-param"><span class="n">d_model</span><span class="o">=</span><span class="default_value">1024</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">attention_dropout</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">activation_dropout</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">init_std</span><span class="o">=</span><span class="default_value">0.02</span></em>, <em class="sig-param"><span class="n">decoder_start_token_id</span><span class="o">=</span><span class="default_value">58100</span></em>, <em class="sig-param"><span class="n">classifier_dropout</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">scale_embedding</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">gradient_checkpointing</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="o">=</span><span class="default_value">58100</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/configuration_marian.html#MarianConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the configuration class to store the configuration of a <a class="reference internal" href="#transformers.MarianModel" title="transformers.MarianModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianModel</span></code></a>. It is used to
instantiate an Marian model according to the specified arguments, defining the model architecture. Instantiating a
configuration with the defaults will yield a similar configuration to that of the Marian
<a class="reference external" href="https://huggingface.co/Helsinki-NLP/opus-mt-en-de">Helsinki-NLP/opus-mt-en-de</a> architecture.</p>
<p>Configuration objects inherit from <a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> and can be used to control the model
outputs. Read the documentation from <a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 50265) – Vocabulary size of the Marian model. Defines the number of different tokens that can be represented by the
<code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_ids</span></code> passed when calling <a class="reference internal" href="#transformers.MarianModel" title="transformers.MarianModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianModel</span></code></a> or
<a class="reference internal" href="#transformers.TFMarianModel" title="transformers.TFMarianModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFMarianModel</span></code></a>.</p></li>
<li><p><strong>d_model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1024) – Dimensionality of the layers and the pooler layer.</p></li>
<li><p><strong>encoder_layers</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 12) – Number of encoder layers.</p></li>
<li><p><strong>decoder_layers</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 12) – Number of decoder layers.</p></li>
<li><p><strong>encoder_attention_heads</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 16) – Number of attention heads for each attention layer in the Transformer encoder.</p></li>
<li><p><strong>decoder_attention_heads</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 16) – Number of attention heads for each attention layer in the Transformer decoder.</p></li>
<li><p><strong>decoder_ffn_dim</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 4096) – Dimensionality of the “intermediate” (often named feed-forward) layer in decoder.</p></li>
<li><p><strong>encoder_ffn_dim</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 4096) – Dimensionality of the “intermediate” (often named feed-forward) layer in decoder.</p></li>
<li><p><strong>activation_function</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">function</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">"gelu"</span></code>) – The non-linear activation function (function or string) in the encoder and pooler. If string,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">"gelu"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"relu"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"silu"</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">"gelu_new"</span></code> are supported.</p></li>
<li><p><strong>dropout</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.1) – The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.</p></li>
<li><p><strong>attention_dropout</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0) – The dropout ratio for the attention probabilities.</p></li>
<li><p><strong>activation_dropout</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0) – The dropout ratio for activations inside the fully connected layer.</p></li>
<li><p><strong>classifier_dropout</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0) – The dropout ratio for classifier.</p></li>
<li><p><strong>max_position_embeddings</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1024) – The maximum sequence length that this model might ever be used with. Typically set this to something large
just in case (e.g., 512 or 1024 or 2048).</p></li>
<li><p><strong>init_std</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.02) – The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p></li>
<li><p><strong>encoder_layerdrop</strong> – (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0):
The LayerDrop probability for the encoder. See the <a class="reference external" href="seehttps://arxiv.org/abs/1909.11556">LayerDrop paper</a> for more details.</p></li>
<li><p><strong>decoder_layerdrop</strong> – (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 0.0):
The LayerDrop probability for the decoder. See the <a class="reference external" href="seehttps://arxiv.org/abs/1909.11556">LayerDrop paper</a> for more details.</p></li>
<li><p><strong>gradient_checkpointing</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – If True, use gradient checkpointing to save memory at the expense of slower backward pass.</p></li>
<li><p><strong>scale_embedding</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Scale embeddings by diving by sqrt(d_model).</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – Whether or not the model should return the last key/values attentions (not used by all models)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianModel</span><span class="p">,</span> <span class="n">MarianConfig</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing a Marian Helsinki-NLP/opus-mt-en-de style configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">configuration</span> <span class="o">=</span> <span class="n">MarianConfig</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing a model from the Helsinki-NLP/opus-mt-en-de style configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MarianModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Accessing the model configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="mariantokenizer">
<h2>MarianTokenizer<a class="headerlink" href="#mariantokenizer" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.MarianTokenizer"><a name="//apple_ref/cpp/Class/transformers.MarianTokenizer"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">MarianTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/utils/dummy_sentencepiece_objects.html#MarianTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianTokenizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="marianmodel">
<h2>MarianModel<a class="headerlink" href="#marianmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.MarianModel"><a name="//apple_ref/cpp/Class/transformers.MarianModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">MarianModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">transformers.models.marian.configuration_marian.MarianConfig</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_marian.html#MarianModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianModel" title="Permalink to this definition">¶</a></dt>
<dd><p>The bare Marian Model outputting raw hidden-states without any specific head on top.
This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) – Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model weights.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.MarianModel.forward"><a name="//apple_ref/cpp/Method/transformers.MarianModel.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_dict</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_marian.html#MarianModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.MarianModel" title="transformers.MarianModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – <p>Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
it.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Indices of decoder input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
<p>Marian uses the <code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_token_id</span></code> as the starting token for <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> generation. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> have to be input (see
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p>
</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p>
<p>If you want to change padding behavior, you should read <code class="xref py py-func docutils literal notranslate"><span class="pre">modeling_marian._prepare_decoder_inputs()</span></code> and
modify to your needs. See diagram 1 in <a class="reference external" href="https://arxiv.org/abs/1910.13461">the paper</a> for more
information on the default strategy.</p>
</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) – Tuple consists of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">hidden_states</span></code>, <cite>optional</cite>:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">attentions</span></code>) <code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>,
<cite>optional</cite>) is a sequence of hidden-states at the output of the last layer of the encoder. Used in the
cross-attention of the decoder.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tuple[torch.Tensor]]</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code> with each tuple having 2 tuples each of which has 2 tensors of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length</span> <span class="pre">-</span> <span class="pre">1,</span> <span class="pre">embed_size_per_head)</span></code>) – <p>Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up decoding.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used, the user can optionally input only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
(those that don’t have their past key value states given to this model) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">1)</span></code>
instead of all <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids`</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>.</p>
</p></li>
<li><p><strong>inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> you can choose to directly pass an embedded representation.
This is useful if you want more control over how to convert <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> indices into associated
vectors than the model’s internal embedding lookup matrix.</p></li>
<li><p><strong>decoder_inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – <p>Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> you can choose to directly pass an embedded
representation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code>
have to be input (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>). This is useful if you want more control over how to convert
<code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> indices into associated vectors than the model’s internal embedding lookup matrix.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code> are both unset, <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code>
takes the value of <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_embeds</span></code>.</p>
</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>return_dict</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return a <a class="reference internal" href="../main_classes/output.html#transformers.file_utils.ModelOutput" title="transformers.file_utils.ModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelOutput</span></code></a> instead of a plain tuple.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqModelOutput" title="transformers.modeling_outputs.Seq2SeqModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqModelOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>) – Sequence of hidden-states at the output of the last layer of the decoder of the model.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used only the last hidden-state of the sequences of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">1,</span> <span class="pre">hidden_size)</span></code> is output.</p>
</li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tuple having 2 tensors
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>) and 2 additional tensors of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">encoder_sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>.</p>
<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
blocks) that can be used (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
<li><p><strong>cross_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the
weighted average in the cross-attention heads.</p>
</li>
<li><p><strong>encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the encoder of the model.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianTokenizer</span><span class="p">,</span> <span class="n">MarianModel</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'Helsinki-NLP/opus-mt-en-de'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MarianModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'Helsinki-NLP/opus-mt-en-de'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies have been shown that owning a dog is good for you"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"&lt;pad&gt; Studien haben gezeigt dass es hilfreich ist einen Hund zu besitzen"</span><span class="p">,</span>
<span class="gp">... </span><span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqModelOutput" title="transformers.modeling_outputs.Seq2SeqModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqModelOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="marianmtmodel">
<h2>MarianMTModel<a class="headerlink" href="#marianmtmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.MarianMTModel"><a name="//apple_ref/cpp/Class/transformers.MarianMTModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">MarianMTModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">transformers.models.marian.configuration_marian.MarianConfig</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_marian.html#MarianMTModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianMTModel" title="Permalink to this definition">¶</a></dt>
<dd><p>The Marian Model with a language modeling head. Can be used for summarization.
This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) – Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model weights.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.MarianMTModel.forward"><a name="//apple_ref/cpp/Method/transformers.MarianMTModel.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_dict</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_marian.html#MarianMTModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MarianMTModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.MarianMTModel" title="transformers.MarianMTModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianMTModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – <p>Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
it.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Indices of decoder input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
<p>Marian uses the <code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_token_id</span></code> as the starting token for <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> generation. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> have to be input (see
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p>
</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p>
<p>If you want to change padding behavior, you should read <code class="xref py py-func docutils literal notranslate"><span class="pre">modeling_marian._prepare_decoder_inputs()</span></code> and
modify to your needs. See diagram 1 in <a class="reference external" href="https://arxiv.org/abs/1910.13461">the paper</a> for more
information on the default strategy.</p>
</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) – Tuple consists of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">hidden_states</span></code>, <cite>optional</cite>:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">attentions</span></code>) <code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>,
<cite>optional</cite>) is a sequence of hidden-states at the output of the last layer of the encoder. Used in the
cross-attention of the decoder.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tuple[torch.Tensor]]</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code> with each tuple having 2 tuples each of which has 2 tensors of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length</span> <span class="pre">-</span> <span class="pre">1,</span> <span class="pre">embed_size_per_head)</span></code>) – <p>Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up decoding.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used, the user can optionally input only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
(those that don’t have their past key value states given to this model) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">1)</span></code>
instead of all <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids`</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>.</p>
</p></li>
<li><p><strong>inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> you can choose to directly pass an embedded representation.
This is useful if you want more control over how to convert <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> indices into associated
vectors than the model’s internal embedding lookup matrix.</p></li>
<li><p><strong>decoder_inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – <p>Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> you can choose to directly pass an embedded
representation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code>
have to be input (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>). This is useful if you want more control over how to convert
<code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> indices into associated vectors than the model’s internal embedding lookup matrix.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code> are both unset, <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_inputs_embeds</span></code>
takes the value of <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_embeds</span></code>.</p>
</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>return_dict</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return a <a class="reference internal" href="../main_classes/output.html#transformers.file_utils.ModelOutput" title="transformers.file_utils.ModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelOutput</span></code></a> instead of a plain tuple.</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – Labels for computing the masked language modeling loss. Indices should either be in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">...,</span>
<span class="pre">config.vocab_size]</span></code> or -100 (see <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> docstring). Tokens with indices set to <code class="docutils literal notranslate"><span class="pre">-100</span></code> are ignored
(masked), the loss is only computed for the tokens with labels in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">...,</span> <span class="pre">config.vocab_size]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqLMOutput" title="transformers.modeling_outputs.Seq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqLMOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) – Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tuple having 2 tensors
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>) and 2 additional tensors of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">encoder_sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>.</p>
<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
blocks) that can be used (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
<li><p><strong>cross_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the
weighted average in the cross-attention heads.</p>
</li>
<li><p><strong>encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the encoder of the model.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
</ul>
<p>Pytorch version of marian-nmt’s transformer.h (c++). Designed for the OPUS-NMT translation checkpoints.
Available models are listed <a class="reference external" href="https://huggingface.co/models?search=Helsinki-NLP">here</a>.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianTokenizer</span><span class="p">,</span> <span class="n">MarianMTModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="s1">'fr'</span>  <span class="c1"># source language</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trg</span> <span class="o">=</span> <span class="s1">'en'</span>  <span class="c1"># target language</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_text</span> <span class="o">=</span> <span class="s2">"où est l'arrêt de bus ?"</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mname</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'Helsinki-NLP/opus-mt-</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">trg</span><span class="si">}</span><span class="s1">'</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mname</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tok</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mname</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch</span> <span class="o">=</span> <span class="n">tok</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="n">src_texts</span><span class="o">=</span><span class="p">[</span><span class="n">sample_text</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>  <span class="c1"># don't need tgt_text for inference</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gen</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">tok</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># returns "Where is the bus stop ?"</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqLMOutput" title="transformers.modeling_outputs.Seq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqLMOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="tfmarianmodel">
<h2>TFMarianModel<a class="headerlink" href="#tfmarianmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.TFMarianModel"><a name="//apple_ref/cpp/Class/transformers.TFMarianModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">TFMarianModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_tf_marian.html#TFMarianModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TFMarianModel" title="Permalink to this definition">¶</a></dt>
<dd><p>The bare MARIAN Model outputting raw hidden-states without any specific head on top.
This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.TFPreTrainedModel" title="transformers.TFPreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFPreTrainedModel</span></code></a>. Check the superclass documentation for the
generic methods the library implements for all its model (such as downloading or saving, resizing the input
embeddings, pruning heads etc.)</p>
<p>This model is also a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">tf.keras.Model</a> subclass. Use
it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage
and behavior.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TF 2.0 models accepts two formats as inputs:</p>
<ul class="simple">
<li><p>having all inputs as keyword arguments (like PyTorch models), or</p></li>
<li><p>having all inputs as a list, tuple or dict in the first positional arguments.</p></li>
</ul>
<p>This second option is useful when using <code class="xref py py-meth docutils literal notranslate"><span class="pre">tf.keras.Model.fit()</span></code> method which currently requires having all
the tensors in the first argument of the model call function: <code class="xref py py-obj docutils literal notranslate"><span class="pre">model(inputs)</span></code>.</p>
<p>If you choose this second option, there are three possibilities you can use to gather all the input Tensors in
the first positional argument :</p>
<ul class="simple">
<li><p>a single Tensor with <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> only and nothing else: <code class="xref py py-obj docutils literal notranslate"><span class="pre">model(input_ids)</span></code></p></li>
<li><p>a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">model([input_ids,</span> <span class="pre">attention_mask])</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">model([input_ids,</span> <span class="pre">attention_mask,</span> <span class="pre">token_type_ids])</span></code></p></li>
<li><p>a dictionary with one or several input Tensors associated to the input names given in the docstring:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">model({"input_ids":</span> <span class="pre">input_ids,</span> <span class="pre">"token_type_ids":</span> <span class="pre">token_type_ids})</span></code></p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) – Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a class="reference internal" href="../main_classes/model.html#transformers.TFPreTrainedModel.from_pretrained" title="transformers.TFPreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the
model weights.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.TFMarianModel.call"><a name="//apple_ref/cpp/Method/transformers.TFMarianModel.call"></a>
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Union<span class="p">[</span>Tuple<span class="p">, </span><a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFBaseModelOutput" title="transformers.modeling_tf_outputs.TFBaseModelOutput">transformers.modeling_tf_outputs.TFBaseModelOutput</a><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_dict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_tf_marian.html#TFMarianModel.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TFMarianModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.TFMarianModel" title="transformers.TFMarianModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFMarianModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) – <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Indices of decoder input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
<p>Marian uses the <code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_token_id</span></code> as the starting token for <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> generation. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> have to be input (see
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p>
</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – will be made by default and ignore pad tokens. It is not recommended to set this for most use cases.</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.FloatTensor</span></code>, <cite>optional</cite>) – hidden states at the output of the last layer of the encoder. Used in the cross-attention of the decoder.
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code> is a sequence of</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tuple[tf.Tensor]]</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>) – contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used, the user can optionally input only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
(those that don’t have their past key value states given to this model) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">1)</span></code>
instead of all <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>). Set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code> during training, <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> during generation</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>return_dict</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return a <a class="reference internal" href="../main_classes/output.html#transformers.file_utils.ModelOutput" title="transformers.file_utils.ModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelOutput</span></code></a> instead of a plain tuple.</p></li>
<li><p><strong>training</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput" title="transformers.modeling_tf_outputs.TFSeq2SeqModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFSeq2SeqModelOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> comprising
various elements depending on the configuration (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>) – Sequence of hidden-states at the output of the last layer of the decoder of the model.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used only the last hidden-state of the sequences of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">1,</span> <span class="pre">hidden_size)</span></code> is output.</p>
</li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[tf.Tensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">batch_size,</span>
<span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains pre-computed hidden-states (key and values in the attention blocks) of the decoder that can be
used (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for the output of the embeddings + one for the output of each layer) of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span>
<span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
<li><p><strong>encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the encoder of the model.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for the output of the embeddings + one for the output of each layer) of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span>
<span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianTokenizer</span><span class="p">,</span> <span class="n">TFMarianModel</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'Helsinki-NLP/opus-mt-en-de'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">TFMarianModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'Helsinki-NLP/opus-mt-en-de'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Studies have been shown that owning a dog is good for you"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"&lt;pad&gt; Studien haben gezeigt dass es hilfreich ist einen Hund zu besitzen"</span><span class="p">,</span>
<span class="gp">... </span><span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput" title="transformers.modeling_tf_outputs.TFSeq2SeqModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFSeq2SeqModelOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="tfmarianmtmodel">
<h2>TFMarianMTModel<a class="headerlink" href="#tfmarianmtmodel" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="transformers.TFMarianMTModel"><a name="//apple_ref/cpp/Class/transformers.TFMarianMTModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">TFMarianMTModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_tf_marian.html#TFMarianMTModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TFMarianMTModel" title="Permalink to this definition">¶</a></dt>
<dd><p>The MARIAN Model with a language modeling head. Can be used for summarization.
This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.TFPreTrainedModel" title="transformers.TFPreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFPreTrainedModel</span></code></a>. Check the superclass documentation for the
generic methods the library implements for all its model (such as downloading or saving, resizing the input
embeddings, pruning heads etc.)</p>
<p>This model is also a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">tf.keras.Model</a> subclass. Use
it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage
and behavior.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TF 2.0 models accepts two formats as inputs:</p>
<ul class="simple">
<li><p>having all inputs as keyword arguments (like PyTorch models), or</p></li>
<li><p>having all inputs as a list, tuple or dict in the first positional arguments.</p></li>
</ul>
<p>This second option is useful when using <code class="xref py py-meth docutils literal notranslate"><span class="pre">tf.keras.Model.fit()</span></code> method which currently requires having all
the tensors in the first argument of the model call function: <code class="xref py py-obj docutils literal notranslate"><span class="pre">model(inputs)</span></code>.</p>
<p>If you choose this second option, there are three possibilities you can use to gather all the input Tensors in
the first positional argument :</p>
<ul class="simple">
<li><p>a single Tensor with <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> only and nothing else: <code class="xref py py-obj docutils literal notranslate"><span class="pre">model(input_ids)</span></code></p></li>
<li><p>a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">model([input_ids,</span> <span class="pre">attention_mask])</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">model([input_ids,</span> <span class="pre">attention_mask,</span> <span class="pre">token_type_ids])</span></code></p></li>
<li><p>a dictionary with one or several input Tensors associated to the input names given in the docstring:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">model({"input_ids":</span> <span class="pre">input_ids,</span> <span class="pre">"token_type_ids":</span> <span class="pre">token_type_ids})</span></code></p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) – Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a class="reference internal" href="../main_classes/model.html#transformers.TFPreTrainedModel.from_pretrained" title="transformers.TFPreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the
model weights.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.TFMarianMTModel.call"><a name="//apple_ref/cpp/Method/transformers.TFMarianMTModel.call"></a>
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span><a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFBaseModelOutput" title="transformers.modeling_tf_outputs.TFBaseModelOutput">transformers.modeling_tf_outputs.TFBaseModelOutput</a><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_dict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/marian/modeling_tf_marian.html#TFMarianMTModel.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TFMarianMTModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.TFMarianMTModel" title="transformers.TFMarianMTModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFMarianMTModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">({0})</span></code>) – <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">({0})</span></code>, <cite>optional</cite>) – <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – <p>Indices of decoder input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="#transformers.MarianTokenizer" title="transformers.MarianTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
<p>Marian uses the <code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_token_id</span></code> as the starting token for <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> generation. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> have to be input (see
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p>
</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) – will be made by default and ignore pad tokens. It is not recommended to set this for most use cases.</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.FloatTensor</span></code>, <cite>optional</cite>) – hidden states at the output of the last layer of the encoder. Used in the cross-attention of the decoder.
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code> is a sequence of</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tuple[tf.Tensor]]</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>) – contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used, the user can optionally input only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
(those that don’t have their past key value states given to this model) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">1)</span></code>
instead of all <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>). Set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code> during training, <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> during generation</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>return_dict</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) – Whether or not to return a <a class="reference internal" href="../main_classes/output.html#transformers.file_utils.ModelOutput" title="transformers.file_utils.ModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelOutput</span></code></a> instead of a plain tuple.</p></li>
<li><p><strong>training</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) – Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) – Labels for computing the masked language modeling loss. Indices should either be in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">...,</span>
<span class="pre">config.vocab_size]</span></code> or -100 (see <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> docstring). Tokens with indices set to <code class="docutils literal notranslate"><span class="pre">-100</span></code> are ignored
(masked), the loss is only computed for the tokens with labels in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">...,</span> <span class="pre">config.vocab_size]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput" title="transformers.modeling_tf_outputs.TFSeq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFSeq2SeqLMOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> comprising
various elements depending on the configuration (<a class="reference internal" href="#transformers.MarianConfig" title="transformers.MarianConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarianConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) – Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[tf.Tensor]</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) – List of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tensor of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">batch_size,</span>
<span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>).</p>
<p>Contains pre-computed hidden-states (key and values in the attention blocks) of the decoder that can be
used (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for the output of the embeddings + one for the output of each layer) of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span>
<span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
<li><p><strong>encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) – Sequence of hidden-states at the output of the last layer of the encoder of the model.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for the output of the embeddings + one for the output of each layer) of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) – Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span>
<span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
</ul>
<p>TF version of marian-nmt’s transformer.h (c++). Designed for the OPUS-NMT translation checkpoints. Available
models are listed <a class="reference external" href="https://huggingface.co/models?search=Helsinki-NLP">here</a>.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianTokenizer</span><span class="p">,</span> <span class="n">TFMarianMTModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="s1">'fr'</span>  <span class="c1"># source language</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trg</span> <span class="o">=</span> <span class="s1">'en'</span>  <span class="c1"># target language</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_text</span> <span class="o">=</span> <span class="s2">"où est l'arrêt de bus ?"</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mname</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'Helsinki-NLP/opus-mt-</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">trg</span><span class="si">}</span><span class="s1">'</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mname</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tok</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mname</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch</span> <span class="o">=</span> <span class="n">tok</span><span class="o">.</span><span class="n">prepare_seq2seq_batch</span><span class="p">(</span><span class="n">src_texts</span><span class="o">=</span><span class="p">[</span><span class="n">sample_text</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span>  <span class="c1"># don't need tgt_text for inference</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gen</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">tok</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># returns "Where is the bus stop ?"</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../main_classes/output.html#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput" title="transformers.modeling_tf_outputs.TFSeq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFSeq2SeqLMOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tf.Tensor)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="mbart.html" rel="next" title="MBart">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
<a accesskey="p" class="btn btn-neutral float-left" href="lxmert.html" rel="prev" title="LXMERT"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
</div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
</section>
</div>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Theme Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>
</body>
</html>