
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Encoder Decoder Models â€” transformers 4.2.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/huggingface.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/code-snippets.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/hidesidebar.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/js/custom.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="flaubert.html" rel="next" title="FlauBERT"/>
<link href="electra.html" rel="prev" title="ELECTRA"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html"> transformers
          

          
          </a>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<div aria-label="main navigation" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using ðŸ¤— Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">ðŸ¤— Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="electra.html">ELECTRA</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Encoder Decoder Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#encoderdecoderconfig">EncoderDecoderConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="#encoderdecodermodel">EncoderDecoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal/generation_utils.html">Utilities for Generation</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="top navigation" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">transformers</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a class="icon icon-home" href="../index.html"></a> Â»</li>
<li>Encoder Decoder Models</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/model_doc/encoderdecoder.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="encoder-decoder-models">
<h1>Encoder Decoder Models<a class="headerlink" href="#encoder-decoder-models" title="Permalink to this headline">Â¶</a></h1>
<p>The <a class="reference internal" href="#transformers.EncoderDecoderModel" title="transformers.EncoderDecoderModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderModel</span></code></a> can be used to initialize a sequence-to-sequence model with any
pretrained autoencoding model as the encoder and any pretrained autoregressive model as the decoder.</p>
<p>The effectiveness of initializing sequence-to-sequence models with pretrained checkpoints for sequence generation tasks
was shown in <a class="reference external" href="https://arxiv.org/abs/1907.12461">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a> by
Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</p>
<p>After such an <a class="reference internal" href="#transformers.EncoderDecoderModel" title="transformers.EncoderDecoderModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderModel</span></code></a> has been trained/fine-tuned, it can be saved/loaded just like
any other models (see the examples for more information).</p>
<p>An application of this architecture could be to leverage two pretrained <a class="reference internal" href="bert.html#transformers.BertModel" title="transformers.BertModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertModel</span></code></a> as the encoder
and decoder for a summarization model as was shown in: <a class="reference external" href="https://arxiv.org/abs/1908.08345">Text Summarization with Pretrained Encoders</a> by Yang Liu and Mirella Lapata.</p>
<div class="section" id="encoderdecoderconfig">
<h2>EncoderDecoderConfig<a class="headerlink" href="#encoderdecoderconfig" title="Permalink to this headline">Â¶</a></h2>
<dl class="py class">
<dt id="transformers.EncoderDecoderConfig"><a name="//apple_ref/cpp/Class/transformers.EncoderDecoderConfig"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">EncoderDecoderConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/encoder_decoder/configuration_encoder_decoder.html#EncoderDecoderConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderConfig" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a> is the configuration class to store the configuration of a
<a class="reference internal" href="#transformers.EncoderDecoderModel" title="transformers.EncoderDecoderModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderModel</span></code></a>. It is used to instantiate an Encoder Decoder model according to the
specified arguments, defining the encoder and decoder configs.</p>
<p>Configuration objects inherit from <a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> and can be used to control the model
outputs. Read the documentation from <a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a> for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<cite>optional</cite>) â€“ <p>Dictionary of keyword arguments. Notably:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a>, <cite>optional</cite>) â€“ An instance of a configuration
object that defines the encoder config.</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="../main_classes/configuration.html#transformers.PretrainedConfig" title="transformers.PretrainedConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedConfig</span></code></a>, <cite>optional</cite>) â€“ An instance of a configuration
object that defines the decoder config.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">EncoderDecoderConfig</span><span class="p">,</span> <span class="n">EncoderDecoderModel</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing a BERT bert-base-uncased style configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_encoder</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_decoder</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">EncoderDecoderConfig</span><span class="o">.</span><span class="n">from_encoder_decoder_configs</span><span class="p">(</span><span class="n">config_encoder</span><span class="p">,</span> <span class="n">config_decoder</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing a Bert2Bert model from the bert-base-uncased style configurations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Accessing the model configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_encoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">encoder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_decoder</span>  <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># set decoder config to causal lm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_decoder</span><span class="o">.</span><span class="n">is_decoder</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config_decoder</span><span class="o">.</span><span class="n">add_cross_attention</span> <span class="o">=</span> <span class="kc">True</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Saving the model, including its configuration</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s1">'my-model'</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># loading model and config from pretrained folder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_decoder_config</span> <span class="o">=</span> <span class="n">EncoderDecoderConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'my-model'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'my-model'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">encoder_decoder_config</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="transformers.EncoderDecoderConfig.from_encoder_decoder_configs"><a name="//apple_ref/cpp/Method/transformers.EncoderDecoderConfig.from_encoder_decoder_configs"></a>
<em class="property">classmethod </em><code class="sig-name descname">from_encoder_decoder_configs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_config</span><span class="p">:</span> <span class="n">transformers.configuration_utils.PretrainedConfig</span></em>, <em class="sig-param"><span class="n">decoder_config</span><span class="p">:</span> <span class="n">transformers.configuration_utils.PretrainedConfig</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> â†’ transformers.configuration_utils.PretrainedConfig<a class="reference internal" href="../_modules/transformers/models/encoder_decoder/configuration_encoder_decoder.html#EncoderDecoderConfig.from_encoder_decoder_configs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderConfig.from_encoder_decoder_configs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Instantiate a <a class="reference internal" href="#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a> (or a derived class) from a pre-trained encoder model
configuration and decoder model configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of a configuration object</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.EncoderDecoderConfig.to_dict"><a name="//apple_ref/cpp/Method/transformers.EncoderDecoderConfig.to_dict"></a>
<code class="sig-name descname">to_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/encoder_decoder/configuration_encoder_decoder.html#EncoderDecoderConfig.to_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderConfig.to_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Serializes this instance to a Python dictionary. Override the default <cite>to_dict()</cite> from <cite>PretrainedConfig</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of all the attributes that make up this configuration instance,</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">any]</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="encoderdecodermodel">
<h2>EncoderDecoderModel<a class="headerlink" href="#encoderdecodermodel" title="Permalink to this headline">Â¶</a></h2>
<dl class="py class">
<dt id="transformers.EncoderDecoderModel"><a name="//apple_ref/cpp/Class/transformers.EncoderDecoderModel"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">EncoderDecoderModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.configuration_utils.PretrainedConfig<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>transformers.modeling_utils.PreTrainedModel<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/encoder_decoder/modeling_encoder_decoder.html#EncoderDecoderModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This class can be used to initialize a sequence-to-sequence model with any pretrained autoencoding model as the
encoder and any pretrained autoregressive model as the decoder. The encoder is loaded via
<a class="reference internal" href="auto.html#transformers.AutoModel.from_pretrained" title="transformers.AutoModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> function and the decoder is loaded via
<a class="reference internal" href="auto.html#transformers.AutoModelForCausalLM.from_pretrained" title="transformers.AutoModelForCausalLM.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> function. Cross-attention layers are automatically added
to the decoder and should be fine-tuned on a downstream generative task, like summarization.</p>
<p>The effectiveness of initializing sequence-to-sequence models with pretrained checkpoints for sequence generation
tasks was shown in <a class="reference external" href="https://arxiv.org/abs/1907.12461">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a> by Sascha Rothe, Shashi Narayan, Aliaksei Severyn. Michael Matena, Yanqi
Zhou, Wei Li, Peter J. Liu.</p>
<p>After such an Encoder Decoder model has been trained/fine-tuned, it can be saved/loaded just like any other models
(see the examples for more information).</p>
<p>This model inherits from <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel" title="transformers.PreTrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedModel</span></code></a>. Check the superclass documentation for the generic
methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
pruning heads etc.)</p>
<p>This model is also a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">torch.nn.Module</a>
subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
general usage and behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="t5.html#transformers.T5Config" title="transformers.T5Config"><code class="xref py py-class docutils literal notranslate"><span class="pre">T5Config</span></code></a>) â€“ Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.from_pretrained" title="transformers.PreTrainedModel.from_pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_pretrained()</span></code></a> method to load the model
weights.</p>
</dd>
</dl>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoder</span></code> is a generic model class that will be instantiated as a transformer
architecture with one of the base model classes of the library as encoder and another one as decoder when created
with the :meth`~transformers.AutoModel.from_pretrained` class method for the encoder and
:meth`~transformers.AutoModelForCausalLM.from_pretrained` class method for the decoder.</p>
<dl class="py method">
<dt id="transformers.EncoderDecoderModel.forward"><a name="//apple_ref/cpp/Method/transformers.EncoderDecoderModel.forward"></a>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_input_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attention_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_outputs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">past_key_values</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_inputs_embeds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">labels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_cache</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_attentions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">output_hidden_states</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_dict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/models/encoder_decoder/modeling_encoder_decoder.html#EncoderDecoderModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderModel.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The <a class="reference internal" href="#transformers.EncoderDecoderModel" title="transformers.EncoderDecoderModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderModel</span></code></a> forward method, overrides the <code class="xref py py-func docutils literal notranslate"><span class="pre">__call__()</span></code> special method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within this function, one should call the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards instead of this since the former takes care of running the pre and post
processing steps while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer" title="transformers.PreTrainedTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) â€“ <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<ul>
<li><p>1 for tokens that are <strong>not masked</strong>,</p></li>
<li><p>0 for tokens that are <strong>masked</strong>.</p></li>
</ul>
<p><a class="reference external" href="../glossary.html#attention-mask">What are attention masks?</a></p>
</p></li>
<li><p><strong>decoder_input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) â€“ <p>Indices of decoder input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer" title="transformers.PreTrainedTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainedTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> is used, optionally only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> have to be input (see
<code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p>
<p>Provide for sequence to sequence training to the decoder. Indices can be obtained using
<code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedTokenizer</span></code>. See <code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and
<a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for details.</p>
</p></li>
<li><p><strong>decoder_attention_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.BoolTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length)</span></code>, <cite>optional</cite>) â€“ Default behavior: generate a tensor that ignores pad tokens in <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>. Causal mask will
also be used by default.</p></li>
<li><p><strong>encoder_outputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>) â€“ This tuple must consist of (<code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code>, <cite>optional</cite>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">hidden_states</span></code>, <cite>optional</cite>:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">attentions</span></code>) <code class="xref py py-obj docutils literal notranslate"><span class="pre">last_hidden_state</span></code> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>) is a tensor of hidden-states at the output of the last layer of the
encoder. Used in the cross-attention of the decoder.</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code> with each tuple having 4 tensors of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length</span> <span class="pre">-</span> <span class="pre">1,</span> <span class="pre">embed_size_per_head)</span></code>) â€“ <p>Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> are used, the user can optionally input only the last <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
(those that donâ€™t have their past key value states given to this model) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">1)</span></code>
instead of all <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>.</p>
</p></li>
<li><p><strong>inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) â€“ Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> you can choose to directly pass an embedded representation.
This is useful if you want more control over how to convert <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> indices into associated
vectors than the modelâ€™s internal embedding lookup matrix.</p></li>
<li><p><strong>decoder_inputs_embeds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">target_sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) â€“ Optionally, instead of passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code> you can choose to directly pass an embedded
representation. This is useful if you want more control over how to convert <code class="xref py py-obj docutils literal notranslate"><span class="pre">decoder_input_ids</span></code>
indices into associated vectors than the modelâ€™s internal embedding lookup matrix.</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>, <cite>optional</cite>) â€“ Labels for computing the masked language modeling loss for the decoder. Indices should be in <code class="docutils literal notranslate"><span class="pre">[-100,</span> <span class="pre">0,</span>
<span class="pre">...,</span> <span class="pre">config.vocab_size]</span></code> (see <code class="docutils literal notranslate"><span class="pre">input_ids</span></code> docstring) Tokens with indices set to <code class="docutils literal notranslate"><span class="pre">-100</span></code> are ignored
(masked), the loss is only computed for the tokens with labels in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">...,</span> <span class="pre">config.vocab_size]</span></code></p></li>
<li><p><strong>use_cache</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) â€“ If set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> key value states are returned and can be used to speed up
decoding (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code>).</p></li>
<li><p><strong>output_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) â€“ Whether or not to return the attentions tensors of all attention layers. See <code class="docutils literal notranslate"><span class="pre">attentions</span></code> under returned
tensors for more detail.</p></li>
<li><p><strong>output_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) â€“ Whether or not to return the hidden states of all layers. See <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> under returned tensors for
more detail.</p></li>
<li><p><strong>return_dict</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>) â€“ If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the model will return a <code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqLMOutput</span></code> instead of a
plain tuple.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>(<cite>optional</cite>) Remaining dictionary of keyword arguments. Keyword arguments come in two flavors:</p>
<ul>
<li><p>Without a prefix which will be input as <code class="docutils literal notranslate"><span class="pre">**encoder_kwargs</span></code> for the encoder forward function.</p></li>
<li><p>With a <cite>decoder_</cite> prefix which will be input as <code class="docutils literal notranslate"><span class="pre">**decoder_kwargs</span></code> for the decoder forward function.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqLMOutput" title="transformers.modeling_outputs.Seq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqLMOutput</span></code></a> (if
<code class="docutils literal notranslate"><span class="pre">return_dict=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.return_dict=True</span></code>) or a tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>
comprising various elements depending on the configuration (<a class="reference internal" href="#transformers.EncoderDecoderConfig" title="transformers.EncoderDecoderConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderDecoderConfig</span></code></a>) and inputs.</p>
<ul>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(1,)</span></code>, <cite>optional</cite>, returned when <code class="xref py py-obj docutils literal notranslate"><span class="pre">labels</span></code> is provided) â€“ Language modeling loss.</p></li>
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p></li>
<li><p><strong>past_key_values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">use_cache=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.use_cache=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">config.n_layers</span></code>, with each tuple having 2 tensors
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>) and 2 additional tensors of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">encoder_sequence_length,</span> <span class="pre">embed_size_per_head)</span></code>.</p>
<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
blocks) that can be used (see <code class="xref py py-obj docutils literal notranslate"><span class="pre">past_key_values</span></code> input) to speed up sequential decoding.</p>
</li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
<li><p><strong>cross_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the decoderâ€™s cross-attention layer, after the attention softmax, used to compute the
weighted average in the cross-attention heads.</p>
</li>
<li><p><strong>encoder_last_hidden_state</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>, <cite>optional</cite>) â€“ Sequence of hidden-states at the output of the last layer of the encoder of the model.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>
</li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span>
<span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p>
<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the
self-attention heads.</p>
</li>
</ul>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">EncoderDecoderModel</span><span class="p">,</span> <span class="n">BertTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'bert-base-uncased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_encoder_decoder_pretrained</span><span class="p">(</span><span class="s1">'bert-base-uncased'</span><span class="p">,</span> <span class="s1">'bert-base-uncased'</span><span class="p">)</span> <span class="c1"># initialize Bert2Bert from pre-trained checkpoints</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># forward</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"Hello, my dog is cute"</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Batch size 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># training</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># save and load from pretrained</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">"bert2bert"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert2bert"</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_start_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
</pre></div>
</div>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../main_classes/output.html#transformers.modeling_outputs.Seq2SeqLMOutput" title="transformers.modeling_outputs.Seq2SeqLMOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">Seq2SeqLMOutput</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.EncoderDecoderModel.from_encoder_decoder_pretrained"><a name="//apple_ref/cpp/Method/transformers.EncoderDecoderModel.from_encoder_decoder_pretrained"></a>
<em class="property">classmethod </em><code class="sig-name descname">from_encoder_decoder_pretrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">model_args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> â†’ transformers.modeling_utils.PreTrainedModel<a class="reference internal" href="../_modules/transformers/models/encoder_decoder/modeling_encoder_decoder.html#EncoderDecoderModel.from_encoder_decoder_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.EncoderDecoderModel.from_encoder_decoder_pretrained" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Instantiate an encoder and a decoder from one or two base classes of the library from pretrained model
checkpoints.</p>
<p>The model is set in evaluation mode by default using <code class="xref py py-obj docutils literal notranslate"><span class="pre">model.eval()</span></code> (Dropout modules are deactivated). To
train the model, you need to first set it back in training mode with <code class="xref py py-obj docutils literal notranslate"><span class="pre">model.train()</span></code>.</p>
<dl>
<dt>Params:</dt><dd><dl>
<dt>encoder_pretrained_model_name_or_path (:obj: <cite>str</cite>, <cite>optional</cite>):</dt><dd><p>Information necessary to initiate the encoder. Can be either:</p>
<blockquote>
<div><ul class="simple">
<li><p>A string, the <cite>model id</cite> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code>, or namespaced under
a user or organization name, like <code class="docutils literal notranslate"><span class="pre">dbmdz/bert-base-german-cased</span></code>.</p></li>
<li><p>A path to a <cite>directory</cite> containing model weights saved using
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.save_pretrained" title="transformers.PreTrainedModel.save_pretrained"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_pretrained()</span></code></a>, e.g., <code class="docutils literal notranslate"><span class="pre">./my_model_directory/</span></code>.</p></li>
<li><p>A path or url to a <cite>tensorflow index checkpoint file</cite> (e.g, <code class="docutils literal notranslate"><span class="pre">./tf_model/model.ckpt.index</span></code>). In
this case, <code class="docutils literal notranslate"><span class="pre">from_tf</span></code> should be set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> and a configuration object should be provided
as <code class="docutils literal notranslate"><span class="pre">config</span></code> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</p></li>
</ul>
</div></blockquote>
</dd>
<dt>decoder_pretrained_model_name_or_path (:obj: <cite>str</cite>, <cite>optional</cite>, defaults to <cite>None</cite>):</dt><dd><p>Information necessary to initiate the decoder. Can be either:</p>
<blockquote>
<div><ul class="simple">
<li><p>A string, the <cite>model id</cite> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code>, or namespaced under
a user or organization name, like <code class="docutils literal notranslate"><span class="pre">dbmdz/bert-base-german-cased</span></code>.</p></li>
<li><p>A path to a <cite>directory</cite> containing model weights saved using
<a class="reference internal" href="../main_classes/model.html#transformers.PreTrainedModel.save_pretrained" title="transformers.PreTrainedModel.save_pretrained"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_pretrained()</span></code></a>, e.g., <code class="docutils literal notranslate"><span class="pre">./my_model_directory/</span></code>.</p></li>
<li><p>A path or url to a <cite>tensorflow index checkpoint file</cite> (e.g, <code class="docutils literal notranslate"><span class="pre">./tf_model/model.ckpt.index</span></code>). In
this case, <code class="docutils literal notranslate"><span class="pre">from_tf</span></code> should be set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> and a configuration object should be provided
as <code class="docutils literal notranslate"><span class="pre">config</span></code> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</p></li>
</ul>
</div></blockquote>
</dd>
<dt>model_args (remaining positional arguments, <cite>optional</cite>):</dt><dd><p>All remaning positional arguments will be passed to the underlying modelâ€™s <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</p>
</dd>
<dt>kwargs (remaining dictionary of keyword arguments, <cite>optional</cite>):</dt><dd><p>Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">output_attentions=True</span></code>).</p>
<ul class="simple">
<li><p>To update the encoder configuration, use the prefix <cite>encoder_</cite> for each configuration parameter.</p></li>
<li><p>To update the decoder configuration, use the prefix <cite>decoder_</cite> for each configuration parameter.</p></li>
<li><p>To update the parent model configuration, do not use a prefix for each configuration parameter.</p></li>
</ul>
<p>Behaves differently depending on whether a <code class="xref py py-obj docutils literal notranslate"><span class="pre">config</span></code> is provided or automatically loaded.</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">EncoderDecoderModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a bert2bert from two pretrained BERT models. Note that the cross-attention layers will be randomly initialized</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_encoder_decoder_pretrained</span><span class="p">(</span><span class="s1">'bert-base-uncased'</span><span class="p">,</span> <span class="s1">'bert-base-uncased'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># saving model after fine-tuning</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">"./bert2bert"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load fine-tuned model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoderModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"./bert2bert"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="flaubert.html" rel="next" title="FlauBERT">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
<a accesskey="p" class="btn btn-neutral float-left" href="electra.html" rel="prev" title="ELECTRA"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        Â© Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
</div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
</section>
</div>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Theme Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>
</body>
</html>