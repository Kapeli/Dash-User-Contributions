
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Utilities for Generation â€” transformers 4.2.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/huggingface.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/code-snippets.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/hidesidebar.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/js/custom.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="trainer_utils.html" rel="prev" title="Utilities for Trainer"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html"> transformers
          

          
          </a>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<div aria-label="main navigation" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using ðŸ¤— Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">ðŸ¤— Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_doc/xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Utilities for Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#generate-outputs">Generate Outputs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#greedysearchoutput">GreedySearchOutput</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sampleoutput">SampleOutput</a></li>
<li class="toctree-l3"><a class="reference internal" href="#beamsearchoutput">BeamSearchOutput</a></li>
<li class="toctree-l3"><a class="reference internal" href="#beamsampleoutput">BeamSampleOutput</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#logitsprocessor">LogitsProcessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#beamsearch">BeamSearch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a></li>
</ul>
</li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="top navigation" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">transformers</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a class="icon icon-home" href="../index.html"></a> Â»</li>
<li>Utilities for Generation</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/internal/generation_utils.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="utilities-for-generation">
<h1>Utilities for Generation<a class="headerlink" href="#utilities-for-generation" title="Permalink to this headline">Â¶</a></h1>
<p>This page lists all the utility functions used by <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">greedy_search()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">sample()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">beam_search()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">beam_sample()</span></code>, and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">group_beam_search()</span></code>.</p>
<p>Most of those are only useful if you are studying the code of the generate methods in the library.</p>
<div class="section" id="generate-outputs">
<h2>Generate Outputs<a class="headerlink" href="#generate-outputs" title="Permalink to this headline">Â¶</a></h2>
<p>The output of <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate()</span></code> is an instance of a subclass of
<a class="reference internal" href="../main_classes/output.html#transformers.file_utils.ModelOutput" title="transformers.file_utils.ModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelOutput</span></code></a>. This output is a data structure containing all the information returned
by <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate()</span></code>, but that can also be used as tuple or dictionary.</p>
<p>Hereâ€™s an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'gpt2'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'gpt2'</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Hello, my dog is cute and "</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="n">generation_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">return_dict_in_generate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">generation_output</span></code> object is a <a class="reference internal" href="#transformers.generation_utils.GreedySearchDecoderOnlyOutput" title="transformers.generation_utils.GreedySearchDecoderOnlyOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">GreedySearchDecoderOnlyOutput</span></code></a>, as we can
see in the documentation of that class below, it means it has the following attributes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sequences</span></code>: the generated sequences of tokens</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scores</span></code> (optional): the prediction scores of the language modelling head, for each generation step</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> (optional): the hidden states of the model, for each generation step</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attentions</span></code> (optional): the attention weights of the model, for each generation step</p></li>
</ul>
<p>Here we have the <code class="docutils literal notranslate"><span class="pre">scores</span></code> since we passed along <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code>, but we donâ€™t have <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> and
<code class="docutils literal notranslate"><span class="pre">attentions</span></code> because we didnâ€™t pass <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> or <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code>.</p>
<p>You can access each attribute as you would usually do, and if that attribute has not been returned by the model, you
will get <code class="docutils literal notranslate"><span class="pre">None</span></code>. Here for instance <code class="docutils literal notranslate"><span class="pre">generation_output.scores</span></code> are all the generated prediction scores of the
language modeling head, and <code class="docutils literal notranslate"><span class="pre">generation_output.attentions</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>When using our <code class="docutils literal notranslate"><span class="pre">generation_output</span></code> object as a tuple, it only keeps the attributes that donâ€™t have <code class="docutils literal notranslate"><span class="pre">None</span></code> values.
Here, for instance, it has two elements, <code class="docutils literal notranslate"><span class="pre">loss</span></code> then <code class="docutils literal notranslate"><span class="pre">logits</span></code>, so</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">generation_output</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>will return the tuple <code class="docutils literal notranslate"><span class="pre">(generation_output.sequences,</span> <span class="pre">generation_output.scores)</span></code> for instance.</p>
<p>When using our <code class="docutils literal notranslate"><span class="pre">generation_output</span></code> object as a dictionary, it only keeps the attributes that donâ€™t have <code class="docutils literal notranslate"><span class="pre">None</span></code>
values. Here, for instance, it has two keys that are <code class="docutils literal notranslate"><span class="pre">sequences</span></code> and <code class="docutils literal notranslate"><span class="pre">scores</span></code>.</p>
<p>We document here all output types.</p>
<div class="section" id="greedysearchoutput">
<h3>GreedySearchOutput<a class="headerlink" href="#greedysearchoutput" title="Permalink to this headline">Â¶</a></h3>
<dl class="py class">
<dt id="transformers.generation_utils.GreedySearchDecoderOnlyOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.GreedySearchDecoderOnlyOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">GreedySearchDecoderOnlyOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#GreedySearchDecoderOnlyOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.GreedySearchDecoderOnlyOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of decoder-only generation models using greedy search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.generation_utils.GreedySearchEncoderDecoderOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.GreedySearchEncoderDecoderOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">GreedySearchEncoderDecoderOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#GreedySearchEncoderDecoderOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.GreedySearchEncoderDecoderOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of encoder-decoder generation models using greedy search. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer of the decoder) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="sampleoutput">
<h3>SampleOutput<a class="headerlink" href="#sampleoutput" title="Permalink to this headline">Â¶</a></h3>
<dl class="py class">
<dt id="transformers.generation_utils.SampleDecoderOnlyOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.SampleDecoderOnlyOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">SampleDecoderOnlyOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#SampleDecoderOnlyOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.SampleDecoderOnlyOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of decoder-only generation models using sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(num_return_sequences*batch_size,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span>
<span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(num_return_sequences*batch_size,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.generation_utils.SampleEncoderDecoderOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.SampleEncoderDecoderOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">SampleEncoderDecoderOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#SampleEncoderDecoderOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.SampleEncoderDecoderOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of encoder-decoder generation models using sampling. Hidden states and attention weights of
the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer of the decoder) of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span>
<span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="beamsearchoutput">
<h3>BeamSearchOutput<a class="headerlink" href="#beamsearchoutput" title="Permalink to this headline">Â¶</a></h3>
<dl class="py class">
<dt id="transformers.generation_utils.BeamSearchDecoderOnlyOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.BeamSearchDecoderOnlyOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">BeamSearchDecoderOnlyOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sequences_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#BeamSearchDecoderOnlyOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.BeamSearchDecoderOnlyOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of decoder-only generation models using beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>sequences_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Final beam scores of the generated <code class="docutils literal notranslate"><span class="pre">sequences</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span>
<span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">generated_length,</span>
<span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.generation_utils.BeamSearchEncoderDecoderOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.BeamSearchEncoderDecoderOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">BeamSearchEncoderDecoderOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sequences_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#BeamSearchEncoderDecoderOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.BeamSearchEncoderDecoderOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of encoder-decoder generation models using beam search. Hidden states and attention weights
of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>sequences_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Final beam scores of the generated <code class="docutils literal notranslate"><span class="pre">sequences</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ </p></li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer of the decoder) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">num_heads,</span>
<span class="pre">generated_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">generated_length,</span>
<span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="beamsampleoutput">
<h3>BeamSampleOutput<a class="headerlink" href="#beamsampleoutput" title="Permalink to this headline">Â¶</a></h3>
<dl class="py class">
<dt id="transformers.generation_utils.BeamSampleDecoderOnlyOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.BeamSampleDecoderOnlyOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">BeamSampleDecoderOnlyOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sequences_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#BeamSampleDecoderOnlyOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.BeamSampleDecoderOnlyOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of decoder-only generation models using beam sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_return_sequences,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>sequences_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequence)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Final beam scores of the generated <code class="docutils literal notranslate"><span class="pre">sequences</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams*num_return_sequences,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span>
<span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.generation_utils.BeamSampleEncoderDecoderOutput"><a name="//apple_ref/cpp/Class/transformers.generation_utils.BeamSampleEncoderDecoderOutput"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.generation_utils.</code><code class="sig-name descname">BeamSampleEncoderDecoderOutput</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequences</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.LongTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sequences_scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.FloatTensor<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_attentions</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">decoder_hidden_states</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Tuple<span class="p">[</span>Tuple<span class="p">[</span>torch.FloatTensor<span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_utils.html#BeamSampleEncoderDecoderOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.generation_utils.BeamSampleEncoderDecoderOutput" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for outputs of encoder-decoder generation models using beam sampling. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">sequence_length)</span></code>) â€“ The generated sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or
shorter if all batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p></li>
<li><p><strong>sequences_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequence)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Final beam scores of the generated <code class="docutils literal notranslate"><span class="pre">sequences</span></code>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code> <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_scores=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_scores=True</span></code>) â€“ Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code class="xref py py-obj docutils literal notranslate"><span class="pre">(max_length,)</span></code>-shaped tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> with each tensor of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">config.vocab_size)</span></code>).</p></li>
<li><p><strong>encoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for each layer of the decoder) of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span>
<span class="pre">num_heads,</span> <span class="pre">sequence_length,</span> <span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>encoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(torch.FloatTensor)</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> (one for the output of the embeddings + one for the output of each layer)
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
<li><p><strong>decoder_attentions</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_attentions=True</span></code> is passed or <code class="docutils literal notranslate"><span class="pre">config.output_attentions=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">num_heads,</span> <span class="pre">generated_length,</span>
<span class="pre">sequence_length)</span></code>.</p></li>
<li><p><strong>decoder_hidden_states</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple(tuple(torch.FloatTensor))</span></code>, <cite>optional</cite>, returned when <code class="docutils literal notranslate"><span class="pre">output_hidden_states=True</span></code> is passed or when <code class="docutils literal notranslate"><span class="pre">config.output_hidden_states=True</span></code>) â€“ Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size*num_beams,</span> <span class="pre">generated_length,</span> <span class="pre">hidden_size)</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
</div>
<div class="section" id="logitsprocessor">
<h2>LogitsProcessor<a class="headerlink" href="#logitsprocessor" title="Permalink to this headline">Â¶</a></h2>
<p>A <a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogitsProcessor</span></code></a> can be used to modify the prediction scores of a language model head for
generation.</p>
<dl class="py class">
<dt id="transformers.LogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.LogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">LogitsProcessor</code><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Abstract base class for all logit processors that can be applied during generation.</p>
<dl class="py method">
<dt id="transformers.LogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.LogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><blockquote>
<div><dl>
<dt>Args:</dt><dd><dl>
<dt>input_ids (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>):</dt><dd><p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</dd>
<dt>scores (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>):</dt><dd><p>Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p>
</dd>
<dt>kwargs:</dt><dd><p>Additional logits processor specific kwargs.</p>
</dd>
</dl>
</dd>
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</div></blockquote>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.LogitsProcessorList"><a name="//apple_ref/cpp/Class/transformers.LogitsProcessorList"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">LogitsProcessorList</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">iterable</span><span class="o">=</span><span class="default_value">()</span></em>, <em class="sig-param"><span class="o">/</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsProcessorList"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsProcessorList" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This class can be used to create a list of <a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogitsProcessor</span></code></a> or
<a class="reference internal" href="#transformers.LogitsWarper" title="transformers.LogitsWarper"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogitsWarper</span></code></a> to subsequently process a <code class="xref py py-obj docutils literal notranslate"><span class="pre">scores</span></code> input tensor. This class inherits from
list and adds a specific <cite>__call__</cite> method to apply each <a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogitsProcessor</span></code></a> or
<a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogitsProcessor</span></code></a> to the inputs.</p>
<dl class="py method">
<dt id="transformers.LogitsProcessorList.__call__"><a name="//apple_ref/cpp/Method/transformers.LogitsProcessorList.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsProcessorList.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsProcessorList.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ Additional logits processor specific kwargs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The processed prediction scores.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.LogitsWarper"><a name="//apple_ref/cpp/Class/transformers.LogitsWarper"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">LogitsWarper</code><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsWarper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsWarper" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Abstract base class for all logit warpers that can be applied during generation with multinomial sampling.</p>
<dl class="py method">
<dt id="transformers.LogitsWarper.__call__"><a name="//apple_ref/cpp/Method/transformers.LogitsWarper.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#LogitsWarper.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.LogitsWarper.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><blockquote>
<div><dl>
<dt>Args:</dt><dd><dl>
<dt>input_ids (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>):</dt><dd><p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</dd>
<dt>scores (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>):</dt><dd><p>Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p>
</dd>
<dt>kwargs:</dt><dd><p>Additional logits processor specific kwargs.</p>
</dd>
</dl>
</dd>
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</div></blockquote>
<p>Torch method for warping logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.MinLengthLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.MinLengthLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">MinLengthLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">min_length</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#MinLengthLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MinLengthLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> enforcing a min-length by setting EOS probability to 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min_length</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ The minimum length below which the score of <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code> is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">-float("Inf")</span></code>.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.MinLengthLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.MinLengthLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#MinLengthLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.MinLengthLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.TemperatureLogitsWarper"><a name="//apple_ref/cpp/Class/transformers.TemperatureLogitsWarper"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">TemperatureLogitsWarper</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">temperature</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TemperatureLogitsWarper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TemperatureLogitsWarper" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsWarper" title="transformers.LogitsWarper"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsWarper</span></code></a> for temperature (exponential scaling output probability distribution).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>temperature</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) â€“ The value used to module the logits distribution.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.TemperatureLogitsWarper.__call__"><a name="//apple_ref/cpp/Method/transformers.TemperatureLogitsWarper.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> â†’ torch.Tensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TemperatureLogitsWarper.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TemperatureLogitsWarper.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for warping logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.RepetitionPenaltyLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.RepetitionPenaltyLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">RepetitionPenaltyLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">penalty</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#RepetitionPenaltyLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RepetitionPenaltyLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> enforcing an exponential penalty on repeated sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>repetition_penalty</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) â€“ The parameter for repetition penalty. 1.0 means no penalty. See <a class="reference external" href="https://arxiv.org/pdf/1909.05858.pdf">this paper</a> for more details.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.RepetitionPenaltyLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.RepetitionPenaltyLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#RepetitionPenaltyLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.RepetitionPenaltyLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.TopPLogitsWarper"><a name="//apple_ref/cpp/Class/transformers.TopPLogitsWarper"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">TopPLogitsWarper</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">top_p</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">filter_value</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">- inf</span></em>, <em class="sig-param"><span class="n">min_tokens_to_keep</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TopPLogitsWarper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TopPLogitsWarper" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsWarper" title="transformers.LogitsWarper"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsWarper</span></code></a> that performs top-p, i.e. restricting to top tokens summing to prob_cut_off &lt;=
prob_cut_off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>top_p</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) â€“ If set to &lt; 1, only the most probable tokens with probabilities that add up to <code class="xref py py-obj docutils literal notranslate"><span class="pre">top_p</span></code> or higher are
kept for generation.</p></li>
<li><p><strong>filter_value</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">-float("Inf")</span></code>) â€“ All filtered values will be set to this float value.</p></li>
<li><p><strong>min_tokens_to_keep</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) â€“ Minimum number of tokens that cannot be filtered.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.TopPLogitsWarper.__call__"><a name="//apple_ref/cpp/Method/transformers.TopPLogitsWarper.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TopPLogitsWarper.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TopPLogitsWarper.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for warping logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.TopKLogitsWarper"><a name="//apple_ref/cpp/Class/transformers.TopKLogitsWarper"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">TopKLogitsWarper</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">top_k</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">filter_value</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">- inf</span></em>, <em class="sig-param"><span class="n">min_tokens_to_keep</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TopKLogitsWarper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TopKLogitsWarper" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsWarper" title="transformers.LogitsWarper"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsWarper</span></code></a> that performs top-k, i.e. restricting to the k highest probability elements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>top_k</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ The number of highest probability vocabulary tokens to keep for top-k-filtering.</p></li>
<li><p><strong>filter_value</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">-float("Inf")</span></code>) â€“ All filtered values will be set to this float value.</p></li>
<li><p><strong>min_tokens_to_keep</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) â€“ Minimum number of tokens that cannot be filtered.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.TopKLogitsWarper.__call__"><a name="//apple_ref/cpp/Method/transformers.TopKLogitsWarper.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#TopKLogitsWarper.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.TopKLogitsWarper.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for warping logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.NoRepeatNGramLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.NoRepeatNGramLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">NoRepeatNGramLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ngram_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#NoRepeatNGramLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.NoRepeatNGramLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> that enforces no repetition of n-grams. See <a class="reference external" href="https://github.com/pytorch/fairseq/blob/a07cb6f40480928c9e0548b737aadd36ee66ac76/fairseq/sequence_generator.py#L345">Fairseq</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ngram_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ All ngrams of size <code class="xref py py-obj docutils literal notranslate"><span class="pre">ngram_size</span></code> can only occur once.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.NoRepeatNGramLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.NoRepeatNGramLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#NoRepeatNGramLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.NoRepeatNGramLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.NoBadWordsLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.NoBadWordsLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">NoBadWordsLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">bad_words_ids</span><span class="p">:</span> <span class="n">Iterable<span class="p">[</span>Iterable<span class="p">[</span>int<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#NoBadWordsLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.NoBadWordsLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> that enforces that specified sequences will never be sampled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bad_words_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[List[int]]</span></code>) â€“ List of list of token ids that are not allowed to be generated. In order to get the tokens of the words
that should not appear in the generated text, use <code class="xref py py-obj docutils literal notranslate"><span class="pre">tokenizer(bad_word,</span>
<span class="pre">add_prefix_space=True).input_ids</span></code>.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.NoBadWordsLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.NoBadWordsLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#NoBadWordsLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.NoBadWordsLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.PrefixConstrainedLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.PrefixConstrainedLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">PrefixConstrainedLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">prefix_allowed_tokens_fn</span><span class="p">:</span> <span class="n">Callable<span class="p">[</span><span class="p">[</span>int<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>List<span class="p">[</span>int<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">num_beams</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#PrefixConstrainedLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.PrefixConstrainedLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> that enforces contrained generation and is useful for prefix-conditioned
constrained generation. See <a class="reference external" href="https://arxiv.org/abs/2010.00904">Autoregressive Entity Retrieval</a> for more
information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix_allowed_tokens_fn</strong> â€“ (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Callable[[int,</span> <span class="pre">torch.Tensor],</span> <span class="pre">List[int]]</span></code>):
This function constraints the beam search to allowed tokens only at each step. This function takes 2
arguments <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_ids</span></code> and the batch ID <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_id</span></code>. It has to return a list with the allowed
tokens for the next generation step conditioned on the previously generated tokens <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs_ids</span></code> and
the batch ID <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_id</span></code>.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.PrefixConstrainedLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.PrefixConstrainedLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#PrefixConstrainedLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.PrefixConstrainedLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.HammingDiversityLogitsProcessor"><a name="//apple_ref/cpp/Class/transformers.HammingDiversityLogitsProcessor"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">HammingDiversityLogitsProcessor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">diversity_penalty</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">num_beams</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">num_beam_groups</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_logits_process.html#HammingDiversityLogitsProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.HammingDiversityLogitsProcessor" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.LogitsProcessor" title="transformers.LogitsProcessor"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.LogitsProcessor</span></code></a> that enforces diverse beam search. Note that this logits processor is only
effective for <code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PretrainedModel.group_beam_search()</span></code>. See <a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">Diverse Beam Search: Decoding Diverse
Solutions from Neural Sequence Models</a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>diversity_penalty</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) â€“ This value is subtracted from a beamâ€™s score if it generates a token same as any beam from other group at a
particular time. Note that <code class="xref py py-obj docutils literal notranslate"><span class="pre">diversity_penalty</span></code> is only effective if <code class="docutils literal notranslate"><span class="pre">group</span> <span class="pre">beam</span> <span class="pre">search</span></code> is enabled.</p></li>
<li><p><strong>num_beams</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ Number of beams used for group beam search. See <a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">this paper</a> for
more details.</p></li>
<li><p><strong>num_beam_groups</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ Number of groups to divide <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_beams</span></code> into in order to ensure diversity among different groups of
beams. See <a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">this paper</a> for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.HammingDiversityLogitsProcessor.__call__"><a name="//apple_ref/cpp/Method/transformers.HammingDiversityLogitsProcessor.__call__"></a>
<code class="sig-name descname">__call__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">current_tokens</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">beam_group_idx</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_logits_process.html#HammingDiversityLogitsProcessor.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.HammingDiversityLogitsProcessor.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a class="reference internal" href="../model_doc/bert.html#transformers.BertTokenizer" title="transformers.BertTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BertTokenizer</span></code></a>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>) â€“ Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.</p></li>
<li><p><strong>kwargs</strong> â€“ <p>Additional logits processor specific kwargs.</p>
<dl class="simple">
<dt>Return:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">config.vocab_size)</span></code>: The processed prediction scores.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<p>Torch method for processing logits.</p>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="beamsearch">
<h2>BeamSearch<a class="headerlink" href="#beamsearch" title="Permalink to this headline">Â¶</a></h2>
<dl class="py class">
<dt id="transformers.BeamScorer"><a name="//apple_ref/cpp/Class/transformers.BeamScorer"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">BeamScorer</code><a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamScorer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamScorer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Abstract base class for all beam scorers that are used for <code class="xref py py-meth docutils literal notranslate"><span class="pre">beam_search()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">beam_sample()</span></code>.</p>
<dl class="py method">
<dt id="transformers.BeamScorer.finalize"><a name="//apple_ref/cpp/Method/transformers.BeamScorer.finalize"></a>
<em class="property">abstract </em><code class="sig-name descname">finalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">next_tokens</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_indices</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> â†’ torch.LongTensor<a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamScorer.finalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamScorer.finalize" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedTokenizer</span></code>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>final_beam_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The final scores of all non-finished beams.</p></li>
<li><p><strong>final_beam_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The last tokens to be added to the non-finished beam_hypotheses.</p></li>
<li><p><strong>final_beam_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The beam indices indicating to which beam the <code class="xref py py-obj docutils literal notranslate"><span class="pre">final_beam_tokens</span></code> shall be added.</p></li>
<li><p><strong>pad_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>padding</cite> token.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The generated
sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or shorter if all
batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequences,</span> <span class="pre">sequence_length)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.BeamScorer.process"><a name="//apple_ref/cpp/Method/transformers.BeamScorer.process"></a>
<em class="property">abstract </em><code class="sig-name descname">process</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">next_tokens</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_indices</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> â†’ Tuple<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamScorer.process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamScorer.process" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedTokenizer</span></code>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>next_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Current scores of the top <code class="xref py py-obj docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams</span></code> non-finished beam hypotheses.</p></li>
<li><p><strong>next_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> of the tokens corresponding to the top <code class="xref py py-obj docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams</span></code> non-finished beam hypotheses.</p></li>
<li><p><strong>next_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Beam indices indicating to which beam hypothesis the <code class="xref py py-obj docutils literal notranslate"><span class="pre">next_tokens</span></code> correspond.</p></li>
<li><p><strong>pad_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>padding</cite> token.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A dictionary composed of the fields as defined above:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>next_beam_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Updated
scores of all non-finished beams.</p></li>
<li><p><strong>next_beam_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Next tokens
to be added to the non-finished beam_hypotheses.</p></li>
<li><p><strong>next_beam_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Beam indices
indicating to which beam the next tokens shall be added.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">UserDict</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="transformers.BeamSearchScorer"><a name="//apple_ref/cpp/Class/transformers.BeamSearchScorer"></a>
<em class="property">class </em><code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">BeamSearchScorer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch_size</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">max_length</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">num_beams</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">device</span><span class="p">:</span> <span class="n">torch.device</span></em>, <em class="sig-param"><span class="n">length_penalty</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>float<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">do_early_stopping</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>bool<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_beam_hyps_to_keep</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1</span></em>, <em class="sig-param"><span class="n">num_beam_groups</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamSearchScorer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamSearchScorer" title="Permalink to this definition">Â¶</a></dt>
<dd><p><a class="reference internal" href="#transformers.BeamScorer" title="transformers.BeamScorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.BeamScorer</span></code></a> implementing standard beam search decoding.</p>
<p>Adapted in part from <a class="reference external" href="https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529">Facebookâ€™s XLM beam search code</a>.</p>
<p>Reference for the diverse beam search algorithm and implementation <a class="reference external" href="https://github.com/ashwinkalyan/dbs/blob/master/dbs/beam_utils.lua">Ashwin Kalyanâ€™s DBS implementation</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ Batch Size of <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> for which standard beam search decoding is run in parallel.</p></li>
<li><p><strong>max_length</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ The maximum length of the sequence to be generated.</p></li>
<li><p><strong>num_beams</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ Number of beams for beam search.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.device</span></code>) â€“ Defines the device type (<em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"cpu"</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">"cuda"</span></code>) on which this instance of
<a class="reference internal" href="#transformers.BeamSearchScorer" title="transformers.BeamSearchScorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BeamSearchScorer</span></code></a> will be allocated.</p></li>
<li><p><strong>length_penalty</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, <cite>optional</cite>, defaults to 1.0) â€“ Exponential penalty to the length. 1.0 means no penalty. Set to values &lt; 1.0 in order to encourage the
model to generate shorter sequences, to a value &gt; 1.0 in order to encourage the model to produce longer
sequences.</p></li>
<li><p><strong>do_early_stopping</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, <cite>optional</cite>, defaults to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>) â€“ Whether to stop the beam search when at least <code class="docutils literal notranslate"><span class="pre">num_beams</span></code> sentences are finished per batch or not.</p></li>
<li><p><strong>num_beam_hyps_to_keep</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>, defaults to 1) â€“ The number of beam hypotheses that shall be returned upon calling
<code class="xref py py-meth docutils literal notranslate"><span class="pre">finalize()</span></code>.</p></li>
<li><p><strong>num_beam_groups</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) â€“ Number of groups to divide <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_beams</span></code> into in order to ensure diversity among different groups of
beams. See <a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">this paper</a> for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers.BeamSearchScorer.finalize"><a name="//apple_ref/cpp/Method/transformers.BeamSearchScorer.finalize"></a>
<code class="sig-name descname">finalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">final_beam_scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">final_beam_tokens</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">final_beam_indices</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> â†’ Tuple<span class="p">[</span>torch.LongTensor<span class="p">]</span><a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamSearchScorer.finalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamSearchScorer.finalize" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedTokenizer</span></code>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>final_beam_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The final scores of all non-finished beams.</p></li>
<li><p><strong>final_beam_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The last tokens to be added to the non-finished beam_hypotheses.</p></li>
<li><p><strong>final_beam_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ The beam indices indicating to which beam the <code class="xref py py-obj docutils literal notranslate"><span class="pre">final_beam_tokens</span></code> shall be added.</p></li>
<li><p><strong>pad_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>padding</cite> token.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The generated
sequences. The second dimension (sequence_length) is either equal to <code class="xref py py-obj docutils literal notranslate"><span class="pre">max_length</span></code> or shorter if all
batches finished early due to the <code class="xref py py-obj docutils literal notranslate"><span class="pre">eos_token_id</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_return_sequences,</span> <span class="pre">sequence_length)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="transformers.BeamSearchScorer.process"><a name="//apple_ref/cpp/Method/transformers.BeamSearchScorer.process"></a>
<code class="sig-name descname">process</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_ids</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_scores</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">next_tokens</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">next_indices</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em>, <em class="sig-param"><span class="n">pad_token_id</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">eos_token_id</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> â†’ Tuple<span class="p">[</span>torch.Tensor<span class="p">]</span><a class="reference internal" href="../_modules/transformers/generation_beam_search.html#BeamSearchScorer.process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.BeamSearchScorer.process" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams,</span> <span class="pre">sequence_length)</span></code>) â€“ <p>Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedTokenizer</span></code>. See
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.encode()</span></code> and <a class="reference internal" href="../main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__" title="transformers.PreTrainedTokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transformers.PreTrainedTokenizer.__call__()</span></code></a> for
details.</p>
<p><a class="reference external" href="../glossary.html#input-ids">What are input IDs?</a></p>
</p></li>
<li><p><strong>next_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Current scores of the top <code class="xref py py-obj docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams</span></code> non-finished beam hypotheses.</p></li>
<li><p><strong>next_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_ids</span></code> of the tokens corresponding to the top <code class="xref py py-obj docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams</span></code> non-finished beam hypotheses.</p></li>
<li><p><strong>next_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Beam indices indicating to which beam hypothesis the <code class="xref py py-obj docutils literal notranslate"><span class="pre">next_tokens</span></code> correspond.</p></li>
<li><p><strong>pad_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>padding</cite> token.</p></li>
<li><p><strong>eos_token_id</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>) â€“ The id of the <cite>end-of-sequence</cite> token.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A dictionary composed of the fields as defined above:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>next_beam_scores</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Updated
scores of all non-finished beams.</p></li>
<li><p><strong>next_beam_tokens</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Next tokens
to be added to the non-finished beam_hypotheses.</p></li>
<li><p><strong>next_beam_indices</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size</span> <span class="pre">*</span> <span class="pre">num_beams)</span></code>) â€“ Beam indices
indicating to which beam the next tokens shall be added.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">UserDict</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">Â¶</a></h2>
<dl class="py function">
<dt id="transformers.top_k_top_p_filtering"><a name="//apple_ref/cpp/Function/transformers.top_k_top_p_filtering"></a>
<code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">top_k_top_p_filtering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">logits</span><span class="p">:</span> <span class="n">torch.FloatTensor</span></em>, <em class="sig-param"><span class="n">top_k</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">top_p</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">filter_value</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">- inf</span></em>, <em class="sig-param"><span class="n">min_tokens_to_keep</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em><span class="sig-paren">)</span> â†’ torch.FloatTensor<a class="reference internal" href="../_modules/transformers/generation_utils.html#top_k_top_p_filtering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.top_k_top_p_filtering" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Filter a distribution of logits using top-k and/or nucleus (top-p) filtering</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> â€“ logits distribution shape (batch size, vocabulary size)</p></li>
<li><p><strong>top_k &gt; 0</strong> (<em>if</em>) â€“ keep only top k tokens with highest probability (top-k filtering).</p></li>
<li><p><strong>top_p &lt; 1.0</strong> (<em>if</em>) â€“ keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering).
Nucleus filtering is described in Holtzman et al. (<a class="reference external" href="http://arxiv.org/abs/1904.09751">http://arxiv.org/abs/1904.09751</a>)</p></li>
<li><p><strong>sure we keep at least min_tokens_to_keep per batch example in the output</strong> (<em>Make</em>) â€“ </p></li>
</ul>
</dd>
</dl>
<p>From: <a class="reference external" href="https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317">https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317</a></p>
</dd></dl>
<dl class="py function">
<dt id="transformers.tf_top_k_top_p_filtering"><a name="//apple_ref/cpp/Function/transformers.tf_top_k_top_p_filtering"></a>
<code class="sig-prename descclassname">transformers.</code><code class="sig-name descname">tf_top_k_top_p_filtering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">logits</span></em>, <em class="sig-param"><span class="n">top_k</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">top_p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">filter_value</span><span class="o">=</span><span class="default_value">- inf</span></em>, <em class="sig-param"><span class="n">min_tokens_to_keep</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers/generation_tf_utils.html#tf_top_k_top_p_filtering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#transformers.tf_top_k_top_p_filtering" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Filter a distribution of logits using top-k and/or nucleus (top-p) filtering</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> â€“ logits distribution shape (batch size, vocabulary size)</p></li>
<li><p><strong>top_k &gt; 0</strong> (<em>if</em>) â€“ keep only top k tokens with highest probability (top-k filtering).</p></li>
<li><p><strong>top_p &lt; 1.0</strong> (<em>if</em>) â€“ keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering).
Nucleus filtering is described in Holtzman et al. (<a class="reference external" href="http://arxiv.org/abs/1904.09751">http://arxiv.org/abs/1904.09751</a>)</p></li>
<li><p><strong>sure we keep at least min_tokens_to_keep per batch example in the output</strong> (<em>Make</em>) â€“ </p></li>
</ul>
</dd>
</dl>
<p>From: <a class="reference external" href="https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317">https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317</a></p>
</dd></dl>
</div>
</div>
</div>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="p" class="btn btn-neutral float-left" href="trainer_utils.html" rel="prev" title="Utilities for Trainer"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        Â© Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
</div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
</section>
</div>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Theme Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>
</body>
</html>