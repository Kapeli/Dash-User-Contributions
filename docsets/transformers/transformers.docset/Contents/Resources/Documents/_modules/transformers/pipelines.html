

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>transformers.pipelines &mdash; transformers 2.6.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/custom.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/huggingface.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/code-snippets.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/hidesidebar.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> transformers
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_sharing.html">Model upload and sharing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks.html">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../serialization.html">Loading Google AI or OpenAI pre-trained weights or PyTorch dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../serialization.html#serialization-best-practices">Serialization best-practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration.html">Migrating from pytorch-pretrained-bert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torchscript.html">TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multilingual.html">Multi-lingual models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/optimizer_schedules.html">Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/optimizer_schedules.html#schedules">Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/optimizer_schedules.html#gradient-strategies">Gradient Strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/processors.html">Processors</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/auto.html">AutoModels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlnet.html">XLNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bart.html">Bart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/t5.html">T5</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">transformers</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>transformers.pipelines</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for transformers.pipelines</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding=utf-8</span>
<span class="c1"># Copyright 2018 The HuggingFace Inc. team.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>


<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">abspath</span><span class="p">,</span> <span class="n">exists</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.configuration_auto</span> <span class="kn">import</span> <span class="n">ALL_PRETRAINED_CONFIG_ARCHIVE_MAP</span><span class="p">,</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">.configuration_bart</span> <span class="kn">import</span> <span class="n">BartConfig</span>
<span class="kn">from</span> <span class="nn">.configuration_distilbert</span> <span class="kn">import</span> <span class="n">DistilBertConfig</span>
<span class="kn">from</span> <span class="nn">.configuration_roberta</span> <span class="kn">import</span> <span class="n">RobertaConfig</span>
<span class="kn">from</span> <span class="nn">.configuration_t5</span> <span class="kn">import</span> <span class="n">T5Config</span>
<span class="kn">from</span> <span class="nn">.configuration_utils</span> <span class="kn">import</span> <span class="n">PretrainedConfig</span>
<span class="kn">from</span> <span class="nn">.configuration_xlm</span> <span class="kn">import</span> <span class="n">XLMConfig</span>
<span class="kn">from</span> <span class="nn">.data</span> <span class="kn">import</span> <span class="n">SquadExample</span><span class="p">,</span> <span class="n">squad_convert_examples_to_features</span>
<span class="kn">from</span> <span class="nn">.file_utils</span> <span class="kn">import</span> <span class="n">is_tf_available</span><span class="p">,</span> <span class="n">is_torch_available</span>
<span class="kn">from</span> <span class="nn">.modelcard</span> <span class="kn">import</span> <span class="n">ModelCard</span>
<span class="kn">from</span> <span class="nn">.tokenization_auto</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">.tokenization_bert</span> <span class="kn">import</span> <span class="n">BasicTokenizer</span>
<span class="kn">from</span> <span class="nn">.tokenization_utils</span> <span class="kn">import</span> <span class="n">PreTrainedTokenizer</span>


<span class="k">if</span> <span class="n">is_tf_available</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">from</span> <span class="nn">.modeling_tf_auto</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">TFAutoModel</span><span class="p">,</span>
        <span class="n">TFAutoModelForSequenceClassification</span><span class="p">,</span>
        <span class="n">TFAutoModelForQuestionAnswering</span><span class="p">,</span>
        <span class="n">TFAutoModelForTokenClassification</span><span class="p">,</span>
        <span class="n">TFAutoModelWithLMHead</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">.modeling_auto</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">AutoModel</span><span class="p">,</span>
        <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
        <span class="n">AutoModelForQuestionAnswering</span><span class="p">,</span>
        <span class="n">AutoModelForTokenClassification</span><span class="p">,</span>
        <span class="n">AutoModelWithLMHead</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_framework</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Select framework (TensorFlow/PyTorch) to use.</span>
<span class="sd">        If both frameworks are installed and no specific model is provided, defaults to using PyTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Both framework are available but the user supplied a model class instance.</span>
        <span class="c1"># Try to guess which framework to use from the model classname</span>
        <span class="n">framework</span> <span class="o">=</span> <span class="s2">&quot;tf&quot;</span> <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;TF&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;pt&quot;</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;At least one of TensorFlow 2.0 or PyTorch should be installed. &quot;</span>
            <span class="s2">&quot;To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ &quot;</span>
            <span class="s2">&quot;To install PyTorch, read the instructions at https://pytorch.org/.&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># framework = &#39;tf&#39; if is_tf_available() else &#39;pt&#39;</span>
        <span class="n">framework</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;tf&quot;</span>
    <span class="k">return</span> <span class="n">framework</span>


<span class="k">class</span> <span class="nc">ArgumentHandler</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base interface for handling varargs for each Pipeline</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">DefaultArgumentHandler</span><span class="p">(</span><span class="n">ArgumentHandler</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Default varargs argument parser handling parameters for each Pipeline</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;data&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unable to infer the format of the provided data (X=, data=, ...)&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PipelineDataFormat</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for all the pipeline supported data format both for reading and writing.</span>
<span class="sd">    Supported data formats currently includes:</span>
<span class="sd">     - JSON</span>
<span class="sd">     - CSV</span>
<span class="sd">     - stdin/stdout (pipe)</span>

<span class="sd">    PipelineDataFormat also includes some utilities to work with multi-columns like mapping from datasets columns</span>
<span class="sd">    to pipelines keyword arguments through the `dataset_kwarg_1=dataset_column_1` format.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SUPPORTED_FORMATS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="s2">&quot;pipe&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">input_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="o">=</span> <span class="n">output_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_path</span> <span class="o">=</span> <span class="n">input_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">column</span> <span class="o">=</span> <span class="n">column</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">column</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_multi_columns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multi_columns</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">column</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">))</span> <span class="k">if</span> <span class="s2">&quot;=&quot;</span> <span class="ow">in</span> <span class="n">c</span> <span class="k">else</span> <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">abspath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">OSError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> already exists on disk&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">input_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="n">abspath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_path</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">OSError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> doesnt exist on disk&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_path</span><span class="p">))</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the provided data object with the representation for the current `DataFormat`.</span>
<span class="sd">        :param data: data to store</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">save_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the provided data object as a pickle-formatted binary data on the disk.</span>
<span class="sd">        :param data: data to store</span>
<span class="sd">        :return: (str) Path where the data has been saved</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">path</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>
        <span class="n">binary_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">extsep</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;pickle&quot;</span><span class="p">))</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">binary_path</span><span class="p">,</span> <span class="s2">&quot;wb+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_output</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">f_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">binary_path</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_str</span><span class="p">(</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">input_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;json&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">JsonPipelineDataFormat</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;csv&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">CsvPipelineDataFormat</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;pipe&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">PipedPipelineDataFormat</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;Unknown reader </span><span class="si">{}</span><span class="s2"> (Available reader are json/csv/pipe)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">format</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">CsvPipelineDataFormat</span><span class="p">(</span><span class="n">PipelineDataFormat</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">input_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multi_columns</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">row</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerows</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">JsonPipelineDataFormat</span><span class="p">(</span><span class="n">PipelineDataFormat</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">input_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_entries</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entries</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multi_columns</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">entry</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">entry</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PipedPipelineDataFormat</span><span class="p">(</span><span class="n">PipelineDataFormat</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read data from piped input to the python process.</span>
<span class="sd">    For multi columns data, columns should separated by \t</span>

<span class="sd">    If columns are provided, then the output will be a dictionary with {column_x: value_x}</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
            <span class="c1"># Split for multi-columns</span>
            <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>

                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">:</span>
                    <span class="c1"># Dictionary to map arguments</span>
                    <span class="k">yield</span> <span class="p">{</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">l</span> <span class="k">for</span> <span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column</span><span class="p">,</span> <span class="n">line</span><span class="p">)}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

            <span class="c1"># No dictionary to map arguments</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">line</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="s2">&quot;When using piped input on pipeline outputting large object requires an output file path. &quot;</span>
                <span class="s2">&quot;Please provide such output path through --output argument.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_binary</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ScikitCompat</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Interface layer for the Scikit and Keras compatibility.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<div class="viewcode-block" id="Pipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.Pipeline">[docs]</a><span class="k">class</span> <span class="nc">Pipeline</span><span class="p">(</span><span class="n">_ScikitCompat</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Pipeline class is the class from which all pipelines inherit. Refer to this class for methods shared across</span>
<span class="sd">    different pipelines.</span>

<span class="sd">    Base class implementing pipelined operations.</span>
<span class="sd">    Pipeline workflow is defined as a sequence of the following operations:</span>
<span class="sd">        Input -&gt; Tokenization -&gt; Model Inference -&gt; Post-Processing (Task dependent) -&gt; Output</span>

<span class="sd">    Pipeline supports running on CPU or GPU through the device argument. Users can specify</span>
<span class="sd">    device argument as an integer, -1 meaning &quot;CPU&quot;, &gt;= 0 referring the CUDA device ordinal.</span>

<span class="sd">    Some pipeline, like for instance FeatureExtractionPipeline (&#39;feature-extraction&#39;) outputs large</span>
<span class="sd">    tensor object as nested-lists. In order to avoid dumping such large structure as textual data we</span>
<span class="sd">    provide the binary_output constructor argument. If set to True, the output will be stored in the</span>
<span class="sd">    pickle format.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">        binary_output (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">            Flag indicating if the output the pipeline should happen in a binary format (i.e. pickle) or as raw text.</span>

<span class="sd">    Return:</span>
<span class="sd">        :obj:`List` or :obj:`Dict`:</span>
<span class="sd">        Pipeline returns list or dictionary depending on:</span>

<span class="sd">         - Whether the user supplied multiple samples</span>
<span class="sd">         - Whether the pipeline exposes multiple fields in the output object</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">default_input_names</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">,</span> <span class="s2">&quot;TFPreTrainedModel&quot;</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
        <span class="n">modelcard</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCard</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">args_parser</span><span class="p">:</span> <span class="n">ArgumentHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">binary_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="k">if</span> <span class="n">framework</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">framework</span> <span class="o">=</span> <span class="n">get_framework</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modelcard</span> <span class="o">=</span> <span class="n">modelcard</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="n">framework</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span> <span class="k">if</span> <span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span> <span class="k">if</span> <span class="n">device</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;cuda:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">binary_output</span> <span class="o">=</span> <span class="n">binary_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args_parser</span> <span class="o">=</span> <span class="n">args_parser</span> <span class="ow">or</span> <span class="n">DefaultArgumentHandler</span><span class="p">()</span>

        <span class="c1"># Special handling</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;pt&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Update config with task specific parameters</span>
        <span class="n">task_specific_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">task_specific_params</span>
        <span class="k">if</span> <span class="n">task_specific_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">task_specific_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">task_specific_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="p">))</span>

<div class="viewcode-block" id="Pipeline.save_pretrained"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.Pipeline.save_pretrained">[docs]</a>    <span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the pipeline&#39;s model and tokenizer to the specified save_directory</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Provided path (</span><span class="si">{}</span><span class="s2">) should be a directory&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">save_directory</span><span class="p">))</span>
            <span class="k">return</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modelcard</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">modelcard</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span></div>

<div class="viewcode-block" id="Pipeline.transform"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.Pipeline.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Scikit / Keras interface to transformers&#39; pipelines. This method will forward to __call__().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="Pipeline.predict"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.Pipeline.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Scikit / Keras interface to transformers&#39; pipelines. This method will forward to __call__().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">device_placement</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Context Manager allowing tensor allocation on the user-specified device in framework agnostic way.</span>
<span class="sd">        example:</span>
<span class="sd">            # Explicitly ask for tensor allocation on CUDA device :0</span>
<span class="sd">            nlp = pipeline(..., device=0)</span>
<span class="sd">            with nlp.device_placement():</span>
<span class="sd">                # Every framework specific tensor allocation will be done on the request device</span>
<span class="sd">                output = nlp(...)</span>
<span class="sd">        Returns:</span>
<span class="sd">            Context manager</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/CPU:0&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;/device:GPU:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)):</span>
                <span class="k">yield</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">yield</span>

    <span class="k">def</span> <span class="nf">ensure_tensor_on_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ensure PyTorch tensors are on the specified device.</span>
<span class="sd">        :param inputs:</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">inputs_for_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the input dictionary with model-specific parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict holding all the required parameters for model&#39;s forward</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="p">(</span><span class="n">DistilBertConfig</span><span class="p">,</span> <span class="n">XLMConfig</span><span class="p">,</span> <span class="n">RobertaConfig</span><span class="p">,</span> <span class="n">BartConfig</span><span class="p">,</span> <span class="n">T5Config</span><span class="p">)):</span>
            <span class="n">args</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">]</span>

        <span class="c1"># PR #1548 (CLI) There is an issue with attention_mask</span>
        <span class="c1"># if &#39;xlnet&#39; in model_type or &#39;xlm&#39; in model_type:</span>
        <span class="c1">#     args += [&#39;cls_index&#39;, &#39;p_mask&#39;]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">args</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">feature</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">args</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">_parse_and_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parse arguments and tokenize</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Parse arguments</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args_parser</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">max_len</span><span class="p">,</span>
            <span class="n">pad_to_max_length</span><span class="o">=</span><span class="n">pad_to_max_length</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Filter out features not available on specific models</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_for_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inputs</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_and_tokenize</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal framework specific forward dispatching.</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs: dict holding all the keyworded arguments for required by the model forward method.</span>
<span class="sd">            return_tensors: Whether to return native framework (pt/tf) tensors rather than numpy array.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Numpy array</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Encode for forward</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_placement</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                <span class="c1"># TODO trace model</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_tensor_on_device</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">return_tensors</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">predictions</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">predictions</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


<div class="viewcode-block" id="FeatureExtractionPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.FeatureExtractionPipeline">[docs]</a><span class="k">class</span> <span class="nc">FeatureExtractionPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Feature extraction pipeline using Model head. This pipeline extracts the hidden states from the base transformer,</span>
<span class="sd">    which can be used as features in a downstream tasks.</span>

<span class="sd">    This feature extraction pipeline can currently be loaded from the :func:`~transformers.pipeline` method using</span>
<span class="sd">    the following task identifier(s):</span>

<span class="sd">    - &quot;feature-extraction&quot;, for extracting features of a sequence.</span>

<span class="sd">    All models may be used for this pipeline. See a list of all models, including community-contributed models on</span>
<span class="sd">    `huggingface.co/models &lt;https://huggingface.co/models&gt;`__.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">,</span> <span class="s2">&quot;TFPreTrainedModel&quot;</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
        <span class="n">modelcard</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCard</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_parser</span><span class="p">:</span> <span class="n">ArgumentHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">modelcard</span><span class="o">=</span><span class="n">modelcard</span><span class="p">,</span>
            <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
            <span class="n">args_parser</span><span class="o">=</span><span class="n">args_parser</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">binary_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span></div>


<div class="viewcode-block" id="TextClassificationPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.TextClassificationPipeline">[docs]</a><span class="k">class</span> <span class="nc">TextClassificationPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Text classification pipeline using ModelForSequenceClassification head. See the</span>
<span class="sd">    `sequence classification usage &lt;../usage.html#sequence-classification&gt;`__ examples for more information.</span>

<span class="sd">    This text classification pipeline can currently be loaded from the :func:`~transformers.pipeline` method using</span>
<span class="sd">    the following task identifier(s):</span>

<span class="sd">    - &quot;sentiment-analysis&quot;, for classifying sequences according to positive or negative sentiments.</span>

<span class="sd">    The models that this pipeline can use are models that have been fine-tuned on a sequence classification task.</span>
<span class="sd">    See the list of available community models fine-tuned on such a task on</span>
<span class="sd">    `huggingface.co/models &lt;https://huggingface.co/models?search=&amp;filter=text-classification&gt;`__.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">argmax</span><span class="p">()],</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">max</span><span class="p">()}</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]</span></div>


<div class="viewcode-block" id="FillMaskPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.FillMaskPipeline">[docs]</a><span class="k">class</span> <span class="nc">FillMaskPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Masked language modeling prediction pipeline using ModelWithLMHead head. See the</span>
<span class="sd">    `masked language modeling usage &lt;../usage.html#masked-language-modeling&gt;`__ examples for more information.</span>

<span class="sd">    This mask filling pipeline can currently be loaded from the :func:`~transformers.pipeline` method using</span>
<span class="sd">    the following task identifier(s):</span>

<span class="sd">    - &quot;fill-mask&quot;, for predicting masked tokens in a sequence.</span>

<span class="sd">    The models that this pipeline can use are models that have been trained with a masked language modeling objective,</span>
<span class="sd">    which includes the bi-directional models in the library.</span>
<span class="sd">    See the list of available community models on</span>
<span class="sd">    `huggingface.co/models &lt;https://huggingface.co/models?search=&amp;filter=lm-head&gt;`__.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">,</span> <span class="s2">&quot;TFPreTrainedModel&quot;</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
        <span class="n">modelcard</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCard</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_parser</span><span class="p">:</span> <span class="n">ArgumentHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">topk</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">modelcard</span><span class="o">=</span><span class="n">modelcard</span><span class="p">,</span>
            <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
            <span class="n">args_parser</span><span class="o">=</span><span class="n">args_parser</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">binary_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">topk</span> <span class="o">=</span> <span class="n">topk</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_and_tokenize</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span> <span class="k">else</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                <span class="n">masked_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">masked_index</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
                <span class="n">topk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">topk</span><span class="p">)</span>
                <span class="n">values</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">topk</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">topk</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">masked_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">masked_index</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">values</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">topk</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">predictions</span><span class="o">.</span><span class="n">tolist</span><span class="p">()):</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">tokens</span><span class="p">[</span><span class="n">masked_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
                <span class="c1"># Filter padding out:</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tokens</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)]</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;sequence&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">})</span>

            <span class="c1"># Append</span>
            <span class="n">results</span> <span class="o">+=</span> <span class="p">[</span><span class="n">result</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">results</span></div>


<div class="viewcode-block" id="NerPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.NerPipeline">[docs]</a><span class="k">class</span> <span class="nc">NerPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Named Entity Recognition pipeline using ModelForTokenClassification head. See the</span>
<span class="sd">    `named entity recognition usage &lt;../usage.html#named-entity-recognition&gt;`__ examples for more information.</span>

<span class="sd">    This token recognition pipeline can currently be loaded from the :func:`~transformers.pipeline` method using</span>
<span class="sd">    the following task identifier(s):</span>

<span class="sd">    - &quot;ner&quot;, for predicting the classes of tokens in a sequence: person, organisation, location or miscellaneous.</span>

<span class="sd">    The models that this pipeline can use are models that have been fine-tuned on a token classification task.</span>
<span class="sd">    See the list of available community models fine-tuned on such a task on</span>
<span class="sd">    `huggingface.co/models &lt;https://huggingface.co/models?search=&amp;filter=token-classification&gt;`__.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">default_input_names</span> <span class="o">=</span> <span class="s2">&quot;sequences&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">,</span> <span class="s2">&quot;TFPreTrainedModel&quot;</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
        <span class="n">modelcard</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCard</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_parser</span><span class="p">:</span> <span class="n">ArgumentHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">binary_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ignore_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">],</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">modelcard</span><span class="o">=</span><span class="n">modelcard</span><span class="p">,</span>
            <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
            <span class="n">args_parser</span><span class="o">=</span><span class="n">args_parser</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">binary_output</span><span class="o">=</span><span class="n">binary_output</span><span class="p">,</span>
            <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_basic_tokenizer</span> <span class="o">=</span> <span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">do_lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_labels</span> <span class="o">=</span> <span class="n">ignore_labels</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args_parser</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>

            <span class="c1"># Manage correct placement of the tensors</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_placement</span><span class="p">():</span>

                <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span>
                    <span class="n">sentence</span><span class="p">,</span>
                    <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">return_tensors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">max_len</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Forward</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                    <span class="n">entities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_tensor_on_device</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">)</span>
                        <span class="n">entities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">entities</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">entities</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">labels_idx</span> <span class="o">=</span> <span class="n">score</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">answer</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">label_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels_idx</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">label_idx</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_labels</span><span class="p">:</span>
                    <span class="n">answer</span> <span class="o">+=</span> <span class="p">[</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;word&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">])),</span>
                            <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">label_idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                            <span class="s2">&quot;entity&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">label_idx</span><span class="p">],</span>
                        <span class="p">}</span>
                    <span class="p">]</span>

            <span class="c1"># Append</span>
            <span class="n">answers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">answer</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">answers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">answers</span></div>


<span class="n">TokenClassificationPipeline</span> <span class="o">=</span> <span class="n">NerPipeline</span>


<span class="k">class</span> <span class="nc">QuestionAnsweringArgumentHandler</span><span class="p">(</span><span class="n">ArgumentHandler</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    QuestionAnsweringPipeline requires the user to provide multiple arguments (i.e. question &amp; context) to be mapped</span>
<span class="sd">    to internal SquadExample / SquadFeature structures.</span>

<span class="sd">    QuestionAnsweringArgumentHandler manages all the possible to create SquadExample from the command-line supplied</span>
<span class="sd">    arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Position args, handling is sensibly the same as X and data, so forwarding to avoid duplicating</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

        <span class="c1"># Generic compatibility with sklearn and Keras</span>
        <span class="c1"># Batched data</span>
        <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="s2">&quot;data&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Copy to avoid overriding arguments</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">item</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;context&quot;</span><span class="p">]):</span>
                        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;You need to provide a dictionary with keys {question:..., context:...}&quot;</span><span class="p">)</span>

                    <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">QuestionAnsweringPipeline</span><span class="o">.</span><span class="n">create_sample</span><span class="p">(</span><span class="o">**</span><span class="n">item</span><span class="p">)</span>

                <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">SquadExample</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> argument needs to be of type (list[SquadExample | dict], SquadExample, dict)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="s2">&quot;X&quot;</span> <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="s2">&quot;data&quot;</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

            <span class="c1"># Tabular input</span>
        <span class="k">elif</span> <span class="s2">&quot;question&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="s2">&quot;context&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">]]</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">]]</span>

            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">QuestionAnsweringPipeline</span><span class="o">.</span><span class="n">create_sample</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">])</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown arguments </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kwargs</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">inputs</span>


<div class="viewcode-block" id="QuestionAnsweringPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.QuestionAnsweringPipeline">[docs]</a><span class="k">class</span> <span class="nc">QuestionAnsweringPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Question Answering pipeline using ModelForQuestionAnswering head. See the</span>
<span class="sd">    `question answering usage &lt;../usage.html#question-answering&gt;`__ examples for more information.</span>

<span class="sd">    This question answering can currently be loaded from the :func:`~transformers.pipeline` method using</span>
<span class="sd">    the following task identifier(s):</span>

<span class="sd">    - &quot;question-answering&quot;, for answering questions given a context.</span>

<span class="sd">    The models that this pipeline can use are models that have been fine-tuned on a question answering task.</span>
<span class="sd">    See the list of available community models fine-tuned on such a task on</span>
<span class="sd">    `huggingface.co/models &lt;https://huggingface.co/models?search=&amp;filter=question-answering&gt;`__.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">        tokenizer (:obj:`~transformers.PreTrainedTokenizer`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">default_input_names</span> <span class="o">=</span> <span class="s2">&quot;question,context&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">,</span> <span class="s2">&quot;TFPreTrainedModel&quot;</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
        <span class="n">modelcard</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCard</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">modelcard</span><span class="o">=</span><span class="n">modelcard</span><span class="p">,</span>
            <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
            <span class="n">args_parser</span><span class="o">=</span><span class="n">QuestionAnsweringArgumentHandler</span><span class="p">(),</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_sample</span><span class="p">(</span>
        <span class="n">question</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">context</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">SquadExample</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">SquadExample</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        QuestionAnsweringPipeline leverages the SquadExample/SquadFeatures internally.</span>
<span class="sd">        This helper method encapsulate all the logic for converting question(s) and context(s) to SquadExample(s).</span>
<span class="sd">        We currently support extractive question answering.</span>
<span class="sd">        Arguments:</span>
<span class="sd">             question: (str, List[str]) The question to be ask for the associated context</span>
<span class="sd">             context: (str, List[str]) The context in which we will look for the answer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SquadExample initialized with the corresponding question and context.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">SquadExample</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">SquadExample</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            We support multiple use-cases, the following are exclusive:</span>
<span class="sd">            X: sequence of SquadExample</span>
<span class="sd">            data: sequence of SquadExample</span>
<span class="sd">            question: (str, List[str]), batch of question(s) to map along with context</span>
<span class="sd">            context: (str, List[str]), batch of context(s) associated with the provided question keyword argument</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: {&#39;answer&#39;: str, &#39;score&quot;: float, &#39;start&quot;: int, &quot;end&quot;: int}</span>
<span class="sd">            answer: the textual answer in the intial context</span>
<span class="sd">            score: the score the current answer scored for the model</span>
<span class="sd">            start: the character index in the original string corresponding to the beginning of the answer&#39; span</span>
<span class="sd">            end: the character index in the original string corresponding to the ending of the answer&#39; span</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set defaults values</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;topk&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;doc_stride&quot;</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;max_answer_len&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;max_seq_len&quot;</span><span class="p">,</span> <span class="mi">384</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;max_question_len&quot;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;topk&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;topk parameter should be &gt;= 1 (got </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;topk&quot;</span><span class="p">]))</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_answer_len&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_answer_len parameter should be &gt;= 1 (got </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_answer_len&quot;</span><span class="p">]))</span>

        <span class="c1"># Convert inputs to features</span>
        <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args_parser</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">features_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">squad_convert_examples_to_features</span><span class="p">(</span>
                <span class="p">[</span><span class="n">example</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_seq_len&quot;</span><span class="p">],</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;doc_stride&quot;</span><span class="p">],</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_question_len&quot;</span><span class="p">],</span>
                <span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span>
        <span class="p">]</span>
        <span class="n">all_answers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features_list</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
            <span class="n">fw_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_for_model</span><span class="p">([</span><span class="n">f</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>

            <span class="c1"># Manage tensor allocation on correct device</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_placement</span><span class="p">():</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                    <span class="n">fw_args</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">fw_args</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                    <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">fw_args</span><span class="p">)</span>
                    <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="c1"># Retrieve the score for the context tokens only (removing question tokens)</span>
                        <span class="n">fw_args</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">fw_args</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">fw_args</span><span class="p">)</span>
                        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">start_</span><span class="p">,</span> <span class="n">end_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
                <span class="c1"># Normalize logits and spans to retrieve the answer</span>
                <span class="n">start_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">start_</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">start_</span><span class="p">))</span>
                <span class="n">end_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">end_</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">end_</span><span class="p">))</span>

                <span class="c1"># Mask padding and question</span>
                <span class="n">start_</span><span class="p">,</span> <span class="n">end_</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">start_</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">p_mask</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">end_</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">p_mask</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">)</span>

                <span class="c1"># TODO : What happens if not possible</span>
                <span class="c1"># Mask CLS</span>
                <span class="n">start_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">end_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">start_</span><span class="p">,</span> <span class="n">end_</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;topk&quot;</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_answer_len&quot;</span><span class="p">])</span>
                <span class="n">char_to_word</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">char_to_word_offset</span><span class="p">)</span>

                <span class="c1"># Convert the answer (tokens) back to the original text</span>
                <span class="n">answers</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="s2">&quot;start&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">char_to_word</span> <span class="o">==</span> <span class="n">feature</span><span class="o">.</span><span class="n">token_to_orig_map</span><span class="p">[</span><span class="n">s</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">char_to_word</span> <span class="o">==</span> <span class="n">feature</span><span class="o">.</span><span class="n">token_to_orig_map</span><span class="p">[</span><span class="n">e</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                            <span class="n">example</span><span class="o">.</span><span class="n">doc_tokens</span><span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">token_to_orig_map</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="p">:</span> <span class="n">feature</span><span class="o">.</span><span class="n">token_to_orig_map</span><span class="p">[</span><span class="n">e</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                        <span class="p">),</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="n">answers</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;topk&quot;</span><span class="p">]]</span>
            <span class="n">all_answers</span> <span class="o">+=</span> <span class="n">answers</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_answers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_answers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">all_answers</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">topk</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_answer_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Take the output of any QuestionAnswering head and will generate probalities for each span to be</span>
<span class="sd">        the actual answer.</span>
<span class="sd">        In addition, it filters out some unwanted/impossible cases like answer len being greater than</span>
<span class="sd">        max_answer_len or answer end position being before the starting position.</span>
<span class="sd">        The method supports output the k-best answer through the topk argument.</span>

<span class="sd">        Args:</span>
<span class="sd">            start: numpy array, holding individual start probabilities for each token</span>
<span class="sd">            end: numpy array, holding individual end probabilities for each token</span>
<span class="sd">            topk: int, indicates how many possible answer span(s) to extract from the model&#39;s output</span>
<span class="sd">            max_answer_len: int, maximum size of the answer to extract from the model&#39;s output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure we have batch axis</span>
        <span class="k">if</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">start</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">end</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">end</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>

        <span class="c1"># Compute the score of each tuple(start, end) to be the real answer</span>
        <span class="n">outer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Remove candidate with end &lt; start and end - start &gt; max_answer_len</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">outer</span><span class="p">),</span> <span class="n">max_answer_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1">#  Inspired by Chen &amp; al. (https://github.com/facebookresearch/DrQA)</span>
        <span class="n">scores_flat</span> <span class="o">=</span> <span class="n">candidates</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">topk</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx_sort</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores_flat</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_flat</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">topk</span><span class="p">:</span>
            <span class="n">idx_sort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">scores_flat</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="o">-</span><span class="n">scores_flat</span><span class="p">,</span> <span class="n">topk</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="n">topk</span><span class="p">]</span>
            <span class="n">idx_sort</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">scores_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">])]</span>

        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">idx_sort</span><span class="p">,</span> <span class="n">candidates</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">return</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">span_to_answer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        When decoding from token probalities, this method maps token indexes to actual word in</span>
<span class="sd">        the initial context.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: str, the actual context to extract the answer from</span>
<span class="sd">            start: int, starting answer token index</span>
<span class="sd">            end: int, ending answer token index</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: {&#39;answer&#39;: str, &#39;start&#39;: int, &#39;end&#39;: int}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">token_idx</span> <span class="o">=</span> <span class="n">char_start_idx</span> <span class="o">=</span> <span class="n">char_end_idx</span> <span class="o">=</span> <span class="n">chars_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)):</span>
            <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

            <span class="c1"># Append words if they are in the span</span>
            <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;=</span> <span class="n">token_idx</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">token_idx</span> <span class="o">==</span> <span class="n">start</span><span class="p">:</span>
                    <span class="n">char_start_idx</span> <span class="o">=</span> <span class="n">chars_idx</span>

                <span class="k">if</span> <span class="n">token_idx</span> <span class="o">==</span> <span class="n">end</span><span class="p">:</span>
                    <span class="n">char_end_idx</span> <span class="o">=</span> <span class="n">chars_idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

                <span class="n">words</span> <span class="o">+=</span> <span class="p">[</span><span class="n">word</span><span class="p">]</span>

            <span class="c1"># Stop if we went over the end of the answer</span>
            <span class="k">if</span> <span class="n">token_idx</span> <span class="o">&gt;</span> <span class="n">end</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># Append the subtokenization length to the running index</span>
            <span class="n">token_idx</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="n">chars_idx</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Join text with spaces</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">),</span>
            <span class="s2">&quot;start&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">char_start_idx</span><span class="p">),</span>
            <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="n">char_end_idx</span><span class="p">),</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="SummarizationPipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.SummarizationPipeline">[docs]</a><span class="k">class</span> <span class="nc">SummarizationPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Summarize news articles and other documents</span>

<span class="sd">    Usage::</span>

<span class="sd">        # use bart in pytorch</span>
<span class="sd">        summarizer = pipeline(&quot;summarization&quot;)</span>
<span class="sd">        summarizer(&quot;Sam Shleifer writes the best docstring examples in the whole world.&quot;, min_length=5, max_length=20)</span>

<span class="sd">        # use t5 in tf</span>
<span class="sd">        summarizer = pipeline(&quot;summarization&quot;, model=&quot;t5-base&quot;, tokenizer=&quot;t5-base&quot;, framework=&quot;tf&quot;)</span>
<span class="sd">        summarizer(&quot;Sam Shleifer writes the best docstring examples in the whole world.&quot;, min_length=5, max_length=20)</span>

<span class="sd">    Supported Models:</span>
<span class="sd">        The models that this pipeline can use are models that have been fine-tuned on a summarization task, which is currently, &#39;`bart-large-cnn`&#39;, &#39;`t5-small`&#39;, &#39;`t5-base`&#39;, &#39;`t5-large`&#39;, &#39;`t5-3b`&#39;, &#39;`t5-11b`&#39;.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`str` or :obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This can be :obj:`None`, a string</span>
<span class="sd">            checkpoint identifier or an actual pre-trained model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>

<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        tokenizer (:obj:`str` or :obj:`~transformers.PreTrainedTokenizer`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This can be :obj:`None`,</span>
<span class="sd">            a string checkpoint identifier or an actual pre-trained tokenizer inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>

<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">documents</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">generate_kwargs</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            *documents: (list of strings) articles to be summarized</span>
<span class="sd">            return_text: (bool, default=True) whether to add a decoded &quot;summary_text&quot; to each result</span>
<span class="sd">            return_tensors: (bool, default=False) whether to return the raw &quot;summary_token_ids&quot; to each result</span>

<span class="sd">            clean_up_tokenization_spaces: (`optional`) bool whether to include extra spaces in the output</span>
<span class="sd">            **generate_kwargs: extra kwargs passed to `self.model.generate`_</span>

<span class="sd">        Returns:</span>
<span class="sd">            list of dicts with &#39;summary_text&#39; and/or &#39;summary_token_ids&#39; for each document_to_summarize</span>

<span class="sd">        .. _`self.model.generate`:</span>
<span class="sd">            https://huggingface.co/transformers/model_doc/bart.html#transformers.BartForConditionalGeneration.generate</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">return_tensors</span> <span class="ow">or</span> <span class="n">return_text</span><span class="p">,</span> <span class="s2">&quot;You must specify return_tensors=True or return_text=True&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Please provide a document to summarize&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span> <span class="ow">and</span> <span class="s2">&quot;BartForConditionalGeneration&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Tensorflow is not yet supported for Bart. Please consider using T5, e.g. `t5-base`&quot;</span>
            <span class="p">)</span>

        <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prefix</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">),</span> <span class="s2">&quot;Please make sure that the tokenizer has a pad_token_id when using a batch input&quot;</span>

            <span class="n">documents</span> <span class="o">=</span> <span class="p">([</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">document</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]],)</span>
            <span class="n">pad_to_max_length</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">documents</span> <span class="o">=</span> <span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span>
            <span class="n">pad_to_max_length</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot; `documents[0]`: </span><span class="si">{}</span><span class="s2"> have the wrong format. The should be either of type `str` or type `list`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_placement</span><span class="p">():</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_and_tokenize</span><span class="p">(</span><span class="o">*</span><span class="n">documents</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="n">pad_to_max_length</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;pt&quot;</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_tensor_on_device</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">input_length</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                <span class="n">input_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">input_length</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">min_length</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Your min_length is set to </span><span class="si">{}</span><span class="s2">, but you input_length is only </span><span class="si">{}</span><span class="s2">. You might consider decreasing min_length manually, e.g. summarizer(&#39;...&#39;, min_length=10)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">min_length</span><span class="p">,</span> <span class="n">input_length</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">input_length</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Your max_length is set to </span><span class="si">{}</span><span class="s2">, but you input_length is only </span><span class="si">{}</span><span class="s2">. You might consider decreasing max_length manually, e.g. summarizer(&#39;...&#39;, max_length=50)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span> <span class="n">input_length</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="n">summaries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">summary</span> <span class="ow">in</span> <span class="n">summaries</span><span class="p">:</span>
                <span class="n">record</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">if</span> <span class="n">return_tensors</span><span class="p">:</span>
                    <span class="n">record</span><span class="p">[</span><span class="s2">&quot;summary_token_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">summary</span>
                <span class="k">if</span> <span class="n">return_text</span><span class="p">:</span>
                    <span class="n">record</span><span class="p">[</span><span class="s2">&quot;summary_text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
                        <span class="n">summary</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">results</span></div>


<span class="k">class</span> <span class="nc">TranslationPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Translates from one language to another.</span>

<span class="sd">    Usage::</span>
<span class="sd">        en_fr_translator = pipeline(&quot;translation_en_to_fr&quot;)</span>
<span class="sd">        en_fr_translator(&quot;How old are you?&quot;)</span>

<span class="sd">    Supported Models: &quot;t5-small&quot;, &quot;t5-base&quot;, &quot;t5-large&quot;, &quot;t5-3b&quot;, &quot;t5-11b&quot;</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (:obj:`str` or :obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This can be :obj:`None`, a string</span>
<span class="sd">            checkpoint identifier or an actual pre-trained model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>
<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        tokenizer (:obj:`str` or :obj:`~transformers.PreTrainedTokenizer`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This can be :obj:`None`,</span>
<span class="sd">            a string checkpoint identifier or an actual pre-trained tokenizer inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>
<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        modelcard (:obj:`str` or :class:`~transformers.ModelCard`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Model card attributed to the model for this pipeline.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>
<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>
<span class="sd">        args_parser (:class:`~transformers.pipelines.ArgumentHandler`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            Reference to the object in charge of parsing supplied pipeline parameters.</span>
<span class="sd">        device (:obj:`int`, `optional`, defaults to :obj:`-1`):</span>
<span class="sd">            Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, &gt;=0 will run the model</span>
<span class="sd">            on the associated CUDA device id.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">generate_kwargs</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            *texts: (list of strings) texts to be translated</span>
<span class="sd">            return_text: (bool, default=True) whether to add a decoded &quot;translation_text&quot; to each result</span>
<span class="sd">            return_tensors: (bool, default=False) whether to return the raw &quot;translation_token_ids&quot; to each result</span>

<span class="sd">            **generate_kwargs: extra kwargs passed to `self.model.generate`_</span>

<span class="sd">        Returns:</span>
<span class="sd">            list of dicts with &#39;translation_text&#39; and/or &#39;translation_token_ids&#39; for each text_to_translate</span>
<span class="sd">        .. _`self.model.generate`:</span>
<span class="sd">            https://huggingface.co/transformers/model_doc/bart.html#transformers.BartForConditionalGeneration.generate</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">return_tensors</span> <span class="ow">or</span> <span class="n">return_text</span><span class="p">,</span> <span class="s2">&quot;You must specify return_tensors=True or return_text=True&quot;</span>

        <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prefix</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">),</span> <span class="s2">&quot;Please make sure that the tokenizer has a pad_token_id when using a batch input&quot;</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">([</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">]],)</span>
            <span class="n">pad_to_max_length</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span>
            <span class="n">pad_to_max_length</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot; `documents[0]`: </span><span class="si">{}</span><span class="s2"> have the wrong format. The should be either of type `str` or type `list`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_placement</span><span class="p">():</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_and_tokenize</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="n">pad_to_max_length</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;pt&quot;</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_tensor_on_device</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">input_length</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
                <span class="n">input_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">input_length</span> <span class="o">&gt;</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Your input_length: </span><span class="si">{}</span><span class="s2"> is bigger than 0.9 * max_length: </span><span class="si">{}</span><span class="s2">. You might consider increasing your max_length manually, e.g. translator(&#39;...&#39;, max_length=400)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">input_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="n">translations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">translation</span> <span class="ow">in</span> <span class="n">translations</span><span class="p">:</span>
                <span class="n">record</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">if</span> <span class="n">return_tensors</span><span class="p">:</span>
                    <span class="n">record</span><span class="p">[</span><span class="s2">&quot;translation_token_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">translation</span>
                <span class="k">if</span> <span class="n">return_text</span><span class="p">:</span>
                    <span class="n">record</span><span class="p">[</span><span class="s2">&quot;translation_text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
                        <span class="n">translation</span><span class="p">,</span>
                        <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">results</span>


<span class="c1"># Register all the supported task here</span>
<span class="n">SUPPORTED_TASKS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;feature-extraction&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">FeatureExtractionPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModel</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModel</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-cased&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-cased&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-cased&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">TextClassificationPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelForSequenceClassification</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelForSequenceClassification</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;ner&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">NerPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelForTokenClassification</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelForTokenClassification</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="s2">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="s2">&quot;bert-large-cased&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;question-answering&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">QuestionAnsweringPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelForQuestionAnswering</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelForQuestionAnswering</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-cased-distilled-squad&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-cased-distilled-squad&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;distilbert-base-cased&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;fill-mask&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">FillMaskPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;distilroberta-base&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;distilroberta-base&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;distilroberta-base&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;summarization&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">SummarizationPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;bart-large-cnn&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;bart-large-cnn&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;translation_en_to_fr&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">TranslationPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;translation_en_to_de&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">TranslationPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">&quot;translation_en_to_ro&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;impl&quot;</span><span class="p">:</span> <span class="n">TranslationPipeline</span><span class="p">,</span>
        <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">TFAutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="n">AutoModelWithLMHead</span> <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pt&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="s2">&quot;t5-base&quot;</span><span class="p">},</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_fast&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>


<div class="viewcode-block" id="pipeline"><a class="viewcode-back" href="../../main_classes/pipelines.html#transformers.pipeline">[docs]</a><span class="k">def</span> <span class="nf">pipeline</span><span class="p">(</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PretrainedConfig</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PreTrainedTokenizer</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Pipeline</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility factory method to build a pipeline.</span>

<span class="sd">    Pipeline are made of:</span>

<span class="sd">        - A Tokenizer instance in charge of mapping raw textual input to token</span>
<span class="sd">        - A Model instance</span>
<span class="sd">        - Some (optional) post processing for enhancing model&#39;s output</span>


<span class="sd">    Args:</span>
<span class="sd">        task (:obj:`str`):</span>
<span class="sd">            The task defining which pipeline will be returned. Currently accepted tasks are:</span>

<span class="sd">            - &quot;feature-extraction&quot;: will return a :class:`~transformers.FeatureExtractionPipeline`</span>
<span class="sd">            - &quot;sentiment-analysis&quot;: will return a :class:`~transformers.TextClassificationPipeline`</span>
<span class="sd">            - &quot;ner&quot;: will return a :class:`~transformers.NerPipeline`</span>
<span class="sd">            - &quot;question-answering&quot;: will return a :class:`~transformers.QuestionAnsweringPipeline`</span>
<span class="sd">            - &quot;fill-mask&quot;: will return a :class:`~transformers.FillMaskPipeline`</span>
<span class="sd">        model (:obj:`str` or :obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The model that will be used by the pipeline to make predictions. This can be :obj:`None`, a string</span>
<span class="sd">            checkpoint identifier or an actual pre-trained model inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for</span>
<span class="sd">            TensorFlow.</span>

<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        config (:obj:`str` or :obj:`~transformers.PretrainedConfig`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The configuration that will be used by the pipeline to instantiate the model. This can be :obj:`None`,</span>
<span class="sd">            a string checkpoint identifier or an actual pre-trained model configuration inheriting from</span>
<span class="sd">            :class:`~transformers.PretrainedConfig`.</span>

<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        tokenizer (:obj:`str` or :obj:`~transformers.PreTrainedTokenizer`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The tokenizer that will be used by the pipeline to encode data for the model. This can be :obj:`None`,</span>
<span class="sd">            a string checkpoint identifier or an actual pre-trained tokenizer inheriting from</span>
<span class="sd">            :class:`~transformers.PreTrainedTokenizer`.</span>

<span class="sd">            If :obj:`None`, the default of the pipeline will be loaded.</span>
<span class="sd">        framework (:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">            The framework to use, either &quot;pt&quot; for PyTorch or &quot;tf&quot; for TensorFlow. The specified framework must be</span>
<span class="sd">            installed.</span>

<span class="sd">            If no framework is specified, will default to the one currently installed. If no framework is specified</span>
<span class="sd">            and both frameworks are installed, will default to PyTorch.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~transformers.Pipeline`: Class inheriting from :class:`~transformers.Pipeline`, according to</span>
<span class="sd">        the task.</span>

<span class="sd">    Examples::</span>

<span class="sd">        from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer</span>

<span class="sd">        # Sentiment analysis pipeline</span>
<span class="sd">        pipeline(&#39;sentiment-analysis&#39;)</span>

<span class="sd">        # Question answering pipeline, specifying the checkpoint identifier</span>
<span class="sd">        pipeline(&#39;question-answering&#39;, model=&#39;distilbert-base-cased-distilled-squad&#39;, tokenizer=&#39;bert-base-cased&#39;)</span>

<span class="sd">        # Named entity recognition pipeline, passing in a specific model and tokenizer</span>
<span class="sd">        model = AutoModelForTokenClassification.from_pretrained(&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;)</span>
<span class="sd">        tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)</span>
<span class="sd">        pipeline(&#39;ner&#39;, model=model, tokenizer=tokenizer)</span>

<span class="sd">        # Named entity recognition pipeline, passing a model and configuration with a HTTPS URL.</span>
<span class="sd">        model_url = &quot;https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-large-cased-finetuned-conll03-english/pytorch_model.bin&quot;</span>
<span class="sd">        config_url = &quot;https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-large-cased-finetuned-conll03-english/config.json&quot;</span>
<span class="sd">        pipeline(&#39;ner&#39;, model=model_url, config=config_url, tokenizer=&#39;bert-base-cased&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Retrieve the task</span>
    <span class="k">if</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_TASKS</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;Unknown task </span><span class="si">{}</span><span class="s2">, available tasks are </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">SUPPORTED_TASKS</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

    <span class="n">framework</span> <span class="o">=</span> <span class="n">framework</span> <span class="ow">or</span> <span class="n">get_framework</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="n">targeted_task</span> <span class="o">=</span> <span class="n">SUPPORTED_TASKS</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>
    <span class="n">task_class</span><span class="p">,</span> <span class="n">model_class</span> <span class="o">=</span> <span class="n">targeted_task</span><span class="p">[</span><span class="s2">&quot;impl&quot;</span><span class="p">],</span> <span class="n">targeted_task</span><span class="p">[</span><span class="n">framework</span><span class="p">]</span>

    <span class="c1"># Use default model/config/tokenizer for the task if no model is provided</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">models</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="p">[</span><span class="n">targeted_task</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">]]</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">framework</span><span class="p">]</span>

    <span class="c1"># Try to infer tokenizer from model or config name (if provided as str)</span>
    <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">ALL_PRETRAINED_CONFIG_ARCHIVE_MAP</span><span class="p">:</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">ALL_PRETRAINED_CONFIG_ARCHIVE_MAP</span><span class="p">:</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">config</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Impossible to guest what is the right tokenizer here</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;Impossible to guess which tokenizer to use. &quot;</span>
                <span class="s2">&quot;Please provided a PretrainedTokenizer class or a path/url/shortcut name to a pretrained tokenizer.&quot;</span>
            <span class="p">)</span>

    <span class="n">modelcard</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Try to infer modelcard from model or config name (if provided as str)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">modelcard</span> <span class="o">=</span> <span class="n">model</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">modelcard</span> <span class="o">=</span> <span class="n">config</span>

    <span class="c1"># Instantiate tokenizer if needed</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="c1"># For tuple we have (tokenizer name, {kwargs})</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">tokenizer</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="c1"># Instantiate config if needed</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Instantiate modelcard if needed</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modelcard</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">modelcard</span> <span class="o">=</span> <span class="n">ModelCard</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">modelcard</span><span class="p">)</span>

    <span class="c1"># Instantiate model if needed</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Handle transparent TF/PT model conversion</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;pt&quot;</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.h5&quot;</span><span class="p">):</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;from_tf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Model might be a TensorFlow model (ending with `.h5`) but TensorFlow is not available. &quot;</span>
                <span class="s2">&quot;Trying to load the model with PyTorch.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.bin&quot;</span><span class="p">):</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;from_pt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Model might be a PyTorch model (ending with `.bin`) but PyTorch is not available. &quot;</span>
                <span class="s2">&quot;Trying to load the model with Tensorflow.&quot;</span>
            <span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">task_class</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">modelcard</span><span class="o">=</span><span class="n">modelcard</span><span class="p">,</span> <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, huggingface

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>