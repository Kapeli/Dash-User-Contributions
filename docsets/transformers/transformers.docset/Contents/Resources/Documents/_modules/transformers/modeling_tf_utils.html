

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>transformers.modeling_tf_utils &mdash; transformers 4.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/huggingface.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/code-snippets.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/hidesidebar.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/js/custom.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> transformers
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using ðŸ¤— Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks.html">ðŸ¤— Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_doc/xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal/generation_utils.html">Utilities for Generation</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">transformers</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>transformers.modeling_tf_utils</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for transformers.modeling_tf_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding=utf-8</span>
<span class="c1"># Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.</span>
<span class="c1"># Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;TF general model utils.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.saving</span> <span class="kn">import</span> <span class="n">hdf5_format</span>

<span class="kn">from</span> <span class="nn">.configuration_utils</span> <span class="kn">import</span> <span class="n">PretrainedConfig</span>
<span class="kn">from</span> <span class="nn">.file_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DUMMY_INPUTS</span><span class="p">,</span>
    <span class="n">TF2_WEIGHTS_NAME</span><span class="p">,</span>
    <span class="n">WEIGHTS_NAME</span><span class="p">,</span>
    <span class="n">ModelOutput</span><span class="p">,</span>
    <span class="n">cached_path</span><span class="p">,</span>
    <span class="n">hf_bucket_url</span><span class="p">,</span>
    <span class="n">is_remote_url</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.generation_tf_utils</span> <span class="kn">import</span> <span class="n">TFGenerationMixin</span>
<span class="kn">from</span> <span class="nn">.tokenization_utils_base</span> <span class="kn">import</span> <span class="n">BatchEncoding</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">logging</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="TFModelUtilsMixin"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFModelUtilsMixin">[docs]</a><span class="k">class</span> <span class="nc">TFModelUtilsMixin</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A few utilities for :obj:`tf.keras.Model`, to be used as a mixin.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TFModelUtilsMixin.num_parameters"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFModelUtilsMixin.num_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">num_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">only_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of (optionally, trainable) parameters in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            only_trainable (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Whether or not to return only the number of trainable parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`int`: The number of parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">only_trainable</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="keras_serializable"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.keras_serializable">[docs]</a><span class="k">def</span> <span class="nf">keras_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decorate a Keras Layer class to support Keras serialization.</span>

<span class="sd">    This is done by:</span>

<span class="sd">    1. Adding a :obj:`transformers_config` dict to the Keras config dictionary in :obj:`get_config` (called by Keras at</span>
<span class="sd">       serialization time.</span>
<span class="sd">    2. Wrapping :obj:`__init__` to accept that :obj:`transformers_config` dict (passed by Keras at deserialization</span>
<span class="sd">       time) and convert it to a config object for the actual layer initializer.</span>
<span class="sd">    3. Registering the class as a custom object in Keras (if the Tensorflow version supports this), so that it does not</span>
<span class="sd">       need to be supplied in :obj:`custom_objects` in the call to :obj:`tf.keras.models.load_model`.</span>

<span class="sd">    Args:</span>
<span class="sd">        cls (a :obj:`tf.keras.layers.Layers subclass`):</span>
<span class="sd">            Typically a :obj:`TF.MainLayer` class in this project, in general must accept a :obj:`config` argument to</span>
<span class="sd">            its initializer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The same class object, with modifications for Keras deserialization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">initializer</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span>

    <span class="n">config_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;config_class&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Must set `config_class` to use @keras_serializable&quot;</span><span class="p">)</span>

    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">wrapped_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">args</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">PretrainedConfig</span><span class="p">)</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">config_class</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
            <span class="n">initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">PretrainedConfig</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must pass either `config` (PretrainedConfig) or `config` (dict)&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

    <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span> <span class="o">=</span> <span class="n">wrapped_init</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;get_config&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Only use @keras_serializable on tf.keras.layers.Layer subclasses&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">get_config</span><span class="p">,</span> <span class="s2">&quot;_is_default&quot;</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
            <span class="n">cfg</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">cfg</span>

        <span class="bp">cls</span><span class="o">.</span><span class="n">get_config</span> <span class="o">=</span> <span class="n">get_config</span>

    <span class="bp">cls</span><span class="o">.</span><span class="n">_keras_serializable</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="p">,</span> <span class="s2">&quot;register_keras_serializable&quot;</span><span class="p">):</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">register_keras_serializable</span><span class="p">()(</span><span class="bp">cls</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">cls</span></div>


<div class="viewcode-block" id="TFCausalLanguageModelingLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFCausalLanguageModelingLoss">[docs]</a><span class="k">class</span> <span class="nc">TFCausalLanguageModelingLoss</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for causal language modeling (CLM), that is, the task of guessing the next token.</span>

<span class="sd">    .. note::</span>

<span class="sd">        Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
            <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="p">)</span>
        <span class="c1"># make sure only labels that are not equal to -100 do not affect loss</span>
        <span class="n">active_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">reduced_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">2</span><span class="p">])),</span> <span class="n">active_loss</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">active_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">reduced_logits</span><span class="p">)</span></div>


<div class="viewcode-block" id="TFQuestionAnsweringLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFQuestionAnsweringLoss">[docs]</a><span class="k">class</span> <span class="nc">TFQuestionAnsweringLoss</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for question answering.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
            <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="p">)</span>
        <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="s2">&quot;start_position&quot;</span><span class="p">],</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="s2">&quot;end_position&quot;</span><span class="p">],</span> <span class="n">logits</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span></div>


<div class="viewcode-block" id="TFTokenClassificationLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFTokenClassificationLoss">[docs]</a><span class="k">class</span> <span class="nc">TFTokenClassificationLoss</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for token classification.</span>

<span class="sd">    .. note::</span>

<span class="sd">        Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
            <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="p">)</span>
        <span class="c1"># make sure only labels that are not equal to -100</span>
        <span class="c1"># are taken into account as loss</span>
        <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.&quot;</span><span class="p">)</span>
            <span class="n">active_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">active_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">reduced_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">2</span><span class="p">])),</span> <span class="n">active_loss</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">active_loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">reduced_logits</span><span class="p">)</span></div>


<div class="viewcode-block" id="TFSequenceClassificationLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFSequenceClassificationLoss">[docs]</a><span class="k">class</span> <span class="nc">TFSequenceClassificationLoss</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for sequence classification.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape_list</span><span class="p">(</span><span class="n">logits</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
                <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span></div>


<div class="viewcode-block" id="TFMultipleChoiceLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFMultipleChoiceLoss">[docs]</a><span class="k">class</span> <span class="nc">TFMultipleChoiceLoss</span><span class="p">(</span><span class="n">TFSequenceClassificationLoss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Loss function suitable for multiple choice tasks.&quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="TFMaskedLanguageModelingLoss"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFMaskedLanguageModelingLoss">[docs]</a><span class="k">class</span> <span class="nc">TFMaskedLanguageModelingLoss</span><span class="p">(</span><span class="n">TFCausalLanguageModelingLoss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for masked language modeling (MLM), that is, the task of guessing the masked tokens.</span>

<span class="sd">    .. note::</span>

<span class="sd">         Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.</span>
<span class="sd">    &quot;&quot;&quot;</span></div>


<span class="k">class</span> <span class="nc">TFNextSentencePredictionLoss</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function suitable for next sentence prediction (NSP), that is, the task of guessing the next sentence.</span>

<span class="sd">    .. note::</span>
<span class="sd">         Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
            <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="p">)</span>
        <span class="c1"># make sure only labels that are not equal to -100</span>
        <span class="c1"># are taken into account as loss</span>
        <span class="n">next_sentence_active_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">next_sentence_reduced_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">next_sentence_active_loss</span><span class="p">)</span>
        <span class="n">next_sentence_label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">next_sentence_active_loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">next_sentence_label</span><span class="p">,</span> <span class="n">next_sentence_reduced_logits</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">booleans_processing</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Process the input booleans of each model in order to be sure they are compliant with the execution mode (eager or</span>
<span class="sd">    graph)</span>

<span class="sd">    Args:</span>
<span class="sd">        config (:class:`~transformers.PretrainedConfig`):</span>
<span class="sd">            The config of the running model.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            The boolean parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary with the proper values for each boolean</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">final_booleans</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;output_attentions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_attentions&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_attentions&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="p">)</span>
        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;output_hidden_states&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_hidden_states&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_hidden_states&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">return_dict</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;use_cache&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;use_cache&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;use_cache&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;use_cache&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">use_cache</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_attentions&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_hidden_states&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="p">(</span><span class="s2">&quot;use_cache&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;use_cache&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                <span class="s2">&quot;The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.&quot;</span>
                <span class="s2">&quot;They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).&quot;</span>
            <span class="p">)</span>

        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;output_attentions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;output_hidden_states&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.&quot;</span><span class="p">)</span>
        <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="s2">&quot;use_cache&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">final_booleans</span><span class="p">[</span><span class="s2">&quot;use_cache&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">use_cache</span>

    <span class="k">return</span> <span class="n">final_booleans</span>


<span class="k">def</span> <span class="nf">input_processing</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Process the input of each TensorFlow model including the booleans. In case of a list of symbolic inputs, each input</span>
<span class="sd">    has to be named accordingly to the parameters name, i.e. `input_ids = tf.keras.Input(shape=(128,), dtype=&#39;int32&#39;,</span>
<span class="sd">    name=&quot;input_ids&quot;)` otherwise the order of the tensors will not be guaranteed during the training.</span>

<span class="sd">    Args:</span>
<span class="sd">        func (:obj:`callable`):</span>
<span class="sd">            The callable function of the TensorFlow model.</span>
<span class="sd">        config (:class:`~transformers.PretrainedConfig`):</span>
<span class="sd">            The config of the running model.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            The inputs of the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Two lists, one for the missing layers, and another one for the unexpected layers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">signature</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">func</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span>
    <span class="n">signature</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;kwargs&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">parameter_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">signature</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">allowed_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ModelOutput</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;inputs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;kwargs_call&quot;</span><span class="p">]:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;The `inputs` argument is deprecated and will be removed in a future version, use `input_ids` instead.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;kwargs_call&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;inputs&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;decoder_cached_states&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;kwargs_call&quot;</span><span class="p">]:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;past_key_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;kwargs_call&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;decoder_cached_states&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;kwargs_call&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The following keyword arguments are not supported by this model: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;kwargs_call&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">allowed_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not allowed only </span><span class="si">{</span><span class="n">allowed_types</span><span class="si">}</span><span class="s2"> is accepted for </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">):</span>
            <span class="c1"># EagerTensors don&#39;t allow to use the .name property so we check for a real Tensor</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
                <span class="c1"># Tensor names have always the pattern name:device_id then we check only the</span>
                <span class="c1"># name and not the device id</span>
                <span class="n">tensor_name</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">tensor_name</span> <span class="ow">in</span> <span class="n">parameter_names</span><span class="p">:</span>
                    <span class="n">output</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output</span><span class="p">[</span><span class="n">parameter_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">input</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">allowed_types</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">output</span><span class="p">[</span><span class="n">parameter_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">input</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Data of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not allowed only </span><span class="si">{</span><span class="n">allowed_types</span><span class="si">}</span><span class="s2"> is accepted for </span><span class="si">{</span><span class="n">parameter_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">BatchEncoding</span><span class="p">)):</span>
        <span class="k">if</span> <span class="s2">&quot;inputs&quot;</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The `inputs` argument is deprecated and will be removed in a future version, use `input_ids` instead.&quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;inputs&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;decoder_cached_states&quot;</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.&quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;past_key_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;decoder_cached_states&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">allowed_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">output</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">elif</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameter_names</span> <span class="ow">and</span> <span class="s2">&quot;args&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameter_names</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The parameter </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> does not belongs to the parameter list </span><span class="si">{</span><span class="n">parameter_names</span><span class="si">}</span><span class="s2"> and will be ignored.&quot;</span>
                <span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not allowed only </span><span class="si">{</span><span class="n">allowed_types</span><span class="si">}</span><span class="s2"> is accepted for </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output</span><span class="p">[</span><span class="n">parameter_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">input_ids</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Data of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not allowed only </span><span class="si">{</span><span class="n">allowed_types</span><span class="si">}</span><span class="s2"> is accepted for </span><span class="si">{</span><span class="n">parameter_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">parameter_names</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="ow">and</span> <span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;args&quot;</span><span class="p">:</span>
            <span class="n">output</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">signature</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">default</span><span class="p">)</span>

    <span class="c1"># When creating a SavedModel TF calls the method with LayerCall.__call__(args, **kwargs)</span>
    <span class="c1"># So to respect the proper output we have to add this exception</span>
    <span class="k">if</span> <span class="s2">&quot;args&quot;</span> <span class="ow">in</span> <span class="n">output</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="n">tensor_name</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">output</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># `args` in this case is always the first parameter, then `input_ids`</span>
            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">]</span>

        <span class="k">del</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s2">&quot;kwargs&quot;</span> <span class="ow">in</span> <span class="n">output</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;kwargs&quot;</span><span class="p">]</span>

    <span class="n">boolean_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;return_dict&quot;</span><span class="p">,</span> <span class="s2">&quot;output_attentions&quot;</span><span class="p">,</span> <span class="s2">&quot;output_hidden_states&quot;</span><span class="p">,</span> <span class="s2">&quot;use_cache&quot;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">output</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">booleans_processing</span><span class="p">(</span>
            <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">boolean_dict</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>


<span class="k">def</span> <span class="nf">load_tf_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">resolved_archive_file</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Detect missing and unexpected layers and load the TF weights accordingly to their names and shapes.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (:obj:`tf.keras.models.Model`):</span>
<span class="sd">            The model to load the weights into.</span>
<span class="sd">        resolved_archive_file (:obj:`str`):</span>
<span class="sd">            The location of the H5 file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Two lists, one for the missing layers, and another one for the unexpected layers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">missing_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">unexpected_layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Read the H5 file</span>
    <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">resolved_archive_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="c1"># Retrieve the name of each layer from the H5 file</span>
        <span class="n">saved_h5_model_layers_name</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_attributes_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s2">&quot;layer_names&quot;</span><span class="p">))</span>

        <span class="c1"># Find the missing layers from the high level list of layers</span>
        <span class="n">missing_layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">])</span> <span class="o">-</span> <span class="n">saved_h5_model_layers_name</span><span class="p">)</span>

        <span class="c1"># Find the unexpected layers from the high level list of layers</span>
        <span class="n">unexpected_layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">saved_h5_model_layers_name</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">]))</span>
        <span class="n">saved_weight_names_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">symbolic_weights_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Compute missing and unexpected sub layers</span>
        <span class="c1"># Store the weights in list of tuples that looks like [(weight_object, value_of_weight),...]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># if layer_name from the H5 file belongs to the layers from the instantiated model</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">saved_h5_model_layers_name</span><span class="p">:</span>
                <span class="c1"># Get the H5 layer object from its name</span>
                <span class="n">h5_layer_object</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                <span class="c1"># Get all the weights as a list from the layer object</span>
                <span class="n">symbolic_weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">non_trainable_weights</span>
                <span class="n">saved_weights</span> <span class="o">=</span> <span class="p">{}</span>

                <span class="c1"># Create a dict from the H5 saved model that looks like {&quot;weight_name&quot;: weight_value}</span>
                <span class="c1"># And a set with only the names</span>
                <span class="k">for</span> <span class="n">weight_name</span> <span class="ow">in</span> <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_attributes_from_hdf5_group</span><span class="p">(</span><span class="n">h5_layer_object</span><span class="p">,</span> <span class="s2">&quot;weight_names&quot;</span><span class="p">):</span>
                    <span class="c1"># TF names always start with the model name so we ignore it</span>
                    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">weight_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
                    <span class="n">saved_weights</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">h5_layer_object</span><span class="p">[</span><span class="n">weight_name</span><span class="p">])</span>

                    <span class="c1"># Add the updated name to the final list for computing missing/unexpected values</span>
                    <span class="n">saved_weight_names_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

                <span class="c1"># Loop over each weights from the instantiated model and compare with the weights from the H5 file</span>
                <span class="k">for</span> <span class="n">symbolic_weight</span> <span class="ow">in</span> <span class="n">symbolic_weights</span><span class="p">:</span>
                    <span class="c1"># TF names always start with the model name so we ignore it</span>
                    <span class="n">symbolic_weight_name</span> <span class="o">=</span> <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">symbolic_weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>

                    <span class="c1"># here we check if the current weight is among the weights from the H5 file</span>
                    <span class="c1"># If yes, get the weight_value of the corresponding weight from the H5 file</span>
                    <span class="c1"># If not, make the value to None</span>
                    <span class="n">saved_weight_value</span> <span class="o">=</span> <span class="n">saved_weights</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">symbolic_weight_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># Add the updated name to the final list for computing missing/unexpected values</span>
                    <span class="n">symbolic_weights_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">symbolic_weight_name</span><span class="p">)</span>

                    <span class="c1"># If the current weight is found</span>
                    <span class="k">if</span> <span class="n">saved_weight_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># Check if the shape of the current weight and the one from the H5 file are different</span>
                        <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">symbolic_weight</span><span class="p">)</span> <span class="o">!=</span> <span class="n">saved_weight_value</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                            <span class="c1"># If yes we reshape the weight from the H5 file accordingly to the current weight</span>
                            <span class="c1"># If the two shapes are not compatible we raise an issue</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">saved_weight_value</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">symbolic_weight</span><span class="p">))</span>
                            <span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                                <span class="n">e</span><span class="o">.</span><span class="n">args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">symbolic_weight</span><span class="p">),</span> <span class="n">saved_weight_value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                                <span class="k">raise</span> <span class="n">e</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">array</span> <span class="o">=</span> <span class="n">saved_weight_value</span>

                        <span class="c1"># We create the tuple that will be loaded and add it to the final list</span>
                        <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">symbolic_weight</span><span class="p">,</span> <span class="n">array</span><span class="p">))</span>

    <span class="c1"># Load all the weights</span>
    <span class="n">K</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>

    <span class="c1"># Compute the missing and unexpected layers</span>
    <span class="n">missing_layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">symbolic_weights_names</span> <span class="o">-</span> <span class="n">saved_weight_names_set</span><span class="p">))</span>
    <span class="n">unexpected_layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">saved_weight_names_set</span> <span class="o">-</span> <span class="n">symbolic_weights_names</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">missing_layers</span><span class="p">,</span> <span class="n">unexpected_layers</span>


<span class="k">def</span> <span class="nf">init_copy_embeddings</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function aims to reduce the embeddings in case new_num_tokens &lt; old_num_tokens or to pad with -1 in case</span>
<span class="sd">    new_num_tokens &gt; old_num_tokens. A mask is also computed in order to know which weight in the embeddings should be</span>
<span class="sd">    kept or not. Example:</span>

<span class="sd">        - if new_num_tokens=5 and old_num_tokens=4 and old_embeddings=[w1,w2,w3,w4]</span>

<span class="sd">            -  mask=[True,True,True,True,False] and current_weights=[w1,w2,w3,w4,-1]</span>
<span class="sd">        - if new_num_tokens=4 and old_num_tokens=5 and old_embeddings=[w1,w2,w3,w4,w5]</span>

<span class="sd">            - mask=[True,True,True,True] and current_weights=[w1,w2,w3,w4]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">old_num_tokens</span><span class="p">,</span> <span class="n">old_embedding_dim</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">)</span>
    <span class="n">size_diff</span> <span class="o">=</span> <span class="n">new_num_tokens</span> <span class="o">-</span> <span class="n">old_num_tokens</span>

    <span class="c1"># initialize new embeddings</span>
    <span class="c1"># Copy token embeddings from the previous ones</span>
    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">size_diff</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
        <span class="c1"># if the new size is greater than the old one, we extend the current embeddings with a padding until getting new size</span>
        <span class="c1"># and we create a mask to properly identify the padded values and be replaced by the values of the newly created</span>
        <span class="c1"># embeddings</span>
        <span class="n">current_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">old_embeddings</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_diff</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">constant_values</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">num_tokens_to_copy</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">old_num_tokens</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span><span class="n">num_tokens_to_copy</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_diff</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">constant_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># if the new size if lower than the old one, we take the current embeddings until the new size</span>
        <span class="n">current_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
            <span class="n">old_embeddings</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">old_embedding_dim</span><span class="p">]),</span>
        <span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mask</span><span class="p">,</span> <span class="n">current_weights</span>


<div class="viewcode-block" id="TFPreTrainedModel"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel">[docs]</a><span class="k">class</span> <span class="nc">TFPreTrainedModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">TFModelUtilsMixin</span><span class="p">,</span> <span class="n">TFGenerationMixin</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for all TF models.</span>

<span class="sd">    :class:`~transformers.TFPreTrainedModel` takes care of storing the configuration of the models and handles methods</span>
<span class="sd">    for loading, downloading and saving models as well as a few methods common to all models to:</span>

<span class="sd">        * resize the input embeddings,</span>
<span class="sd">        * prune heads in the self-attention heads.</span>

<span class="sd">    Class attributes (overridden by derived classes):</span>

<span class="sd">        - **config_class** (:class:`~transformers.PretrainedConfig`) -- A subclass of</span>
<span class="sd">          :class:`~transformers.PretrainedConfig` to use as configuration class for this model architecture.</span>
<span class="sd">        - **base_model_prefix** (:obj:`str`) -- A string indicating the attribute associated to the base model in</span>
<span class="sd">          derived classes of the same architecture adding modules on top of the base model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="c1"># a list of re pattern of tensor names to ignore from the model when loading the model weights</span>
    <span class="c1"># (and avoid unnecessary warnings).</span>
    <span class="n">_keys_to_ignore_on_load_missing</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># a list of re pattern of tensor names to ignore from the weights when loading the model weights</span>
    <span class="c1"># (and avoid unnecessary warnings).</span>
    <span class="n">_keys_to_ignore_on_load_unexpected</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dummy_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dummy inputs to build the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`Dict[str, tf.Tensor]`: The dummy inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">DUMMY_INPUTS</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">PretrainedConfig</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `PretrainedConfig`. &quot;</span>
                <span class="s2">&quot;To create a model from a pretrained model use &quot;</span>
                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># Save config and origin of the pretrained weights if given in model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name_or_path</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">name_or_path</span>

<div class="viewcode-block" id="TFPreTrainedModel.serving"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.serving">[docs]</a>    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
        <span class="n">input_signature</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_ids&quot;</span><span class="p">),</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">),</span>
                <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">serving</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method used for serving the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (:obj:`Dict[str, tf.Tensor]`):</span>
<span class="sd">                The input of the saved model as a dictionnary of tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">serving_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.serving_output"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.serving_output">[docs]</a>    <span class="k">def</span> <span class="nf">serving_output</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare the output of the saved model. Each model must implement this function.</span>

<span class="sd">        Args:</span>
<span class="sd">            output (:obj:`~transformers.TFBaseModelOutput`):</span>
<span class="sd">                The output returned by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_input_embeddings"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_input_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the model&#39;s input embeddings layer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`tf.Variable`: The embeddings layer mapping vocabulary to hidden states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">main_layer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model_prefix</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">main_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">main_layer</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.set_input_embeddings"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.set_input_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set model&#39;s input embeddings</span>

<span class="sd">        Args:</span>
<span class="sd">            value (:obj:`tf.Variable`):</span>
<span class="sd">                The new weights mapping hidden states to vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">main_layer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model_prefix</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">main_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The model does not implements the base_model_prefix attribute.&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">main_layer</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Building the model&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>
            <span class="n">main_layer</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_output_embeddings"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_output_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the model&#39;s output embeddings</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`tf.Variable`: The new weights mapping vocabulary to hidden states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lm_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">lm_head</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span>

        <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># Overwrite for models with output embeddings</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.set_output_embeddings"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.set_output_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">set_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set model&#39;s output embeddings</span>

<span class="sd">        Args:</span>
<span class="sd">            value (:obj:`tf.Variable`):</span>
<span class="sd">                The new weights mapping hidden states to vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lm_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">lm_head</span><span class="o">.</span><span class="n">set_output_embeddings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Building the model&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>
                <span class="n">lm_head</span><span class="o">.</span><span class="n">set_output_embeddings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_output_layer_with_bias"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_output_layer_with_bias">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_layer_with_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the layer that handles a bias attribute in case the model has an LM head with weights tied to the</span>
<span class="sd">        embeddings</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.keras.layers.Layer`: The layer that handles the bias, None if not an LM model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;The method get_output_layer_with_bias is deprecated. Please use `get_lm_head` instead.&quot;</span><span class="p">,</span> <span class="ne">FutureWarning</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_prefix_bias_name"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_prefix_bias_name">[docs]</a>    <span class="k">def</span> <span class="nf">get_prefix_bias_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the concatenated prefix name of the bias from the model name to the parent layer</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`str`: The prefix name of the bias.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The method get_prefix_bias_name is deprecated. Please use `get_bias` instead.&quot;</span><span class="p">,</span> <span class="ne">FutureWarning</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_bias"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_bias">[docs]</a>    <span class="k">def</span> <span class="nf">get_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dict of bias attached to an LM head. The key represents the name of the bias attribute.</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.Variable`: The weights representing the bias, None if not an LM model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lm_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lm_head</span><span class="o">.</span><span class="n">get_bias</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>

                <span class="k">return</span> <span class="n">lm_head</span><span class="o">.</span><span class="n">get_bias</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.set_bias"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.set_bias">[docs]</a>    <span class="k">def</span> <span class="nf">set_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set all the bias in the LM head.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (:obj:`Dict[tf.Variable]`):</span>
<span class="sd">                All the new bias attached to an LM head.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lm_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lm_head</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">lm_head</span><span class="o">.</span><span class="n">set_bias</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>
                <span class="n">lm_head</span><span class="o">.</span><span class="n">set_bias</span><span class="p">(</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.get_lm_head"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.get_lm_head">[docs]</a>    <span class="k">def</span> <span class="nf">get_lm_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The LM Head layer. This method must be overwritten by all the models that have a lm head.</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.keras.layers.Layer`: The LM head layer if the model has one, None if not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.resize_token_embeddings"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.resize_token_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">resize_token_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resizes input token embeddings matrix of the model if :obj:`new_num_tokens != config.vocab_size`.</span>

<span class="sd">        Takes care of tying weights embeddings afterwards if the model class has a :obj:`tie_weights()` method.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            new_num_tokens (:obj:`int`, `optional`):</span>
<span class="sd">                The number of new tokens in the embedding matrix. Increasing the size will add newly initialized</span>
<span class="sd">                vectors at the end. Reducing the size will remove vectors from the end. If not provided or :obj:`None`,</span>
<span class="sd">                just returns a pointer to the input tokens :obj:`tf.Variable` module of the model without doing</span>
<span class="sd">                anything.</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.Variable`: Pointer to the input tokens Embeddings Module of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">new_num_tokens</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">new_num_tokens</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_word_embedding_weight</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">())</span>

        <span class="n">model_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resize_token_embeddings</span><span class="p">(</span><span class="n">new_num_tokens</span><span class="p">)</span>

        <span class="c1"># Update base model and current model config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">new_num_tokens</span>

        <span class="k">return</span> <span class="n">model_embeds</span></div>

    <span class="k">def</span> <span class="nf">_get_word_embedding_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_layer</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;word_embeddings&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">word_embeddings</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">weight</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">decoder</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Here we build the word embeddings weights if not exists.</span>
            <span class="c1"># And then we retry to get the attribute once built.</span>
            <span class="bp">self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;word_embeddings&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">word_embeddings</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">weight</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">embedding_layer</span><span class="o">.</span><span class="n">decoder</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_resize_token_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">):</span>
        <span class="n">old_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_word_embedding_weight</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">())</span>
        <span class="n">new_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_resized_embeddings</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>

        <span class="c1"># if word embeddings are not tied, make sure that lm head bias is resized as well</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_bias</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">old_lm_head_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_bias</span><span class="p">()</span>
            <span class="n">new_lm_head_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_resized_lm_head_bias</span><span class="p">(</span><span class="n">old_lm_head_bias</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">set_bias</span><span class="p">(</span><span class="n">new_lm_head_bias</span><span class="p">)</span>

        <span class="c1"># if word embeddings are not tied, make sure that lm head decoder is resized as well</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">old_lm_head_decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_word_embedding_weight</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">())</span>
            <span class="n">new_lm_head_decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_resized_lm_head_decoder</span><span class="p">(</span><span class="n">old_lm_head_decoder</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">set_output_embeddings</span><span class="p">(</span><span class="n">new_lm_head_decoder</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">new_embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_resized_lm_head_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_lm_head_bias</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a resized bias from the old ones. Increasing the size will add newly initialized vectors at the end.</span>
<span class="sd">        Reducing the size will remove vectors from the end</span>

<span class="sd">        Args:</span>
<span class="sd">            old_lm_head_bias (:obj:`tf.Variable`):</span>
<span class="sd">                Old lm head bias to be resized.</span>
<span class="sd">            new_num_tokens (:obj:`int`, `optional`):</span>
<span class="sd">                New number of tokens in the linear matrix.</span>

<span class="sd">                Increasing the size will add newly initialized vectors at the end. Reducing the size will remove</span>
<span class="sd">                vectors from the end. If not provided or :obj:`None`, just returns None</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.Variable`: Pointer to the resized bias.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_lm_head_bias</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">attr</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">old_lm_head_bias</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">first_dim</span><span class="p">,</span> <span class="n">old_num_tokens</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">weight</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">size_diff</span> <span class="o">=</span> <span class="n">new_num_tokens</span> <span class="o">-</span> <span class="n">old_num_tokens</span>
            <span class="n">final_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_num_tokens</span><span class="p">]</span> <span class="k">if</span> <span class="n">first_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">first_dim</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">]</span>

            <span class="c1"># initialize new bias</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">size_diff</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">padding_shape</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_diff</span><span class="p">]]</span> <span class="k">if</span> <span class="n">first_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_diff</span><span class="p">]]</span>
                <span class="n">current_bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">padding_shape</span><span class="p">),</span> <span class="n">constant_values</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">num_tokens_to_copy</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">old_num_tokens</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>
                <span class="n">mask_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_tokens_to_copy</span><span class="p">]</span> <span class="k">if</span> <span class="n">first_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_tokens_to_copy</span><span class="p">]</span>
                <span class="n">bias_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">mask_shape</span><span class="p">),</span> <span class="kc">True</span><span class="p">)</span>
                <span class="n">bias_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">bias_mask</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">padding_shape</span><span class="p">),</span> <span class="n">constant_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">slice_from</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">first_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="n">current_bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
                    <span class="n">weight</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">slice_from</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">final_shape</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">bias_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">final_shape</span><span class="p">),</span> <span class="kc">True</span><span class="p">)</span>

            <span class="n">new_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">final_shape</span><span class="p">,</span>
                <span class="n">initializer</span><span class="o">=</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span>
                <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">init_bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bias_mask</span><span class="p">,</span> <span class="n">current_bias</span><span class="p">,</span> <span class="n">new_bias</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>

            <span class="n">new_bias</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">init_bias</span><span class="p">)</span>
            <span class="n">new_lm_head_bias</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_bias</span>

        <span class="k">return</span> <span class="n">new_lm_head_bias</span>

    <span class="k">def</span> <span class="nf">_get_resized_lm_head_decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_lm_head_decoder</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a resized decoder from the old ones. Increasing the size will add newly initialized vectors at the end.</span>
<span class="sd">        Reducing the size will remove vectors from the end</span>

<span class="sd">        Args:</span>
<span class="sd">            old_lm_head_decoder (:obj:`tf.Variable`):</span>
<span class="sd">                Old lm head decoder to be resized.</span>
<span class="sd">            new_num_tokens (:obj:`int`, `optional`):</span>
<span class="sd">                New number of tokens in the linear matrix.</span>

<span class="sd">                Increasing the size will add newly initialized vectors at the end. Reducing the size will remove</span>
<span class="sd">                vectors from the end. If not provided or :obj:`None`, just returns None</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.Variable`: Pointer to the resized decoder or None if the output embeddings are differents of the</span>
<span class="sd">            input ones.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_lm_head_decoder</span> <span class="o">=</span> <span class="n">old_lm_head_decoder</span>
        <span class="n">is_input_output_equals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_word_embedding_weight</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">())</span> <span class="o">==</span> <span class="n">old_lm_head_decoder</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">old_lm_head_decoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_input_output_equals</span><span class="p">:</span>
            <span class="n">old_embedding_dim</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">old_lm_head_decoder</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">decoder_mask</span><span class="p">,</span> <span class="n">current_decoder</span> <span class="o">=</span> <span class="n">init_copy_embeddings</span><span class="p">(</span><span class="n">old_lm_head_decoder</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>
            <span class="n">new_lm_head_decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">old_embedding_dim</span><span class="p">),</span>
                <span class="n">initializer</span><span class="o">=</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span>
                <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">old_lm_head_decoder</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">init_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">decoder_mask</span><span class="p">,</span> <span class="n">current_decoder</span><span class="p">,</span> <span class="n">new_lm_head_decoder</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>

            <span class="n">new_lm_head_decoder</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">init_decoder</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_lm_head_decoder</span>

    <span class="k">def</span> <span class="nf">_get_resized_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_embeddings</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a resized Embedding weights from a provided token Embedding weights. Increasing the size will add newly</span>
<span class="sd">        initialized vectors at the end. Reducing the size will remove vectors from the end</span>

<span class="sd">        Args:</span>
<span class="sd">            old_embeddings (:obj:`tf.Variable`):</span>
<span class="sd">                Old embeddings to be resized.</span>
<span class="sd">            new_num_tokens (:obj:`int`, `optional`):</span>
<span class="sd">                New number of tokens in the embedding matrix.</span>

<span class="sd">                Increasing the size will add newly initialized vectors at the end. Reducing the size will remove</span>
<span class="sd">                vectors from the end. If not provided or :obj:`None`, just returns a pointer to the input tokens</span>
<span class="sd">                :obj:`tf.Variable`` module of the model without doing anything.</span>

<span class="sd">        Return:</span>
<span class="sd">            :obj:`tf.Variable`: Pointer to the resized Embedding Module or the old Embedding Module if</span>
<span class="sd">            :obj:`new_num_tokens` is :obj:`None`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">old_embedding_dim</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">init_range</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;initializer_range&quot;</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">embeddings_mask</span><span class="p">,</span> <span class="n">current_embeddings</span> <span class="o">=</span> <span class="n">init_copy_embeddings</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span>
        <span class="n">new_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">old_embeddings</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">old_embedding_dim</span><span class="p">],</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">get_initializer</span><span class="p">(</span><span class="n">init_range</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">init_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">embeddings_mask</span><span class="p">,</span> <span class="n">current_embeddings</span><span class="p">,</span> <span class="n">new_embeddings</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>

        <span class="n">new_embeddings</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">init_embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_embeddings</span>

<div class="viewcode-block" id="TFPreTrainedModel.prune_heads"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.prune_heads">[docs]</a>    <span class="k">def</span> <span class="nf">prune_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heads_to_prune</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prunes heads of the base model.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            heads_to_prune (:obj:`Dict[int, List[int]]`):</span>
<span class="sd">                Dictionary with keys being selected layer indices (:obj:`int`) and associated values being the list of</span>
<span class="sd">                heads to prune in said layer (list of :obj:`int`). For instance {1: [0, 2], 2: [2, 3]} will prune heads</span>
<span class="sd">                0 and 2 on layer 1 and heads 2 and 3 on layer 2.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.save_pretrained"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.save_pretrained">[docs]</a>    <span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">,</span> <span class="n">saved_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save a model and its configuration file to a directory, so that it can be re-loaded using the</span>
<span class="sd">        :func:`~transformers.TFPreTrainedModel.from_pretrained` class method.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            save_directory (:obj:`str`):</span>
<span class="sd">                Directory to which to save. Will be created if it doesn&#39;t exist.</span>
<span class="sd">            saved_model (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                If the model has to be saved in saved model format as well or not.</span>
<span class="sd">            version (:obj:`int`, `optional`, defaults to 1):</span>
<span class="sd">                The version of the saved model. A saved model needs to be versioned in order to be properly loaded by</span>
<span class="sd">                TensorFlow Serving as detailed in the official documentation</span>
<span class="sd">                https://www.tensorflow.org/tfx/serving/serving_basic</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Provided path (</span><span class="si">{}</span><span class="s2">) should be a directory, not a file&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">save_directory</span><span class="p">))</span>
            <span class="k">return</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">saved_model</span><span class="p">:</span>
            <span class="n">saved_model_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="s2">&quot;saved_model&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">saved_model_dir</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">signatures</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">serving</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saved model created in </span><span class="si">{</span><span class="n">saved_model_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save configuration file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span>

        <span class="c1"># If we save using the predefined names, we can load using `from_pretrained`</span>
        <span class="n">output_model_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">TF2_WEIGHTS_NAME</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">output_model_file</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model weights saved in </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_model_file</span><span class="p">))</span></div>

<div class="viewcode-block" id="TFPreTrainedModel.from_pretrained"><a class="viewcode-back" href="../../main_classes/model.html#transformers.modeling_tf_utils.TFPreTrainedModel.from_pretrained">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.</span>

<span class="sd">        The warning `Weights from XXX not initialized from pretrained model` means that the weights of XXX do not come</span>
<span class="sd">        pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning</span>
<span class="sd">        task.</span>

<span class="sd">        The warning `Weights from XXX not used in YYY` means that the layer XXX is not used by YYY, therefore those</span>
<span class="sd">        weights are discarded.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            pretrained_model_name_or_path (:obj:`str`, `optional`):</span>
<span class="sd">                Can be either:</span>

<span class="sd">                    - A string, the `model id` of a pretrained model hosted inside a model repo on huggingface.co.</span>
<span class="sd">                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under</span>
<span class="sd">                      a user or organization name, like ``dbmdz/bert-base-german-cased``.</span>
<span class="sd">                    - A path to a `directory` containing model weights saved using</span>
<span class="sd">                      :func:`~transformersTF.PreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.</span>
<span class="sd">                    - A path or url to a `PyTorch state_dict save file` (e.g, ``./pt_model/pytorch_model.bin``). In</span>
<span class="sd">                      this case, ``from_pt`` should be set to :obj:`True` and a configuration object should be provided</span>
<span class="sd">                      as ``config`` argument. This loading path is slower than converting the PyTorch model in a</span>
<span class="sd">                      TensorFlow model using the provided conversion scripts and loading the TensorFlow model</span>
<span class="sd">                      afterwards.</span>
<span class="sd">                    - :obj:`None` if you are both providing the configuration and state dictionary (resp. with keyword</span>
<span class="sd">                      arguments ``config`` and ``state_dict``).</span>
<span class="sd">            model_args (sequence of positional arguments, `optional`):</span>
<span class="sd">                All remaning positional arguments will be passed to the underlying model&#39;s ``__init__`` method.</span>
<span class="sd">            config (:obj:`Union[PretrainedConfig, str]`, `optional`):</span>
<span class="sd">                Can be either:</span>

<span class="sd">                    - an instance of a class derived from :class:`~transformers.PretrainedConfig`,</span>
<span class="sd">                    - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained`.</span>

<span class="sd">                Configuration for the model to use instead of an automatically loaded configuation. Configuration can</span>
<span class="sd">                be automatically loaded when:</span>

<span class="sd">                    - The model is a model provided by the library (loaded with the `model id` string of a pretrained</span>
<span class="sd">                      model).</span>
<span class="sd">                    - The model was saved using :func:`~transformers.TFPreTrainedModel.save_pretrained` and is reloaded</span>
<span class="sd">                      by supplying the save directory.</span>
<span class="sd">                    - The model is loaded by supplying a local directory as ``pretrained_model_name_or_path`` and a</span>
<span class="sd">                      configuration JSON file named `config.json` is found in the directory.</span>
<span class="sd">            from_pt: (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Load the model weights from a PyTorch state_dict save file (see docstring of</span>
<span class="sd">                ``pretrained_model_name_or_path`` argument).</span>
<span class="sd">            cache_dir (:obj:`str`, `optional`):</span>
<span class="sd">                Path to a directory in which a downloaded pretrained model configuration should be cached if the</span>
<span class="sd">                standard cache should not be used.</span>
<span class="sd">            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Whether or not to force the (re-)download of the model weights and configuration files, overriding the</span>
<span class="sd">                cached versions if they exist.</span>
<span class="sd">            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Whether or not to delete incompletely received files. Will attempt to resume the download if such a</span>
<span class="sd">                file exists.</span>
<span class="sd">            proxies: (:obj:`Dict[str, str], `optional`):</span>
<span class="sd">                A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{&#39;http&#39;: &#39;foo.bar:3128&#39;,</span>
<span class="sd">                &#39;http://hostname&#39;: &#39;foo.bar:4012&#39;}`. The proxies are used on each request.</span>
<span class="sd">            output_loading_info(:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.</span>
<span class="sd">            local_files_only(:obj:`bool`, `optional`, defaults to :obj:`False`):</span>
<span class="sd">                Whether or not to only look at local files (e.g., not try doanloading the model).</span>
<span class="sd">            use_auth_token (:obj:`str` or `bool`, `optional`):</span>
<span class="sd">                The token to use as HTTP bearer authorization for remote files. If :obj:`True`, will use the token</span>
<span class="sd">                generated when running :obj:`transformers-cli login` (stored in :obj:`~/.huggingface`).</span>
<span class="sd">            revision(:obj:`str`, `optional`, defaults to :obj:`&quot;main&quot;`):</span>
<span class="sd">                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a</span>
<span class="sd">                git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any</span>
<span class="sd">                identifier allowed by git.</span>
<span class="sd">            mirror(:obj:`str`, `optional`, defaults to :obj:`None`):</span>
<span class="sd">                Mirror source to accelerate downloads in China. If you are from China and have an accessibility</span>
<span class="sd">                problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.</span>
<span class="sd">                Please refer to the mirror site for more information.</span>
<span class="sd">            kwargs (remaining dictionary of keyword arguments, `optional`):</span>
<span class="sd">                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,</span>
<span class="sd">                :obj:`output_attentions=True`). Behaves differently depending on whether a ``config`` is provided or</span>
<span class="sd">                automatically loaded:</span>

<span class="sd">                    - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the</span>
<span class="sd">                      underlying model&#39;s ``__init__`` method (we assume all relevant updates to the configuration have</span>
<span class="sd">                      already been done)</span>
<span class="sd">                    - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class</span>
<span class="sd">                      initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of</span>
<span class="sd">                      ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute</span>
<span class="sd">                      with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration</span>
<span class="sd">                      attribute will be passed to the underlying model&#39;s ``__init__`` function.</span>

<span class="sd">        .. note::</span>

<span class="sd">            Passing :obj:`use_auth_token=True` is required when you want to use a private model.</span>

<span class="sd">        Examples::</span>

<span class="sd">            &gt;&gt;&gt; from transformers import BertConfig, TFBertModel</span>
<span class="sd">            &gt;&gt;&gt; # Download model and configuration from huggingface.co and cache.</span>
<span class="sd">            &gt;&gt;&gt; model = TFBertModel.from_pretrained(&#39;bert-base-uncased&#39;)</span>
<span class="sd">            &gt;&gt;&gt; # Model was saved using `save_pretrained(&#39;./test/saved_model/&#39;)` (for example purposes, not runnable).</span>
<span class="sd">            &gt;&gt;&gt; model = TFBertModel.from_pretrained(&#39;./test/saved_model/&#39;)</span>
<span class="sd">            &gt;&gt;&gt; # Update configuration during loading.</span>
<span class="sd">            &gt;&gt;&gt; model = TFBertModel.from_pretrained(&#39;bert-base-uncased&#39;, output_attentions=True)</span>
<span class="sd">            &gt;&gt;&gt; assert model.config.output_attentions == True</span>
<span class="sd">            &gt;&gt;&gt; # Loading from a Pytorch model file instead of a TensorFlow checkpoint (slower, for example purposes, not runnable).</span>
<span class="sd">            &gt;&gt;&gt; config = BertConfig.from_json_file(&#39;./pt_model/my_pt_model_config.json&#39;)</span>
<span class="sd">            &gt;&gt;&gt; model = TFBertModel.from_pretrained(&#39;./pt_model/my_pytorch_model.bin&#39;, from_pt=True, config=config)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">from_pt</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;from_pt&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">force_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">resume_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">proxies</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">output_loading_info</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;output_loading_info&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">local_files_only</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">use_auth_token</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_auth_token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">revision</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;revision&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">mirror</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;mirror&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Load config if we don&#39;t provide a configuration</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">PretrainedConfig</span><span class="p">):</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">config</span> <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pretrained_model_name_or_path</span>
            <span class="n">config</span><span class="p">,</span> <span class="n">model_kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">config_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">config_path</span><span class="p">,</span>
                <span class="o">*</span><span class="n">model_args</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                <span class="n">return_unused_kwargs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                <span class="n">use_auth_token</span><span class="o">=</span><span class="n">use_auth_token</span><span class="p">,</span>
                <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

        <span class="c1"># Load model</span>
        <span class="k">if</span> <span class="n">pretrained_model_name_or_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">from_pt</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)):</span>
                    <span class="c1"># Load from a PyTorch checkpoint in priority if from_pt</span>
                    <span class="n">archive_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">TF2_WEIGHTS_NAME</span><span class="p">)):</span>
                    <span class="c1"># Load from a TF 2.0 checkpoint</span>
                    <span class="n">archive_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">TF2_WEIGHTS_NAME</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">EnvironmentError</span><span class="p">(</span>
                        <span class="s2">&quot;Error no file named </span><span class="si">{}</span><span class="s2"> found in directory </span><span class="si">{}</span><span class="s2"> or `from_pt` set to False&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="p">[</span><span class="n">WEIGHTS_NAME</span><span class="p">,</span> <span class="n">TF2_WEIGHTS_NAME</span><span class="p">],</span> <span class="n">pretrained_model_name_or_path</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_remote_url</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">):</span>
                <span class="n">archive_file</span> <span class="o">=</span> <span class="n">pretrained_model_name_or_path</span>
            <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span> <span class="o">+</span> <span class="s2">&quot;.index&quot;</span><span class="p">):</span>
                <span class="n">archive_file</span> <span class="o">=</span> <span class="n">pretrained_model_name_or_path</span> <span class="o">+</span> <span class="s2">&quot;.index&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">archive_file</span> <span class="o">=</span> <span class="n">hf_bucket_url</span><span class="p">(</span>
                    <span class="n">pretrained_model_name_or_path</span><span class="p">,</span>
                    <span class="n">filename</span><span class="o">=</span><span class="p">(</span><span class="n">WEIGHTS_NAME</span> <span class="k">if</span> <span class="n">from_pt</span> <span class="k">else</span> <span class="n">TF2_WEIGHTS_NAME</span><span class="p">),</span>
                    <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                    <span class="n">mirror</span><span class="o">=</span><span class="n">mirror</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Load from URL or cache if already cached</span>
                <span class="n">resolved_archive_file</span> <span class="o">=</span> <span class="n">cached_path</span><span class="p">(</span>
                    <span class="n">archive_file</span><span class="p">,</span>
                    <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                    <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                    <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                    <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                    <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                    <span class="n">use_auth_token</span><span class="o">=</span><span class="n">use_auth_token</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">EnvironmentError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Can&#39;t load weights for &#39;</span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2">&#39;. Make sure that:</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;- &#39;</span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2">&#39; is a correct model identifier listed on &#39;https://huggingface.co/models&#39;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;- or &#39;</span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2">&#39; is the correct path to a directory containing a file named one of </span><span class="si">{</span><span class="n">TF2_WEIGHTS_NAME</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">WEIGHTS_NAME</span><span class="si">}</span><span class="s2">.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">EnvironmentError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">resolved_archive_file</span> <span class="o">==</span> <span class="n">archive_file</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;loading weights file </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">archive_file</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;loading weights file </span><span class="si">{}</span><span class="s2"> from cache at </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">archive_file</span><span class="p">,</span> <span class="n">resolved_archive_file</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">resolved_archive_file</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">config</span><span class="o">.</span><span class="n">name_or_path</span> <span class="o">=</span> <span class="n">pretrained_model_name_or_path</span>

        <span class="c1"># Instantiate model.</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">from_pt</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">.modeling_tf_pytorch_utils</span> <span class="kn">import</span> <span class="n">load_pytorch_checkpoint_in_tf2_model</span>

            <span class="c1"># Load from a PyTorch checkpoint</span>
            <span class="k">return</span> <span class="n">load_pytorch_checkpoint_in_tf2_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">resolved_archive_file</span><span class="p">,</span> <span class="n">allow_missing_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">model</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>  <span class="c1"># build the network with dummy inputs</span>

        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">resolved_archive_file</span><span class="p">),</span> <span class="s2">&quot;Error retrieving file </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">resolved_archive_file</span><span class="p">)</span>
        <span class="c1"># &#39;by_name&#39; allow us to do transfer learning by skipping/adding layers</span>
        <span class="c1"># see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1339-L1357</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">missing_keys</span><span class="p">,</span> <span class="n">unexpected_keys</span> <span class="o">=</span> <span class="n">load_tf_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">resolved_archive_file</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">OSError</span><span class="p">(</span>
                <span class="s2">&quot;Unable to load weights from h5 file. &quot;</span>
                <span class="s2">&quot;If you tried to load a TF 2.0 model from a PyTorch checkpoint, please set from_pt=True. &quot;</span>
            <span class="p">)</span>

        <span class="n">model</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">)</span>  <span class="c1"># Make sure restore ops are run</span>

        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_keys_to_ignore_on_load_missing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pat</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_keys_to_ignore_on_load_missing</span><span class="p">:</span>
                <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">missing_keys</span> <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pat</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_keys_to_ignore_on_load_unexpected</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pat</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_keys_to_ignore_on_load_unexpected</span><span class="p">:</span>
                <span class="n">unexpected_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">unexpected_keys</span> <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pat</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unexpected_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Some layers from the model checkpoint at </span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2"> were not used when &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;initializing </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;- This IS expected if you are initializing </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> from the checkpoint of a model trained on another task &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;- This IS NOT expected if you are initializing </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> from the checkpoint of a model that you expect &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All model checkpoint layers were used when initializing </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Some layers of </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> were not initialized from the model checkpoint at </span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;and are newly initialized: </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;All the layers of </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> were initialized from the model checkpoint at </span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;If your task is similar to the task the model of the checkpoint was trained on, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;you can already use </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> for predictions without further training.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">output_loading_info</span><span class="p">:</span>
            <span class="n">loading_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;missing_keys&quot;</span><span class="p">:</span> <span class="n">missing_keys</span><span class="p">,</span> <span class="s2">&quot;unexpected_keys&quot;</span><span class="p">:</span> <span class="n">unexpected_keys</span><span class="p">}</span>

            <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">loading_info</span>

        <span class="k">return</span> <span class="n">model</span></div></div>


<div class="viewcode-block" id="TFConv1D"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFConv1D">[docs]</a><span class="k">class</span> <span class="nc">TFConv1D</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).</span>

<span class="sd">    Basically works like a linear layer but the weights are transposed.</span>

<span class="sd">    Args:</span>
<span class="sd">        nf (:obj:`int`):</span>
<span class="sd">            The number of output features.</span>
<span class="sd">        nx (:obj:`int`):</span>
<span class="sd">            The number of input features.</span>
<span class="sd">        initializer_range (:obj:`float`, `optional`, defaults to 0.02):</span>
<span class="sd">            The standard deviation to use to initialize the weights.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Additional keyword arguments passed along to the :obj:`__init__` of :obj:`tf.keras.layers.Layer`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nf</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nf</span> <span class="o">=</span> <span class="n">nf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nx</span> <span class="o">=</span> <span class="n">nx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nf</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">get_initializer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nf</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bz</span><span class="p">,</span> <span class="n">sl</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">x</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">bz</span><span class="p">,</span> <span class="n">sl</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nf</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="TFSharedEmbeddings"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFSharedEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">TFSharedEmbeddings</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct shared token embeddings.</span>

<span class="sd">    The weights of the embedding layer is usually shared with the weights of the linear decoder when doing language</span>
<span class="sd">    modeling.</span>

<span class="sd">    Args:</span>
<span class="sd">        vocab_size (:obj:`int`):</span>
<span class="sd">            The size of the vocabulary, e.g., the number of unique tokens.</span>
<span class="sd">        hidden_size (:obj:`int`):</span>
<span class="sd">            The size of the embedding vectors.</span>
<span class="sd">        initializer_range (:obj:`float`, `optional`):</span>
<span class="sd">            The standard deviation to use when initializing the weights. If no value is provided, it will default to</span>
<span class="sd">            :math:`1/\sqrt{hidden\_size}`.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Additional keyword arguments passed along to the :obj:`__init__` of :obj:`tf.keras.layers.Layer`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">initializer_range</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">hidden_size</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span> <span class="k">if</span> <span class="n">initializer_range</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">initializer_range</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build shared token embedding layer Shared weights logic adapted from</span>
<span class="sd">        https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">get_initializer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;vocab_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="s2">&quot;initializer_range&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">base_config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_config</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

<div class="viewcode-block" id="TFSharedEmbeddings.call"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFSharedEmbeddings.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;embedding&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get token embeddings of inputs or decode final hidden state.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (:obj:`tf.Tensor`):</span>
<span class="sd">                In embedding mode, should be an int64 tensor with shape :obj:`[batch_size, length]`.</span>

<span class="sd">                In linear mode, should be a float tensor with shape :obj:`[batch_size, length, hidden_size]`.</span>
<span class="sd">            mode (:obj:`str`, defaults to :obj:`&quot;embedding&quot;`):</span>
<span class="sd">               A valid value is either :obj:`&quot;embedding&quot;` or :obj:`&quot;linear&quot;`, the first one indicates that the layer</span>
<span class="sd">               should be used as an embedding layer, the second one that the layer should be used as a linear decoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`tf.Tensor`: In embedding mode, the output is a float32 embedding tensor, with shape</span>
<span class="sd">            :obj:`[batch_size, length, embedding_size]`.</span>

<span class="sd">            In linear mode, the output is a float32 with shape :obj:`[batch_size, length, vocab_size]`.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if :obj:`mode` is not valid.</span>

<span class="sd">        Shared weights logic is adapted from `here</span>
<span class="sd">        &lt;https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24&gt;`__.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;embedding&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_linear</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;mode </span><span class="si">{}</span><span class="s2"> is not valid.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Applies embedding based on inputs tensor.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes logits by running inputs through a linear layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A float32 tensor with shape [..., hidden_size]</span>

<span class="sd">        Returns:</span>
<span class="sd">            float32 tensor with shape [..., vocab_size].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">first_dims</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">])</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">first_dims</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">])</span></div>


<div class="viewcode-block" id="TFSequenceSummary"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFSequenceSummary">[docs]</a><span class="k">class</span> <span class="nc">TFSequenceSummary</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a single vector summary of a sequence hidden states.</span>

<span class="sd">    Args:</span>
<span class="sd">        config (:class:`~transformers.PretrainedConfig`):</span>
<span class="sd">            The config used by the model. Relevant arguments in the config class of the model are (refer to the actual</span>
<span class="sd">            config class of your model for the default values it uses):</span>

<span class="sd">            - **summary_type** (:obj:`str`) -- The method to use to make this summary. Accepted values are:</span>

<span class="sd">                - :obj:`&quot;last&quot;` -- Take the last token hidden state (like XLNet)</span>
<span class="sd">                - :obj:`&quot;first&quot;` -- Take the first token hidden state (like Bert)</span>
<span class="sd">                - :obj:`&quot;mean&quot;` -- Take the mean of all tokens hidden states</span>
<span class="sd">                - :obj:`&quot;cls_index&quot;` -- Supply a Tensor of classification token position (GPT/GPT-2)</span>
<span class="sd">                - :obj:`&quot;attn&quot;` -- Not implemented now, use multi-head attention</span>

<span class="sd">            - **summary_use_proj** (:obj:`bool`) -- Add a projection after the vector extraction.</span>
<span class="sd">            - **summary_proj_to_labels** (:obj:`bool`) -- If :obj:`True`, the projection outputs to</span>
<span class="sd">              :obj:`config.num_labels` classes (otherwise to :obj:`config.hidden_size`).</span>
<span class="sd">            - **summary_activation** (:obj:`Optional[str]`) -- Set to :obj:`&quot;tanh&quot;` to add a tanh activation to the</span>
<span class="sd">              output, another string or :obj:`None` will add no activation.</span>
<span class="sd">            - **summary_first_dropout** (:obj:`float`) -- Optional dropout probability before the projection and</span>
<span class="sd">              activation.</span>
<span class="sd">            - **summary_last_dropout** (:obj:`float`)-- Optional dropout probability after the projection and</span>
<span class="sd">              activation.</span>

<span class="sd">        initializer_range (:obj:`float`, defaults to 0.02): The standard deviation to use to initialize the weights.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Additional keyword arguments passed along to the :obj:`__init__` of :obj:`tf.keras.layers.Layer`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span><span class="p">,</span> <span class="n">initializer_range</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_type</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_use_proj&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;last&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;attn&quot;</span><span class="p">:</span>
            <span class="c1"># We should use a standard multi-head attention module with absolute positional embedding for that.</span>
            <span class="c1"># Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276</span>
            <span class="c1"># We can probably just use the multi-head attention module of PyTorch &gt;=1.1.0</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">has_summary</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_use_proj&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_use_proj</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_summary</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_proj_to_labels&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_proj_to_labels</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">num_classes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_classes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">get_initializer</span><span class="p">(</span><span class="n">initializer_range</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;summary&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">has_activation</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_activation&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_activation</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_activation</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">tanh</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">has_first_dropout</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_first_dropout&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_first_dropout</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_first_dropout</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">first_dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">summary_first_dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">has_last_dropout</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_last_dropout&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_last_dropout</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_last_dropout</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">summary_last_dropout</span><span class="p">)</span>

<div class="viewcode-block" id="TFSequenceSummary.call"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.TFSequenceSummary.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">cls_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cls_index</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Too many inputs.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hidden_states&quot;</span><span class="p">)</span>
            <span class="n">cls_index</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cls_index&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;cls_index&quot;</span><span class="p">:</span>
            <span class="n">hidden_shape</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>  <span class="c1"># e.g. [batch, num choices, seq length, hidden dims]</span>
            <span class="k">if</span> <span class="n">cls_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cls_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span>
                    <span class="n">hidden_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>  <span class="c1"># A tensor full of shape [batch] or [batch, num choices] full of sequence length</span>
            <span class="n">cls_shape</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cls_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">cls_index</span> <span class="o">=</span> <span class="n">cls_index</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="c1"># else:</span>
            <span class="c1"># cls_index = cls_index[..., tf.newaxis]</span>
            <span class="c1"># cls_index = cls_index.expand((-1,) * (cls_index.dim()-1) + (hidden_states.size(-1),))</span>
            <span class="c1"># shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">cls_index</span><span class="p">,</span> <span class="n">batch_dims</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="p">)</span>  <span class="c1"># shape of output: (batch, num choices, hidden_size)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;attn&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_first_dropout</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_dropout</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_summary</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_activation</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_last_dropout</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_dropout</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span></div></div>


<div class="viewcode-block" id="shape_list"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.shape_list">[docs]</a><span class="k">def</span> <span class="nf">shape_list</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deal with dynamic shape in tensorflow cleanly.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :obj:`List[int]`: The shape of the tensor as a list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dynamic</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dynamic</span>

    <span class="n">static</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">dynamic</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">s</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">static</span><span class="p">)]</span></div>


<div class="viewcode-block" id="get_initializer"><a class="viewcode-back" href="../../internal/modeling_utils.html#transformers.modeling_tf_utils.get_initializer">[docs]</a><span class="k">def</span> <span class="nf">get_initializer</span><span class="p">(</span><span class="n">initializer_range</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a :obj:`tf.initializers.TruncatedNormal` with the given range.</span>

<span class="sd">    Args:</span>
<span class="sd">        initializer_range (`float`, defaults to 0.02): Standard deviation of the initializer range.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :obj:`tf.initializers.TruncatedNormal`: The truncated normal initializer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">TFWrappedEmbeddings</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    this class wraps a the TFSharedEmbeddingTokens layer into a python &#39;no-keras-layer&#39; class to avoid problem with</span>
<span class="sd">    weight restoring. Also it makes sure that the layer is called from the correct scope to avoid problem with</span>
<span class="sd">    saving/storing the correct weights</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">abs_scope_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span> <span class="o">=</span> <span class="n">layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_abs_scope_name</span> <span class="o">=</span> <span class="n">abs_scope_name</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_abs_scope_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

        <span class="c1"># if an abs scope name is given to the embedding variable, call variable from absolute scope</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_abs_scope_name</span><span class="p">,</span> <span class="n">auxiliary_name_scope</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">abs_scope_name</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">abs_scope_name</span><span class="o">.</span><span class="n">original_name_scope</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_abs_scope_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

        <span class="c1"># if an abs scope name is given to the embedding variable, call variable from absolute scope</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_abs_scope_name</span><span class="p">,</span> <span class="n">auxiliary_name_scope</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">abs_scope_name</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">abs_scope_name</span><span class="o">.</span><span class="n">original_name_scope</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>