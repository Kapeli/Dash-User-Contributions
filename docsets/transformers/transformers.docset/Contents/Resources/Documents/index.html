

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Transformers &mdash; transformers 4.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/huggingface.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/code-snippets.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/hidesidebar.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/js/custom.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick tour" href="quicktour.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> transformers
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using ğŸ¤— Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Training and fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">ğŸ¤— Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/trainer.html">Trainer</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mbart.html">MBart</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlnet.html">XLNet</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/generation_utils.html">Utilities for Generation</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">transformers</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>Transformers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transformers">
<h1>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">Â¶</a></h1>
<p>State-of-the-art Natural Language Processing for Pytorch and TensorFlow 2.0.</p>
<p>ğŸ¤— Transformers (formerly known as <cite>pytorch-transformers</cite> and <cite>pytorch-pretrained-bert</cite>) provides general-purpose
architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural
Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between
TensorFlow 2.0 and PyTorch.</p>
<p>This is the documentation of our repository <a class="reference external" href="https://github.com/huggingface/transformers">transformers</a>.</p>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>High performance on NLU and NLG tasks</p></li>
<li><p>Low barrier to entry for educators and practitioners</p></li>
</ul>
<p>State-of-the-art NLP for everyone:</p>
<ul class="simple">
<li><p>Deep learning researchers</p></li>
<li><p>Hands-on practitioners</p></li>
<li><p>AI/ML/NLP teachers and educators</p></li>
</ul>
<p>Lower compute costs, smaller carbon footprint:</p>
<ul class="simple">
<li><p>Researchers can share trained models instead of always retraining</p></li>
<li><p>Practitioners can reduce compute time and production costs</p></li>
<li><p>8 architectures with over 30 pretrained models, some in more than 100 languages</p></li>
</ul>
<p>Choose the right framework for every part of a modelâ€™s lifetime:</p>
<ul class="simple">
<li><p>Train state-of-the-art models in 3 lines of code</p></li>
<li><p>Deep interoperability between TensorFlow 2.0 and PyTorch models</p></li>
<li><p>Move a single model between TF2.0/PyTorch frameworks at will</p></li>
<li><p>Seamlessly pick the right framework for training, evaluation, production</p></li>
</ul>
<p>Experimental support for Flax with a few models right now, expected to grow in the coming months.</p>
<p><a class="reference external" href="https://huggingface.co/models">All the model checkpoints</a> are seamlessly integrated from the huggingface.co <a class="reference external" href="https://huggingface.co">model
hub</a> where they are uploaded directly by <a class="reference external" href="https://huggingface.co/users">users</a> and
<a class="reference external" href="https://huggingface.co/organizations">organizations</a>.</p>
<p>Current number of checkpoints: <img alt="checkpoints" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&amp;color=brightgreen" /></p>
</div>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">Â¶</a></h2>
<p>The documentation is organized in five parts:</p>
<ul>
<li><p><strong>GET STARTED</strong> contains a quick tour, the installation instructions and some useful information about our philosophy
and a glossary.</p></li>
<li><p><strong>USING ğŸ¤— TRANSFORMERS</strong> contains general tutorials on how to use the library.</p></li>
<li><p><strong>ADVANCED GUIDES</strong> contains more advanced guides that are more specific to a given script or part of the library.</p></li>
<li><p><strong>RESEARCH</strong> focuses on tutorials that have less to do with how to use the library but more about general research in
transformers model</p></li>
<li><p>The three last section contain the documentation of each public class and function, grouped in:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>MAIN CLASSES</strong> for the main classes exposing the important APIs of the library.</p></li>
<li><p><strong>MODELS</strong> for the classes and functions related to each model implemented in the library.</p></li>
<li><p><strong>INTERNAL HELPERS</strong> for the classes and functions we use internally.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The library currently contains PyTorch, Tensorflow and Flax implementations, pretrained model weights, usage scripts
and conversion utilities for the following models:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="model_doc/albert.html"><span class="doc">ALBERT</span></a> (from Google Research and the Toyota Technological Institute at Chicago) released
with the paper <a class="reference external" href="https://arxiv.org/abs/1909.11942">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, Radu Soricut.</p></li>
<li><p><a class="reference internal" href="model_doc/bart.html"><span class="doc">BART</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/pdf/1910.13461.pdf">BART: Denoising Sequence-to-Sequence
Pre-training for Natural Language Generation, Translation, and Comprehension</a> by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/barthez.html"><span class="doc">BARThez</span></a> (from Ã‰cole polytechnique) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.12321">BARThez: a Skilled Pretrained
French Sequence-to-Sequence Model</a> by Moussa Kamal Eddine, Antoine J.-P.
Tixier, Michalis Vazirgiannis.</p></li>
<li><p><a class="reference internal" href="model_doc/bert.html"><span class="doc">BERT</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang,
Kenton Lee and Kristina Toutanova.</p></li>
<li><p><a class="reference internal" href="model_doc/bertgeneration.html"><span class="doc">BERT For Sequence Generation</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1907.12461">Leveraging
Pre-trained Checkpoints for Sequence Generation Tasks</a> by Sascha Rothe, Shashi
Narayan, Aliaksei Severyn.</p></li>
<li><p><a class="reference internal" href="model_doc/blenderbot.html"><span class="doc">Blenderbot</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.13637">Recipes for building an
open-domain chatbot</a> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary
Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</p></li>
<li><p><a class="reference internal" href="model_doc/blenderbot_small.html"><span class="doc">BlenderbotSmall</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.13637">Recipes for building an
open-domain chatbot</a> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary
Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</p></li>
<li><p><a class="reference internal" href="model_doc/camembert.html"><span class="doc">CamemBERT</span></a> (from Inria/Facebook/Sorbonne) released with the paper <a class="reference external" href="https://arxiv.org/abs/1911.03894">CamemBERT: a Tasty
French Language Model</a> by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz
SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.</p></li>
<li><p><a class="reference internal" href="model_doc/ctrl.html"><span class="doc">CTRL</span></a> (from Salesforce) released with the paper <a class="reference external" href="https://arxiv.org/abs/1909.05858">CTRL: A Conditional Transformer Language
Model for Controllable Generation</a> by Nitish Shirish Keskar*, Bryan McCann*,
Lav R. Varshney, Caiming Xiong and Richard Socher.</p></li>
<li><p><a class="reference internal" href="model_doc/deberta.html"><span class="doc">DeBERTa</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.03654">DeBERTa: Decoding-enhanced
BERT with Disentangled Attention</a> by Pengcheng He, Xiaodong Liu, Jianfeng Gao,
Weizhu Chen.</p></li>
<li><p><a class="reference internal" href="model_doc/dialogpt.html"><span class="doc">DialoGPT</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/1911.00536">DialoGPT: Large-Scale
Generative Pre-training for Conversational Response Generation</a> by Yizhe
Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.</p></li>
<li><p><a class="reference internal" href="model_doc/distilbert.html"><span class="doc">DistilBERT</span></a> (from HuggingFace), released together with the paper <a class="reference external" href="https://arxiv.org/abs/1910.01108">DistilBERT, a
distilled version of BERT: smaller, faster, cheaper and lighter</a> by Victor
Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilGPT2</a>, RoBERTa into <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilRoBERTa</a>, Multilingual BERT into
<a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilmBERT</a> and a German
version of DistilBERT.</p></li>
<li><p><a class="reference internal" href="model_doc/dpr.html"><span class="doc">DPR</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.04906">Dense Passage Retrieval for Open-Domain
Question Answering</a> by Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.</p></li>
<li><p><a class="reference internal" href="model_doc/electra.html"><span class="doc">ELECTRA</span></a> (from Google Research/Stanford University) released with the paper <a class="reference external" href="https://arxiv.org/abs/2003.10555">ELECTRA:
Pre-training text encoders as discriminators rather than generators</a> by Kevin
Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.</p></li>
<li><p><a class="reference internal" href="model_doc/flaubert.html"><span class="doc">FlauBERT</span></a> (from CNRS) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.05372">FlauBERT: Unsupervised Language Model
Pre-training for French</a> by Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne,
Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.</p></li>
<li><p><a class="reference internal" href="model_doc/funnel.html"><span class="doc">Funnel Transformer</span></a> (from CMU/Google Brain) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.03236">Funnel-Transformer:
Filtering out Sequential Redundancy for Efficient Language Processing</a> by
Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt.html"><span class="doc">GPT</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://blog.openai.com/language-unsupervised/">Improving Language Understanding by Generative
Pre-Training</a> by Alec Radford, Karthik Narasimhan, Tim Salimans
and Ilya Sutskever.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt2.html"><span class="doc">GPT-2</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://blog.openai.com/better-language-models/">Language Models are Unsupervised Multitask
Learners</a> by Alec Radford*, Jeffrey Wu*, Rewon Child, David
Luan, Dario Amodei** and Ilya Sutskever**.</p></li>
<li><p><a class="reference internal" href="model_doc/layoutlm.html"><span class="doc">LayoutLM</span></a> (from Microsoft Research Asia) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.13318">LayoutLM: Pre-training
of Text and Layout for Document Image Understanding</a> by Yiheng Xu, Minghao Li,
Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/led.html"><span class="doc">LED</span></a> (from AllenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.05150">Longformer: The Long-Document Transformer</a> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</p></li>
<li><p><a class="reference internal" href="model_doc/longformer.html"><span class="doc">Longformer</span></a> (from AllenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.05150">Longformer: The Long-Document
Transformer</a> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</p></li>
<li><p><a class="reference internal" href="model_doc/lxmert.html"><span class="doc">LXMERT</span></a> (from UNC Chapel Hill) released with the paper <a class="reference external" href="https://arxiv.org/abs/1908.07490">LXMERT: Learning Cross-Modality
Encoder Representations from Transformers for Open-Domain Question Answering</a>
by Hao Tan and Mohit Bansal.</p></li>
<li><p><a class="reference internal" href="model_doc/marian.html"><span class="doc">MarianMT</span></a> Machine translation models trained using <a class="reference external" href="http://opus.nlpl.eu/">OPUS</a> data by
JÃ¶rg Tiedemann. The <a class="reference external" href="https://marian-nmt.github.io/">Marian Framework</a> is being developed by the Microsoft
Translator Team.</p></li>
<li><p><a class="reference internal" href="model_doc/mbart.html"><span class="doc">MBart</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.08210">Multilingual Denoising Pre-training for
Neural Machine Translation</a> by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li,
Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/mpnet.html"><span class="doc">MPNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.09297">MPNet: Masked and Permuted
Pre-training for Language Understanding</a> by Kaitao Song, Xu Tan, Tao Qin,
Jianfeng Lu, Tie-Yan Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/mt5.html"><span class="doc">MT5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11934">mT5: A massively multilingual pre-trained
text-to-text transformer</a> by Linting Xue, Noah Constant, Adam Roberts, Mihir
Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</p></li>
<li><p><a class="reference internal" href="model_doc/pegasus.html"><span class="doc">Pegasus</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.08777">PEGASUS: Pre-training with Extracted
Gap-sentences for Abstractive Summarization</a>&gt; by Jingqing Zhang, Yao Zhao,
Mohammad Saleh and Peter J. Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/prophetnet.html"><span class="doc">ProphetNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04063">ProphetNet: Predicting
Future N-gram for Sequence-to-Sequence Pre-training</a> by Yu Yan, Weizhen Qi,
Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/reformer.html"><span class="doc">Reformer</span></a> (from Google Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04451">Reformer: The Efficient
Transformer</a> by Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.</p></li>
<li><p><a class="reference internal" href="model_doc/roberta.html"><span class="doc">RoBERTa</span></a> (from Facebook), released together with the paper a <a class="reference external" href="https://arxiv.org/abs/1907.11692">Robustly Optimized BERT
Pretraining Approach</a> by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar
Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. ultilingual BERT into <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilmBERT</a> and a German version of
DistilBERT.</p></li>
<li><p><a class="reference internal" href="model_doc/squeezebert.html"><span class="doc">SqueezeBert</span></a> released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.11316">SqueezeBERT: What can computer vision teach NLP
about efficient neural networks?</a> by Forrest N. Iandola, Albert E. Shaw, Ravi
Krishna, and Kurt W. Keutzer.</p></li>
<li><p><a class="reference internal" href="model_doc/t5.html"><span class="doc">T5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a
Unified Text-to-Text Transformer</a> by Colin Raffel and Noam Shazeer and Adam
Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/tapas.html"><span class="doc">TAPAS</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.02349">TAPAS: Weakly Supervised Table Parsing via
Pre-training</a> by Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller,
Francesco Piccinno and Julian Martin Eisenschlos.</p></li>
<li><p><a class="reference internal" href="model_doc/transformerxl.html"><span class="doc">Transformer-XL</span></a> (from Google/CMU) released with the paper <a class="reference external" href="https://arxiv.org/abs/1901.02860">Transformer-XL:
Attentive Language Models Beyond a Fixed-Length Context</a> by Zihang Dai*,
Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</p></li>
<li><p><a class="reference internal" href="model_doc/xlm.html"><span class="doc">XLM</span></a> (from Facebook) released together with the paper <a class="reference external" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model
Pretraining</a> by Guillaume Lample and Alexis Conneau.</p></li>
<li><p><a class="reference internal" href="model_doc/xlmprophetnet.html"><span class="doc">XLM-ProphetNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04063">ProphetNet:
Predicting Future N-gram for Sequence-to-Sequence Pre-training</a> by Yu Yan,
Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/xlmroberta.html"><span class="doc">XLM-RoBERTa</span></a> (from Facebook AI), released together with the paper <a class="reference external" href="https://arxiv.org/abs/1911.02116">Unsupervised
Cross-lingual Representation Learning at Scale</a> by Alexis Conneau*, Kartikay
Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke
Zettlemoyer and Veselin Stoyanov.</p></li>
<li><p><a class="reference internal" href="model_doc/xlnet.html"><span class="doc">XLNet</span></a> (from Google/CMU) released with the paper <a class="reference external" href="https://arxiv.org/abs/1906.08237">â€‹XLNet: Generalized Autoregressive
Pretraining for Language Understanding</a> by Zhilin Yang*, Zihang Dai*, Yiming
Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</p></li>
</ol>
<p id="bigtable">The table below represents the current support in the library for each of those models, whether they have a Python
tokenizer (called â€œslowâ€). A â€œfastâ€ tokenizer backed by the ğŸ¤— Tokenizers library, whether they have support in PyTorch,
TensorFlow and/or Flax.</p>
<table class="center-aligned-table docutils align-default">
<colgroup>
<col style="width: 26%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 18%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Tokenizer slow</p></th>
<th class="head"><p>Tokenizer fast</p></th>
<th class="head"><p>PyTorch support</p></th>
<th class="head"><p>TensorFlow support</p></th>
<th class="head"><p>Flax Support</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ALBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>BART</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>BERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
</tr>
<tr class="row-odd"><td><p>Bert Generation</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>Blenderbot</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>BlenderbotSmall</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>CTRL</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>CamemBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>DPR</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>DeBERTa</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>DistilBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>ELECTRA</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>Encoder decoder</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>FairSeq Machine-Translation</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>FlauBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>Funnel Transformer</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>LED</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>LXMERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>LayoutLM</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>Longformer</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>MPNet</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>Marian</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>MobileBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI GPT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI GPT-2</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>Pegasus</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>ProphetNet</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>RAG</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>Reformer</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>RetriBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>RoBERTa</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
</tr>
<tr class="row-odd"><td><p>SqueezeBERT</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>T5</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>TAPAS</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>Transformer-XL</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>XLM</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>XLM-RoBERTa</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>XLMProphetNet</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>XLNet</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>mBART</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
<tr class="row-even"><td><p>mT5</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âœ…</p></td>
<td><p>âŒ</p></td>
</tr>
</tbody>
</table>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quicktour.html">Quick tour</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quicktour.html#getting-started-on-a-task-with-a-pipeline">Getting started on a task with a pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="quicktour.html#under-the-hood-pretrained-models">Under the hood: pretrained models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#installation-with-pip">Installation with pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#installing-from-source">Installing from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#with-conda">With conda</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#caching-models">Caching models</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#do-you-want-to-run-a-transformer-model-on-a-mobile-device">Do you want to run a Transformer model on a mobile device?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="philosophy.html#main-concepts">Main concepts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a><ul>
<li class="toctree-l2"><a class="reference internal" href="glossary.html#general-terms">General terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="glossary.html#model-inputs">Model inputs</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Using ğŸ¤— Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="task_summary.html">Summary of the tasks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#sequence-classification">Sequence Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#extractive-question-answering">Extractive Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#language-modeling">Language Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#summarization">Summarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#translation">Translation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_summary.html">Summary of the models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#autoregressive-models">Autoregressive models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#autoencoding-models">Autoencoding models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#sequence-to-sequence-models">Sequence-to-sequence models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#multimodal-models">Multimodal models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#retrieval-based-models">Retrieval-based models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#more-technical-aspects">More technical aspects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Preprocessing data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#base-use">Base use</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#preprocessing-pairs-of-sentences">Preprocessing pairs of sentences</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation">Everything you always wanted to know about padding and truncation</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#pre-tokenized-inputs">Pre-tokenized inputs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Training and fine-tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="training.html#fine-tuning-in-native-pytorch">Fine-tuning in native PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#fine-tuning-in-native-tensorflow-2">Fine-tuning in native TensorFlow 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#trainer">Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#additional-resources">Additional resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_sharing.html">Model sharing and uploading</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#prepare-your-model-for-uploading">Prepare your model for uploading</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#uploading-your-files">Uploading your files</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#workflow-in-a-colab-notebook">Workflow in a Colab notebook</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_summary.html">Summary of the tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tokenizer_summary.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenizer_summary.html#byte-pair-encoding-bpe">Byte-Pair Encoding (BPE)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multilingual.html">Multi-lingual models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#xlm">XLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#xlm-roberta">XLM-RoBERTa</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#important-note">Important note</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#the-big-table-of-tasks">The Big Table of Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#distributed-training-and-mixed-precision">Distributed training and mixed precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#running-on-tpus">Running on TPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#logging-experiment-tracking">Logging &amp; Experiment tracking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_datasets.html">Fine-tuning with custom datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#sequence-classification-with-imdb-reviews">Sequence Classification with IMDb Reviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#token-classification-with-w-nut-emerging-entities">Token Classification with W-NUT Emerging Entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#question-answering-with-squad-2-0">Question Answering with SQuAD 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">ğŸ¤— Transformers Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks.html#hugging-face-s-notebooks">Hugging Faceâ€™s notebooks ğŸ¤—</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks.html#community-notebooks">Community notebooks:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a><ul>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#albert">ALBERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#openai-gpt">OpenAI GPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#openai-gpt-2">OpenAI GPT-2</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#transformer-xl">Transformer-XL</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#xlnet">XLNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#xlm">XLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="migration.html">Migrating from previous packages</a><ul>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-transformers-v3-x-to-v4-x">Migrating from transformers <code class="docutils literal notranslate"><span class="pre">v3.x</span></code> to <code class="docutils literal notranslate"><span class="pre">v4.x</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-pytorch-transformers-to-transformers">Migrating from pytorch-transformers to ğŸ¤— Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-pytorch-pretrained-bert">Migrating from pytorch-pretrained-bert</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">How to contribute to transformers?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#you-can-contribute-in-so-many-ways">You can contribute in so many ways!</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#submitting-a-new-issue-or-feature-request">Submitting a new issue or feature request</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#start-contributing-pull-requests">Start contributing! (Pull Requests)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="testing.html#how-transformers-are-tested">How transformers are tested</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#running-tests">Running tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#writing-tests">Writing tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#testing-experimental-ci-features">Testing Experimental CI Features</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Exporting transformers models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="serialization.html#onnx-onnxruntime">ONNX / ONNXRuntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="serialization.html#torchscript">TorchScript</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="perplexity.html">Perplexity of fixed-length models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="perplexity.html#calculating-ppl-with-fixed-length-models">Calculating PPL with fixed-length models</a></li>
<li class="toctree-l2"><a class="reference internal" href="perplexity.html#example-calculating-perplexity-with-gpt-2-in-transformers">Example: Calculating perplexity with GPT-2 in ğŸ¤— Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#how-to-benchmark-transformer-models">How to benchmark ğŸ¤— Transformer models</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#benchmark-best-practices">Benchmark best practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#sharing-your-benchmark">Sharing your benchmark</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main_classes/callback.html">Callbacks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#available-callbacks">Available Callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainercallback">TrainerCallback</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainerstate">TrainerState</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainercontrol">TrainerControl</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/configuration.html">Configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/configuration.html#pretrainedconfig">PretrainedConfig</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/logging.html#base-setters">Base setters</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/logging.html#other-functions">Other functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/model.html">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#pretrainedmodel">PreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#moduleutilsmixin">ModuleUtilsMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#tfpretrainedmodel">TFPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#tfmodelutilsmixin">TFModelUtilsMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#flaxpretrainedmodel">FlaxPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#generation">Generation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/optimizer_schedules.html">Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adamw-pytorch">AdamW (PyTorch)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adafactor-pytorch">AdaFactor (PyTorch)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adamweightdecay-tensorflow">AdamWeightDecay (TensorFlow)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#schedules">Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#gradient-strategies">Gradient Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/output.html">Model outputs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#modeloutput">ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutput">BaseModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpooling">BaseModelOutputWithPooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithcrossattentions">BaseModelOutputWithCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpoolingandcrossattentions">BaseModelOutputWithPoolingAndCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpast">BaseModelOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpastandcrossattentions">BaseModelOutputWithPastAndCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqmodeloutput">Seq2SeqModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutput">CausalLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutputwithcrossattentions">CausalLMOutputWithCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutputwithpast">CausalLMOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#maskedlmoutput">MaskedLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqlmoutput">Seq2SeqLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#nextsentencepredictoroutput">NextSentencePredictorOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#sequenceclassifieroutput">SequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqsequenceclassifieroutput">Seq2SeqSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#multiplechoicemodeloutput">MultipleChoiceModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tokenclassifieroutput">TokenClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#questionansweringmodeloutput">QuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqquestionansweringmodeloutput">Seq2SeqQuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutput">TFBaseModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutputwithpooling">TFBaseModelOutputWithPooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutputwithpast">TFBaseModelOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqmodeloutput">TFSeq2SeqModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfcausallmoutput">TFCausalLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfcausallmoutputwithpast">TFCausalLMOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfmaskedlmoutput">TFMaskedLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqlmoutput">TFSeq2SeqLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfnextsentencepredictoroutput">TFNextSentencePredictorOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfsequenceclassifieroutput">TFSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqsequenceclassifieroutput">TFSeq2SeqSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfmultiplechoicemodeloutput">TFMultipleChoiceModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tftokenclassifieroutput">TFTokenClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfquestionansweringmodeloutput">TFQuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqquestionansweringmodeloutput">TFSeq2SeqQuestionAnsweringModelOutput</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/pipelines.html">Pipelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#the-pipeline-abstraction">The pipeline abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#the-task-specific-pipelines">The task specific pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#parent-class-pipeline">Parent class: <code class="xref py py-obj docutils literal notranslate"><span class="pre">Pipeline</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/processors.html">Processors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#id1">Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#glue">GLUE</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#xnli">XNLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#squad">SQuAD</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/tokenizer.html">Tokenizer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#pretrainedtokenizer">PreTrainedTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#pretrainedtokenizerfast">PreTrainedTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#batchencoding">BatchEncoding</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/trainer.html">Trainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#id1">Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#seq2seqtrainer">Seq2SeqTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#tftrainer">TFTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#trainingarguments">TrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#seq2seqtrainingarguments">Seq2SeqTrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#tftrainingarguments">TFTrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#trainer-integrations">Trainer Integrations</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertconfig">AlbertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#alberttokenizer">AlbertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#alberttokenizerfast">AlbertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albert-specific-outputs">Albert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertmodel">AlbertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforpretraining">AlbertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertformaskedlm">AlbertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforsequenceclassification">AlbertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertformultiplechoice">AlbertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertfortokenclassification">AlbertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforquestionanswering">AlbertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertmodel">TFAlbertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforpretraining">TFAlbertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertformaskedlm">TFAlbertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforsequenceclassification">TFAlbertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertformultiplechoice">TFAlbertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertfortokenclassification">TFAlbertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforquestionanswering">TFAlbertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/auto.html">Auto Classes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#autoconfig">AutoConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#autotokenizer">AutoTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodel">AutoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforpretraining">AutoModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforcausallm">AutoModelForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelformaskedlm">AutoModelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforseq2seqlm">AutoModelForSeq2SeqLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforsequenceclassification">AutoModelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelformultiplechoice">AutoModelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfornextsentenceprediction">AutoModelForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfortokenclassification">AutoModelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforquestionanswering">AutoModelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfortablequestionanswering">AutoModelForTableQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodel">TFAutoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforpretraining">TFAutoModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforcausallm">TFAutoModelForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelformaskedlm">TFAutoModelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforseq2seqlm">TFAutoModelForSeq2SeqLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforsequenceclassification">TFAutoModelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelformultiplechoice">TFAutoModelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelfortokenclassification">TFAutoModelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforquestionanswering">TFAutoModelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodel">FlaxAutoModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bart.html">BART</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#mask-filling">Mask Filling</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartconfig">BartConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#barttokenizer">BartTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#barttokenizerfast">BartTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartmodel">BartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforconditionalgeneration">BartForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforsequenceclassification">BartForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforquestionanswering">BartForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#tfbartmodel">TFBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#tfbartforconditionalgeneration">TFBartForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/barthez.html">BARThez</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#bartheztokenizer">BarthezTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#bartheztokenizerfast">BarthezTokenizerFast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertconfig">BertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#berttokenizer">BertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#berttokenizerfast">BertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bert-specific-outputs">Bert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertmodel">BertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforpretraining">BertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertmodellmheadmodel">BertModelLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertformaskedlm">BertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertfornextsentenceprediction">BertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforsequenceclassification">BertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertformultiplechoice">BertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertfortokenclassification">BertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforquestionanswering">BertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertmodel">TFBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforpretraining">TFBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertmodellmheadmodel">TFBertModelLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertformaskedlm">TFBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertfornextsentenceprediction">TFBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforsequenceclassification">TFBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertformultiplechoice">TFBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertfortokenclassification">TFBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforquestionanswering">TFBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertmodel">FlaxBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertformaskedlm">FlaxBertForMaskedLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertweet.html">Bertweet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertweet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertweet.html#bertweettokenizer">BertweetTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertgeneration.html">BertGeneration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationconfig">BertGenerationConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationtokenizer">BertGenerationTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationencoder">BertGenerationEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationdecoder">BertGenerationDecoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot.html">Blenderbot</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotconfig">BlenderbotConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbottokenizer">BlenderbotTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotmodel">BlenderbotModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotforconditionalgeneration">BlenderbotForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#tfblenderbotmodel">TFBlenderbotModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#tfblenderbotforconditionalgeneration">TFBlenderbotForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot_small.html">Blenderbot Small</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallconfig">BlenderbotSmallConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmalltokenizer">BlenderbotSmallTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallmodel">BlenderbotSmallModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallforconditionalgeneration">BlenderbotSmallForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#tfblenderbotsmallmodel">TFBlenderbotSmallModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#tfblenderbotsmallforconditionalgeneration">TFBlenderbotSmallForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/camembert.html">CamemBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertconfig">CamembertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camemberttokenizer">CamembertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camemberttokenizerfast">CamembertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertmodel">CamembertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforcausallm">CamembertForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertformaskedlm">CamembertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforsequenceclassification">CamembertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertformultiplechoice">CamembertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertfortokenclassification">CamembertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforquestionanswering">CamembertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertmodel">TFCamembertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertformaskedlm">TFCamembertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertforsequenceclassification">TFCamembertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertformultiplechoice">TFCamembertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertfortokenclassification">TFCamembertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertforquestionanswering">TFCamembertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ctrl.html">CTRL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlconfig">CTRLConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrltokenizer">CTRLTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlmodel">CTRLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrllmheadmodel">CTRLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlforsequenceclassification">CTRLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrlmodel">TFCTRLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrllmheadmodel">TFCTRLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrlforsequenceclassification">TFCTRLForSequenceClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta.html">DeBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaconfig">DebertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertatokenizer">DebertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertamodel">DebertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertapretrainedmodel">DebertaPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaforsequenceclassification">DebertaForSequenceClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dialogpt.html">DialoGPT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dialogpt.html#overview">Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/distilbert.html">DistilBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertconfig">DistilBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilberttokenizer">DistilBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilberttokenizerfast">DistilBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertmodel">DistilBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertformaskedlm">DistilBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertforsequenceclassification">DistilBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertformultiplechoice">DistilBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertfortokenclassification">DistilBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertforquestionanswering">DistilBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertmodel">TFDistilBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertformaskedlm">TFDistilBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertforsequenceclassification">TFDistilBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertformultiplechoice">TFDistilBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertfortokenclassification">TFDistilBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertforquestionanswering">TFDistilBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dpr.html">DPR</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprconfig">DPRConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencodertokenizer">DPRContextEncoderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencodertokenizerfast">DPRContextEncoderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencodertokenizer">DPRQuestionEncoderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencodertokenizerfast">DPRQuestionEncoderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreadertokenizer">DPRReaderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreadertokenizerfast">DPRReaderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dpr-specific-outputs">DPR specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencoder">DPRContextEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencoder">DPRQuestionEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreader">DPRReader</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprcontextencoder">TFDPRContextEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprquestionencoder">TFDPRQuestionEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprreader">TFDPRReader</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/electra.html">ELECTRA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraconfig">ElectraConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electratokenizer">ElectraTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electratokenizerfast">ElectraTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electra-specific-outputs">Electra specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electramodel">ElectraModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforpretraining">ElectraForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraformaskedlm">ElectraForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforsequenceclassification">ElectraForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraformultiplechoice">ElectraForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electrafortokenclassification">ElectraForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforquestionanswering">ElectraForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectramodel">TFElectraModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforpretraining">TFElectraForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraformaskedlm">TFElectraForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforsequenceclassification">TFElectraForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraformultiplechoice">TFElectraForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectrafortokenclassification">TFElectraForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforquestionanswering">TFElectraForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/encoderdecoder.html">Encoder Decoder Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/encoderdecoder.html#encoderdecoderconfig">EncoderDecoderConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/encoderdecoder.html#encoderdecodermodel">EncoderDecoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/flaubert.html">FlauBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertconfig">FlaubertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flauberttokenizer">FlaubertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertmodel">FlaubertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertwithlmheadmodel">FlaubertWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforsequenceclassification">FlaubertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertformultiplechoice">FlaubertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertfortokenclassification">FlaubertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforquestionansweringsimple">FlaubertForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforquestionanswering">FlaubertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertmodel">TFFlaubertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertwithlmheadmodel">TFFlaubertWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertforsequenceclassification">TFFlaubertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertformultiplechoice">TFFlaubertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertfortokenclassification">TFFlaubertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertforquestionansweringsimple">TFFlaubertForQuestionAnsweringSimple</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/fsmt.html">FSMT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtconfig">FSMTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmttokenizer">FSMTTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtmodel">FSMTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtforconditionalgeneration">FSMTForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/funnel.html">Funnel Transformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelconfig">FunnelConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funneltokenizer">FunnelTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funneltokenizerfast">FunnelTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnel-specific-outputs">Funnel specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelbasemodel">FunnelBaseModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelmodel">FunnelModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelmodelforpretraining">FunnelModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelformaskedlm">FunnelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelforsequenceclassification">FunnelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelformultiplechoice">FunnelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelfortokenclassification">FunnelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelforquestionanswering">FunnelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelbasemodel">TFFunnelBaseModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelmodel">TFFunnelModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelmodelforpretraining">TFFunnelModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelformaskedlm">TFFunnelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelforsequenceclassification">TFFunnelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelformultiplechoice">TFFunnelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelfortokenclassification">TFFunnelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelforquestionanswering">TFFunnelForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/herbert.html">herBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#herberttokenizer">HerbertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#herberttokenizerfast">HerbertTokenizerFast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/layoutlm.html">LayoutLM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmconfig">LayoutLMConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmtokenizer">LayoutLMTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmtokenizerfast">LayoutLMTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmmodel">LayoutLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmformaskedlm">LayoutLMForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmforsequenceclassification">LayoutLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmfortokenclassification">LayoutLMForTokenClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/led.html">LED</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledconfig">LEDConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledtokenizer">LEDTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledtokenizerfast">LEDTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#led-specific-outputs">LED specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledmodel">LEDModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforconditionalgeneration">LEDForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforsequenceclassification">LEDForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforquestionanswering">LEDForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#tfledmodel">TFLEDModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#tfledforconditionalgeneration">TFLEDForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/longformer.html">Longformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformer-self-attention">Longformer Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerconfig">LongformerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformertokenizer">LongformerTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformertokenizerfast">LongformerTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformer-specific-outputs">Longformer specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformermodel">LongformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerformaskedlm">LongformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerforsequenceclassification">LongformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerformultiplechoice">LongformerForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerfortokenclassification">LongformerForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerforquestionanswering">LongformerForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformermodel">TFLongformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerformaskedlm">TFLongformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerforquestionanswering">TFLongformerForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerforsequenceclassification">TFLongformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerfortokenclassification">TFLongformerForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerformultiplechoice">TFLongformerForMultipleChoice</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/lxmert.html">LXMERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertconfig">LxmertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmerttokenizer">LxmertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmerttokenizerfast">LxmertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmert-specific-outputs">Lxmert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertmodel">LxmertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertforpretraining">LxmertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertforquestionanswering">LxmertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#tflxmertmodel">TFLxmertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#tflxmertforpretraining">TFLxmertForPreTraining</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/marian.html">MarianMT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#naming">Naming</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#examples">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#multilingual-models">Multilingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#old-style-multi-lingual-models">Old Style Multi-Lingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianconfig">MarianConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#mariantokenizer">MarianTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianmodel">MarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianmtmodel">MarianMTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#tfmarianmodel">TFMarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#tfmarianmtmodel">TFMarianMTModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mbart.html">MBart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartconfig">MBartConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbarttokenizer">MBartTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbarttokenizerfast">MBartTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartmodel">MBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforconditionalgeneration">MBartForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforquestionanswering">MBartForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforsequenceclassification">MBartForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#tfmbartmodel">TFMBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#tfmbartforconditionalgeneration">TFMBartForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mobilebert.html">MobileBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertconfig">MobileBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobileberttokenizer">MobileBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobileberttokenizerfast">MobileBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebert-specific-outputs">MobileBert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertmodel">MobileBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforpretraining">MobileBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertformaskedlm">MobileBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertfornextsentenceprediction">MobileBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforsequenceclassification">MobileBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertformultiplechoice">MobileBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertfortokenclassification">MobileBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforquestionanswering">MobileBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertmodel">TFMobileBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforpretraining">TFMobileBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertformaskedlm">TFMobileBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertfornextsentenceprediction">TFMobileBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforsequenceclassification">TFMobileBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertformultiplechoice">TFMobileBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertfortokenclassification">TFMobileBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforquestionanswering">TFMobileBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mpnet.html">MPNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetconfig">MPNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnettokenizer">MPNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnettokenizerfast">MPNetTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetmodel">MPNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetformaskedlm">MPNetForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetforsequenceclassification">MPNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetformultiplechoice">MPNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetfortokenclassification">MPNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetforquestionanswering">MPNetForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetmodel">TFMPNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetformaskedlm">TFMPNetForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetforsequenceclassification">TFMPNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetformultiplechoice">TFMPNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetfortokenclassification">TFMPNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetforquestionanswering">TFMPNetForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5config">MT5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5tokenizer">MT5Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5tokenizerfast">MT5TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5model">MT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5forconditionalgeneration">MT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5encodermodel">MT5EncoderModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5model">TFMT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5forconditionalgeneration">TFMT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5encodermodel">TFMT5EncoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt.html">OpenAI GPT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptconfig">OpenAIGPTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigpttokenizer">OpenAIGPTTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigpttokenizerfast">OpenAIGPTTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openai-specific-outputs">OpenAI specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptmodel">OpenAIGPTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptlmheadmodel">OpenAIGPTLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptdoubleheadsmodel">OpenAIGPTDoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptforsequenceclassification">OpenAIGPTForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptmodel">TFOpenAIGPTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptlmheadmodel">TFOpenAIGPTLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptdoubleheadsmodel">TFOpenAIGPTDoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptforsequenceclassification">TFOpenAIGPTForSequenceClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2config">GPT2Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2tokenizer">GPT2Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2tokenizerfast">GPT2TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2-specific-outputs">GPT2 specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2model">GPT2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2lmheadmodel">GPT2LMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2doubleheadsmodel">GPT2DoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2forsequenceclassification">GPT2ForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2model">TFGPT2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2lmheadmodel">TFGPT2LMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2doubleheadsmodel">TFGPT2DoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2forsequenceclassification">TFGPT2ForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfsequenceclassifieroutputwithpast">TFSequenceClassifierOutputWithPast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/pegasus.html">Pegasus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#checkpoints">Checkpoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#usage-example">Usage Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusconfig">PegasusConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasustokenizer">PegasusTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasustokenizerfast">PegasusTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusmodel">PegasusModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusforconditionalgeneration">PegasusForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#tfpegasusmodel">TFPegasusModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#tfpegasusforconditionalgeneration">TFPegasusForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/phobert.html">PhoBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/phobert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/phobert.html#phoberttokenizer">PhobertTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/prophetnet.html">ProphetNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetconfig">ProphetNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnettokenizer">ProphetNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnet-specific-outputs">ProphetNet specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetmodel">ProphetNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetencoder">ProphetNetEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetdecoder">ProphetNetDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetforconditionalgeneration">ProphetNetForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetforcausallm">ProphetNetForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/rag.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragconfig">RagConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragtokenizer">RagTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#rag-specific-outputs">Rag specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragretriever">RagRetriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragmodel">RagModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragsequenceforgeneration">RagSequenceForGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragtokenforgeneration">RagTokenForGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/reformer.html">Reformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#axial-positional-encodings">Axial Positional Encodings</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#lsh-self-attention">LSH Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#local-self-attention">Local Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerconfig">ReformerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformertokenizer">ReformerTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformertokenizerfast">ReformerTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformermodel">ReformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformermodelwithlmhead">ReformerModelWithLMHead</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerformaskedlm">ReformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerforsequenceclassification">ReformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerforquestionanswering">ReformerForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/retribert.html">RetriBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retribertconfig">RetriBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retriberttokenizer">RetriBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retriberttokenizerfast">RetriBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retribertmodel">RetriBertModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaconfig">RobertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertatokenizer">RobertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertatokenizerfast">RobertaTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertamodel">RobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforcausallm">RobertaForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaformaskedlm">RobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforsequenceclassification">RobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaformultiplechoice">RobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertafortokenclassification">RobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforquestionanswering">RobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertamodel">TFRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaformaskedlm">TFRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaforsequenceclassification">TFRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaformultiplechoice">TFRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertafortokenclassification">TFRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaforquestionanswering">TFRobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertamodel">FlaxRobertaModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/squeezebert.html">SqueezeBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertconfig">SqueezeBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezeberttokenizer">SqueezeBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezeberttokenizerfast">SqueezeBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertmodel">SqueezeBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertformaskedlm">SqueezeBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertforsequenceclassification">SqueezeBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertformultiplechoice">SqueezeBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertfortokenclassification">SqueezeBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertforquestionanswering">SqueezeBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5config">T5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5tokenizer">T5Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5tokenizerfast">T5TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5model">T5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5forconditionalgeneration">T5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5encodermodel">T5EncoderModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5model">TFT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5forconditionalgeneration">TFT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5encodermodel">TFT5EncoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/tapas.html">TAPAS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#usage-fine-tuning">Usage: fine-tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#usage-inference">Usage: inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapas-specific-outputs">Tapas specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasconfig">TapasConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapastokenizer">TapasTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasmodel">TapasModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasformaskedlm">TapasForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasforsequenceclassification">TapasForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasforquestionanswering">TapasForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/transformerxl.html">Transformer XL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlconfig">TransfoXLConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxltokenizer">TransfoXLTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxl-specific-outputs">TransfoXL specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlmodel">TransfoXLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxllmheadmodel">TransfoXLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlforsequenceclassification">TransfoXLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxlmodel">TFTransfoXLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxllmheadmodel">TFTransfoXLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxlforsequenceclassification">TFTransfoXLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#internal-layers">Internal Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlm.html">XLM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmconfig">XLMConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmtokenizer">XLMTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlm-specific-outputs">XLM specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmmodel">XLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmwithlmheadmodel">XLMWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforsequenceclassification">XLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmformultiplechoice">XLMForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmfortokenclassification">XLMForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforquestionansweringsimple">XLMForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforquestionanswering">XLMForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmmodel">TFXLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmwithlmheadmodel">TFXLMWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmforsequenceclassification">TFXLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmformultiplechoice">TFXLMForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmfortokenclassification">TFXLMForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmforquestionansweringsimple">TFXLMForQuestionAnsweringSimple</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmprophetnet.html">XLM-ProphetNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetconfig">XLMProphetNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnettokenizer">XLMProphetNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetmodel">XLMProphetNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetencoder">XLMProphetNetEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetdecoder">XLMProphetNetDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetforconditionalgeneration">XLMProphetNetForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetforcausallm">XLMProphetNetForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmroberta.html">XLM-RoBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaconfig">XLMRobertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertatokenizer">XLMRobertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertatokenizerfast">XLMRobertaTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertamodel">XLMRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforcausallm">XLMRobertaForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaformaskedlm">XLMRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforsequenceclassification">XLMRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaformultiplechoice">XLMRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertafortokenclassification">XLMRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforquestionanswering">XLMRobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertamodel">TFXLMRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaformaskedlm">TFXLMRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaforsequenceclassification">TFXLMRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaformultiplechoice">TFXLMRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertafortokenclassification">TFXLMRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaforquestionanswering">TFXLMRobertaForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlnet.html">XLNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetconfig">XLNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnettokenizer">XLNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnettokenizerfast">XLNetTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnet-specific-outputs">XLNet specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetmodel">XLNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetlmheadmodel">XLNetLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforsequenceclassification">XLNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetformultiplechoice">XLNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetfortokenclassification">XLNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforquestionansweringsimple">XLNetForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforquestionanswering">XLNetForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetmodel">TFXLNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetlmheadmodel">TFXLNetLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetforsequenceclassification">TFXLNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tflnetformultiplechoice">TFLNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetfortokenclassification">TFXLNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetforquestionansweringsimple">TFXLNetForQuestionAnsweringSimple</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="internal/modeling_utils.html">Custom Layers and Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#pytorch-custom-modules">Pytorch custom modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#pytorch-helper-functions">PyTorch Helper Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-custom-layers">TensorFlow custom layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-loss-functions">TensorFlow loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-helper-functions">TensorFlow Helper Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/pipelines_utils.html">Utilities for pipelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#argument-handling">Argument handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#data-format">Data format</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#utilities">Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/tokenization_utils.html">Utilities for Tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#pretrainedtokenizerbase">PreTrainedTokenizerBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#specialtokensmixin">SpecialTokensMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#enums-and-namedtuples">Enums and namedtuples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/trainer_utils.html">Utilities for Trainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#utilities">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#callbacks-internals">Callbacks internals</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#distributed-evaluation">Distributed Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#id1">Distributed Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/generation_utils.html">Utilities for Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#generate-outputs">Generate Outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#logitsprocessor">LogitsProcessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#beamsearch">BeamSearch</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#utilities">Utilities</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="quicktour.html" class="btn btn-neutral float-right" title="Quick tour" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>